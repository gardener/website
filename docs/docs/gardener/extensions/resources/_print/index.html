<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=https://gardener.cloud/docs/gardener/extensions/resources/><link rel=alternate type=application/rss+xml href=https://gardener.cloud/docs/gardener/extensions/resources/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Resources | Gardener</title>
<meta name=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:url" content="https://gardener.cloud/docs/gardener/extensions/resources/"><meta property="og:site_name" content="Gardener"><meta property="og:title" content="Resources"><meta property="og:description" content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:locale" content="en_US"><meta property="og:type" content="website"><meta property="og:image" content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta itemprop=name content="Resources"><meta itemprop=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta itemprop=image content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta name=twitter:title content="Resources"><meta name=twitter:description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><link rel=preload href=/scss/main.min.52d93bcd446cd63373e35bf3f68b78c63f08370d066ccb303bdd0e25f237661c.css as=style integrity="sha256-Utk7zURs1jNz41vz9ot4xj8INw0GbMswO90OJfI3Zhw=" crossorigin=anonymous><link href=/scss/main.min.52d93bcd446cd63373e35bf3f68b78c63f08370d066ccb303bdd0e25f237661c.css rel=stylesheet integrity="sha256-Utk7zURs1jNz41vz9ot4xj8INw0GbMswO90OJfI3Zhw=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><style>.nav-link:hover{text-decoration:none}.ml-md-auto{margin-left:auto!important}.td-search__icon{color:#fff!important}.td-search__input.form-control::placeholder{color:#fff;border:1px;border-radius:20px}.td-search__input.form-control{border:1px;border-radius:20px}.td-search__input{max-width:90%}.td-search:not(:focus-within){color:#fff!important}</style><a class=navbar-brand href=/><span class=navbar-logo><svg width="90" height="90" viewBox="0 0 90 90" xmlns:xlink="http://www.w3.org/1999/xlink"><title>logo</title><desc>Created with Sketch.</desc><defs><path d="M41.8864954.994901575c.996545099999999-.479910833 2.6164002-.477918931 3.6088091.0L76.8159138 16.0781121C77.8124589 16.5580229 78.8208647 17.8257185 79.0659694 18.8995926l7.7355517 33.8916663C87.0476474 53.8696088 86.6852538 55.4484075 85.9984855 56.3095876L64.3239514 83.4885938C63.6343208 84.3533632 62.1740175 85.0543973 61.0725268 85.0543973H26.3092731c-1.1060816.0-2.5646564-.704623400000003-3.2514246-1.5658035L1.38331434 56.3095876C.693683723 55.4448182.335174016 53.865133.580278769 52.7912589L8.31583044 18.8995926C8.56195675 17.8212428 9.57347722 16.556031 10.5658861 16.0781121L41.8864954.994901575z" id="path-1"/><linearGradient x1="12.7542673%" y1="-18.6617048%" x2="88.2666158%" y2="84.6075483%" id="linearGradient-3"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="50%" y1="4.93673768%" x2="148.756007%" y2="175.514523%" id="linearGradient-4"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="19.1574381%" y1="-9.04800713%" x2="82.2203149%" y2="77.9084293%" id="linearGradient-5"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="57.4403751%" y1="26.3148481%" x2="137.966711%" y2="158.080556%" id="linearGradient-6"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="logo"><g id="Rectangle-2" transform="translate(1.000000, 0.000000)"><mask id="mask-2" fill="#fff"><use xlink:href="#path-1"/></mask><use id="Mask" fill="#009f76" xlink:href="#path-1"/><polygon fill="#000" opacity=".289628623" mask="url(#mask-2)" points="-17.6484375 54.5224609 30.8242188 25.0791016 63.4726562 58.5 24.7324219 92.6689453"/></g><path d="M56.8508631 39.260019C56.4193519 40.443987 55.6088085 41.581593 54.6736295 42.1938694l-8.0738997 5.2861089c-1.3854671.907087099999998-3.6247515.9116711-5.0172201.0L33.50861 42.1938694C32.123143 41.2867823 31 39.206345 31 37.545932V26.4150304c0-.725313.2131118-1.5301454.569268099999999-2.2825772L56.8508631 39.260019z" id="Combined-Shape" fill="url(#linearGradient-3)" transform="translate(43.925432, 36.147233) scale(-1, 1) translate(-43.925432, -36.147233)"/><path d="M56.0774672 25.1412464C56.4306829 25.8903325 56.6425556 26.6907345 56.6425556 27.4119019V38.5428034c0 1.6598979-1.1161415 3.73626640000001-2.50861 4.6479374l-8.0738997 5.286109c-1.3854671.907087000000004-3.6247516.911671000000005-5.0172201.0L32.9689261 43.1907408C32.2918101 42.7474223 31.6773514 42.0238435 31.2260376 41.206007L56.0774672 25.1412464z" id="Combined-Shape" fill="url(#linearGradient-4)" transform="translate(43.821278, 37.246598) scale(-1, 1) translate(-43.821278, -37.246598)"/><path d="M65.0702134 57.1846889C64.5985426 58.2007851 63.8367404 59.1236871 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.1597438 58.7930183 24 56.7816693 24 55.1323495V37.1145303C24 36.3487436 24.249712 35.5060005 24.6599102 34.7400631L65.0702134 57.1846889z" id="Combined-Shape" fill="url(#linearGradient-5)"/><path d="M65.0189476 34.954538C65.3636909 35.6617313 65.5692194 36.42021 65.5692194 37.1145303V55.1323495C65.5692194 56.7842831 64.4072119 58.7943252 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.9237304 59.2341061 25.3159155 58.5918431 24.8568495 57.8487596L65.0189476 34.954538z" id="Combined-Shape" fill="url(#linearGradient-6)"/></g></g></svg></span><span class=text-capitalize>Gardener</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://demo.gardener.cloud target=_blank><span>Demo</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/adopter><span>Adopters</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><div class=dropdown><a href=/docs class=nav-link>Documentation</a><div class=dropdown-content><a class=taxonomy-term href=/docs>Users</a>
<a class=taxonomy-term href=/docs>Operators</a>
<a class=taxonomy-term href=/docs>Developers</a>
<a class=taxonomy-term href=/docs>All</a></div></div></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog><span>Blogs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community><span>Community</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.17aa0a4d6e70462cde1acbae47ea4b3a.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/gardener/extensions/resources/>Return to the regular view of this page</a>.</p></div><h1 class=title>Resources</h1><div class=content></div></div><div class=td-content><h1 id=pg-726a459affee2db83e184092421ca712>1 - BackupBucket</h1><h1 id=contract-backupbucket-resource>Contract: <code>BackupBucket</code> Resource</h1><p>The Gardener project features a sub-project called <a href=https://github.com/gardener/etcd-backup-restore>etcd-backup-restore</a> to take periodic backups of etcd backing Shoot clusters. It demands the bucket (or its equivalent in different object store providers) to be created and configured externally with appropriate credentials. The <code>BackupBucket</code> resource takes this responsibility in Gardener.</p><p>Before introducing the <code>BackupBucket</code> extension resource, Gardener was using Terraform in order to create and manage these provider-specific resources (e.g., see <a href=https://github.com/gardener/gardener/tree/0.27.0/charts/seed-terraformer/charts/aws-backup>AWS Backup</a>).
Now, Gardener commissions an external, provider-specific controller to take over this task. You can also refer to <a href=https://github.com/gardener/gardener/blob/master/docs/proposals/02-backupinfra.md>backupInfra proposal documentation</a> to get an idea about how the transition was done and understand the resource in a broader scope.</p><h2 id=what-is-the-scope-of-a-bucket>What Is the Scope of a Bucket?</h2><p>A bucket will be provisioned per <code>Seed</code>. So, a backup of every <code>Shoot</code> created on that <code>Seed</code> will be stored under a different shoot specific prefix under the bucket.
For the backup of the <code>Shoot</code> rescheduled on different <code>Seed</code>, it will continue to use the same bucket.</p><h2 id=what-is-the-lifespan-of-a-backupbucket>What Is the Lifespan of a <code>BackupBucket</code>?</h2><p>The bucket associated with <code>BackupBucket</code> will be created at the creation of the <code>Seed</code>. And as per current implementation, it will also be deleted on deletion of the <code>Seed</code>, if there isn&rsquo;t any <code>BackupEntry</code> resource associated with it.</p><p>In the future, we plan to introduce a schedule for <code>BackupBucket</code> - the deletion logic for the <code>BackupBucket</code> resource, which will reschedule it on different available <code>Seed</code>s on deletion or failure of a health check for the currently associated <code>seed</code>. In that case, the <code>BackupBucket</code> will be deleted only if there isn&rsquo;t any schedulable <code>Seed</code> available and there isn&rsquo;t any associated <code>BackupEntry</code> resource.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What Needs to Be Implemented to Support a New Infrastructure Provider?</h2><p>As part of the seed flow, Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: BackupBucket
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: foo
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: azure
</span></span><span style=display:flex><span>  providerConfig:
</span></span><span style=display:flex><span>    &lt;some-optional-provider-specific-backupbucket-configuration&gt;
</span></span><span style=display:flex><span>  region: eu-west-1
</span></span><span style=display:flex><span>  secretRef:
</span></span><span style=display:flex><span>    name: backupprovider
</span></span><span style=display:flex><span>    namespace: shoot--foo--bar
</span></span></code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used to create the needed resources. This provider secret will be configured by the Gardener operator in the <code>Seed</code> resource and propagated over there by the seed controller.</p><p>After your controller has created the required bucket, if required, it generates the secret to access the objects in the bucket and put a reference to it in <code>status</code>. This secret is supposed to be used by Gardener, or eventually a <code>BackupEntry</code> resource and etcd-backup-restore component, to backup the etcd.</p><p>In order to support a new infrastructure provider, you need to write a controller that watches all <code>BackupBucket</code>s with <code>.spec.type=&lt;my-provider-name></code>. You can take a look at the below referenced example implementation for the Azure provider.</p><h2 id=references-and-additional-resources>References and Additional Resources</h2><ul><li><a href=/docs/gardener/api-reference/extensions/#backupbucket><code>BackupBucket</code> API Reference</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-azure/tree/master/pkg/controller/backupbucket>Exemplary Implementation for the Azure Provider</a></li><li><a href=/docs/gardener/extensions/resources/backupentry/><code>BackupEntry</code> Resource Documentation</a></li><li><a href=https://github.com/gardener/gardener/blob/master/docs/proposals/02-backupinfra.md>Shared Bucket Proposal</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-251f8a8469da660999f31cc790f740f9>2 - BackupEntry</h1><h1 id=contract-backupentry-resource>Contract: <code>BackupEntry</code> Resource</h1><p>The Gardener project features a sub-project called <a href=https://github.com/gardener/etcd-backup-restore>etcd-backup-restore</a> to take periodic backups of etcd backing Shoot clusters. It demands the bucket (or its equivalent in different object store providers) access credentials to be created and configured externally with appropriate credentials. The <code>BackupEntry</code> resource takes this responsibility in Gardener to provide this information by creating a secret specific to the component.</p><p>That being said, the core motivation for introducing this resource was to support retention of backups post deletion of <code>Shoot</code>. The etcd-backup-restore components take responsibility of garbage collecting old backups out of the defined period. Once a shoot is deleted, we need to persist the backups for few days. Hence, Gardener uses the <code>BackupEntry</code> resource for this housekeeping work post deletion of a <code>Shoot</code>. The <code>BackupEntry</code> resource is responsible for shoot specific prefix under referred bucket.</p><p>Before introducing the <code>BackupEntry</code> extension resource, Gardener was using Terraform in order to create and manage these provider-specific resources (e.g., see <a href=https://github.com/gardener/gardener/tree/0.27.0/charts/seed-terraformer/charts/aws-backup>AWS Backup</a>).
Now, Gardener commissions an external, provider-specific controller to take over this task. You can also refer to <a href=https://github.com/gardener/gardener/blob/master/docs/proposals/02-backupinfra.md>backupInfra proposal documentation</a> to get idea about how the transition was done and understand the resource in broader scope.</p><h2 id=what-is-the-lifespan-of-a-backupentry>What Is the Lifespan of a <code>BackupEntry</code>?</h2><p>The bucket associated with <code>BackupEntry</code> will be created by using a <code>BackupBucket</code> resource. The <code>BackupEntry</code> resource will be created as a part of the <code>Shoot</code> creation. But resources might continue to exist post deletion of a <code>Shoot</code> (see <a href=https://github.com/gardener/gardener/blob/master/docs/extensions/concepts/gardenlet.md#backupentry-controller>gardenlet</a> for more details).</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What Needs to be Implemented to Support a New Infrastructure Provider?</h2><p>As part of the shoot flow, Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: BackupEntry
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: azure
</span></span><span style=display:flex><span>  providerConfig:
</span></span><span style=display:flex><span>    &lt;some-optional-provider-specific-backup-bucket-configuration&gt;
</span></span><span style=display:flex><span>  backupBucketProviderStatus:
</span></span><span style=display:flex><span>    &lt;some-optional-provider-specific-backup-bucket-status&gt;
</span></span><span style=display:flex><span>  region: eu-west-1
</span></span><span style=display:flex><span>  bucketName: foo
</span></span><span style=display:flex><span>  secretRef:
</span></span><span style=display:flex><span>    name: backupprovider
</span></span><span style=display:flex><span>    namespace: shoot--foo--bar
</span></span></code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used to create the needed resources. This provider secret will be propagated from the <code>BackupBucket</code> resource by the shoot controller.</p><p>Your controller is supposed to create the <code>etcd-backup</code> secret in the control plane namespace of a shoot. This secret is supposed to be used by Gardener or eventually by the etcd-backup-restore component to backup the etcd. The controller implementation should clean up the objects created under the shoot specific prefix in the bucket equivalent to the name of the <code>BackupEntry</code> resource.</p><p>In order to support a new infrastructure provider, you need to write a controller that watches all the <code>BackupBucket</code>s with <code>.spec.type=&lt;my-provider-name></code>. You can take a look at the below referenced example implementation for the Azure provider.</p><h2 id=references-and-additional-resources>References and Additional Resources</h2><ul><li><a href=/docs/gardener/api-reference/extensions/#backupbucket><code>BackupEntry</code> API Reference</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-azure/tree/master/pkg/controller/backupentry>Exemplary Implementation for the Azure Provider</a></li><li><a href=/docs/gardener/extensions/resources/backupbucket/><code>BackupBucket</code> Resource Documentation</a></li><li><a href=https://github.com/gardener/gardener/blob/master/docs/proposals/02-backupinfra.md>Shared Bucket Proposal</a></li><li><a href=https://github.com/gardener/gardener/blob/master/pkg/controllermanager/apis/config/types.go#L101-%23L107>Gardener-controller-manager-component-config API Specification</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-9568268ecec1c9449d169970ad590f31>3 - Bastion</h1><h1 id=contract-bastion-resource>Contract: <code>Bastion</code> Resource</h1><p>The Gardener project allows users to connect to Shoot worker nodes via SSH. As nodes are usually firewalled and not directly accessible from the public internet, <a href=https://github.com/gardener/gardener/blob/master/docs/proposals/15-manage-bastions-and-ssh-key-pair-rotation.md>GEP-15</a> introduced the concept of &ldquo;Bastions&rdquo;. A bastion is a dedicated server that only serves to allow SSH ingress to the worker nodes.</p><p><code>Bastion</code> resources contain the user&rsquo;s public SSH key and IP address, in order to provision the server accordingly: The public key is put onto the Bastion and SSH ingress is only authorized for the given IP address (in fact, it&rsquo;s not a single IP address, but a set of IP ranges, however for most purposes a single IP is be used).</p><h2 id=what-is-the-lifespan-of-a-bastion>What Is the Lifespan of a <code>Bastion</code>?</h2><p>Once a <code>Bastion</code> has been created in the garden, it will be replicated to the appropriate seed cluster, where a controller then reconciles a server and firewall rules etc., on the cloud provider used by the target Shoot. When the Bastion is ready (i.e. has a public IP), that IP is stored in the <code>Bastion</code>&rsquo;s status and from there it is picked up by the garden cluster and <code>gardenctl</code> eventually.</p><p>To make multiple SSH sessions possible, the existence of the <code>Bastion</code> is not directly tied to the execution of <code>gardenctl</code>: users can exit out of <code>gardenctl</code> and use <code>ssh</code> manually to connect to the bastion and worker nodes.</p><p>However, <code>Bastion</code>s have an expiry date, after which they will be garbage collected.</p><p>When SSH access is set to <code>false</code> for the <code>Shoot</code> in the workers settings (see <a href=https://github.com/gardener/gardener/blob/master/docs/extensions/usage/shoot/shoot_workers_settings.md>Shoot Worker Nodes Settings</a>), <code>Bastion</code> resources are deleted during <code>Shoot</code> reconciliation and new <code>Bastion</code>s are prevented from being created.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What Needs to Be Implemented to Support a New Infrastructure Provider?</h2><p>As part of the shoot flow, Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Bastion
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: mybastion
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: aws
</span></span><span style=display:flex><span>  <span style=color:green># userData is base64-encoded cloud provider user data; this contains the</span>
</span></span><span style=display:flex><span>  <span style=color:green># user&#39;s SSH key</span>
</span></span><span style=display:flex><span>  userData: IyEvYmluL2Jhc2ggL....Nlcgo=
</span></span><span style=display:flex><span>  ingress:
</span></span><span style=display:flex><span>    - ipBlock:
</span></span><span style=display:flex><span>        cidr: 192.88.99.0/32 <span style=color:green># this is most likely the user&#39;s IP address</span>
</span></span></code></pre></div><p>Your controller is supposed to create a new instance at the given cloud provider, firewall it to only allow SSH (TCP port 22) from the given IP blocks, and then configure the firewall for the worker nodes to allow SSH from the bastion instance. When a <code>Bastion</code> is deleted, all these changes need to be reverted.</p><h2 id=implementation-details>Implementation Details</h2><h3 id=configvalidator-interface><code>ConfigValidator</code> Interface</h3><p>For bastion controllers, the generic <code>Reconciler</code> also delegates to a <a href=https://github.com/gardener/gardener/blob/master/extensions/pkg/controller/bastion/configvalidator.go><code>ConfigValidator</code> interface</a> that contains a single <code>Validate</code> method. This method is called by the generic <code>Reconciler</code> at the beginning of every reconciliation, and can be implemented by the extension to validate the <code>.spec.providerConfig</code> part of the <code>Bastion</code> resource with the respective cloud provider, typically the existence and validity of cloud provider resources such as VPCs, images, etc.</p><p>The <code>Validate</code> method returns a list of errors. If this list is non-empty, the generic <code>Reconciler</code> will fail with an error. This error will have the error code <code>ERR_CONFIGURATION_PROBLEM</code>, unless there is at least one error in the list that has its <code>ErrorType</code> field set to <code>field.ErrorTypeInternal</code>.</p><h2 id=references-and-additional-resources>References and Additional Resources</h2><ul><li><a href=/docs/gardener/api-reference/extensions/#bastion><code>Bastion</code> API Reference</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/bastion>Exemplary Implementation for the AWS Provider</a></li><li><a href=https://github.com/gardener/gardener/blob/master/docs/proposals/15-manage-bastions-and-ssh-key-pair-rotation.md>GEP-15</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-b9b82275abd886de2aa659f2356aabdb>4 - ContainerRuntime</h1><h1 id=contract-containerruntime-resource>Contract: <code>ContainerRuntime</code> Resource</h1><p>At the lowest layers of a Kubernetes node is the software that, among other things, starts and stops containers. It is called “Container Runtime”.
The most widely known container runtime is Docker, but it is not alone in this space. In fact, the container runtime space has been rapidly evolving.</p><p>Kubernetes supports different container runtimes using Container Runtime Interface (CRI) – a plugin interface which enables kubelet to use a wide variety of container runtimes.</p><p>Gardener supports creation of Worker machines using CRI. For more information, see <a href=/docs/gardener/extensions/resources/operatingsystemconfig/#cri-support>CRI Support</a>.</p><h2 id=motivation>Motivation</h2><p>Prior to the <code>Container Runtime Extensibility</code> concept, Gardener used Docker as the only
container runtime to use in shoot worker machines. Because of the wide variety of different container runtimes
offering multiple important features (for example, enhanced security concepts), it is important to enable end users to use other container runtimes as well.</p><h2 id=the-containerruntime-extension-resource>The <code>ContainerRuntime</code> Extension Resource</h2><p>Here is what a typical <code>ContainerRuntime</code> resource would look like:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: ContainerRuntime
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: my-container-runtime
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  binaryPath: /var/bin/containerruntimes
</span></span><span style=display:flex><span>  type: gvisor
</span></span><span style=display:flex><span>  workerPool:
</span></span><span style=display:flex><span>    name: worker-ubuntu
</span></span><span style=display:flex><span>    selector:
</span></span><span style=display:flex><span>      matchLabels:
</span></span><span style=display:flex><span>        worker.gardener.cloud/pool: worker-ubuntu
</span></span></code></pre></div><p>Gardener deploys one <code>ContainerRuntime</code> resource per worker pool per CRI.
To exemplify this, consider a Shoot having two worker pools (<code>worker-one</code>, <code>worker-two</code>) using <code>containerd</code> as the CRI as well as <code>gvisor</code> and <code>kata</code> as enabled container runtimes.
Gardener would deploy four <code>ContainerRuntime</code> resources. For <code>worker-one</code>: one <code>ContainerRuntime</code> for type <code>gvisor</code> and one for type <code>kata</code>. The same resource are being deployed for <code>worker-two</code>.</p><h2 id=supporting-a-new-container-runtime-provider>Supporting a New Container Runtime Provider</h2><p>To add support for another container runtime (e.g., gvisor, kata-containers), a container runtime extension controller needs to be implemented. It should support Gardener&rsquo;s supported CRI plugins.</p><p>The container runtime extension should install the necessary resources into the shoot cluster (e.g., <code>RuntimeClass</code>es), and it should copy the runtime binaries to the relevant worker machines in path: <code>spec.binaryPath</code>.
Gardener labels the shoot nodes according to the CRI configured: <code>worker.gardener.cloud/cri-name=&lt;value></code> (e.g., <code>worker.gardener.cloud/cri-name=containerd</code>) and multiple labels for each of the container runtimes configured for the shoot Worker machine:
<code>containerruntime.worker.gardener.cloud/&lt;container-runtime-type-value>=true</code> (e.g., <code>containerruntime.worker.gardener.cloud/gvisor=true</code>).
The way to install the binaries is by creating a daemon set which copies the binaries from an image in a docker registry to the relevant labeled Worker&rsquo;s nodes (avoid downloading binaries from the internet to also cater with isolated environments).</p><p>For additional reference, please have a look at the <a href=https://github.com/gardener/gardener-extension-runtime-gvisor>runtime-gvsior</a> provider extension, which provides more information on how to configure the necessary charts, as well as the actuators required to reconcile container runtime inside the <code>Shoot</code> cluster to the desired state.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-def81e56da2846b7d66a8d14fff21357>5 - ControlPlane</h1><h1 id=contract-controlplane-resource>Contract: <code>ControlPlane</code> Resource</h1><p>Most Kubernetes clusters require a <code>cloud-controller-manager</code> or CSI drivers in order to work properly.
Before introducing the <code>ControlPlane</code> extension resource Gardener was having several different Helm charts for the <code>cloud-controller-manager</code> deployments for the various providers.
Now, Gardener commissions an external, provider-specific controller to take over this task.</p><h2 id=which-control-plane-resources-are-required>Which control plane resources are required?</h2><p>As mentioned in the <a href=/docs/gardener/extensions/controlplane-webhooks/>controlplane customization webhooks</a> document, Gardener shall not deploy any <code>cloud-controller-manager</code> or any other provider-specific component.
Instead, it creates a <code>ControlPlane</code> CRD that should be picked up by provider extensions.
Its purpose is to trigger the deployment of such provider-specific components in the shoot namespace in the seed cluster.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What needs to be implemented to support a new infrastructure provider?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: ControlPlane
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: control-plane
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: openstack
</span></span><span style=display:flex><span>  region: europe-west1
</span></span><span style=display:flex><span>  secretRef:
</span></span><span style=display:flex><span>    name: cloudprovider
</span></span><span style=display:flex><span>    namespace: shoot--foo--bar
</span></span><span style=display:flex><span>  providerConfig:
</span></span><span style=display:flex><span>    apiVersion: openstack.provider.extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>    kind: ControlPlaneConfig
</span></span><span style=display:flex><span>    loadBalancerProvider: provider
</span></span><span style=display:flex><span>    zone: eu-1a
</span></span><span style=display:flex><span>    cloudControllerManager:
</span></span><span style=display:flex><span>      featureGates:
</span></span><span style=display:flex><span>        CustomResourceValidation: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>  infrastructureProviderStatus:
</span></span><span style=display:flex><span>    apiVersion: openstack.provider.extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>    kind: InfrastructureStatus
</span></span><span style=display:flex><span>    networks:
</span></span><span style=display:flex><span>      floatingPool:
</span></span><span style=display:flex><span>        id: vpc-1234
</span></span><span style=display:flex><span>      subnets:
</span></span><span style=display:flex><span>      - purpose: nodes
</span></span><span style=display:flex><span>        id: subnetid
</span></span></code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used for the shoot cluster.
However, the most important section is the <code>.spec.providerConfig</code> and the <code>.spec.infrastructureProviderStatus</code>.
The first one contains an embedded declaration of the provider specific configuration for the control plane (that cannot be known by Gardener itself).
You are responsible for designing how this configuration looks like.
Gardener does not evaluate it but just copies this part from what has been provided by the end-user in the <code>Shoot</code> resource.
The second one contains the output of the <a href=/docs/gardener/extensions/resources/infrastructure/><code>Infrastructure</code> resource</a> (that might be relevant for the CCM config).</p><p>In order to support a new control plane provider, you need to write a controller that watches all <code>ControlPlane</code>s with <code>.spec.type=&lt;my-provider-name></code>.
You can take a look at the below referenced example implementation for the Alicloud provider.</p><p>The control plane controller as part of the <code>ControlPlane</code> reconciliation often deploys resources (e.g. pods/deployments) into the Shoot namespace in the <code>Seed</code> as part of its <code>ControlPlane</code> reconciliation loop.
Because the namespace contains <a href=https://kubernetes.io/docs/concepts/services-networking/network-policies/>network policies</a> that per default <a href=https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-deny-all-ingress-and-all-egress-traffic>deny all ingress and egress traffic</a>,
the pods may need to have proper labels matching to the selectors of the network policies in order to allow the required network traffic.
Otherwise, they won&rsquo;t be allowed to talk to certain other components (e.g., the kube-apiserver of the shoot).
For more information, see <a href=https://github.com/gardener/gardener/blob/master/docs/extensions/operations/network_policies.md><code>NetworkPolicy</code>s In Garden, Seed, Shoot Clusters</a>.</p><h2 id=non-provider-specific-information-required-for-infrastructure-creation>Non-Provider Specific Information Required for Infrastructure Creation</h2><p>Most providers might require further information that is not provider specific but already part of the shoot resource.
One example for this is the <a href=https://github.com/gardener/gardener-extension-provider-gcp/tree/master/pkg/controller/controlplane>GCP control plane controller</a>, which needs the Kubernetes version of the shoot cluster (because it already uses the in-tree Kubernetes cloud-controller-manager).
As Gardener cannot know which information is required by providers, it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information that is not part of the <code>Infrastructure</code> resource itself.</p><h2 id=references-and-additional-resources>References and Additional Resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_controlplane.go><code>ControlPlane</code> API (Golang Specification)</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-alicloud/tree/master/pkg/controller/controlplane>Exemplary Implementation for the Alicloud Provider</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4ace13d3026eabe4e3300e6d018ed093>6 - ControlPlane Exposure</h1><h1 id=contract-controlplane-resource-with-purpose-exposure>Contract: <code>ControlPlane</code> Resource with Purpose <code>exposure</code></h1><p>Some Kubernetes clusters require an additional deployments required by the seed cloud provider in order to work properly, e.g. AWS Load Balancer Readvertiser.
Before using ControlPlane resources with purpose <code>exposure</code>, Gardener was having different Helm charts for the deployments for the various providers.
Now, Gardener commissions an external, provider-specific controller to take over this task.</p><h2 id=which-control-plane-resources-are-required>Which control plane resources are required?</h2><p>As mentioned in the <a href=/docs/gardener/extensions/resources/controlplane/>controlplane</a> document, Gardener shall not deploy any other provider-specific component.
Instead, it creates a <code>ControlPlane</code> CRD with purpose <code>exposure</code> that should be picked up by provider extensions.
Its purpose is to trigger the deployment of such provider-specific components in the shoot namespace in the seed cluster that are needed to expose the kube-apiserver.</p><p>The shoot cluster&rsquo;s kube-apiserver are exposed via a <code>Service</code> of type <code>LoadBalancer</code> from the shoot provider (you may run the control plane of an Azure shoot in a GCP seed). It&rsquo;s the seed provider extension controller that should act on the <code>ControlPlane</code> resources with purpose <code>exposure</code>.</p><p>If <a href=https://github.com/gardener/gardener/blob/master/docs/extensions/proposals/08-shoot-apiserver-via-sni.md>SNI</a> is enabled, then the <code>Service</code> from above is of type <code>ClusterIP</code> and Gardner will not create <code>ControlPlane</code> resources with purpose <code>exposure</code>.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What needs to be implemented to support a new infrastructure provider?</h2><p>As part of the shoot flow, Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: ControlPlane
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: control-plane-exposure
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: aws
</span></span><span style=display:flex><span>  purpose: exposure
</span></span><span style=display:flex><span>  region: europe-west1
</span></span><span style=display:flex><span>  secretRef:
</span></span><span style=display:flex><span>    name: cloudprovider
</span></span><span style=display:flex><span>    namespace: shoot--foo--bar
</span></span></code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used for the shoot cluster.
It is most likely not needed, however, still added for some potential corner cases.
If you don&rsquo;t need it, then just ignore it.
The <code>.spec.region</code> contains the region of the seed cluster.</p><p>In order to support a control plane provider with purpose <code>exposure</code>, you need to write a controller or expand the existing <a href=/docs/gardener/extensions/resources/controlplane/>controlplane controller</a> that watches all <code>ControlPlane</code>s with <code>.spec.type=&lt;my-provider-name></code> and purpose <code>exposure</code>.
You can take a look at the below referenced example implementation for the AWS provider.</p><h2 id=non-provider-specific-information-required-for-infrastructure-creation>Non-Provider Specific Information Required for Infrastructure Creation</h2><p>Most providers might require further information that is not provider specific but already part of the shoot resource.
As Gardener cannot know which information is required by providers, it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information.</p><h2 id=references-and-additional-resources>References and Additional Resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_controlplane.go><code>ControlPlane</code> API (Golang Specification)</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/controlplane>Exemplary Implementation for the AWS Provider</a></li><li><a href=https://github.com/gardener/aws-lb-readvertiser>AWS Load Balancer Readvertiser</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-83ab5475cb85c0e0d03648790fccc822>7 - DNS Record</h1><h1 id=contract-dnsrecord-resources>Contract: <code>DNSRecord</code> Resources</h1><p>Every shoot cluster requires external DNS records that are publicly resolvable.
The management of these DNS records requires provider-specific knowledge which is to be developed outside the Gardener&rsquo;s core repository.</p><p>Currently, Gardener uses <code>DNSProvider</code> and <code>DNSEntry</code> resources. However, this introduces undesired coupling of Gardener to a controller that does not adhere to the Gardener extension contracts. Because of this, we plan to stop using <code>DNSProvider</code> and <code>DNSEntry</code> resources for Gardener DNS records in the future and use the <code>DNSRecord</code> resources described here instead.</p><h2 id=what-does-gardener-create-dns-records-for>What does Gardener create DNS records for?</h2><h3 id=internal-domain-name>Internal Domain Name</h3><p>Every shoot cluster&rsquo;s kube-apiserver running in the seed is exposed via a load balancer that has a public endpoint (IP or hostname).
This endpoint is used by end-users and also by system components (that are running in another network, e.g., the kubelet or kube-proxy) to talk to the cluster.
In order to be robust against changes of this endpoint (e.g., caused due to re-creation of the load balancer or move of the DNS record to another seed cluster), Gardener creates a so-called <em>internal domain name</em> for every shoot cluster.
The <em>internal domain name</em> is a publicly resolvable DNS record that points to the load balancer of the kube-apiserver.
Gardener uses this domain name in the kubeconfigs of all system components, instead of using directly the load balancer endpoint.
This way Gardener does not need to recreate all kubeconfigs if the endpoint changes - it just needs to update the DNS record.</p><h3 id=external-domain-name>External Domain Name</h3><p>The internal domain name is not configurable by end-users directly but configured by the Gardener administrator.
However, end-users usually prefer to have another DNS name, maybe even using their own domain sometimes, to access their Kubernetes clusters.
Gardener supports that by creating another DNS record, named <em>external domain name</em>, that actually points to the <em>internal domain name</em>.
The kubeconfig handed out to end-users does contain this <em>external domain name</em>, i.e., users can access their clusters with the DNS name they like to.</p><p>As not every end-user has an own domain, it is possible for Gardener administrators to configure so-called <em>default domains</em>.
If configured, shoots that do not specify a domain explicitly get an <em>external domain name</em> based on a default domain (unless explicitly stated that this shoot should not get an external domain name (<code>.spec.dns.provider=unmanaged</code>)).</p><h3 id=ingress-domain-name-deprecated>Ingress Domain Name (Deprecated)</h3><p>Gardener allows to deploy a <code>nginx-ingress-controller</code> into a shoot cluster (deprecated).
This controller is exposed via a public load balancer (again, either IP or hostname).
Gardener creates a wildcard DNS record pointing to this load balancer.
<code>Ingress</code> resources can later use this wildcard DNS record to expose underlying applications.</p><h3 id=seed-ingress>Seed Ingress</h3><p>If <code>.spec.ingress</code> is configured in the Seed, Gardener deploys the ingress controller mentioned in <code>.spec.ingress.controller.kind</code> to the seed cluster. Currently, the only supported kind is &ldquo;nginx&rdquo;. If the ingress field is set, then <code>.spec.dns.provider</code> must also be set. Gardener creates a wildcard DNS record pointing to the load balancer of the ingress controller. The <code>Ingress</code> resources of components like Plutono and Prometheus in the <code>garden</code> namespace and the shoot namespaces use this wildcard DNS record to expose their underlying applications.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-dns-provider>What needs to be implemented to support a new DNS provider?</h2><p>As part of the shoot flow, Gardener will create a number of <code>DNSRecord</code> resources in the seed cluster (one for each of the DNS records mentioned above) that need to be reconciled by an extension controller.
These resources contain the following information:</p><ul><li>The DNS provider type (e.g., <code>aws-route53</code>, <code>google-clouddns</code>, &mldr;)</li><li>A reference to a <code>Secret</code> object that contains the provider-specific credentials used to communicate with the provider&rsquo;s API.</li><li>The fully qualified domain name (FQDN) of the DNS record, e.g. &ldquo;api.&lt;shoot domain>&rdquo;.</li><li>The DNS record type, one of <code>A</code>, <code>AAAA</code>, <code>CNAME</code>, or <code>TXT</code>.</li><li>The DNS record values, that is a list of IP addresses for A records, a single hostname for CNAME records, or a list of texts for TXT records.</li></ul><p>Optionally, the <code>DNSRecord</code> resource may contain also the following information:</p><ul><li>The region of the DNS record. If not specified, the region specified in the referenced <code>Secret</code> shall be used. If that is also not specified, the extension controller shall use a certain default region.</li><li>The DNS hosted zone of the DNS record. If not specified, it shall be determined automatically by the extension controller by getting all hosted zones of the account and searching for the longest zone name that is a suffix of the fully qualified domain name (FQDN) mentioned above.</li><li>The TTL of the DNS record in seconds. If not specified, it shall be set by the extension controller to 120.</li></ul><p><strong>Example <code>DNSRecord</code></strong>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Secret
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: dnsrecord-bar-external
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>type: Opaque
</span></span><span style=display:flex><span>data:
</span></span><span style=display:flex><span>  <span style=color:green># aws-route53 specific credentials here</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: DNSRecord
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: dnsrecord-external
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: aws-route53
</span></span><span style=display:flex><span>  secretRef:
</span></span><span style=display:flex><span>    name: dnsrecord-bar-external
</span></span><span style=display:flex><span>    namespace: shoot--foo--bar
</span></span><span style=display:flex><span><span style=color:green># region: eu-west-1</span>
</span></span><span style=display:flex><span><span style=color:green># zone: ZFOO</span>
</span></span><span style=display:flex><span>  name: api.bar.foo.my-fancy-domain.com
</span></span><span style=display:flex><span>  recordType: A
</span></span><span style=display:flex><span>  values:
</span></span><span style=display:flex><span>  - 1.2.3.4
</span></span><span style=display:flex><span><span style=color:green># ttl: 600</span>
</span></span></code></pre></div><p>In order to support a new DNS record provider, you need to write a controller that watches all <code>DNSRecord</code>s with <code>.spec.type=&lt;my-provider-name></code>.
You can take a look at the below referenced example implementation for the AWS route53 provider.</p><h2 id=key-names-in-secrets-containing-provider-specific-credentials>Key Names in Secrets Containing Provider-Specific Credentials</h2><p>For compatibility with existing setups, extension controllers shall support two different namings of keys in secrets containing provider-specific credentials:</p><ul><li>The naming used by the <a href=https://github.com/gardener/external-dns-management>external-dns-management DNS controller</a>. For example, on AWS the key names are <code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, and <code>AWS_REGION</code>.</li><li>The naming used by other provider-specific extension controllers, e.g., for <a href=/docs/gardener/extensions/resources/infrastructure/>infrastructure</a>. For example, on AWS the key names are <code>accessKeyId</code>, <code>secretAccessKey</code>, and <code>region</code>.</li></ul><h2 id=avoiding-reading-the-dns-hosted-zones>Avoiding Reading the DNS Hosted Zones</h2><p>If the DNS hosted zone is not specified in the <code>DNSRecord</code> resource, during the first reconciliation the extension controller shall determine the correct DNS hosted zone for the specified FQDN and write it to the status of the resource:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: DNSRecord
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: dnsrecord-external
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  ...
</span></span><span style=display:flex><span>status:
</span></span><span style=display:flex><span>  lastOperation: ...
</span></span><span style=display:flex><span>  zone: ZFOO
</span></span></code></pre></div><p>On subsequent reconciliations, the extension controller shall use the zone from the status and avoid reading the DNS hosted zones from the provider.
If the <code>DNSRecord</code> resource specifies a zone in <code>.spec.zone</code> and the extension controller has written a value to <code>.status.zone</code>, the first one shall be considered with higher priority by the extension controller.</p><h2 id=non-provider-specific-information-required-for-dns-record-creation>Non-Provider Specific Information Required for DNS Record Creation</h2><p>Some providers might require further information that is not provider specific but already part of the shoot resource.
As Gardener cannot know which information is required by providers, it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information that is not part of the <code>DNSRecord</code> resource itself.</p><h2 id=using-dnsrecord-resources>Using <code>DNSRecord</code> Resources</h2><p>gardenlet manages <code>DNSRecord</code> resources for all three DNS records mentioned above (internal, external, and ingress).
In order to successfully reconcile a shoot with the feature gate enabled, extension controllers for <code>DNSRecord</code> resources for types used in the default, internal, and custom domain secrets should be registered via <code>ControllerRegistration</code> resources.</p><blockquote><p><strong>Note:</strong> For compatibility reasons, the <code>spec.dns.providers</code> section is still used to specify additional providers. Only the one marked as <code>primary: true</code> will be used for <code>DNSRecord</code>. All others are considered by the <code>shoot-dns-service</code> extension only (if deployed).</p></blockquote><h3 id=support-for-dnsrecord-resources-in-the-provider-extensions>Support for <code>DNSRecord</code> Resources in the Provider Extensions</h3><p>The following table contains information about the provider extension version that adds support for <code>DNSRecord</code> resources:</p><table><thead><tr><th>Extension</th><th>Version</th></tr></thead><tbody><tr><td>provider-alicloud</td><td><code>v1.26.0</code></td></tr><tr><td>provider-aws</td><td><code>v1.27.0</code></td></tr><tr><td>provider-azure</td><td><code>v1.21.0</code></td></tr><tr><td>provider-gcp</td><td><code>v1.18.0</code></td></tr><tr><td>provider-openstack</td><td><code>v1.21.0</code></td></tr><tr><td>provider-vsphere</td><td>N/A</td></tr><tr><td>provider-equinix-metal</td><td>N/A</td></tr><tr><td>provider-kubevirt</td><td>N/A</td></tr><tr><td>provider-openshift</td><td>N/A</td></tr></tbody></table><h3 id=support-for-dnsrecord-ipv6-recordtype-aaaa-in-the-provider-extensions>Support for <code>DNSRecord</code> IPv6 <code>recordType: AAAA</code> in the Provider Extensions</h3><p>The following table contains information about the provider extension version that adds support for <code>DNSRecord</code> IPv6 <code>recordType: AAAA</code>:</p><table><thead><tr><th>Extension</th><th>Version</th></tr></thead><tbody><tr><td>provider-alicloud</td><td>N/A</td></tr><tr><td>provider-aws</td><td>N/A</td></tr><tr><td>provider-azure</td><td>N/A</td></tr><tr><td>provider-gcp</td><td>N/A</td></tr><tr><td>provider-openstack</td><td>N/A</td></tr><tr><td>provider-vsphere</td><td>N/A</td></tr><tr><td>provider-equinix-metal</td><td>N/A</td></tr><tr><td>provider-kubevirt</td><td>N/A</td></tr><tr><td>provider-openshift</td><td>N/A</td></tr><tr><td>provider-local</td><td><code>v1.63.0</code></td></tr></tbody></table><h2 id=references-and-additional-resources>References and Additional Resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_dnsrecord.go><code>DNSRecord</code> API (Golang specification)</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/dnsrecord>Sample Implementation for the AWS Route53 Provider</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-91f9cbe2d031184a3ec1d350c23635ab>8 - Extension</h1><h1 id=contract-extension-resource>Contract: <code>Extension</code> Resource</h1><p>Gardener defines common procedures which must be passed to create a functioning shoot cluster. Well known steps are represented by special resources like <code>Infrastructure</code>, <code>OperatingSystemConfig</code> or <code>DNS</code>. These resources are typically reconciled by dedicated controllers setting up the infrastructure on the hyperscaler or managing DNS entries, etc.</p><p>But, some requirements don&rsquo;t match with those special resources or don&rsquo;t depend on being proceeded at a specific step in the creation / deletion flow of the shoot. They require a more generic hook. Therefore, Gardener offers the <code>Extension</code> resource.</p><h2 id=what-is-required-to-register-and-support-an-extension-type>What is required to register and support an Extension type?</h2><p>Gardener creates one <code>Extension</code> resource per registered extension type in <code>ControllerRegistration</code> per shoot.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: ControllerRegistration
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: extension-example
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  resources:
</span></span><span style=display:flex><span>  - kind: Extension
</span></span><span style=display:flex><span>    type: example
</span></span><span style=display:flex><span>    globallyEnabled: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>    workerlessSupported: <span style=color:#00f>true</span>
</span></span></code></pre></div><p>If <code>spec.resources[].globallyEnabled</code> is <code>true</code>, then the <code>Extension</code> resources of the given <code>type</code> is created for every shoot cluster. Set to <code>false</code>, the <code>Extension</code> resource is only created if configured in the <code>Shoot</code> manifest. In case of workerless <code>Shoot</code>, a globally enabled <code>Extension</code> resource is created only if <code>spec.resources[].workerlessSupported</code> is also set to <code>true</code>. If an extension configured in the spec of a workerless <code>Shoot</code> is not supported yet, the admission request will be rejected.</p><p>The <code>Extension</code> resources are created in the shoot namespace of the seed cluster.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Extension
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: example
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: example
</span></span><span style=display:flex><span>  providerConfig: {}
</span></span></code></pre></div><p>Your controller needs to reconcile <code>extensions.extensions.gardener.cloud</code>. Since there can exist multiple <code>Extension</code> resources per shoot, each one holds a <code>spec.type</code> field to let controllers check their responsibility (similar to all other extension resources of Gardener).</p><h2 id=providerconfig>ProviderConfig</h2><p>It is possible to provide data in the <code>Shoot</code> resource which is copied to <code>spec.providerConfig</code> of the <code>Extension</code> resource.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: bar
</span></span><span style=display:flex><span>  namespace: garden-foo
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  extensions:
</span></span><span style=display:flex><span>  - type: example
</span></span><span style=display:flex><span>    providerConfig:
</span></span><span style=display:flex><span>      foo: bar
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><p>results in</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Extension
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: example
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: example
</span></span><span style=display:flex><span>  providerConfig:
</span></span><span style=display:flex><span>    foo: bar
</span></span></code></pre></div><h2 id=shoot-reconciliation-flow-and-extension-status>Shoot Reconciliation Flow and Extension Status</h2><p>Gardener creates Extension resources as part of the Shoot reconciliation. Moreover, it is guaranteed that the <a href=https://github.com/gardener/gardener/blob/master/docs/extensions/resources/cluster.md>Cluster</a> resource exists before the <code>Extension</code> resource is created. <code>Extension</code>s can be reconciled at different stages during Shoot reconciliation depending on the defined extension lifecycle strategy in the respective <a href=/docs/gardener/extensions/controllerregistration/>ControllerRegistration</a> resource. Please consult the <a href=/docs/gardener/extensions/controllerregistration/#extension-lifecycle>Extension Lifecycle</a> section for more information.</p><p>For an <code>Extension</code> controller it is crucial to maintain the <code>Extension</code>&rsquo;s status correctly. At the end Gardener checks the status of each <code>Extension</code> and only reports a successful shoot reconciliation if the state of the last operation is <code>Succeeded</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Extension
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  generation: 1
</span></span><span style=display:flex><span>  name: example
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: example
</span></span><span style=display:flex><span>status:
</span></span><span style=display:flex><span>  lastOperation:
</span></span><span style=display:flex><span>    state: Succeeded
</span></span><span style=display:flex><span>  observedGeneration: 1
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-9fab39308fc7f83d0ed56a33c24a7e39>9 - Infrastructure</h1><h1 id=contract-infrastructure-resource>Contract: <code>Infrastructure</code> Resource</h1><p>Every Kubernetes cluster requires some low-level infrastructure to be setup in order to work properly.
Examples for that are networks, routing entries, security groups, IAM roles, etc.
Before introducing the <code>Infrastructure</code> extension resource Gardener was using Terraform in order to create and manage these provider-specific resources (e.g., see <a href=https://github.com/gardener/gardener/tree/0.20.0/charts/seed-terraformer/charts/aws-infra>here</a>).
Now, Gardener commissions an external, provider-specific controller to take over this task.</p><h2 id=which-infrastructure-resources-are-required>Which infrastructure resources are required?</h2><p>Unfortunately, there is no general answer to this question as it is highly provider specific.
Consider the above mentioned resources, i.e. VPC, subnets, route tables, security groups, IAM roles, SSH key pairs.
Most of the resources are required in order to create VMs (the shoot cluster worker nodes), load balancers, and volumes.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What needs to be implemented to support a new infrastructure provider?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Infrastructure
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: infrastructure
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: azure
</span></span><span style=display:flex><span>  region: eu-west-1
</span></span><span style=display:flex><span>  secretRef:
</span></span><span style=display:flex><span>    name: cloudprovider
</span></span><span style=display:flex><span>    namespace: shoot--foo--bar
</span></span><span style=display:flex><span>  providerConfig:
</span></span><span style=display:flex><span>    apiVersion: azure.provider.extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>    kind: InfrastructureConfig
</span></span><span style=display:flex><span>    resourceGroup:
</span></span><span style=display:flex><span>      name: mygroup
</span></span><span style=display:flex><span>    networks:
</span></span><span style=display:flex><span>      vnet: <span style=color:green># specify either &#39;name&#39; or &#39;cidr&#39;</span>
</span></span><span style=display:flex><span>      <span style=color:green># name: my-vnet</span>
</span></span><span style=display:flex><span>        cidr: 10.250.0.0/16
</span></span><span style=display:flex><span>      workers: 10.250.0.0/19
</span></span></code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used to create the needed resources.
However, the most important section is the <code>.spec.providerConfig</code>.
It contains an embedded declaration of the provider specific configuration for the infrastructure (that cannot be known by Gardener itself).
You are responsible for designing how this configuration looks like.
Gardener does not evaluate it but just copies this part from what has been provided by the end-user in the <code>Shoot</code> resource.</p><p>After your controller has created the required resources in your provider&rsquo;s infrastructure it needs to generate an output that can be used by other controllers in subsequent steps.
An example for that is the <code>Worker</code> extension resource controller.
It is responsible for creating virtual machines (shoot worker nodes) in this prepared infrastructure.
Everything that it needs to know in order to do that (e.g. the network IDs, security group names, etc. (again: provider-specific)) needs to be provided as output in the <code>Infrastructure</code> resource:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Infrastructure
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: infrastructure
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  ...
</span></span><span style=display:flex><span>status:
</span></span><span style=display:flex><span>  lastOperation: ...
</span></span><span style=display:flex><span>  providerStatus:
</span></span><span style=display:flex><span>    apiVersion: azure.provider.extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>    kind: InfrastructureStatus
</span></span><span style=display:flex><span>    resourceGroup:
</span></span><span style=display:flex><span>      name: mygroup
</span></span><span style=display:flex><span>    networks:
</span></span><span style=display:flex><span>      vnet:
</span></span><span style=display:flex><span>        name: my-vnet
</span></span><span style=display:flex><span>      subnets:
</span></span><span style=display:flex><span>      - purpose: nodes
</span></span><span style=display:flex><span>        name: my-subnet
</span></span><span style=display:flex><span>    availabilitySets:
</span></span><span style=display:flex><span>    - purpose: nodes
</span></span><span style=display:flex><span>      id: av-set-id
</span></span><span style=display:flex><span>      name: av-set-name
</span></span><span style=display:flex><span>    routeTables:
</span></span><span style=display:flex><span>    - purpose: nodes
</span></span><span style=display:flex><span>      name: route-table-name
</span></span><span style=display:flex><span>    securityGroups:
</span></span><span style=display:flex><span>    - purpose: nodes
</span></span><span style=display:flex><span>      name: sec-group-name
</span></span></code></pre></div><p>In order to support a new infrastructure provider you need to write a controller that watches all <code>Infrastructure</code>s with <code>.spec.type=&lt;my-provider-name></code>.
You can take a look at the below referenced example implementation for the Azure provider.</p><h2 id=dynamic-nodes-network-for-shoot-clusters>Dynamic nodes network for shoot clusters</h2><p>Some environments do not allow end-users to statically define a CIDR for the network that shall be used for the shoot worker nodes.
In these cases it is possible for the extension controllers to dynamically provision a network for the nodes (as part of their reconciliation loops), and to provide the CIDR in the <code>status</code> of the <code>Infrastructure</code> resource:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Infrastructure
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: infrastructure
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  ...
</span></span><span style=display:flex><span>status:
</span></span><span style=display:flex><span>  lastOperation: ...
</span></span><span style=display:flex><span>  providerStatus: ...
</span></span><span style=display:flex><span>  nodesCIDR: 10.250.0.0/16
</span></span></code></pre></div><p>Gardener will pick this <code>nodesCIDR</code> and use it to configure the VPN components to establish network connectivity between the control plane and the worker nodes.
If the <code>Shoot</code> resource already specifies a nodes CIDR in <code>.spec.networking.nodes</code> and the extension controller provides also a value in <code>.status.nodesCIDR</code> in the <code>Infrastructure</code> resource then the latter one will always be considered with higher priority by Gardener.</p><h2 id=non-provider-specific-information-required-for-infrastructure-creation>Non-provider specific information required for infrastructure creation</h2><p>Some providers might require further information that is not provider specific but already part of the shoot resource.
One example for this is the <a href=https://github.com/gardener/gardener-extension-provider-gcp/tree/master/pkg/controller/infrastructure>GCP infrastructure controller</a> which needs the pod and the service network of the cluster in order to prepare and configure the infrastructure correctly.
As Gardener cannot know which information is required by providers it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information that is not part of the <code>Infrastructure</code> resource itself.</p><h2 id=implementation-details>Implementation details</h2><h3 id=actuator-interface><code>Actuator</code> interface</h3><p>Most existing infrastructure controller implementations follow a common pattern where a generic <code>Reconciler</code> delegates to <a href=https://github.com/gardener/gardener/blob/master/extensions/pkg/controller/infrastructure/actuator.go>an <code>Actuator</code> interface</a> that contains the methods <code>Reconcile</code>, <code>Delete</code>, <code>Migrate</code>, and <code>Restore</code>. These methods are called by the generic <code>Reconciler</code> for the respective operations, and should be implemented by the extension according to the contract described here and the <a href=https://github.com/gardener/gardener/blob/master/docs/extensions/resources/migration.md>migration guidelines</a>.</p><h3 id=configvalidator-interface><code>ConfigValidator</code> interface</h3><p>For infrastructure controllers, the generic <code>Reconciler</code> also delegates to <a href=https://github.com/gardener/gardener/blob/master/extensions/pkg/controller/infrastructure/configvalidator.go>a <code>ConfigValidator</code> interface</a> that contains a single <code>Validate</code> method. This method is called by the generic <code>Reconciler</code> at the beginning of every reconciliation, and can be implemented by the extension to validate the <code>.spec.providerConfig</code> part of the <code>Infrastructure</code> resource with the respective cloud provider, typically the existence and validity of cloud provider resources such as AWS VPCs or GCP Cloud NAT IPs.</p><p>The <code>Validate</code> method returns a list of errors. If this list is non-empty, the generic <code>Reconciler</code> will fail with an error. This error will have the error code <code>ERR_CONFIGURATION_PROBLEM</code>, unless there is at least one error in the list that has its <code>ErrorType</code> field set to <code>field.ErrorTypeInternal</code>.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_infrastructure.go><code>Infrastructure</code> API (Golang specification)</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-azure/tree/master/pkg/controller/infrastructure>Sample implementation for the Azure provider</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/infrastructure/configvalidator.go>Sample ConfigValidator implementation</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-b1186cfbcb1dcd9fa54c7981efa4b617>10 - Network</h1><h1 id=contract-network-resource>Contract: <code>Network</code> Resource</h1><p>Gardener is an open-source project that provides a nested user model. Basically, there are two types of services provided by Gardener to its users:</p><ul><li>Managed: end-users only request a Kubernetes cluster (Clusters-as-a-Service)</li><li>Hosted: operators utilize Gardener to provide their own managed version of Kubernetes (Cluster-Provisioner-as-a-service)</li></ul><p>Whether a user is an operator or an end-user, it makes sense to provide choice. For example, for an end-user it might make sense to
choose a network-plugin that would support enforcing network policies (some plugins does not come with network-policy support by default).
For operators however, choice only matters for delegation purposes, i.e., when providing an own managed-service, it becomes important to also provide choice over which network-plugins to use.</p><p>Furthermore, Gardener provisions clusters on different cloud-providers with different networking requirements. For example, Azure does not support Calico overlay networking with IP in IP [1], this leads to the introduction of manual exceptions in static add-on charts which is error prone and can lead to failures during upgrades.</p><p>Finally, every provider is different, and thus the network always needs to adapt to the infrastructure needs to provide better performance. Consistency does not necessarily lie in the implementation but in the interface.</p><h2 id=motivation>Motivation</h2><p>Prior to the <code>Network Extensibility</code> concept, Gardener followed a mono network-plugin support model (i.e., Calico). Although this seemed to be the easier approach, it did not completely reflect the real use-case.
The goal of the Gardener Network Extensions is to support different network plugins, therefore, the specification for the network resource won&rsquo;t be fixed and will be customized based on the underlying network plugin.</p><p>To do so, a <code>ProviderConfig</code> field in the spec will be provided where each plugin will define. Below is an example for how to deploy Calico as the cluster network plugin.</p><h2 id=the-network-extensions-resource>The Network Extensions Resource</h2><p>Here is what a typical <code>Network</code> resource would look-like:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Network
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: my-network
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  ipFamilies:
</span></span><span style=display:flex><span>  - IPv4
</span></span><span style=display:flex><span>  podCIDR: 100.244.0.0/16
</span></span><span style=display:flex><span>  serviceCIDR: 100.32.0.0/13
</span></span><span style=display:flex><span>  type: calico
</span></span><span style=display:flex><span>  providerConfig:
</span></span><span style=display:flex><span>    apiVersion: calico.networking.extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>    kind: NetworkConfig
</span></span><span style=display:flex><span>    backend: bird
</span></span><span style=display:flex><span>    ipam:
</span></span><span style=display:flex><span>      cidr: usePodCIDR
</span></span><span style=display:flex><span>      type: host-local
</span></span></code></pre></div><p>The above resources is divided into two parts (more information can be found at <a href=/docs/extensions/network-extensions/gardener-extension-networking-calico/usage/>Using the Networking Calico Extension</a>):</p><ul><li>global configuration (e.g., podCIDR, serviceCIDR, and type)</li><li>provider specific config (e.g., for calico we can choose to configure a <code>bird</code> backend)</li></ul><blockquote><p><strong>Note</strong>: Certain cloud-provider extensions might have webhooks that would modify the network-resource to fit into their network specific context. As previously mentioned, Azure does not support IPIP, as a result, the <a href=https://github.com/gardener/gardener-extension-provider-azure>Azure provider extension</a> implements a <a href=https://github.com/gardener/gardener-extension-provider-azure/blob/master/pkg/webhook/network/mutate.go>webhook</a> to mutate the backend and set it to <code>None</code> instead of <code>bird</code>.</p></blockquote><h2 id=supporting-a-new-network-extension-provider>Supporting a New Network Extension Provider</h2><p>To add support for another networking provider (e.g., weave, Cilium, Flannel) a network extension controller needs to be implemented which would optionally have its own custom configuration specified in the <code>spec.providerConfig</code> in the <code>Network</code> resource. For example, if support for a network plugin named <code>gardenet</code> is required, the following <code>Network</code> resource would be created:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Network
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: my-network
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  ipFamilies:
</span></span><span style=display:flex><span>  - IPv4
</span></span><span style=display:flex><span>  podCIDR: 100.244.0.0/16
</span></span><span style=display:flex><span>  serviceCIDR: 100.32.0.0/13
</span></span><span style=display:flex><span>  type: gardenet
</span></span><span style=display:flex><span>  providerConfig:
</span></span><span style=display:flex><span>    apiVersion: gardenet.networking.extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>    kind: NetworkConfig
</span></span><span style=display:flex><span>    gardenetCustomConfigField: &lt;value&gt;
</span></span><span style=display:flex><span>    ipam:
</span></span><span style=display:flex><span>      cidr: usePodCIDR
</span></span><span style=display:flex><span>      type: host-local
</span></span></code></pre></div><p>Once applied, the presumably implemented <code>Gardenet</code> extension controller would pick the configuration up, parse the <code>providerConfig</code>, and create the necessary resources in the shoot.</p><p>For additional reference, please have a look at the <a href=https://github.com/gardener/gardener-extension-networking-calico>networking-calico</a> provider extension, which provides more information on how to configure the necessary charts, as well as the actuators required to reconcile networking inside the <code>Shoot</code> cluster to the desired state.</p><h2 id=supporting-kube-proxy-less-service-routing>Supporting <code>kube-proxy</code>-less Service Routing</h2><p>Some networking extensions support service routing without the <code>kube-proxy</code> component. This is why Gardener supports disabling of <code>kube-proxy</code> for service routing by setting <code>.spec.kubernetes.kubeproxy.enabled</code> to <code>false</code> in the <code>Shoot</code> specification. The implicit contract of the flag is:</p><p><em>If <code>kube-proxy</code> is disabled, then the networking extension is responsible for the service routing.</em></p><p>The networking extensions need to handle this twofold:</p><ol><li>During the reconciliation of the networking resources, the extension needs to check whether <code>kube-proxy</code> takes care of the service routing or the networking extension itself should handle it. In case the networking extension should be responsible according to <code>.spec.kubernetes.kubeproxy.enabled</code> (but is unable to perform the service routing), it should raise an error during the reconciliation. If the networking extension should handle the service routing, it may reconfigure itself accordingly.</li><li>(Optional) In case the networking extension does not support taking over the service routing (in some scenarios), it is recommended to also provide a validating admission webhook to reject corresponding changes early on. The validation may take the current operating mode of the networking extension into consideration.</li></ol><h2 id=related-links>Related Links</h2><ul><li>[1] <a href=https://docs.tigera.io/calico/latest/networking/configuring/vxlan-ipip#encapsulation-types>Calico overlay networking on Azure</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-4bbb7bebb23dcb225674012a6fcf92e8>11 - OperatingSystemConfig</h1><h1 id=contract-operatingsystemconfig-resource>Contract: <code>OperatingSystemConfig</code> Resource</h1><p>Gardener uses the machine API and leverages the functionalities of the <a href=https://github.com/gardener/machine-controller-manager>machine-controller-manager</a> (MCM) in order to manage the worker nodes of a shoot cluster.
The machine-controller-manager itself simply takes a reference to an OS-image and (optionally) some user-data (a script or configuration that is executed when a VM is bootstrapped), and forwards both to the provider&rsquo;s API when creating VMs.
MCM does not have any restrictions regarding supported operating systems as it does not modify or influence the machine&rsquo;s configuration in any way - it just creates/deletes machines with the provided metadata.</p><p>Consequently, Gardener needs to provide this information when interacting with the machine-controller-manager.
This means that basically every operating system is possible to be used, as long as there is some implementation that generates the OS-specific configuration in order to provision/bootstrap the machines.</p><p>&#9888;&#xfe0f; Currently, there are a few requirements of pre-installed components that must be present in all OS images:</p><ol><li><a href=https://containerd.io/>containerd</a><ol><li><a href=https://github.com/projectatomic/containerd/blob/master/docs/cli.md/>ctr (client CLI)</a></li><li><code>containerd</code> must listen on its default socket path: <code>unix:///run/containerd/containerd.sock</code></li><li><code>containerd</code> must be configured to work with the default configuration file in: <code>/etc/containerd/config.toml</code> (eventually created by Gardener).</li></ol></li><li><a href=https://www.freedesktop.org/wiki/Software/systemd/>systemd</a></li></ol><p>The reasons for that will become evident later.</p><h2 id=what-does-the-user-data-bootstrapping-the-machines-contain>What does the user-data bootstrapping the machines contain?</h2><p>Gardener installs a few components onto every worker machine in order to allow it to join the shoot cluster.
There is the <code>kubelet</code> process, some scripts for continuously checking the health of <code>kubelet</code> and <code>containerd</code>, but also configuration for log rotation, CA certificates, etc.
You can find the complete configuration <a href=https://github.com/gardener/gardener/tree/master/pkg/component/extensions/operatingsystemconfig/original/components>at the components folder</a>. We are calling this the &ldquo;original&rdquo; user-data.</p><h2 id=how-does-gardener-bootstrap-the-machines>How does Gardener bootstrap the machines?</h2><p><code>gardenlet</code> makes use of <code>gardener-node-agent</code> to perform the bootstrapping and reconciliation of systemd units and files on the machine.
Please refer to <a href=/docs/gardener/concepts/node-agent/#installation-and-bootstrapping>this document</a> for a first overview.</p><p>Usually, you would submit all the components you want to install onto the machine as part of the user-data during creation time.
However, some providers do have a size limitation (around ~16KB) for that user-data.
That&rsquo;s why we do not send the &ldquo;original&rdquo; user-data to the machine-controller-manager (who then forwards it to the provider&rsquo;s API).
Instead, we only send a small &ldquo;init&rdquo; script that bootstrap the <a href=/docs/gardener/concepts/node-agent/><code>gardener-node-agent</code></a>.
It fetches the &ldquo;original&rdquo; content from a <code>Secret</code> and applies it on the machine directly.
This way we can extend the &ldquo;original&rdquo; user-data without any size restrictions (except for the <code>1 MB</code> limit for <code>Secret</code>s).</p><p>The high-level flow is as follows:</p><ol><li>For every worker pool <code>X</code> in the <code>Shoot</code> specification, Gardener creates a <code>Secret</code> named <code>cloud-config-&lt;X></code> in the <code>kube-system</code> namespace of the shoot cluster. The secret contains the &ldquo;original&rdquo; <code>OperatingSystemConfig</code> (i.e., systemd units and files for <code>kubelet</code>).</li><li>Gardener generates a kubeconfig with minimal permissions just allowing reading these secrets. It is used by the <code>gardener-node-agent</code> later.</li><li>Gardener provides the <code>gardener-node-init.sh</code> bash script and the machine image stated in the <code>Shoot</code> specification to the machine-controller-manager.</li><li>Based on this information, the machine-controller-manager creates the VM.</li><li>After the VM has been provisioned, the <code>gardener-node-init.sh</code> script starts, fetches the <code>gardener-node-agent</code> binary, and starts it.</li><li>The <code>gardener-node-agent</code> will read the <code>gardener-node-agent-&lt;X></code> <code>Secret</code> for its worker pool (containing the &ldquo;original&rdquo; <code>OperatingSystemConfig</code>), and reconciles it.</li></ol><p>The <code>gardener-node-agent</code> can update itself in case of newer Gardener versions, and it performs a continuous reconciliation of the systemd units and files in the provided <code>OperatingSystemConfig</code> (just like any other Kubernetes controller).</p><h2 id=what-needs-to-be-implemented-to-support-a-new-operating-system>What needs to be implemented to support a new operating system?</h2><p>As part of the <a href=/docs/gardener/concepts/gardenlet/#shoot-controller><code>Shoot</code> reconciliation flow</a>, <code>gardenlet</code> will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: OperatingSystemConfig
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: pool-01-original
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: &lt;my-operating-system&gt;
</span></span><span style=display:flex><span>  purpose: reconcile
</span></span><span style=display:flex><span>  units:
</span></span><span style=display:flex><span>  - name: containerd.service
</span></span><span style=display:flex><span>    dropIns:
</span></span><span style=display:flex><span>    - name: 10-containerd-opts.conf
</span></span><span style=display:flex><span>      content: |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>        [Service]
</span></span></span><span style=display:flex><span><span style=color:#a31515>        Environment=&#34;SOME_OPTS=--foo=bar&#34;</span>        
</span></span><span style=display:flex><span>  - name: containerd-monitor.service
</span></span><span style=display:flex><span>    command: start
</span></span><span style=display:flex><span>    enable: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>    content: |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>      [Unit]
</span></span></span><span style=display:flex><span><span style=color:#a31515>      Description=Containerd-monitor daemon
</span></span></span><span style=display:flex><span><span style=color:#a31515>      After=kubelet.service
</span></span></span><span style=display:flex><span><span style=color:#a31515>      [Install]
</span></span></span><span style=display:flex><span><span style=color:#a31515>      WantedBy=multi-user.target
</span></span></span><span style=display:flex><span><span style=color:#a31515>      [Service]
</span></span></span><span style=display:flex><span><span style=color:#a31515>      Restart=always
</span></span></span><span style=display:flex><span><span style=color:#a31515>      EnvironmentFile=/etc/environment
</span></span></span><span style=display:flex><span><span style=color:#a31515>      ExecStart=/opt/bin/health-monitor containerd</span>      
</span></span><span style=display:flex><span>  files:
</span></span><span style=display:flex><span>  - path: /var/lib/kubelet/ca.crt
</span></span><span style=display:flex><span>    permissions: 0644
</span></span><span style=display:flex><span>    encoding: b64
</span></span><span style=display:flex><span>    content:
</span></span><span style=display:flex><span>      secretRef:
</span></span><span style=display:flex><span>        name: default-token-5dtjz
</span></span><span style=display:flex><span>        dataKey: token
</span></span><span style=display:flex><span>  - path: /etc/sysctl.d/99-k8s-general.conf
</span></span><span style=display:flex><span>    permissions: 0644
</span></span><span style=display:flex><span>    content:
</span></span><span style=display:flex><span>      inline:
</span></span><span style=display:flex><span>        data: |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>          # A higher vm.max_map_count is great for elasticsearch, mongo, or other mmap users
</span></span></span><span style=display:flex><span><span style=color:#a31515>          # See https://github.com/kubernetes/kops/issues/1340
</span></span></span><span style=display:flex><span><span style=color:#a31515>          vm.max_map_count = 135217728</span>          
</span></span></code></pre></div><p>In order to support a new operating system, you need to write a controller that watches all <code>OperatingSystemConfig</code>s with <code>.spec.type=&lt;my-operating-system></code>.
For those it shall generate a configuration blob that fits to your operating system.</p><p><code>OperatingSystemConfig</code>s can have two purposes: either <code>provision</code> or <code>reconcile</code>.</p><h3 id=provision-purpose><code>provision</code> Purpose</h3><p>The <code>provision</code> purpose is used by <code>gardenlet</code> for the user-data that it later passes to the machine-controller-manager (and then to the provider&rsquo;s API) when creating new VMs.
It contains the <code>gardener-node-init.sh</code> script and systemd unit.</p><p>The OS controller has to translate the <code>.spec.units</code> and <code>.spec.files</code> into configuration that fits to the operating system.
For example, a Flatcar controller might generate a <a href=https://github.com/flatcar/coreos-cloudinit/blob/flatcar-master/Documentation/cloud-config-examples.md>CoreOS cloud-config</a> or <a href=https://coreos.com/ignition/docs/latest/what-is-ignition.html>Ignition</a>, SLES might generate <a href=https://cloudinit.readthedocs.io/en/latest/>cloud-init</a>, and others might simply generate a bash script translating the <code>.spec.units</code> into <code>systemd</code> units, and <code>.spec.files</code> into real files on the disk.</p><blockquote><p>⚠️ Please avoid mixing in additional systemd units or files - this step should just translate what <code>gardenlet</code> put into <code>.spec.units</code> and <code>.spec.files</code>.</p></blockquote><p>After generation, extension controllers are asked to store their OS config inside a <code>Secret</code> (as it might contain confidential data) in the same namespace.
The secret&rsquo;s <code>.data</code> could look like this:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Secret
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: osc-result-pool-01-original
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  ownerReferences:
</span></span><span style=display:flex><span>  - apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>    blockOwnerDeletion: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>    controller: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>    kind: OperatingSystemConfig
</span></span><span style=display:flex><span>    name: pool-01-original
</span></span><span style=display:flex><span>    uid: 99c0c5ca-19b9-11e9-9ebd-d67077b40f82
</span></span><span style=display:flex><span>data:
</span></span><span style=display:flex><span>  cloud_config: base64(generated-user-data)
</span></span></code></pre></div><p>Finally, the secret&rsquo;s metadata must be provided in the <code>OperatingSystemConfig</code>&rsquo;s <code>.status</code> field:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>...
</span></span><span style=display:flex><span>status:
</span></span><span style=display:flex><span>  cloudConfig:
</span></span><span style=display:flex><span>    secretRef:
</span></span><span style=display:flex><span>      name: osc-result-pool-01-original
</span></span><span style=display:flex><span>      namespace: default
</span></span><span style=display:flex><span>  lastOperation:
</span></span><span style=display:flex><span>    description: Successfully generated cloud config
</span></span><span style=display:flex><span>    lastUpdateTime: <span style=color:#a31515>&#34;2019-01-23T07:45:23Z&#34;</span>
</span></span><span style=display:flex><span>    progress: 100
</span></span><span style=display:flex><span>    state: Succeeded
</span></span><span style=display:flex><span>    type: Reconcile
</span></span><span style=display:flex><span>  observedGeneration: 5
</span></span></code></pre></div><h3 id=reconcile-purpose><code>reconcile</code> Purpose</h3><p>The <code>reconcile</code> purpose contains the &ldquo;original&rdquo; <code>OperatingSystemConfig</code> (which is later stored in <code>Secret</code>s in the shoot&rsquo;s <code>kube-system</code> namespace (see step 1)).</p><p>The OS controller does not need to translate anything here, but it has the option to provide additional systemd units or files via the <code>.status</code> field:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>status:
</span></span><span style=display:flex><span>  extensionUnits:
</span></span><span style=display:flex><span>  - name: my-custom-service.service
</span></span><span style=display:flex><span>    command: start
</span></span><span style=display:flex><span>    enable: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>    content: |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>      [Unit]
</span></span></span><span style=display:flex><span><span style=color:#a31515>      // some systemd unit content</span>      
</span></span><span style=display:flex><span>  extensionFiles:
</span></span><span style=display:flex><span>  - path: /etc/some/file
</span></span><span style=display:flex><span>    permissions: 0644
</span></span><span style=display:flex><span>    content:
</span></span><span style=display:flex><span>      inline:
</span></span><span style=display:flex><span>        data: some-file-content
</span></span><span style=display:flex><span>  lastOperation:
</span></span><span style=display:flex><span>    description: Successfully generated cloud config
</span></span><span style=display:flex><span>    lastUpdateTime: <span style=color:#a31515>&#34;2019-01-23T07:45:23Z&#34;</span>
</span></span><span style=display:flex><span>    progress: 100
</span></span><span style=display:flex><span>    state: Succeeded
</span></span><span style=display:flex><span>    type: Reconcile
</span></span><span style=display:flex><span>  observedGeneration: 5
</span></span></code></pre></div><p>The <code>gardener-node-agent</code> will merge <code>.spec.units</code> and <code>.status.extensionUnits</code> as well as <code>.spec.files</code> and <code>.status.extensionFiles</code> when applying.</p><p>You can find an example implementation <a href=https://github.com/gardener/gardener/blob/master/pkg/provider-local/controller/operatingsystemconfig/actuator.go>here</a>.</p><h3 id=bootstrap-tokens>Bootstrap Tokens</h3><p><code>gardenlet</code> adds a file with the content <code>&lt;&lt;BOOTSTRAP_TOKEN>></code> to the <code>OperatingSystemConfig</code> with purpose <code>provision</code> and sets <code>transmitUnencoded=true</code>.
This instructs the responsible OS extension to pass this file (with its content in clear-text) to the corresponding <code>Worker</code> resource.</p><p><code>machine-controller-manager</code> makes sure that:</p><ul><li>a bootstrap token gets created per machine</li><li>the <code>&lt;&lt;BOOTSTRAP_TOKEN>></code> string in the user data of the machine gets replaced by the generated token</li></ul><p>After the machine has been bootstrapped, the token secret in the shoot cluster gets deleted again.</p><p>The token is used to bootstrap <a href=/docs/gardener/concepts/node-agent/>Gardener Node Agent</a> and <code>kubelet</code>.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-operating-system-1>What needs to be implemented to support a new operating system?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: OperatingSystemConfig
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: pool-01-original
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: &lt;my-operating-system&gt;
</span></span><span style=display:flex><span>  purpose: reconcile
</span></span><span style=display:flex><span>  units:
</span></span><span style=display:flex><span>  - name: docker.service
</span></span><span style=display:flex><span>    dropIns:
</span></span><span style=display:flex><span>    - name: 10-docker-opts.conf
</span></span><span style=display:flex><span>      content: |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>        [Service]
</span></span></span><span style=display:flex><span><span style=color:#a31515>        Environment=&#34;DOCKER_OPTS=--log-opt max-size=60m --log-opt max-file=3&#34;</span>        
</span></span><span style=display:flex><span>  - name: docker-monitor.service
</span></span><span style=display:flex><span>    command: start
</span></span><span style=display:flex><span>    enable: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>    content: |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>      [Unit]
</span></span></span><span style=display:flex><span><span style=color:#a31515>      Description=Containerd-monitor daemon
</span></span></span><span style=display:flex><span><span style=color:#a31515>      After=kubelet.service
</span></span></span><span style=display:flex><span><span style=color:#a31515>      [Install]
</span></span></span><span style=display:flex><span><span style=color:#a31515>      WantedBy=multi-user.target
</span></span></span><span style=display:flex><span><span style=color:#a31515>      [Service]
</span></span></span><span style=display:flex><span><span style=color:#a31515>      Restart=always
</span></span></span><span style=display:flex><span><span style=color:#a31515>      EnvironmentFile=/etc/environment
</span></span></span><span style=display:flex><span><span style=color:#a31515>      ExecStart=/opt/bin/health-monitor docker</span>      
</span></span><span style=display:flex><span>  files:
</span></span><span style=display:flex><span>  - path: /var/lib/kubelet/ca.crt
</span></span><span style=display:flex><span>    permissions: 0644
</span></span><span style=display:flex><span>    encoding: b64
</span></span><span style=display:flex><span>    content:
</span></span><span style=display:flex><span>      secretRef:
</span></span><span style=display:flex><span>        name: default-token-5dtjz
</span></span><span style=display:flex><span>        dataKey: token
</span></span><span style=display:flex><span>  - path: /etc/sysctl.d/99-k8s-general.conf
</span></span><span style=display:flex><span>    permissions: 0644
</span></span><span style=display:flex><span>    content:
</span></span><span style=display:flex><span>      inline:
</span></span><span style=display:flex><span>        data: |<span style=color:#a31515>
</span></span></span><span style=display:flex><span><span style=color:#a31515>          # A higher vm.max_map_count is great for elasticsearch, mongo, or other mmap users
</span></span></span><span style=display:flex><span><span style=color:#a31515>          # See https://github.com/kubernetes/kops/issues/1340
</span></span></span><span style=display:flex><span><span style=color:#a31515>          vm.max_map_count = 135217728</span>          
</span></span></code></pre></div><p>In order to support a new operating system, you need to write a controller that watches all <code>OperatingSystemConfig</code>s with <code>.spec.type=&lt;my-operating-system></code>.
For those it shall generate a configuration blob that fits to your operating system.
For example, a CoreOS controller might generate a <a href=https://coreos.com/os/docs/latest/cloud-config.html>CoreOS cloud-config</a> or <a href=https://coreos.com/ignition/docs/latest/what-is-ignition.html>Ignition</a>, SLES might generate <a href=https://cloudinit.readthedocs.io/en/latest/>cloud-init</a>, and others might simply generate a bash script translating the <code>.spec.units</code> into <code>systemd</code> units, and <code>.spec.files</code> into real files on the disk.</p><p><code>OperatingSystemConfig</code>s can have two purposes which can be used (or ignored) by the extension controllers: either <code>provision</code> or <code>reconcile</code>.</p><ul><li>The <code>provision</code> purpose is used by Gardener for the user-data that it later passes to the machine-controller-manager (and then to the provider&rsquo;s API) when creating new VMs. It contains the <code>gardener-node-init</code> unit.</li><li>The <code>reconcile</code> purpose contains the &ldquo;original&rdquo; user-data (that is then stored in <code>Secret</code>s in the shoot&rsquo;s <code>kube-system</code> namespace (see step 1)). This is downloaded and applies late (see step 5).</li></ul><p>As described above, the &ldquo;original&rdquo; user-data must be re-applicable to allow in-place updates.
The way how this is done is specific to the generated operating system config (e.g., for CoreOS cloud-init the command is <code>/usr/bin/coreos-cloudinit --from-file=&lt;path></code>, whereas SLES would run <code>cloud-init --file &lt;path> single -n write_files --frequency=once</code>).
Consequently, besides the generated OS config, the extension controller must also provide a command for re-application an updated version of the user-data.
As visible in the mentioned examples, the command requires a path to the user-data file.
As soon as Gardener detects that the user data has changed it will reload the systemd daemon and restart all the units provided in the <code>.status.units[]</code> list (see the below example). The same logic applies during the very first application of the whole configuration.</p><p>After generation, extension controllers are asked to store their OS config inside a <code>Secret</code> (as it might contain confidential data) in the same namespace.
The secret&rsquo;s <code>.data</code> could look like this:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Secret
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: osc-result-pool-01-original
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  ownerReferences:
</span></span><span style=display:flex><span>  - apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>    blockOwnerDeletion: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>    controller: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>    kind: OperatingSystemConfig
</span></span><span style=display:flex><span>    name: pool-01-original
</span></span><span style=display:flex><span>    uid: 99c0c5ca-19b9-11e9-9ebd-d67077b40f82
</span></span><span style=display:flex><span>data:
</span></span><span style=display:flex><span>  cloud_config: base64(generated-user-data)
</span></span></code></pre></div><p>Finally, the secret&rsquo;s metadata, the OS-specific command to re-apply the configuration, and the list of <code>systemd</code> units that shall be considered to be restarted if an updated version of the user-data is re-applied must be provided in the <code>OperatingSystemConfig</code>&rsquo;s <code>.status</code> field:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>...
</span></span><span style=display:flex><span>status:
</span></span><span style=display:flex><span>  cloudConfig:
</span></span><span style=display:flex><span>    secretRef:
</span></span><span style=display:flex><span>      name: osc-result-pool-01-original
</span></span><span style=display:flex><span>      namespace: default
</span></span><span style=display:flex><span>  lastOperation:
</span></span><span style=display:flex><span>    description: Successfully generated cloud config
</span></span><span style=display:flex><span>    lastUpdateTime: <span style=color:#a31515>&#34;2019-01-23T07:45:23Z&#34;</span>
</span></span><span style=display:flex><span>    progress: 100
</span></span><span style=display:flex><span>    state: Succeeded
</span></span><span style=display:flex><span>    type: Reconcile
</span></span><span style=display:flex><span>  observedGeneration: 5
</span></span><span style=display:flex><span>  units:
</span></span><span style=display:flex><span>  - docker-monitor.service
</span></span></code></pre></div><p>Once the <code>.status</code> indicates that the extension controller finished reconciling Gardener will continue with the next step of the shoot reconciliation flow.</p><h2 id=cri-support>CRI Support</h2><p>Gardener supports specifying a Container Runtime Interface (CRI) configuration in the <code>OperatingSystemConfig</code> resource. If the <code>.spec.cri</code> section exists, then the <code>name</code> property is mandatory. The only supported value for <code>cri.name</code> at the moment is: <code>containerd</code>.
For example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: OperatingSystemConfig
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: pool-01-original
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: &lt;my-operating-system&gt;
</span></span><span style=display:flex><span>  purpose: reconcile
</span></span><span style=display:flex><span>  cri:
</span></span><span style=display:flex><span>    name: containerd
</span></span><span style=display:flex><span><span style=color:green>#   cgroupDriver: cgroupfs # or systemd</span>
</span></span><span style=display:flex><span>    containerd:
</span></span><span style=display:flex><span>      sandboxImage: registry.k8s.io/pause
</span></span><span style=display:flex><span><span style=color:green>#     registries:</span>
</span></span><span style=display:flex><span><span style=color:green>#     - upstream: docker.io</span>
</span></span><span style=display:flex><span><span style=color:green>#       server: https://registry-1.docker.io</span>
</span></span><span style=display:flex><span><span style=color:green>#       hosts:</span>
</span></span><span style=display:flex><span><span style=color:green>#       - url: http://&lt;service-ip&gt;:&lt;port&gt;]</span>
</span></span><span style=display:flex><span><span style=color:green>#     plugins:</span>
</span></span><span style=display:flex><span><span style=color:green>#     - op: add # add (default) or remove</span>
</span></span><span style=display:flex><span><span style=color:green>#       path: [io.containerd.grpc.v1.cri, containerd]</span>
</span></span><span style=display:flex><span><span style=color:green>#       values: &#39;{&#34;default_runtime_name&#34;: &#34;runc&#34;}&#39;</span>
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><p>To support <code>containerd</code>, an OS extension must satisfy the following criteria:</p><ol><li>The operating system must have built-in <a href=https://containerd.io/>containerd</a> and <a href=https://github.com/projectatomic/containerd/blob/master/docs/cli.md/>ctr (client CLI)</a>.</li><li><code>containerd</code> must listen on its default socket path: <code>unix:///run/containerd/containerd.sock</code></li><li><code>containerd</code> must be configured to work with the default configuration file in: <code>/etc/containerd/config.toml</code> (Created by Gardener).</li></ol><p>For a convenient handling, <a href=/docs/gardener/concepts/node-agent/>gardener-node-agent</a> can manage various aspects of containerd&rsquo;s config, e.g. the registry configuration, if given in the <code>OperatingSystemConfig</code>.
Any Gardener extension which needs to modify the config, should check the functionality exposed through this API first.
If applicable, adjustments can be implemented through mutating webhooks, acting on the created or updated <code>OperatingSystemConfig</code> resource.</p><p>If CRI configurations are not supported, it is recommended to create a validating webhook running in the garden cluster that prevents specifying the <code>.spec.providers.workers[].cri</code> section in the <code>Shoot</code> objects.</p><h3 id=cgroup-driver>cgroup driver</h3><p>For Shoot clusters using Kubernetes &lt; 1.31, Gardener is setting the kubelet&rsquo;s cgroup driver to <a href=https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cgroupfs-cgroup-driver><code>cgroupfs</code></a> and containerd&rsquo;s cgroup driver is unmanaged. For Shoot clusters using Kubernetes 1.31+, Gardener is setting both kubelet&rsquo;s and containerd&rsquo;s cgroup driver to <a href=https://kubernetes.io/docs/setup/production-environment/container-runtimes/#systemd-cgroup-driver><code>systemd</code></a>.</p><p>The <code>systemd</code> cgroup driver is a requirement for operating systems using <a href=https://kubernetes.io/docs/concepts/architecture/cgroups/>cgroup v2</a>. It&rsquo;s important to ensure that both kubelet and the container runtime (containerd) are using the same cgroup driver to avoid potential issues.</p><p>OS extensions might also overwrite the cgroup driver for containerd and kubelet.</p><h2 id=references-and-additional-resources>References and Additional Resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_operatingsystemconfig.go><code>OperatingSystemConfig</code> API (Golang Specification)</a></li><li><a href=/docs/gardener/concepts/node-agent/>Gardener Node Agent</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-cb90be03fc1226f8ac3dd89d3a062129>12 - Worker</h1><h1 id=contract-worker-resource>Contract: <code>Worker</code> Resource</h1><p>While the control plane of a shoot cluster is living in the seed and deployed as native Kubernetes workload, the worker nodes of the shoot clusters are normal virtual machines (VMs) in the end-users infrastructure account.
The Gardener project features a sub-project called <a href=https://github.com/gardener/machine-controller-manager>machine-controller-manager</a>.
This controller is extending the Kubernetes API using custom resource definitions to represent actual VMs as <code>Machine</code> objects inside a Kubernetes system.
This approach unlocks the possibility to manage virtual machines in the Kubernetes style and benefit from all its design principles.</p><h2 id=what-is-the-machine-controller-manager-doing-exactly>What is the machine-controller-manager doing exactly?</h2><p>Generally, there are provider-specific <code>MachineClass</code> objects (<code>AWSMachineClass</code>, <code>AzureMachineClass</code>, etc.; similar to <code>StorageClass</code>), and <code>MachineDeployment</code>, <code>MachineSet</code>, and <code>Machine</code> objects (similar to <code>Deployment</code>, <code>ReplicaSet</code>, and <code>Pod</code>).
A machine class describes <strong>where</strong> and <strong>how</strong> to create virtual machines (in which networks, region, availability zone, SSH key, user-data for bootstrapping, etc.), while a <code>Machine</code> results in an actual virtual machine.
You can read up <a href=https://github.com/gardener/machine-controller-manager>more information</a> in the machine-controller-manager&rsquo;s <a href=https://github.com/gardener/machine-controller-manager>repository</a>.</p><p>The <code>gardenlet</code> deploys the <code>machine-controller-manager</code>, hence, provider extensions only have to inject their specific out-of-tree <code>machine-controller-manager</code> sidecar container into the <code>Deployment</code>.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-worker-provider>What needs to be implemented to support a new worker provider?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Worker
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: bar
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  type: azure
</span></span><span style=display:flex><span>  region: eu-west-1
</span></span><span style=display:flex><span>  secretRef:
</span></span><span style=display:flex><span>    name: cloudprovider
</span></span><span style=display:flex><span>    namespace: shoot--foo--bar
</span></span><span style=display:flex><span>  infrastructureProviderStatus:
</span></span><span style=display:flex><span>    apiVersion: aws.provider.extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>    kind: InfrastructureStatus
</span></span><span style=display:flex><span>    ec2:
</span></span><span style=display:flex><span>      keyName: shoot--foo--bar-ssh-publickey
</span></span><span style=display:flex><span>    iam:
</span></span><span style=display:flex><span>      instanceProfiles:
</span></span><span style=display:flex><span>      - name: shoot--foo--bar-nodes
</span></span><span style=display:flex><span>        purpose: nodes
</span></span><span style=display:flex><span>      roles:
</span></span><span style=display:flex><span>      - arn: arn:aws:iam::0123456789:role/shoot--foo--bar-nodes
</span></span><span style=display:flex><span>        purpose: nodes
</span></span><span style=display:flex><span>    vpc:
</span></span><span style=display:flex><span>      id: vpc-0123456789
</span></span><span style=display:flex><span>      securityGroups:
</span></span><span style=display:flex><span>      - id: sg-1234567890
</span></span><span style=display:flex><span>        purpose: nodes
</span></span><span style=display:flex><span>      subnets:
</span></span><span style=display:flex><span>      - id: subnet-01234
</span></span><span style=display:flex><span>        purpose: nodes
</span></span><span style=display:flex><span>        zone: eu-west-1b
</span></span><span style=display:flex><span>      - id: subnet-56789
</span></span><span style=display:flex><span>        purpose: public
</span></span><span style=display:flex><span>        zone: eu-west-1b
</span></span><span style=display:flex><span>      - id: subnet-0123a
</span></span><span style=display:flex><span>        purpose: nodes
</span></span><span style=display:flex><span>        zone: eu-west-1c
</span></span><span style=display:flex><span>      - id: subnet-5678a
</span></span><span style=display:flex><span>        purpose: public
</span></span><span style=display:flex><span>        zone: eu-west-1c
</span></span><span style=display:flex><span>  pools:
</span></span><span style=display:flex><span>  - name: cpu-worker
</span></span><span style=display:flex><span>    minimum: 3
</span></span><span style=display:flex><span>    maximum: 5
</span></span><span style=display:flex><span>    maxSurge: 1
</span></span><span style=display:flex><span>    maxUnavailable: 0
</span></span><span style=display:flex><span>    machineType: m4.large
</span></span><span style=display:flex><span>    machineImage:
</span></span><span style=display:flex><span>      name: coreos
</span></span><span style=display:flex><span>      version: 1967.5.0
</span></span><span style=display:flex><span>    nodeAgentSecretName: gardener-node-agent-local-ee46034b8269353b
</span></span><span style=display:flex><span>    nodeTemplate:
</span></span><span style=display:flex><span>      capacity:
</span></span><span style=display:flex><span>        cpu: 2
</span></span><span style=display:flex><span>        gpu: 0
</span></span><span style=display:flex><span>        memory: 8Gi
</span></span><span style=display:flex><span>    labels:
</span></span><span style=display:flex><span>      node.kubernetes.io/role: node
</span></span><span style=display:flex><span>      worker.gardener.cloud/cri-name: containerd
</span></span><span style=display:flex><span>      worker.gardener.cloud/pool: cpu-worker
</span></span><span style=display:flex><span>      worker.gardener.cloud/system-components: <span style=color:#a31515>&#34;true&#34;</span>
</span></span><span style=display:flex><span>    userDataSecretRef:
</span></span><span style=display:flex><span>      name: user-data-secret
</span></span><span style=display:flex><span>      key: cloud_config
</span></span><span style=display:flex><span>    volume:
</span></span><span style=display:flex><span>      size: 20Gi
</span></span><span style=display:flex><span>      type: gp2
</span></span><span style=display:flex><span>    zones:
</span></span><span style=display:flex><span>    - eu-west-1b
</span></span><span style=display:flex><span>    - eu-west-1c
</span></span><span style=display:flex><span>    machineControllerManager:
</span></span><span style=display:flex><span>      drainTimeout: 10m
</span></span><span style=display:flex><span>      healthTimeout: 10m
</span></span><span style=display:flex><span>      creationTimeout: 10m
</span></span><span style=display:flex><span>      maxEvictRetries: 30
</span></span><span style=display:flex><span>      nodeConditions:
</span></span><span style=display:flex><span>      - ReadonlyFilesystem
</span></span><span style=display:flex><span>      - DiskPressure
</span></span><span style=display:flex><span>      - KernelDeadlock
</span></span><span style=display:flex><span>    clusterAutoscaler:
</span></span><span style=display:flex><span>      scaleDownUtilizationThreshold: 0.5
</span></span><span style=display:flex><span>      scaleDownGpuUtilizationThreshold: 0.5
</span></span><span style=display:flex><span>      scaleDownUnneededTime: 30m
</span></span><span style=display:flex><span>      scaleDownUnreadyTime: 1h
</span></span><span style=display:flex><span>      maxNodeProvisionTime: 15m
</span></span></code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used to create the needed virtual machines.
Also, as you can see, Gardener copies the output of the infrastructure creation (<code>.spec.infrastructureProviderStatus</code>, see <a href=/docs/gardener/extensions/resources/infrastructure/><code>Infrastructure</code> resource</a>), into the <code>.spec</code>.</p><p>In the <code>.spec.pools[]</code> field, the desired worker pools are listed.
In the above example, one pool with machine type <code>m4.large</code> and <code>min=3</code>, <code>max=5</code> machines shall be spread over two availability zones (<code>eu-west-1b</code>, <code>eu-west-1c</code>).
This information together with the infrastructure status must be used to determine the proper configuration for the machine classes.</p><p>The <code>spec.pools[].labels</code> map contains all labels that should be added to all nodes of the corresponding worker pool.
Gardener configures kubelet&rsquo;s <code>--node-labels</code> flag to contain all labels that are mentioned here and allowed by the <a href=https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#noderestriction><code>NodeRestriction</code> admission plugin</a>.
This makes sure that kubelet adds all user-specified and gardener-managed labels to the new <code>Node</code> object when registering a new machine with the API server.
Nevertheless, this is only effective when bootstrapping new nodes.
The provider extension (respectively, machine-controller-manager) is still responsible for updating the labels of existing <code>Nodes</code> when the worker specification changes.</p><p>The <code>spec.pools[].nodeTemplate.capacity</code> field contains the resource information of the machine like <code>cpu</code>, <code>gpu</code>, and <code>memory</code>. This info is used by Cluster Autoscaler to generate <code>nodeTemplate</code> during scaling the <code>nodeGroup</code> from zero.</p><p>The <code>spec.pools[].machineControllerManager</code> field allows to configure the settings for machine-controller-manager component. Providers must populate these settings on worker-pool to the related <a href=https://github.com/gardener/machine-controller-manager/blob/master/kubernetes/machine_objects/machine-deployment.yaml#L30-L34>fields</a> in MachineDeployment.</p><p>The <code>spec.pools[].clusterAutoscaler</code> field contains <code>cluster-autoscaler</code> settings that are to be applied only to specific worker group. <code>cluster-autoscaler</code> expects to find these settings as annotations on the <code>MachineDeployment</code>, and so providers must pass these values to the corresponding <code>MachineDeployment</code> via annotations. The keys for these annotations can be found <a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_worker.go>here</a> and the values for the corresponding annotations should be the same as what is passed into the field. Providers can use the helper function <a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/helper/helper.go#L73><code>extensionsv1alpha1helper.GetMachineDeploymentClusterAutoscalerAnnotations</code></a> that returns the annotation map to be used.</p><p>The controller must only inject its provider-specific sidecar container into the <code>machine-controller-manager</code> <code>Deployment</code> managed by <code>gardenlet</code>.</p><p>After that, it must compute the desired machine classes and the desired machine deployments.
Typically, one class maps to one deployment, and one class/deployment is created per availability zone.
Following this convention, the created resource would look like this:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Secret
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: shoot--foo--bar-cpu-worker-z1-3db65
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    gardener.cloud/purpose: machineclass
</span></span><span style=display:flex><span>type: Opaque
</span></span><span style=display:flex><span>data:
</span></span><span style=display:flex><span>  providerAccessKeyId: eW91ci1hd3MtYWNjZXNzLWtleS1pZAo=
</span></span><span style=display:flex><span>  providerSecretAccessKey: eW91ci1hd3Mtc2VjcmV0LWFjY2Vzcy1rZXkK
</span></span><span style=display:flex><span>  userData: c29tZSBkYXRhIHRvIGJvb3RzdHJhcCB0aGUgVk0K
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: machine.sapcloud.io/v1alpha1
</span></span><span style=display:flex><span>kind: AWSMachineClass
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: shoot--foo--bar-cpu-worker-z1-3db65
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  ami: ami-0123456789 <span style=color:green># Your controller must map the stated version to the provider specific machine image information, in the AWS case the AMI.</span>
</span></span><span style=display:flex><span>  blockDevices:
</span></span><span style=display:flex><span>  - ebs:
</span></span><span style=display:flex><span>      volumeSize: 20
</span></span><span style=display:flex><span>      volumeType: gp2
</span></span><span style=display:flex><span>  iam:
</span></span><span style=display:flex><span>    name: shoot--foo--bar-nodes
</span></span><span style=display:flex><span>  keyName: shoot--foo--bar-ssh-publickey
</span></span><span style=display:flex><span>  machineType: m4.large
</span></span><span style=display:flex><span>  networkInterfaces:
</span></span><span style=display:flex><span>  - securityGroupIDs:
</span></span><span style=display:flex><span>    - sg-1234567890
</span></span><span style=display:flex><span>    subnetID: subnet-01234
</span></span><span style=display:flex><span>  region: eu-west-1
</span></span><span style=display:flex><span>  secretRef:
</span></span><span style=display:flex><span>    name: shoot--foo--bar-cpu-worker-z1-3db65
</span></span><span style=display:flex><span>    namespace: shoot--foo--bar
</span></span><span style=display:flex><span>  tags:
</span></span><span style=display:flex><span>    kubernetes.io/cluster/shoot--foo--bar: <span style=color:#a31515>&#34;1&#34;</span>
</span></span><span style=display:flex><span>    kubernetes.io/role/node: <span style=color:#a31515>&#34;1&#34;</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: machine.sapcloud.io/v1alpha1
</span></span><span style=display:flex><span>kind: MachineDeployment
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: shoot--foo--bar-cpu-worker-z1
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  replicas: 2
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      name: shoot--foo--bar-cpu-worker-z1
</span></span><span style=display:flex><span>  strategy:
</span></span><span style=display:flex><span>    type: RollingUpdate
</span></span><span style=display:flex><span>    rollingUpdate:
</span></span><span style=display:flex><span>      maxSurge: 1
</span></span><span style=display:flex><span>      maxUnavailable: 0
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        name: shoot--foo--bar-cpu-worker-z1
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      class:
</span></span><span style=display:flex><span>        kind: AWSMachineClass
</span></span><span style=display:flex><span>        name: shoot--foo--bar-cpu-worker-z1-3db65
</span></span></code></pre></div><p>for the first availability zone <code>eu-west-1b</code>, and</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Secret
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: shoot--foo--bar-cpu-worker-z2-5z6as
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    gardener.cloud/purpose: machineclass
</span></span><span style=display:flex><span>type: Opaque
</span></span><span style=display:flex><span>data:
</span></span><span style=display:flex><span>  providerAccessKeyId: eW91ci1hd3MtYWNjZXNzLWtleS1pZAo=
</span></span><span style=display:flex><span>  providerSecretAccessKey: eW91ci1hd3Mtc2VjcmV0LWFjY2Vzcy1rZXkK
</span></span><span style=display:flex><span>  userData: c29tZSBkYXRhIHRvIGJvb3RzdHJhcCB0aGUgVk0K
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: machine.sapcloud.io/v1alpha1
</span></span><span style=display:flex><span>kind: AWSMachineClass
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: shoot--foo--bar-cpu-worker-z2-5z6as
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  ami: ami-0123456789 <span style=color:green># Your controller must map the stated version to the provider specific machine image information, in the AWS case the AMI.</span>
</span></span><span style=display:flex><span>  blockDevices:
</span></span><span style=display:flex><span>  - ebs:
</span></span><span style=display:flex><span>      volumeSize: 20
</span></span><span style=display:flex><span>      volumeType: gp2
</span></span><span style=display:flex><span>  iam:
</span></span><span style=display:flex><span>    name: shoot--foo--bar-nodes
</span></span><span style=display:flex><span>  keyName: shoot--foo--bar-ssh-publickey
</span></span><span style=display:flex><span>  machineType: m4.large
</span></span><span style=display:flex><span>  networkInterfaces:
</span></span><span style=display:flex><span>  - securityGroupIDs:
</span></span><span style=display:flex><span>    - sg-1234567890
</span></span><span style=display:flex><span>    subnetID: subnet-0123a
</span></span><span style=display:flex><span>  region: eu-west-1
</span></span><span style=display:flex><span>  secretRef:
</span></span><span style=display:flex><span>    name: shoot--foo--bar-cpu-worker-z2-5z6as
</span></span><span style=display:flex><span>    namespace: shoot--foo--bar
</span></span><span style=display:flex><span>  tags:
</span></span><span style=display:flex><span>    kubernetes.io/cluster/shoot--foo--bar: <span style=color:#a31515>&#34;1&#34;</span>
</span></span><span style=display:flex><span>    kubernetes.io/role/node: <span style=color:#a31515>&#34;1&#34;</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: machine.sapcloud.io/v1alpha1
</span></span><span style=display:flex><span>kind: MachineDeployment
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: shoot--foo--bar-cpu-worker-z1
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  replicas: 1
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      name: shoot--foo--bar-cpu-worker-z1
</span></span><span style=display:flex><span>  strategy:
</span></span><span style=display:flex><span>    type: RollingUpdate
</span></span><span style=display:flex><span>    rollingUpdate:
</span></span><span style=display:flex><span>      maxSurge: 1
</span></span><span style=display:flex><span>      maxUnavailable: 0
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        name: shoot--foo--bar-cpu-worker-z1
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      class:
</span></span><span style=display:flex><span>        kind: AWSMachineClass
</span></span><span style=display:flex><span>        name: shoot--foo--bar-cpu-worker-z2-5z6as
</span></span></code></pre></div><p>for the second availability zone <code>eu-west-1c</code>.</p><p>Another convention is the 5-letter hash at the end of the machine class names.
Most controllers compute a checksum out of the specification of the machine class.
Any change to the value of the <code>nodeAgentSecretName</code> field must result in a change of the machine class name.
The checksum in the machine class name helps to trigger a rolling update of the worker nodes if, for example, the machine image version changes.
In this case, a new checksum will be generated which results in the creation of a new machine class.
The <code>MachineDeployment</code>&rsquo;s machine class reference (<code>.spec.template.spec.class.name</code>) is updated, which triggers the rolling update process in the machine-controller-manager.
However, all of this is only a convention that eases writing the controller, but you can do it completely differently if you desire - as long as you make sure that the described behaviours are implemented correctly.</p><p>After the machine classes and machine deployments have been created, the machine-controller-manager will start talking to the provider&rsquo;s IaaS API and create the virtual machines.
Gardener makes sure that the content of the <code>Secret</code> referenced in the <code>userDataSecretRef</code> field that is used to bootstrap the machines contains the required configuration for installation of the kubelet and registering the VM as worker node in the shoot cluster.
The <code>Worker</code> extension controller shall wait until all the created <code>MachineDeployment</code>s indicate healthiness/readiness before it ends the control loop.</p><h2 id=does-gardener-need-some-information-that-must-be-returned-back>Does Gardener need some information that must be returned back?</h2><p>Another important benefit of the machine-controller-manager&rsquo;s design principles (extending the Kubernetes API using CRDs) is that the <a href=https://github.com/gardener/autoscaler>cluster-autoscaler</a> can be used <strong>without</strong> any provider-specific implementation.
We have forked the <a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler>upstream Kubernetes community&rsquo;s cluster-autoscaler</a> and extended it so that it understands the machine API.
Definitely, we will merge it back into the community&rsquo;s versions once it has been adapted properly.</p><p>Our cluster-autoscaler only needs to know the minimum and maximum number of replicas <strong>per</strong> <code>MachineDeployment</code> and is ready to act. Without knowing that, it needs to talk to the provider APIs (it just modifies the <code>.spec.replicas</code> field in the <code>MachineDeployment</code> object).
Gardener deploys this autoscaler if there is at least one worker pool that specifies <code>max>min</code>.
In order to know how it needs to configure it, the provider-specific <code>Worker</code> extension controller must expose which <code>MachineDeployment</code>s it has created and how the <code>min</code>/<code>max</code> numbers should look like.</p><p>Consequently, your controller should write this information into the <code>Worker</code> resource&rsquo;s <code>.status.machineDeployments</code> field. It should also update the <code>.status.machineDeploymentsLastUpdateTime</code> field along with <code>.status.machineDeployments</code>, so that gardener is able to deploy Cluster-Autoscaler right after the status is updated with the latest <code>MachineDeployment</code>s and does not wait for the reconciliation to be completed:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: extensions.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Worker
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: worker
</span></span><span style=display:flex><span>  namespace: shoot--foo--bar
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  ...
</span></span><span style=display:flex><span>status:
</span></span><span style=display:flex><span>  lastOperation: ...
</span></span><span style=display:flex><span>  machineDeployments:
</span></span><span style=display:flex><span>  - name: shoot--foo--bar-cpu-worker-z1
</span></span><span style=display:flex><span>    minimum: 2
</span></span><span style=display:flex><span>    maximum: 3
</span></span><span style=display:flex><span>  - name: shoot--foo--bar-cpu-worker-z2
</span></span><span style=display:flex><span>    minimum: 1
</span></span><span style=display:flex><span>    maximum: 2
</span></span><span style=display:flex><span>  machineDeploymentsLastUpdateTime: <span style=color:#a31515>&#34;2023-05-01T12:44:27Z&#34;</span>
</span></span></code></pre></div><p>In order to support a new worker provider, you need to write a controller that watches all <code>Worker</code>s with <code>.spec.type=&lt;my-provider-name></code>.
You can take a look at the below referenced example implementation for the AWS provider.</p><h2 id=that-sounds-like-a-lot-that-needs-to-be-done-can-you-help-me>That sounds like a lot that needs to be done, can you help me?</h2><p>All of the described behaviour is mostly the same for every provider.
The only difference is maybe the version/configuration of the provider-specific <code>machine-controller-manager</code> sidecar container, and the machine class specification itself.
You can take a look at our <a href=https://github.com/gardener/gardener/tree/master/extensions>extension library</a>, especially the <a href=https://github.com/gardener/gardener/tree/master/extensions/pkg/controller/worker>worker controller</a> part where you will find a lot of utilities that you can use.
Note that there are also utility functions for getting the default sidecar container specification or corresponding VPA container policy in the <a href=https://github.com/gardener/gardener/tree/master/pkg/component/nodemanagement/machinecontrollermanager><code>machinecontrollermanager</code> package</a> called <code>ProviderSidecarContainer</code> and <code>ProviderSidecarVPAContainerPolicy</code>.
Also, using the library you only need to implement your provider specifics - all the things that can be handled generically can be taken for free and do not need to be re-implemented.
Take a look at the <a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/worker>AWS worker controller</a> for finding an example.</p><h2 id=non-provider-specific-information-required-for-worker-creation>Non-provider specific information required for worker creation</h2><p>All the providers require further information that is not provider specific but already part of the shoot resource.
One example for such information is whether the shoot is hibernated or not.
In this case, all the virtual machines should be deleted/terminated, and after that the machine controller-manager should be scaled down.
You can take a look at the <a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/worker>AWS worker controller</a> to see how it reads this information and how it is used.
As Gardener cannot know which information is required by providers, it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information that is not part of the <code>Worker</code> resource itself.</p><h2 id=references-and-additional-resources>References and Additional Resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_worker.go><code>Worker</code> API (Golang Specification)</a></li><li><a href=https://github.com/gardener/gardener/tree/master/extensions>Extension Controller Library</a></li><li><a href=https://github.com/gardener/gardener/tree/master/extensions/pkg/controller/worker>Generic Worker Controller</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/worker>Exemplary Implementation for the AWS Provider</a></li></ul></div></main></div></div><footer class="footer row d-print-none"><div class="container-fluid footer-wrapper"><ul class=nav><li><a href=https://gardener.cloud/blog/>Blogs</a></li><li><a href=https://gardener.cloud/community/>Community</a></li><li><a href=https://gardener.cloud/adopter/>Adopters</a></li><li><a href=/docs/>Documentation</a></li></ul><img src=/images/lp/gardener-logo.svg alt="Logo Gardener" class=logo><ul class=media-wr><li><a target=_blank href=https://kubernetes.slack.com/archives/CB57N0BFG><img src=/images/branding/slack-logo-white.svg class=media-icon><div class=media-text>Slack</div></a></li><li><a target=_blank href=https://github.com/gardener><img src=/images/branding/github-mark-logo.png class=media-icon><div class=media-text>GitHub</div></a></li><li><a target=_blank href=https://www.youtube.com/channel/UCwUhwKFREV8Su0gwAJQX7tw><img src=/images/branding/youtube-logo-dark.svg class=media-icon><div class=media-text>YouTube</div></a></li><li><a target=_blank href=https://twitter.com/GardenerProject><img src=/images/branding/twitter-logo-white.svg class=media-icon><div class=media-text>Twitter</div></a></li></ul><span class=copyright>Copyright 2019-2025 Gardener project authors. <a href=https://www.sap.com/corporate/en/legal/privacy.html>Privacy policy
<i class="fa fa-external-link" aria-hidden=true></i></a></span></div></footer></div><script src=/js/main.min.69e2c1ae9320465ab10236d9ef752c6a4442c54b48b883b17c497b7c7d96a796.js integrity="sha256-aeLBrpMgRlqxAjbZ73UsakRCxUtIuIOxfEl7fH2Wp5Y=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>