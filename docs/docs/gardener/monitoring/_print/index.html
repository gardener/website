<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.83.1"><link rel=canonical type=text/html href=https://gardener.cloud/docs/gardener/monitoring/><link rel=alternate type=application/rss+xml href=https://gardener.cloud/docs/gardener/monitoring/index.xml><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=icon type=image/x-icon href=https://gardener.cloud/images/favicon.ico><link rel=icon type=image/png href=https://gardener.cloud/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://gardener.cloud/images/favicon-16x16.png sizes=16x16><title>Monitoring | Gardener</title><meta name=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:title" content="Monitoring"><meta property="og:description" content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:type" content="website"><meta property="og:url" content="https://gardener.cloud/docs/gardener/monitoring/"><meta itemprop=name content="Monitoring"><meta itemprop=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta name=twitter:card content="summary"><meta name=twitter:title content="Monitoring"><meta name=twitter:description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><link rel=preload href=/scss/main.min.ca2e9ddee7809848b536632b41e4e4df665800778ffe11b75edde5bdd6c78963.css as=style><link href=/scss/main.min.ca2e9ddee7809848b536632b41e4e4df665800778ffe11b75edde5bdd6c78963.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://unpkg.com/lunr@2.3.8/lunr.min.js integrity=sha384-vRQ9bDyE0Wnu+lMfm57BlYLO0/XauFuKpVsZPs7KEDwYKktWi5+Kz3MP8++DFlRY crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg width="90" height="90" viewBox="0 0 90 90" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>logo</title><desc>Created with Sketch.</desc><defs><path d="M41.8864954.994901575c.996545099999999-.479910833 2.6164002-.477918931 3.6088091.0L76.8159138 16.0781121C77.8124589 16.5580229 78.8208647 17.8257185 79.0659694 18.8995926l7.7355517 33.8916663C87.0476474 53.8696088 86.6852538 55.4484075 85.9984855 56.3095876L64.3239514 83.4885938C63.6343208 84.3533632 62.1740175 85.0543973 61.0725268 85.0543973H26.3092731c-1.1060816.0-2.5646564-.704623400000003-3.2514246-1.5658035L1.38331434 56.3095876C.693683723 55.4448182.335174016 53.865133.580278769 52.7912589L8.31583044 18.8995926C8.56195675 17.8212428 9.57347722 16.556031 10.5658861 16.0781121L41.8864954.994901575z" id="path-1"/><linearGradient x1="12.7542673%" y1="-18.6617048%" x2="88.2666158%" y2="84.6075483%" id="linearGradient-3"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="50%" y1="4.93673768%" x2="148.756007%" y2="175.514523%" id="linearGradient-4"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="19.1574381%" y1="-9.04800713%" x2="82.2203149%" y2="77.9084293%" id="linearGradient-5"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="57.4403751%" y1="26.3148481%" x2="137.966711%" y2="158.080556%" id="linearGradient-6"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="logo"><g id="Rectangle-2" transform="translate(1.000000, 0.000000)"><mask id="mask-2" fill="#fff"><use xlink:href="#path-1"/></mask><use id="Mask" fill="#009f76" xlink:href="#path-1"/><polygon fill="#000" opacity=".289628623" mask="url(#mask-2)" points="-17.6484375 54.5224609 30.8242188 25.0791016 63.4726562 58.5 24.7324219 92.6689453"/></g><path d="M56.8508631 39.260019C56.4193519 40.443987 55.6088085 41.581593 54.6736295 42.1938694l-8.0738997 5.2861089c-1.3854671.907087099999998-3.6247515.9116711-5.0172201.0L33.50861 42.1938694C32.123143 41.2867823 31 39.206345 31 37.545932V26.4150304c0-.725313.2131118-1.5301454.569268099999999-2.2825772L56.8508631 39.260019z" id="Combined-Shape" fill="url(#linearGradient-3)" transform="translate(43.925432, 36.147233) scale(-1, 1) translate(-43.925432, -36.147233)"/><path d="M56.0774672 25.1412464C56.4306829 25.8903325 56.6425556 26.6907345 56.6425556 27.4119019V38.5428034c0 1.6598979-1.1161415 3.73626640000001-2.50861 4.6479374l-8.0738997 5.286109c-1.3854671.907087000000004-3.6247516.911671000000005-5.0172201.0L32.9689261 43.1907408C32.2918101 42.7474223 31.6773514 42.0238435 31.2260376 41.206007L56.0774672 25.1412464z" id="Combined-Shape" fill="url(#linearGradient-4)" transform="translate(43.821278, 37.246598) scale(-1, 1) translate(-43.821278, -37.246598)"/><path d="M65.0702134 57.1846889C64.5985426 58.2007851 63.8367404 59.1236871 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.1597438 58.7930183 24 56.7816693 24 55.1323495V37.1145303C24 36.3487436 24.249712 35.5060005 24.6599102 34.7400631L65.0702134 57.1846889z" id="Combined-Shape" fill="url(#linearGradient-5)"/><path d="M65.0189476 34.954538C65.3636909 35.6617313 65.5692194 36.42021 65.5692194 37.1145303V55.1323495C65.5692194 56.7842831 64.4072119 58.7943252 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.9237304 59.2341061 25.3159155 58.5918431 24.8568495 57.8487596L65.0189476 34.954538z" id="Combined-Shape" fill="url(#linearGradient-6)"/></g></g></svg></span><span class=text-capitalize>Gardener</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/adopter><span>Adopters</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog><span>Blogs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community><span>Community</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs><span>Documentation</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.2035d9813dafac83fe2a48b18d50f237.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/gardener/monitoring/>Return to the regular view of this page</a>.</p></div><h1 class=title>Monitoring</h1><div class=content><h1 id=monitoring>Monitoring</h1><h2 id=roles-of-the-different-prometheus-instances>Roles of the different Prometheus instances</h2><p><img src=/__resources/monitoring_06c124.png alt=monitoring></p><h3 id=prometheus>Prometheus</h3><p>Deployed in the <code>garden</code> namespace. Important scrape targets:</p><ul><li>cadvisor</li><li>node-exporter</li><li>kube-state-metrics</li></ul><p><strong>Purpose</strong>: Acts as a cache for other Prometheus instances. The metrics are kept for a short amount of time (~2 hours) due to the high cardinality. For example if another Prometheus needs access to cadvisor metrics it will query this Prometheus instead of the cadvisor. This also reduces load on the kubelets and API Server.</p><p>Some of the high cardinality metrics are aggregated with recording rules. These <em>pre-aggregated</em> metrics are scraped by the <a href=#aggregate-prometheus>Aggregate Prometheus</a>.</p><p>This Prometheus is not used for alerting.</p><h3 id=aggregate-prometheus>Aggregate Prometheus</h3><p>Deployed in the <code>garden</code> namespace. Important scrape targets:</p><ul><li>other prometheus instances</li><li>logging components</li></ul><p><strong>Purpose</strong>: Store pre-aggregated data from <a href=#prometheus>prometheus</a> and <a href=#shoot-prometheus>shoot prometheus</a>. An ingress exposes this Prometheus allowing it to be scraped from another cluster.</p><h3 id=seed-prometheus>Seed Prometheus</h3><p>Deployed in the <code>garden</code> namespace. Important scrape targets:</p><ul><li>pods in extension namespaces annotated with:</li></ul><pre><code>prometheus.io/scrape=true
prometheus.io/port=&lt;port&gt;
</code></pre><ul><li>cadvisor metrics from pods in the garden and extension namespaces</li></ul><p><strong>Purpose</strong>: Entrypoint for operators when debugging issues with extensions or other garden components.</p><h3 id=shoot-prometheus>Shoot Prometheus</h3><p>Deployed in the shoot control plane namespace. Important scrape targets:</p><ul><li>control plane components</li><li>shoot nodes (node-exporter)</li><li>blackbox-exporter used to measure <a href=/docs/gardener/monitoring/connectivity/>connectivity</a></li></ul><p><strong>Purpose</strong>: Monitor all relevant components belonging to a shoot cluster managed by Gardener. Shoot owners can view the metrics in Grafana dashboards and receive <a href=/docs/gardener/monitoring/user_alerts/>alerts</a> based on these metrics. Gardener operators will receive a different set of <a href=/docs/gardener/monitoring/operator_alerts/>alerts</a>. For alerting internals refer to <a href=/docs/gardener/monitoring/alerting/>this</a> document.</p><h2 id=collect-all-shoot-prometheus-with-remote-write>Collect all Shoot Prometheus with remote write</h2><p>An optional collection of all Shoot Prometheus metrics to a central prometheus (or cortex) instance is possible with the <code>monitoring.shoot</code> setting in <code>GardenletConfiguration</code>:</p><pre><code>monitoring:
  shoot:
    remoteWrite:
      url: https://remoteWriteUrl # remote write URL
      keep:# metrics that should be forwarded to the external write endpoint. If empty all metrics get forwarded
      - kube_pod_container_info
      queueConfig: | # queue_config of prometheus remote write as multiline string
        max_shards: 100
        batch_send_deadline: 20s
        min_backoff: 500ms
        max_backoff: 60s
    externalLabels: # add additional labels to metrics to identify it on the central instance
      additional: label
</code></pre><p>If basic auth is needed it can be set via secret in garden namespace (Gardener API Server). <a href=https://github.com/gardener/gardener/blob/master/example/10-secret-remote-write.yaml>Example secret</a></p></div></div><div class=td-content style=page-break-before:always><h1 id=pg-954b7364e06db9899aa6264a5b0a9e91>1 - Alerting</h1><h1 id=alerting>Alerting</h1><p>Gardener uses <a href=https://prometheus.io/>Prometheus</a> to gather metrics from each component. A Prometheus is deployed in each shoot control plane (on the seed) which is responsible for gathering control plane and cluster metrics. Prometheus can be configured to fire alerts based on these metrics and send them to an <a href=https://prometheus.io/docs/alerting/alertmanager/>alertmanager</a>. The alertmanager is responsible for sending the alerts to users and operators. This document describes how to setup alerting for:</p><ul><li><a href=#Alerting-for-Users>end-users/stakeholders/customers</a></li><li><a href=#Alerting-for-Operators>operators/administrators</a></li></ul><h1 id=alerting-for-users>Alerting for Users</h1><p>To receive email alerts as a user set the following values in the shoot spec:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>spec:
  monitoring:
    alerting:
      emailReceivers:
      - john.doe@example.com
</code></pre></div><p><code>emailReceivers</code> is a list of emails that will receive alerts if something is wrong with the shoot cluster. A list of alerts for users can be found <a href=/docs/gardener/monitoring/user_alerts/>here</a>.</p><h1 id=alerting-for-operators>Alerting for Operators</h1><p>Currently, Gardener supports two options for alerting:</p><ul><li><a href=#Email-Alerting>Email Alerting</a></li><li><a href=#External-Alertmanager>Sending Alerts to an external alertmanager</a></li></ul><p>A list of operator alerts can be found <a href=/docs/gardener/monitoring/operator_alerts/>here</a>.</p><h2 id=email-alerting>Email Alerting</h2><p>Gardener provides the option to deploy an alertmanager into each seed. This alertmanager is responsible for sending out alerts to operators for each shoot cluster in the seed. Only email alerts are supported by the alertmanager managed by Gardener. This is configurable by setting the Gardener controller manager configuration values <code>alerting</code>. See <a href=/docs/gardener/usage/configuration/>this</a> on how to configure the Gardener&rsquo;s SMTP secret. If the values are set, a secret with the label <code>gardener.cloud/role: alerting</code> will be created in the garden namespace of the garden cluster. This secret will be used by each alertmanager in each seed.</p><h2 id=external-alertmanager>External Alertmanager</h2><p>The alertmanager supports different kinds of <a href=https://prometheus.io/docs/alerting/configuration/>alerting configurations</a>. The alertmanager provided by Gardener only supports email alerts. If email is not sufficient, then alerts can be sent to an external alertmanager. Prometheus will send alerts to a URL and then alerts will be handled by the external alertmanager. This external alertmanager is operated and configured by the operator (i.e. Gardener does not configure or deploy this alertmanager). To configure sending alerts to an external alertmanager, create a secret in the virtual garden cluster in the garden namespace with the label: <code>gardener.cloud/role: alerting</code>. This secret needs to contain a URL to the external alertmanager and information regarding authentication. Supported authentication types are:</p><ul><li>No Authentication (none)</li><li>Basic Authentication (basic)</li><li>Mutual TLS (certificate)</li></ul><h3 id=remote-alertmanager-examples>Remote Alertmanager Examples</h3><p>Note: the <code>url</code> value cannot be prepended with <code>http</code> or <code>https</code>.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green># No Authentication</span>
apiVersion: v1
kind: Secret
metadata:
  labels:
    gardener.cloud/role: alerting
  name: alerting-auth
  namespace: garden
data:
  <span style=color:green># No Authentication</span>
  auth_type: base64(none)
  url: base64(external.alertmanager.foo)

  <span style=color:green># Basic Auth</span>
  auth_type: base64(basic)
  url: base64(extenal.alertmanager.foo)
  username: base64(admin)
  password: base64(password)

  <span style=color:green># Mutual TLS</span>
  auth_type: base64(certificate)
  url: base64(external.alertmanager.foo)
  ca.crt: base64(ca)
  tls.crt: base64(certificate)
  tls.key: base64(key)
  insecure_skip_verify: base64(false)

  <span style=color:green># Email Alerts (internal alertmanager)</span>
  auth_type: base64(smtp)
  auth_identity: base64(internal.alertmanager.auth_identity)
  auth_password: base64(internal.alertmanager.auth_password)
  auth_username: base64(internal.alertmanager.auth_username)
  from: base64(internal.alertmanager.from)
  smarthost: base64(internal.alertmanager.smarthost)
  to: base64(internal.alertmanager.to)
type: Opaque
</code></pre></div><h3 id=configuring-your-external-alertmanager>Configuring your External Alertmanager</h3><p>Please refer to the <a href=https://prometheus.io/docs/alerting/alertmanager/>alertmanager</a> documentation on how to configure an alertmanager.</p><p>We recommend you use at least the following inhibition rules in your alertmanager configuration to prevent excessive alerts:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>inhibit_rules:
<span style=color:green># Apply inhibition if the alert name is the same.</span>
- source_match:
    severity: critical
  target_match:
    severity: warning
  equal: [<span style=color:#a31515>&#39;alertname&#39;</span>, <span style=color:#a31515>&#39;service&#39;</span>, <span style=color:#a31515>&#39;cluster&#39;</span>]

<span style=color:green># Stop all alerts for type=shoot if there are VPN problems.</span>
- source_match:
    service: vpn
  target_match_re:
    type: shoot
  equal: [<span style=color:#a31515>&#39;type&#39;</span>, <span style=color:#a31515>&#39;cluster&#39;</span>]

<span style=color:green># Stop warning and critical alerts if there is a blocker</span>
- source_match:
    severity: blocker
  target_match_re:
    severity: ^(critical|warning)$
  equal: [<span style=color:#a31515>&#39;cluster&#39;</span>]

<span style=color:green># If the API server is down inhibit no worker nodes alert. No worker nodes depends on kube-state-metrics which depends on the API server.</span>
- source_match:
    service: kube-apiserver
  target_match_re:
    service: nodes
  equal: [<span style=color:#a31515>&#39;cluster&#39;</span>]

<span style=color:green># If API server is down inhibit kube-state-metrics alerts.</span>
- source_match:
    service: kube-apiserver
  target_match_re:
    severity: info
  equal: [<span style=color:#a31515>&#39;cluster&#39;</span>]

<span style=color:green># No Worker nodes depends on kube-state-metrics. Inhibit no worker nodes if kube-state-metrics is down.</span>
- source_match:
    service: kube-state-metrics-shoot
  target_match_re:
    service: nodes
  equal: [<span style=color:#a31515>&#39;cluster&#39;</span>]
</code></pre></div><p>Below is a graph visualizing the inhibition rules:</p><p><img src=/__resources/alertInhibitionGraph_ceaef0.png alt=inhibitionGraph></p></div><div class=td-content style=page-break-before:always><h1 id=pg-7c33abee93181fcc22c3692c1a9c8f2a>2 - Connectivity</h1><h1 id=connectivity>Connectivity</h1><h2 id=shoot-connectivity>Shoot Connectivity</h2><p>We measure the connectivity from the shoot to the API Server. This is done via the <code>blackbox exporter</code> which is deployed in the shoot&rsquo;s <code>kube-system</code> namespace. Prometheus will scrape the <code>blackbox exporter</code> and then the exporter will try to access the API Server. Metrics are exposed if the connection was successful or not. This can be seen in the dashboard <code>Kubernetes Control Plane Status</code> dashboard under the <code>API Server Connectivity</code> panel. The <code>shoot</code> line represents the connectivity from the shoot.</p><p><img src=/__resources/panel_393a41.png alt=image></p><h2 id=seed-connectivity>Seed Connectivity</h2><p>In addition to the shoot connectivity, we also measure the seed connectivity. This means trying to reach the API Server from the seed via the external fully qualified domain name of the API server. The connectivity is also displayed in the above panel as the <code>seed</code> line. Both <code>seed</code> and <code>shoot</code> connectivity are shown below.</p><p><img src=/__resources/connectivity_b79584.png alt=image></p></div><div class=td-content style=page-break-before:always><h1 id=pg-52cd1f12c4a525b9382c2ae0184ec4c3>3 - Operator Alerts</h1><h1 id=operator-alerts>Operator Alerts</h1><table><thead><tr><th>Alertname</th><th>Severity</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td>ApiServerUnreachableViaKubernetesService</td><td>critical</td><td>shoot</td><td><code>The Api server has been unreachable for 3 minutes via the kubernetes service in the shoot.</code></td></tr><tr><td>KubeletTooManyOpenFileDescriptorsSeed</td><td>critical</td><td>seed</td><td><code>Seed-kubelet ({{ $labels.kubernetes_io_hostname }}) is using {{ $value }}% of the available file/socket descriptors. Kubelet could be under heavy load.</code></td></tr><tr><td>KubePersistentVolumeUsageCritical</td><td>critical</td><td>seed</td><td><code>The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} is only {{ printf "%0.2f" $value }}% free.</code></td></tr><tr><td>KubePersistentVolumeFullInFourDays</td><td>warning</td><td>seed</td><td><code>Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} is expected to fill up within four days. Currently {{ printf "%0.2f" $value }}% is available.</code></td></tr><tr><td>KubePodPendingControlPlane</td><td>warning</td><td>seed</td><td><code>Pod {{ $labels.pod }} is stuck in "Pending" state for more than 30 minutes.</code></td></tr><tr><td>KubePodNotReadyControlPlane</td><td>warning</td><td></td><td><code>Pod {{ $labels.pod }} is not ready for more than 30 minutes.</code></td></tr><tr><td>KubeStateMetricsShootDown</td><td>info</td><td>seed</td><td><code>There are no running kube-state-metric pods for the shoot cluster. No kubernetes resource metrics can be scraped.</code></td></tr><tr><td>KubeStateMetricsSeedDown</td><td>critical</td><td>seed</td><td><code>There are no running kube-state-metric pods for the seed cluster. No kubernetes resource metrics can be scraped.</code></td></tr><tr><td>NoWorkerNodes</td><td>blocker</td><td></td><td><code>There are no worker nodes in the cluster or all of the worker nodes in the cluster are not schedulable.</code></td></tr><tr><td>PrometheusCantScrape</td><td>warning</td><td>seed</td><td><code>Prometheus failed to scrape metrics. Instance {{ $labels.instance }}, job {{ $labels.job }}.</code></td></tr><tr><td>PrometheusConfigurationFailure</td><td>warning</td><td>seed</td><td><code>Latest Prometheus configuration is broken and Prometheus is using the previous one.</code></td></tr><tr><td>VPNProbeAPIServerProxyFailed</td><td>critical</td><td>shoot</td><td><code>The API Server proxy functionality is not working. Probably the vpn connection from an API Server pod to the vpn-shoot endpoint on the Shoot workers does not work.</code></td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-4bd3553c7141772a5c5be0814ce3145b>4 - Profiling</h1><h1 id=profiling-gardener-components>Profiling Gardener Components</h1><p>Similar to Kubernetes, Gardener components support profiling using <a href=https://golang.org/doc/diagnostics#profiling>standard Go tools</a> for analyzing CPU and memory usage by different code sections and more.
This document shows how to enable and use profiling handlers with Gardener components.</p><p>Enabling profiling handlers and the ports on which they are exposed differs between components.
However, once the handlers are enabled, they provide profiles via the same HTTP endpoint paths, from which you can retrieve them via <code>curl</code>/<code>wget</code> or directly using <code>go tool pprof</code>.
(You might need to use <code>kubectl port-forward</code> in order to access HTTP endpoints of Gardener components running in clusters.)</p><p>For example (gardener-controller-manager):</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ curl http://localhost:2718/debug/pprof/heap &gt; /tmp/heap-controller-manager
$ go tool pprof /tmp/heap-controller-manager
Type: inuse_space
Time: Sep 3, 2021 at 10:05am (CEST)
Entering interactive mode (type <span style=color:#a31515>&#34;help&#34;</span> <span style=color:#00f>for</span> commands, <span style=color:#a31515>&#34;o&#34;</span> <span style=color:#00f>for</span> options)
(pprof)
</code></pre></div><p>or</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ go tool pprof http://localhost:2718/debug/pprof/heap
Fetching profile over HTTP from http://localhost:2718/debug/pprof/heap
Saved profile in /Users/timebertt/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.008.pb.gz
Type: inuse_space
Time: Sep 3, 2021 at 10:05am (CEST)
Entering interactive mode (type <span style=color:#a31515>&#34;help&#34;</span> <span style=color:#00f>for</span> commands, <span style=color:#a31515>&#34;o&#34;</span> <span style=color:#00f>for</span> options)
(pprof)
</code></pre></div><h2 id=gardener-apiserver>gardener-apiserver</h2><p>gardener-apiserver provides the same flags as kube-apiserver for enabling profiling handlers (enabled by default):</p><pre><code>--contention-profiling    Enable lock contention profiling, if profiling is enabled
--profiling               Enable profiling via web interface host:port/debug/pprof/ (default true)
</code></pre><p>The handlers are served on the same port as the API endpoints (configured via <code>--secure-port</code>).
This means, you will also have to authenticate against the API server according to the configured authentication and authorization policy.</p><p>For example, in the <a href=/docs/gardener/development/local_setup/>local-setup</a> you can use:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ curl -k --cert ./hack/local-development/local-garden/certificates/certs/default-admin.crt --key ./hack/local-development/local-garden/certificates/keys/default-admin.key https://localhost:8443/debug/pprof/heap &gt; /tmp/heap-apiserver
$ go tool pprof /tmp/heap-apiserver
</code></pre></div><h2 id=gardener-controller-manager-gardenlet>gardener-controller-manager, gardenlet</h2><p>gardener-controller-manager and gardenlet allow enabling profiling handlers via their respective component configs (currently disabled by default):</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: gardenlet.config.gardener.cloud/v1alpha1
kind: GardenletConfiguration
<span style=color:green># ...</span>
server:
  https:
    port: 2720
debugging:
  enableProfiling: <span style=color:#00f>true</span>
  enableContentionProfiling: <span style=color:#00f>true</span>
</code></pre></div><p>The handlers are served on the same port as configured in <code>server.http(s).port</code> via HTTP or HTTPS respectively.</p><p>For example (gardenlet with HTTPS configured):</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ curl -k https://localhost:2720/debug/pprof/heap &gt; /tmp/heap-gardenlet
$ go tool pprof /tmp/heap-gardenlet
</code></pre></div><h2 id=gardener-admission-controller-gardener-scheduler>gardener-admission-controller, gardener-scheduler</h2><p>gardener-admission-controller and gardener-scheduler also allow enabling profiling handlers via their respective component configs (currently disabled by default):</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: admissioncontroller.config.gardener.cloud/v1alpha1
kind: AdmissionControllerConfiguration
<span style=color:green># ...</span>
server:
  metrics:
    port: 2723
debugging:
  enableProfiling: <span style=color:#00f>true</span>
  enableContentionProfiling: <span style=color:#00f>true</span>
</code></pre></div><p>However, the handlers are served on the same port as configured in <code>server.metrics.port</code> via HTTP.</p><p>For example (gardener-admission-controller):</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>$ curl http://localhost:2723/debug/pprof/heap &gt; /tmp/heap-admission-controller
$ go tool pprof /tmp/heap-admission-controller
</code></pre></div><h2 id=gardener-seed-admission-controller>gardener-seed-admission-controller</h2><p>gardener-seed-admission-controller doesn&rsquo;t support profiling yet. See <a href=https://github.com/gardener/gardener/issues/4567>gardener/gardener#4567</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-e5728941ab1558f050d903ea1fc6ece4>5 - User Alerts</h1><h1 id=user-alerts>User Alerts</h1><table><thead><tr><th>Alertname</th><th>Severity</th><th>Type</th><th>Description</th></tr></thead><tbody><tr><td>ApiServerUnreachableViaKubernetesService</td><td>critical</td><td>shoot</td><td><code>The Api server has been unreachable for 3 minutes via the kubernetes service in the shoot.</code></td></tr><tr><td>KubeKubeletNodeDown</td><td>warning</td><td>shoot</td><td><code>The kubelet {{ $labels.instance }} has been unavailable/unreachable for more than 1 hour. Workloads on the affected node may not be schedulable.</code></td></tr><tr><td>KubeletTooManyOpenFileDescriptorsShoot</td><td>warning</td><td>shoot</td><td><code>Shoot-kubelet ({{ $labels.kubernetes_io_hostname }}) is using {{ $value }}% of the available file/socket descriptors. Kubelet could be under heavy load.</code></td></tr><tr><td>KubeletTooManyOpenFileDescriptorsShoot</td><td>critical</td><td>shoot</td><td><code>Shoot-kubelet ({{ $labels.kubernetes_io_hostname }}) is using {{ $value }}% of the available file/socket descriptors. Kubelet could be under heavy load.</code></td></tr><tr><td>KubePodPendingShoot</td><td>warning</td><td>shoot</td><td><code>Pod {{ $labels.pod }} is stuck in "Pending" state for more than 1 hour.</code></td></tr><tr><td>KubePodNotReadyShoot</td><td>warning</td><td>shoot</td><td><code>Pod {{ $labels.pod }} is not ready for more than 1 hour.</code></td></tr><tr><td>NoWorkerNodes</td><td>blocker</td><td></td><td><code>There are no worker nodes in the cluster or all of the worker nodes in the cluster are not schedulable.</code></td></tr><tr><td>NodeExporterDown</td><td>warning</td><td>shoot</td><td><code>The NodeExporter has been down or unreachable from Prometheus for more than 1 hour.</code></td></tr><tr><td>K8SNodeOutOfDisk</td><td>critical</td><td>shoot</td><td><code>Node {{ $labels.node }} has run out of disk space.</code></td></tr><tr><td>K8SNodeMemoryPressure</td><td>warning</td><td>shoot</td><td><code>Node {{ $labels.node }} is under memory pressure.</code></td></tr><tr><td>K8SNodeDiskPressure</td><td>warning</td><td>shoot</td><td><code>Node {{ $labels.node }} is under disk pressure</code></td></tr><tr><td>VMRootfsFull</td><td>critical</td><td>shoot</td><td><code>Root filesystem device on instance {{ $labels.instance }} is almost full.</code></td></tr><tr><td>VMConntrackTableFull</td><td>critical</td><td>shoot</td><td><code>The nf_conntrack table is {{ $value }}% full.</code></td></tr><tr><td>VPNProbeAPIServerProxyFailed</td><td>critical</td><td>shoot</td><td><code>The API Server proxy functionality is not working. Probably the vpn connection from an API Server pod to the vpn-shoot endpoint on the Shoot workers does not work.</code></td></tr></tbody></table></div></main></div></div><footer class="footer row d-print-none"><div class="container-fluid footer-wrapper"><ul class=nav><li><a href=https://gardener.cloud/blog/>Blogs</a></li><li><a href=https://gardener.cloud/community/>Community</a></li><li><a href=https://gardener.cloud/adopter/>Adopters</a></li><li><a href=/docs/>Documentation</a></li></ul><img src=/images/lp/gardener-logo.svg alt="Logo Gardener" class=logo><ul class=media-wr><li><a target=_blank href=https://kubernetes.slack.com/archives/CB57N0BFG><img src=/images/branding/slack-logo-white.svg class=media-icon><div class=media-text>Slack</div></a></li><li><a target=_blank href=https://github.com/gardener><img src=/images/branding/github-mark-logo.png class=media-icon><div class=media-text>GitHub</div></a></li><li><a target=_blank href=https://www.youtube.com/channel/UCwUhwKFREV8Su0gwAJQX7tw><img src=/images/branding/youtube-logo-dark.svg class=media-icon><div class=media-text>YouTube</div></a></li><li><a target=_blank href=https://twitter.com/GardenerProject><img src=/images/branding/twitter-logo-white.svg class=media-icon><div class=media-text>Twitter</div></a></li></ul><span class=copyright>Copyright 2019-2022 Gardener project authors. <a href=https://www.sap.com/corporate/en/legal/privacy.html>Privacy policy
<i class="fa fa-external-link" aria-hidden=true></i></a></span></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js integrity=sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/mermaid@8.9.2/dist/mermaid.min.js integrity=sha384-uQikAXnCAqsMb3ygtdqBYvcwvHUkzGIpjdGyy9owhURXHUxLC5LgTcSxJQH/RzjK crossorigin=anonymous></script><script src=/js/main.min.ef8e0714aff556fd5a9768ed6ecabd2964dd962cd9f89762a373947bb53bc742.js integrity="sha256-744HFK/1Vv1al2jtbsq9KWTdlizZ+Jdio3OUe7U7x0I=" crossorigin=anonymous></script></body></html>