<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gardener – Docs</title><link>https://gardener.cloud/docs/</link><description>Recent content in Docs on Gardener</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Wed, 20 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://gardener.cloud/docs/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Gardenctl V2</title><link>https://gardener.cloud/docs/gardenctl-v2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardenctl-v2/</guid><description>
&lt;h1 id="gardenctl-v2">gardenctl-v2&lt;/h1>
&lt;p>&lt;img src="https://github.com/gardener/gardenctl-v2/raw/DEFAULT_BRANCH/logo/logo_gardener_cli_large.png" alt="">&lt;/p>
&lt;p>&lt;a href="https://goreportcard.com/report/github.com/gardener/gardenctl-v2">&lt;img src="https://goreportcard.com/badge/github.com/gardener/gardenctl-v2" alt="Go Report Card">&lt;/a>
&lt;a href="https://badge.fury.io/gh/gardener%2Fgardenctl-v2">&lt;img src="https://badge.fury.io/gh/gardener%2Fgardenctl-v2.svg" alt="release">&lt;/a>
&lt;a href="https://reuse.software/">&lt;img src="https://reuse.software/badge/reuse-compliant.svg" alt="reuse compliant">&lt;/a>&lt;/p>
&lt;h2 id="what-is-gardenctl">What is &lt;code>gardenctl&lt;/code>?&lt;/h2>
&lt;p>gardenctl is a command-line client for the Gardener. It facilitates the administration of one or many garden, seed and shoot clusters. Use this tool to configure access to clusters and configure cloud provider CLI tools. It also provides support for accessing cluster nodes via ssh.&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>Install the latest release from &lt;a href="https://brew.sh/">Homebrew&lt;/a>, &lt;a href="https://chocolatey.org/packages/gardenctl">Chocolatey&lt;/a> or &lt;a href="https://github.com/gardener/gardenctl-v2/releases">GitHub Releases&lt;/a>.&lt;/p>
&lt;h3 id="install-using-package-managers">Install using Package Managers&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Homebrew (macOS and Linux)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>brew install gardener/tap/gardenctl-v2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Chocolatey (Windows)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>choco install gardenctl-v2
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Attention &lt;code>brew&lt;/code> users: &lt;code>gardenctl-v2&lt;/code> uses the same binary name as the legacy &lt;code>gardenctl&lt;/code> (&lt;code>gardener/gardenctl&lt;/code>) CLI. If you have an existing installation you should remove it with &lt;code>brew uninstall gardenctl&lt;/code> before attempting to install &lt;code>gardenctl-v2&lt;/code>. Alternatively, you can choose to link the binary using a different name. If you try to install without removing or relinking the old installation, brew will run into an error and provide instructions how to resolve it.&lt;/p>
&lt;h3 id="install-from-github-release">Install from Github Release&lt;/h3>
&lt;p>If you install via GitHub releases, you need to put the &lt;code>gardenctl&lt;/code> binary on your path. The other install methods do this for you.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Example for macOS&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># set operating system and architecture&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>os=darwin &lt;span style="color:#008000"># choose between darwin, linux, windows&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>arch=amd64 &lt;span style="color:#008000"># choose between amd64, arm64&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Get latest version. Alternatively set your desired version&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>version=&lt;span style="color:#00f">$(&lt;/span>curl -s https://raw.githubusercontent.com/gardener/gardenctl-v2/master/LATEST&lt;span style="color:#00f">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Download gardenctl&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>curl -LO &lt;span style="color:#a31515">&amp;#34;https://github.com/gardener/gardenctl-v2/releases/download/&lt;/span>&lt;span style="color:#a31515">${&lt;/span>version&lt;span style="color:#a31515">}&lt;/span>&lt;span style="color:#a31515">/gardenctl_v2_&lt;/span>&lt;span style="color:#a31515">${&lt;/span>os&lt;span style="color:#a31515">}&lt;/span>&lt;span style="color:#a31515">_&lt;/span>&lt;span style="color:#a31515">${&lt;/span>arch&lt;span style="color:#a31515">}&lt;/span>&lt;span style="color:#a31515">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Make the gardenctl binary executable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>chmod +x &lt;span style="color:#a31515">&amp;#34;./gardenctl_v2_&lt;/span>&lt;span style="color:#a31515">${&lt;/span>os&lt;span style="color:#a31515">}&lt;/span>&lt;span style="color:#a31515">_&lt;/span>&lt;span style="color:#a31515">${&lt;/span>arch&lt;span style="color:#a31515">}&lt;/span>&lt;span style="color:#a31515">&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Move the binary in to your PATH&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>sudo mv &lt;span style="color:#a31515">&amp;#34;./gardenctl_v2_&lt;/span>&lt;span style="color:#a31515">${&lt;/span>os&lt;span style="color:#a31515">}&lt;/span>&lt;span style="color:#a31515">_&lt;/span>&lt;span style="color:#a31515">${&lt;/span>arch&lt;span style="color:#a31515">}&lt;/span>&lt;span style="color:#a31515">&amp;#34;&lt;/span> /usr/local/bin/gardenctl
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="configuration">Configuration&lt;/h2>
&lt;p>&lt;code>gardenctl&lt;/code> requires a configuration file. The default location is in &lt;code>~/.garden/gardenctl-v2.yaml&lt;/code>.&lt;/p>
&lt;p>You can modify this file directly using the &lt;code>gardenctl config&lt;/code> command. It allows adding, modifying and deleting gardens.&lt;/p>
&lt;p>Example &lt;code>config&lt;/code> command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Adapt the path to your kubeconfig file for the garden cluster&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export KUBECONFIG=~/relative/path/to/kubeconfig.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Fetch cluster-identity of garden cluster&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>CLUSTER_IDENTITY=&lt;span style="color:#00f">$(&lt;/span>kubectl -n kube-system get configmap cluster-identity -ojsonpath={.data.cluster-identity}&lt;span style="color:#00f">)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Configure garden cluster&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gardenctl config set-garden $CLUSTER_IDENTITY --kubeconfig $KUBECONFIG
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This command will create or update a garden with the provided identity and kubeconfig path of your garden cluster.&lt;/p>
&lt;h3 id="example-config">Example Config&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>gardens:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- identity: landscape-dev &lt;span style="color:#008000"># Unique identity of the garden cluster. See cluster-identity ConfigMap in kube-system namespace of the garden cluster&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kubeconfig: ~/relative/path/to/kubeconfig.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># context: different-context # Overrides the current-context of the garden cluster kubeconfig &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># patterns: ~ # List of regex patterns for pattern targeting&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Note: You need to have &lt;a href="https://github.com/gardener/gardenlogin">gardenlogin&lt;/a> installed as &lt;code>kubectl&lt;/code> plugin in order to use the &lt;code>kubeconfig&lt;/code>s for &lt;code>Shoot&lt;/code> clusters provided by &lt;code>gardenctl&lt;/code>.&lt;/p>
&lt;h3 id="config-path-overwrite">Config Path Overwrite&lt;/h3>
&lt;ul>
&lt;li>The &lt;code>gardenctl&lt;/code> config path can be overwritten with the environment variable &lt;code>GCTL_HOME&lt;/code>.&lt;/li>
&lt;li>The &lt;code>gardenctl&lt;/code> config name can be overwritten with the environment variable &lt;code>GCTL_CONFIG_NAME&lt;/code>.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>export GCTL_HOME=/alternate/garden/config/dir
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>export GCTL_CONFIG_NAME=myconfig &lt;span style="color:#008000"># without extension!&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># config is expected to be under /alternate/garden/config/dir/myconfig.yaml&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="shell-session">Shell Session&lt;/h3>
&lt;p>The state of gardenctl is bound to a shell session and is not shared across windows, tabs or panes.
A shell session is defined by the environment variable &lt;code>GCTL_SESSION_ID&lt;/code>. If this is not defined,
the value of the &lt;code>TERM_SESSION_ID&lt;/code> environment variable is used instead. If both are not defined,
this leads to an error and gardenctl cannot be executed. The &lt;code>target.yaml&lt;/code> and temporary
&lt;code>kubeconfig.*.yaml&lt;/code> files are store in the following directory &lt;code>${TMPDIR}/garden/${GCTL_SESSION_ID}&lt;/code>.&lt;/p>
&lt;p>You can make sure that &lt;code>GCTL_SESSION_ID&lt;/code> or &lt;code>TERM_SESSION_ID&lt;/code> is always present by adding
the following code to your terminal profile &lt;code>~/.profile&lt;/code>, &lt;code>~/.bashrc&lt;/code> or comparable file.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>bash and zsh: [ -n &lt;span style="color:#a31515">&amp;#34;&lt;/span>$GCTL_SESSION_ID&lt;span style="color:#a31515">&amp;#34;&lt;/span> ] || [ -n &lt;span style="color:#a31515">&amp;#34;&lt;/span>$TERM_SESSION_ID&lt;span style="color:#a31515">&amp;#34;&lt;/span> ] || export GCTL_SESSION_ID=&lt;span style="color:#00f">$(&lt;/span>uuidgen&lt;span style="color:#00f">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>fish: [ -n &lt;span style="color:#a31515">&amp;#34;&lt;/span>$GCTL_SESSION_ID&lt;span style="color:#a31515">&amp;#34;&lt;/span> ] || [ -n &lt;span style="color:#a31515">&amp;#34;&lt;/span>$TERM_SESSION_ID&lt;span style="color:#a31515">&amp;#34;&lt;/span> ] || set -gx GCTL_SESSION_ID (uuidgen)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-ps" data-lang="ps">&lt;span style="display:flex;">&lt;span>powershell: if &lt;span style="color:#a31515">( !(Test-Path Env:GCTL_SESSION_ID) -and !(Test-Path Env:TERM_SESSION_ID) )&lt;/span> { $Env:GCTL_SESSION_ID = [guid]::NewGuid&lt;span style="color:#a31515">()&lt;/span>.ToString&lt;span style="color:#a31515">()&lt;/span> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="completion">Completion&lt;/h3>
&lt;p>Gardenctl supports completion that will help you working with the CLI and save you typing effort.
It will also help you find clusters by providing suggestions for gardener resources such as shoots or projects.
Completion is supported for &lt;code>bash&lt;/code>, &lt;code>zsh&lt;/code>, &lt;code>fish&lt;/code> and &lt;code>powershell&lt;/code>.
You will find more information on how to configure your shell completion for gardenctl by executing the help for
your shell completion command. Example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>gardenctl completion bash --help
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="usage">Usage&lt;/h2>
&lt;h3 id="targeting">Targeting&lt;/h3>
&lt;p>You can set a target to use it in subsequent commands. You can also overwrite the target for each command individually.&lt;/p>
&lt;p>Note that this will not affect your KUBECONFIG env variable. To update the KUBECONFIG env for your current target see &lt;a href="#configure-kubeconfig-for-shoot-clusters">Configure KUBECONFIG&lt;/a> section&lt;/p>
&lt;p>Example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># target control plane&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gardenctl target --garden landscape-dev --project my-project --shoot my-shoot --control-plane
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Find more information in the &lt;a href="https://github.com/gardener/gardenctl-v2/blob/DEFAULT_BRANCH/docs/usage/targeting.md">documentation&lt;/a>.&lt;/p>
&lt;h3 id="configure-kubeconfig-for-shoot-clusters">Configure KUBECONFIG for Shoot Clusters&lt;/h3>
&lt;p>Generate a script that points KUBECONFIG to the targeted cluster for the specified shell. Use together with &lt;code>eval&lt;/code> to configure your shell. Example for &lt;code>bash&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>eval &lt;span style="color:#00f">$(&lt;/span>gardenctl kubectl-env bash&lt;span style="color:#00f">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="configure-cloud-provider-clis">Configure Cloud Provider CLIs&lt;/h3>
&lt;p>Generate the cloud provider CLI configuration script for the specified shell. Use together with &lt;code>eval&lt;/code> to configure your shell. Example for &lt;code>bash&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>eval &lt;span style="color:#00f">$(&lt;/span>gardenctl provider-env bash&lt;span style="color:#00f">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="ssh">SSH&lt;/h3>
&lt;p>Establish an SSH connection to a Shoot cluster&amp;rsquo;s node.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>gardenctl ssh my-node
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Manage certificates with Gardener for default domain</title><link>https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/request_default_domain_cert/</link><pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/request_default_domain_cert/</guid><description>
&lt;h1 id="manage-certificates-with-gardener-for-default-domain">Manage certificates with Gardener for default domain&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>Dealing with applications on Kubernetes which offer a secure service endpoints (e.g. HTTPS) also require you to enable a
secured communication via SSL/TLS. With the &lt;a href="https://github.com/gardener/gardener-extension-shoot-cert-service">certificate extension&lt;/a> enabled, Gardener can manage commonly trusted X.509 certificate for your application
endpoint. From initially requesting certificate, it also handeles their renewal in time using the free Let&amp;rsquo;s Encrypt API.&lt;/p>
&lt;p>&lt;strong>There are two senarios with which you can use the certificate extension&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>You want to use a certificate for a subdomain the shoot&amp;rsquo;s default DNS (see &lt;code>.spec.dns.domain&lt;/code> of your shoot resource, e.g. &lt;code>short.ingress.shoot.project.default-domain.gardener.cloud&lt;/code>). If this is your case, please keep reading this article.&lt;/li>
&lt;li>You want to use a certificate for a custom domain. If this is your case, please see &lt;a href="https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/request_cert/">Manage certificates with Gardener for public domain&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="prerequisites">Prerequisites&lt;/h2>
&lt;p>Before you start this guide there are a few requirements you need to fulfill:&lt;/p>
&lt;ul>
&lt;li>You have an existing shoot cluster&lt;/li>
&lt;/ul>
&lt;p>Since you are using the default DNS name, all DNS configuration should already be done and ready.&lt;/p>
&lt;h2 id="issue-a-certificate">Issue a certificate&lt;/h2>
&lt;p>Every X.509 certificate is represented by a Kubernetes custom resource &lt;code>certificate.cert.gardener.cloud&lt;/code> in your cluster. A &lt;code>Certificate&lt;/code> resource may be used to initiate a new certificate request as well as to manage its lifecycle. Gardener&amp;rsquo;s certificate service regularly checks the expiration timestamp of Certificates, triggers a renewal process if necessary and replaces the existing X.509 certificate with a new one.&lt;/p>
&lt;blockquote>
&lt;p>Your application should be able to reload replaced certificates in a timely manner to avoid service disruptions.&lt;/p>
&lt;/blockquote>
&lt;p>Certificates can be requested via 3 resources type&lt;/p>
&lt;ul>
&lt;li>Ingress&lt;/li>
&lt;li>Service (type LoadBalancer)&lt;/li>
&lt;li>certificate (Gardener CRD)&lt;/li>
&lt;/ul>
&lt;p>If either of the first 2 are used, a corresponding &lt;code>Certificate&lt;/code> resource will automatically be created.&lt;/p>
&lt;h3 id="using-an-ingress-resource">Using an ingress Resource&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: networking.k8s.io/v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Ingress
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: amazing-ingress
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> annotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/purpose: managed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">#cert.gardener.cloud/issuer: custom-issuer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tls:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - hosts:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Must not exceed 64 characters.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - short.ingress.shoot.project.default-domain.gardener.cloud
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Certificate and private key reside in this secret.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretName: tls-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rules:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - host: short.ingress.shoot.project.default-domain.gardener.cloud
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> http:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> paths:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - pathType: Prefix
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> path: &lt;span style="color:#a31515">&amp;#34;/&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backend:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: amazing-svc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> number: 8080
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="using-a-service-type-loadbalancer">Using a service type LoadBalancer&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> annotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/purpose: managed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Certificate and private key reside in this secret.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/secretname: tls-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># You may add more domains separated by commas (e.g. &amp;#34;service.shoot.project.default-domain.gardener.cloud, amazing.shoot.project.default-domain.gardener.cloud&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dns.gardener.cloud/dnsnames: &lt;span style="color:#a31515">&amp;#34;service.shoot.project.default-domain.gardener.cloud&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dns.gardener.cloud/ttl: &lt;span style="color:#a31515">&amp;#34;600&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">#cert.gardener.cloud/issuer: custom-issuer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: test-service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ports:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: http
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port: 80
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> protocol: TCP
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> targetPort: 8080
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: LoadBalancer
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="using-the-custom-certificate-resource">Using the custom Certificate resource&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: cert.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Certificate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: cert-example
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> commonName: short.ingress.shoot.project.default-domain.gardener.cloud
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: tls-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Optionnal if using the default issuer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> issuerRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: garden
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you&amp;rsquo;re interested in the current progress of your request, you&amp;rsquo;re advised to consult the description, more specifically the &lt;code>status&lt;/code> attribute in case the issuance failed.&lt;/p>
&lt;h2 id="request-a-wildcard-certificate">Request a wildcard certificate&lt;/h2>
&lt;p>In order to avoid the creation of multiples certificates for every single endpoints, you may want to create a wildcard certificate for your shoot&amp;rsquo;s default cluster.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: networking.k8s.io/v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Ingress
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: amazing-ingress
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> annotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/purpose: managed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/commonName: &lt;span style="color:#a31515">&amp;#34;*.ingress.shoot.project.default-domain.gardener.cloud&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tls:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - hosts:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - amazing.ingress.shoot.project.default-domain.gardener.cloud
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretName: tls-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rules:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - host: amazing.ingress.shoot.project.default-domain.gardener.cloud
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> http:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> paths:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - pathType: Prefix
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> path: &lt;span style="color:#a31515">&amp;#34;/&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backend:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: amazing-svc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> number: 8080
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Please note that this can also be achived by directly adding an annotation to a Service type LoadBalancer. You could also create a Certificate object with a wildcard domain.&lt;/p>
&lt;h2 id="more-information">More information&lt;/h2>
&lt;p>For more information and more examples about using the certificate extension, please see &lt;a href="https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/request_cert/">Manage certificates with Gardener for public domain&lt;/a>&lt;/p></description></item><item><title>Docs: Manage certificates with Gardener for public domain</title><link>https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/request_cert/</link><pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/request_cert/</guid><description>
&lt;h1 id="manage-certificates-with-gardener-for-public-domain">Manage certificates with Gardener for public domain&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;/h2>
&lt;p>Dealing with applications on Kubernetes which offer a secure service endpoints (e.g. HTTPS) also require you to enable a
secured communication via SSL/TLS. With the &lt;a href="https://github.com/gardener/gardener-extension-shoot-cert-service">certificate extension&lt;/a> enabled, Gardener can manage commonly trusted X.509 certificate for your application
endpoint. From initially requesting certificate, it also handeles their renewal in time using the free Let&amp;rsquo;s Encrypt API.&lt;/p>
&lt;p>&lt;strong>There are two senarios with which you can use the certificate extension&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>You want to use a certificate for a subdomain the shoot&amp;rsquo;s default DNS (see &lt;code>.spec.dns.domain&lt;/code> of your shoot resource, e.g. &lt;code>short.ingress.shoot.project.default-domain.gardener.cloud&lt;/code>). If this is your case, please see &lt;a href="https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/request_default_domain_cert/">Manage certificates with Gardener for default domain&lt;/a>&lt;/li>
&lt;li>You want to use a certificate for a custom domain. If this is your case, please keep reading this article.&lt;/li>
&lt;/ul>
&lt;h2 id="prerequisites">Prerequisites&lt;/h2>
&lt;p>Before you start this guide there are a few requirements you need to fulfill:&lt;/p>
&lt;ul>
&lt;li>You have an existing shoot cluster&lt;/li>
&lt;li>Your custom domain is under a &lt;a href="https://www.iana.org/domains/root/db">public top level domain&lt;/a> (e.g. &lt;code>.com&lt;/code>)&lt;/li>
&lt;li>Your custom zone is resolvable with a public resolver via the internet (e.g. &lt;code>8.8.8.8&lt;/code>)&lt;/li>
&lt;li>You have a custom DNS provider configured and working (see &lt;a href="https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-dns-service/docs/usage/dns_providers/">&amp;ldquo;DNS Providers&amp;rdquo;&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>As part of the &lt;a href="https://letsencrypt.org/">Let&amp;rsquo;s Encrypt&lt;/a> &lt;a href="https://tools.ietf.org/html/rfc8555">ACME&lt;/a> challenge validation process, Gardener sets a DNS TXT entry and Let&amp;rsquo;s Encrypt checks if it can both resolve and authenticate it. Therefore, it&amp;rsquo;s important that your DNS-entries are publicly resolvable. You can check this by querying e.g. Googles public DNS server and if it returns an entry your DNS is publicly visible:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># returns the A record for cert-example.example.com using Googles DNS server (8.8.8.8)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>dig cert-example.example.com @8.8.8.8 A
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="dns-provider">DNS provider&lt;/h3>
&lt;p>In order to issue certificates for a custom domain you need to specify a DNS provider which is permitted to create DNS records for subdomains of your requested domain in the certificate. For example, if you request a certificate for &lt;code>host.example.com&lt;/code> your DNS provider must be capable of managing subdomains of &lt;code>host.example.com&lt;/code>.&lt;/p>
&lt;p>DNS providers are normally specified in the shoot manifest. To learn more on how to configure one, please see the &lt;a href="https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-dns-service/docs/usage/dns_providers/">DNS provider&lt;/a> documentation.&lt;/p>
&lt;h2 id="issue-a-certificate">Issue a certificate&lt;/h2>
&lt;p>Every X.509 certificate is represented by a Kubernetes custom resource &lt;code>certificate.cert.gardener.cloud&lt;/code> in your cluster. A &lt;code>Certificate&lt;/code> resource may be used to initiate a new certificate request as well as to manage its lifecycle. Gardener&amp;rsquo;s certificate service regularly checks the expiration timestamp of Certificates, triggers a renewal process if necessary and replaces the existing X.509 certificate with a new one.&lt;/p>
&lt;blockquote>
&lt;p>Your application should be able to reload replaced certificates in a timely manner to avoid service disruptions.&lt;/p>
&lt;/blockquote>
&lt;p>Certificates can be requested via 3 resources type&lt;/p>
&lt;ul>
&lt;li>Ingress&lt;/li>
&lt;li>Service (type LoadBalancer)&lt;/li>
&lt;li>Certificate (Gardener CRD)&lt;/li>
&lt;/ul>
&lt;p>If either of the first 2 are used, a corresponding &lt;code>Certificate&lt;/code> resource will created automatically.&lt;/p>
&lt;h3 id="using-an-ingress-resource">Using an ingress Resource&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: networking.k8s.io/v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Ingress
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: amazing-ingress
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> annotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/purpose: managed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Optional but recommended, this is going to create the DNS entry at the same time&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dns.gardener.cloud/class: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dns.gardener.cloud/ttl: &lt;span style="color:#a31515">&amp;#34;600&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tls:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - hosts:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Must not exceed 64 characters.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - amazing.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Certificate and private key reside in this secret.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretName: tls-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rules:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - host: amazing.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> http:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> paths:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - pathType: Prefix
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> path: &lt;span style="color:#a31515">&amp;#34;/&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backend:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: amazing-svc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> number: 8080
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Replace the &lt;code>hosts&lt;/code> and &lt;code>rules[].host&lt;/code> value again with your own domain and adjust the remaining Ingress attributes in accordance with your deployment (e.g. the above is for an &lt;code>istio&lt;/code> Ingress controller and forwards traffic to a &lt;code>service1&lt;/code> on port 80).&lt;/p>
&lt;h3 id="using-a-service-type-loadbalancer">Using a service type LoadBalancer&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> annotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/secretname: tls-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dns.gardener.cloud/dnsnames: example.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dns.gardener.cloud/class: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Optional&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dns.gardener.cloud/ttl: &lt;span style="color:#a31515">&amp;#34;600&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/commonname: &lt;span style="color:#a31515">&amp;#34;*.example.example.com&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/dnsnames: &lt;span style="color:#a31515">&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: test-service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ports:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: http
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port: 80
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> protocol: TCP
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> targetPort: 8080
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: LoadBalancer
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="using-the-custom-certificate-resource">Using the custom Certificate resource&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: cert.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Certificate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: cert-example
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> commonName: amazing.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: tls-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Optionnal if using the default issuer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> issuerRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: garden
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="supported-attributes">Supported attributes&lt;/h2>
&lt;p>Here is a list of all supported annotations regarding the certificate extension:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Path&lt;/th>
&lt;th style="text-align:left">Annotation&lt;/th>
&lt;th style="text-align:left">Value&lt;/th>
&lt;th style="text-align:left">Required&lt;/th>
&lt;th style="text-align:left">Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">N/A&lt;/td>
&lt;td style="text-align:left">&lt;code>cert.gardener.cloud/purpose:&lt;/code>&lt;/td>
&lt;td style="text-align:left">&lt;code>managed&lt;/code>&lt;/td>
&lt;td style="text-align:left">Yes when using annotations&lt;/td>
&lt;td style="text-align:left">Flag for Gardener that this specific Ingress or Service requires a certificate&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>spec.commonName&lt;/code>&lt;/td>
&lt;td style="text-align:left">&lt;code>cert.gardener.cloud/commonname:&lt;/code>&lt;/td>
&lt;td style="text-align:left">E.g. &amp;ldquo;*.demo.example.com&amp;rdquo; or &lt;br> &amp;ldquo;special.example.com&amp;rdquo;&lt;/td>
&lt;td style="text-align:left">Certificate and Ingress : No &lt;br/> Service: yes&lt;/td>
&lt;td style="text-align:left">Specifies for which domain the certificate request will be created. If not specified, the names from spec.tls[].hosts are used. This entry must comply with the &lt;a href="#Character-Restrictions">64 character&lt;/a> limit.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>spec.dnsName&lt;/code>&lt;/td>
&lt;td style="text-align:left">&lt;code>cert.gardener.cloud/dnsnames:&lt;/code>&lt;/td>
&lt;td style="text-align:left">E.g. &amp;ldquo;special.example.com&amp;rdquo;&lt;/td>
&lt;td style="text-align:left">Certificate and Ingress : No &lt;br/> Service: yes&lt;/td>
&lt;td style="text-align:left">Additional domains the certificate should be valid for (Subject Alternative Name). If not specified, the names from spec.tls[].hosts are used. Entries in this list can be longer than 64 characters.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>spec.secretRef.name&lt;/code>&lt;/td>
&lt;td style="text-align:left">&lt;code>cert.gardener.cloud/secretname:&lt;/code>&lt;/td>
&lt;td style="text-align:left">&lt;code>any-name&lt;/code>&lt;/td>
&lt;td style="text-align:left">Yes for certificate and Service&lt;/td>
&lt;td style="text-align:left">Specifies the secret which contains the certificate/key pair. If the secret is not available yet, it&amp;rsquo;ll be created automatically as soon as the certificate has been issued.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;code>spec.issuerRef.name&lt;/code>&lt;/td>
&lt;td style="text-align:left">&lt;code>cert.gardener.cloud/issuer:&lt;/code>&lt;/td>
&lt;td style="text-align:left">E.g. &lt;code>gardener&lt;/code>&lt;/td>
&lt;td style="text-align:left">No&lt;/td>
&lt;td style="text-align:left">Specifies the issuer you want to use. Only necessary if you request certificates for &lt;a href="#Custom-Domains">custom domains&lt;/a>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">N/A&lt;/td>
&lt;td style="text-align:left">&lt;code>cert.gardener.cloud/revoked:&lt;/code>&lt;/td>
&lt;td style="text-align:left">&lt;code>true&lt;/code> otherwise always false&lt;/td>
&lt;td style="text-align:left">No&lt;/td>
&lt;td style="text-align:left">Use only to revoke a certificate, see &lt;a href="#references">reference&lt;/a> for more details&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="request-a-wildcard-certificate">Request a wildcard certificate&lt;/h2>
&lt;p>In order to avoid the creation of multiples certificates for every single endpoints, you may want to create a wildcard certificate for your shoot&amp;rsquo;s default cluster.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: networking.k8s.io/v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Ingress
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: amazing-ingress
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> annotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/purpose: managed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cert.gardener.cloud/commonName: &lt;span style="color:#a31515">&amp;#34;*.example.com&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tls:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - hosts:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - amazing.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretName: tls-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rules:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - host: amazing.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> http:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> paths:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - pathType: Prefix
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> path: &lt;span style="color:#a31515">&amp;#34;/&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backend:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: amazing-svc
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> number: 8080
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Please note that this can also be achived by directly adding an annotation to a Service type LoadBalancer. You could also create a Certificate object with a wildcard domain.&lt;/p>
&lt;h2 id="using-a-custom-issuer">Using a custom Issuer&lt;/h2>
&lt;p>Most Gardener deployment with the certification extension enabled have a preconfigured &lt;code>garden&lt;/code> issuer. It is also usually configured to use Let&amp;rsquo;s Encrypt as the certificate provider.&lt;/p>
&lt;p>If you need a custom issuer for a specific cluster, please see &lt;a href="https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/custom_shoot_issuer/">Using a custom Issuer&lt;/a>&lt;/p>
&lt;h2 id="quotas">Quotas&lt;/h2>
&lt;p>For security reasons there may be a default quota on the certificate requests per day set globally in the controller
registration of the shoot-cert-service.&lt;/p>
&lt;p>The default quota only applies if there is no explicit quota defined for the issuer itself with the field
&lt;code>requestsPerDayQuota&lt;/code>, e.g.:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>kind: Shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> extensions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: shoot-cert-service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: service.cert.extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: CertConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> issuers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - email: your-email@example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: custom-issuer &lt;span style="color:#008000"># issuer name must be specified in every custom issuer request, must not be &amp;#34;garden&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> server: &lt;span style="color:#a31515">&amp;#39;https://acme-v02.api.letsencrypt.org/directory&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> requestsPerDayQuota: 10
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="dns-propagation">DNS Propagation&lt;/h2>
&lt;p>As stated before, cert-manager uses the ACME challenge protocol to authenticate that you are the DNS owner for the domain&amp;rsquo;s certificate you are requesting. This works by creating a DNS TXT record in your DNS provider under &lt;code>_acme-challenge.example.example.com&lt;/code> containing a token to compare with. The TXT record is only visible during the domain validation. Typically, the record is propagated within a few minutes. But if the record is not visible to the ACME server for any reasons, the certificate request is retried again after several minutes. This means you may have to wait up to one hour after the propagation problem has been resolved before the certificate request is retried. Take a look in the events with &lt;code>kubectl describe ingress example&lt;/code> for troubleshooting.&lt;/p>
&lt;h2 id="character-restrictions">Character Restrictions&lt;/h2>
&lt;p>Due to the ACME protocol specification, at least one domain of the domains you request a certificate for must not exceed a character limit of 64 (CN - Common Name).&lt;/p>
&lt;p>For example, the following request is invalid:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: cert.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Certificate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: cert-invalid
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> commonName: morethan64characters.ingress.shoot.project.default-domain.gardener.cloud
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>But it is valid to request a certificate for this domain if you have at least one domain which does not exceed the mentioned limit:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: cert.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Certificate
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: cert-example
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> commonName: short.ingress.shoot.project.default-domain.gardener.cloud
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dnsNames:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - morethan64characters.ingress.shoot.project.default-domain.gardener.cloud
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/gardener/cert-management">Gardener cert-management&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/gardener/gardener-extension-shoot-dns-service">Managing DNS with Gardener&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: Using a custom Issuer</title><link>https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/custom_shoot_issuer/</link><pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/extensions/others/gardener-extension-shoot-cert-service/docs/usage/custom_shoot_issuer/</guid><description>
&lt;h1 id="using-a-custom-issuer">Using a custom Issuer&lt;/h1>
&lt;p>Another possibility to request certificates for custom domains is a dedicated issuer.&lt;/p>
&lt;blockquote>
&lt;p>Note: This is only needed if the default issuer provided by Gardener is restricted to shoot related domains or you are using domain names not visible to public DNS servers. &lt;strong>Which means that your senario most likely doesn&amp;rsquo;t require your to add an issuer&lt;/strong>.&lt;/p>
&lt;/blockquote>
&lt;p>The custom issuers are specified normally in the shoot manifest. If the &lt;code>shootIssuers&lt;/code> feature is enabled, it can alternatively be defined in the shoot cluster.&lt;/p>
&lt;h2 id="custom-issuer-in-the-shoot-manifest">Custom issuer in the shoot manifest&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>kind: Shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> extensions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: shoot-cert-service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: service.cert.extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: CertConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> issuers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - email: your-email@example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: custom-issuer &lt;span style="color:#008000"># issuer name must be specified in every custom issuer request, must not be &amp;#34;garden&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> server: &lt;span style="color:#a31515">&amp;#39;https://acme-v02.api.letsencrypt.org/directory&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> privateKeySecretName: my-privatekey &lt;span style="color:#008000"># referenced resource, the private key must be stored in the secret at `data.privateKey` (optionally, only needed as alternative to auto registration) &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">#precheckNameservers: # to provide special set of nameservers to be used for prechecking DNSChallenges for an issuer&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">#- dns1.private.company-net:53&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">#- dns2.private.company-net:53&amp;#34; &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">#shootIssuers:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># if true, allows to specify issuers in the shoot cluster&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">#enabled: true &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resources:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: my-privatekey
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resourceRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: Secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: custom-issuer-privatekey &lt;span style="color:#008000"># name of secret in Gardener project&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you are using an ACME provider for private domains, you may need to change the nameservers used for
checking the availability of the DNS challenge&amp;rsquo;s TXT record before the certificate is requested from the ACME provider.
By default, only public DNS servers may be used for this purpose.
At least one of the &lt;code>precheckNameservers&lt;/code> must be able to resolve the private domain names.&lt;/p>
&lt;h2 id="using-an-issuer-in-the-shoot-cluster">Using an issuer in the shoot cluster&lt;/h2>
&lt;p>&lt;em>Prerequiste&lt;/em>: The &lt;code>shootIssuers&lt;/code> feature has to be enabled.
It is either enabled globally in the &lt;code>ControllerDeployment&lt;/code> or in the shoot manifest
with:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>kind: Shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> extensions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: shoot-cert-service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: service.cert.extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: CertConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootIssuers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span> &lt;span style="color:#008000"># if true, allows to specify issuers in the shoot cluster&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Example for specifying an &lt;code>Issuer&lt;/code> resource and its &lt;code>Secret&lt;/code> directly in any
namespace of the shoot cluster:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: cert.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Issuer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-own-issuer
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: my-namespace
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> acme:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> domains:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> include:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - my.own.domain.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> email: some.user@my.own.domain.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> privateKeySecretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-own-issuer-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: my-namespace
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> server: https://acme-v02.api.letsencrypt.org/directory
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-own-issuer-secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: my-namespace
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>type: Opaque
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> privateKey: ... &lt;span style="color:#008000"># replace &amp;#39;...&amp;#39; with valus encoded as base64&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Hibernate a Cluster</title><link>https://gardener.cloud/docs/gardener/usage/shoot_hibernate/</link><pubDate>Thu, 19 Nov 2020 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/usage/shoot_hibernate/</guid><description>
&lt;h1 id="hibernate-a-cluster">Hibernate a Cluster&lt;/h1>
&lt;p>Clusters are only needed 24 hours a day if they run productive workload. So whenever you do development in a cluster, or just use it for tests or demo purposes, you can save much money if you scale-down your Kubernetes resources whenever you don&amp;rsquo;t need them. However, scaling them down manually can become time-consuming the more resources you have.&lt;/p>
&lt;p>Gardener offers a clever way to automatically scale-down all resources to zero: cluster hibernation. You can either hibernate a cluster by pushing a button or by defining a hibernation schedule.&lt;/p>
&lt;blockquote>
&lt;p>To save costs, it&amp;rsquo;s recommended to define a hibernation schedule before the creation of a cluster. You can hibernate your cluster or wake up your cluster manually even if there&amp;rsquo;s a schedule for its hibernation.&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>&lt;a href="#what-is-hibernated">What is hibernated?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#what-isnt-affected-by-the-hibernation">What isn’t affected by the hibernation?&lt;/a>&lt;/li>
&lt;li>&lt;a href="#hibernate-your-cluster-manually">Hibernate your cluster manually&lt;/a>&lt;/li>
&lt;li>&lt;a href="#wake-up-your-cluster-manually">Wake up your cluster manually&lt;/a>&lt;/li>
&lt;li>&lt;a href="#create-a-schedule-to-hibernate-your-cluster">Create a schedule to hibernate your cluster&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="what-is-hibernated">What is hibernated?&lt;/h2>
&lt;p>When a cluster is hibernated, Gardener scales down worker nodes and the cluster&amp;rsquo;s control plane to free resources at the IaaS provider. This affects:&lt;/p>
&lt;ul>
&lt;li>Your workload, for example, pods, deployments, custom resources.&lt;/li>
&lt;li>The virtual machines running your workload.&lt;/li>
&lt;li>The resources of the control plane of your cluster.&lt;/li>
&lt;/ul>
&lt;h2 id="what-isnt-affected-by-the-hibernation">What isn’t affected by the hibernation?&lt;/h2>
&lt;p>To scale up everything where it was before hibernation, Gardener doesn’t delete state-related information, that is, information stored in persistent volumes. The cluster state as persistent in &lt;code>etcd&lt;/code> is also preserved.&lt;/p>
&lt;h2 id="hibernate-your-cluster-manually">Hibernate your cluster manually&lt;/h2>
&lt;p>The &lt;code>.spec.hibernation.enabled&lt;/code> field specifies whether the cluster needs to be hibernated or not. If the field is set to &lt;code>true&lt;/code>, the cluster&amp;rsquo;s desired state is to be hibernated. If it is set to &lt;code>false&lt;/code> or not specified at all, the cluster&amp;rsquo;s desired state is to be awakened.&lt;/p>
&lt;p>To hibernate your cluster you can run the following &lt;code>kubectl&lt;/code> command:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ kubectl patch shoot -n $NAMESPACE $SHOOT_NAME -p &amp;#39;{&amp;#34;spec&amp;#34;:{&amp;#34;hibernation&amp;#34;:{&amp;#34;enabled&amp;#34;: true}}}&amp;#39;
&lt;/code>&lt;/pre>&lt;h2 id="wake-up-your-cluster-manually">Wake up your cluster manually&lt;/h2>
&lt;p>To wake up your cluster you can run the following &lt;code>kubectl&lt;/code> command:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ kubectl patch shoot -n $NAMESPACE $SHOOT_NAME -p &amp;#39;{&amp;#34;spec&amp;#34;:{&amp;#34;hibernation&amp;#34;:{&amp;#34;enabled&amp;#34;: false}}}&amp;#39;
&lt;/code>&lt;/pre>&lt;h2 id="create-a-schedule-to-hibernate-your-cluster">Create a schedule to hibernate your cluster&lt;/h2>
&lt;p>You can specify a hibernation schedule to automatically hibernate/wake up a cluster.&lt;/p>
&lt;p>Let&amp;rsquo;s have a look into the following example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span> hibernation:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> schedules:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - start: &lt;span style="color:#a31515">&amp;#34;0 20 * * *&amp;#34;&lt;/span> &lt;span style="color:#008000"># Start hibernation every day at 8PM&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> end: &lt;span style="color:#a31515">&amp;#34;0 6 * * *&amp;#34;&lt;/span> &lt;span style="color:#008000"># Stop hibernation every day at 6AM&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> location: &lt;span style="color:#a31515">&amp;#34;America/Los_Angeles&amp;#34;&lt;/span> &lt;span style="color:#008000"># Specify a location for the cron to run in&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The above section configures a hibernation schedule that hibernates the cluster every day at 08:00 PM and wakes it up at 06:00 AM. The &lt;code>start&lt;/code> or &lt;code>end&lt;/code> fields can be omitted, though at least one of them has to be specified. Hence, it is possible to configure a hibernation schedule that only hibernates or wakes up a cluster. The &lt;code>location&lt;/code> field is the time location used to evaluate the cron expressions.&lt;/p></description></item><item><title>Docs: 01 Extensibility</title><link>https://gardener.cloud/docs/gardener/proposals/01-extensibility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/01-extensibility/</guid><description>
&lt;h1 id="gardener-extensibility-and-extraction-of-cloud-specificos-specific-knowledge-308httpsgithubcomgardenergardenerissues308-262httpsgithubcomgardenergardenerissues262">Gardener extensibility and extraction of cloud-specific/OS-specific knowledge (&lt;a href="https://github.com/gardener/gardener/issues/308">#308&lt;/a>, &lt;a href="https://github.com/gardener/gardener/issues/262">#262&lt;/a>)&lt;/h1>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#goals">Goals&lt;/a>&lt;/li>
&lt;li>&lt;a href="#non-goals">Non-Goals&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#proposal">Proposal&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#modification-of-existing-cloudprofile-and-shoot-resources">Modification of existing &lt;code>CloudProfile&lt;/code> and &lt;code>Shoot&lt;/code> resources&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#cloudprofiles">CloudProfiles&lt;/a>&lt;/li>
&lt;li>&lt;a href="#shoots">Shoots&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#crd-definitions-and-workflow-adaptation">CRD definitions and workflow adaptation&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#custom-resource-definitions">Custom resource definitions&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#dns-records">DNS records&lt;/a>&lt;/li>
&lt;li>&lt;a href="#infrastructure-provisioning">Infrastructure provisioning&lt;/a>&lt;/li>
&lt;li>&lt;a href="#backup-infrastructure-provisioning">Backup infrastructure provisioning&lt;/a>&lt;/li>
&lt;li>&lt;a href="#cloud-config-user-data-for-bootstrapping-machines">Cloud config (user-data) for bootstrapping machines&lt;/a>&lt;/li>
&lt;li>&lt;a href="#worker-pools-definition">Worker pools definition&lt;/a>&lt;/li>
&lt;li>&lt;a href="#generic-resources">Generic resources&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#shoot-state">Shoot state&lt;/a>&lt;/li>
&lt;li>&lt;a href="#shoot-health-checksconditions">Shoot health checks/conditions&lt;/a>&lt;/li>
&lt;li>&lt;a href="#reconciliation-flow">Reconciliation flow&lt;/a>&lt;/li>
&lt;li>&lt;a href="#deletion-flow">Deletion flow&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#gardenlet">Gardenlet&lt;/a>&lt;/li>
&lt;li>&lt;a href="#shoot-control-plane-movementmigration">Shoot control plane movement/migration&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#registration-of-external-controllers-at-gardener">Registration of external controllers at Gardener&lt;/a>&lt;/li>
&lt;li>&lt;a href="#other-cloud-specific-parts">Other cloud-specific parts&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#defaulting-and-validation-admission-plugins">Defaulting and validation admission plugins&lt;/a>&lt;/li>
&lt;li>&lt;a href="#dns-hosted-zone-admission-plugin">DNS Hosted Zone admission plugin&lt;/a>&lt;/li>
&lt;li>&lt;a href="#shoot-quota-admission-plugin">Shoot Quota admission plugin&lt;/a>&lt;/li>
&lt;li>&lt;a href="#shoot-maintenance-controller">Shoot maintenance controller&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#alternatives">Alternatives&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Gardener has evolved to a large compound of packages containing lots of highly specific knowledge which makes it very hard to extend (supporting a new cloud provider, new OS, &amp;hellip;, or behave differently depending on the underlying infrastructure).&lt;/p>
&lt;p>This proposal aims to move out the cloud-specific implementations (called &amp;ldquo;(cloud) botanists&amp;rdquo;) and the OS-specifics into dedicated controllers, and simultaneously to allow deviation from the standard Gardener deployment.&lt;/p>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Currently, it is too hard to support additional cloud providers or operation systems/distributions as everything must be done in-tree which might affect the implementation of other cloud providers as well.
The various conditions and branches make the code hard to maintain and hard to test.
Every change must be done centrally, requires to completely rebuild Gardener, and cannot be deployed individually. Similar to the motivation for Kubernetes to extract their cloud-specifics into dedicated cloud-controller-managers or to extract the container/storage/network/&amp;hellip; specifics into CRI/CSI/CNI/&amp;hellip;, we aim to do the same right now.&lt;/p>
&lt;h3 id="goals">Goals&lt;/h3>
&lt;ul>
&lt;li>Gardener does not contain any cloud-specific knowledge anymore but defines a clear contract allowing external controllers (botanists) to support different environments (AWS, Azure, GCP, &amp;hellip;).&lt;/li>
&lt;li>Gardener does not contain any operation system-specific knowledge anymore but defines a clear contract allowing external controllers to support different operation systems/distributions (CoreOS, SLES, Ubuntu, &amp;hellip;).&lt;/li>
&lt;li>It shall become much easier to move control planes of Shoot clusters between Seed clusters (&lt;a href="https://github.com/gardener/gardener/issues/232">#232&lt;/a>) which is a necessary requirement of an automated setup for the Gardener Ring (&lt;a href="https://github.com/gardener/gardener/issues/233">#233&lt;/a>).&lt;/li>
&lt;/ul>
&lt;h3 id="non-goals">Non-Goals&lt;/h3>
&lt;ul>
&lt;li>We want to also factor out the specific knowledge of the addon deployments (nginx-ingress, kubernetes-dashboard, &amp;hellip;), but we already have dedicated projects/issues for that: &lt;a href="https://github.com/gardener/bouquet">https://github.com/gardener/bouquet&lt;/a> and &lt;a href="https://github.com/gardener/gardener/issues/246">#246&lt;/a>. We will keep the addons in-tree as part of this proposal and tackle their extraction separately.&lt;/li>
&lt;li>We do not want to make the Gardener a plain workflow engine that just executes a given template (which indeed would allow to be generic, open, and extensible in their highest forms but which would end-up in building a &amp;ldquo;programming/scripting language&amp;rdquo; inside a serialization format (YAML/JSON/&amp;hellip;)). Rather, we want to have well-defined contracts and APIs, keeping Gardener responsible for the clusters management.&lt;/li>
&lt;/ul>
&lt;h2 id="proposal">Proposal&lt;/h2>
&lt;p>Gardener heavily relies on and implements Kubernetes principles, and its ultimate strategy is to use Kubernetes wherever applicable.
The extension concept in Kubernetes is based on (next to others) &lt;code>CustomResourceDefinition&lt;/code>s, &lt;code>ValidatingWebhookConfiguration&lt;/code>s and &lt;code>MutatingWebhookConfiguration&lt;/code>s, and &lt;code>InitializerConfiguration&lt;/code>s.
Consequently, Gardener&amp;rsquo;s extensibility concept relies on these mechanisms.&lt;/p>
&lt;p>Instead of implementing all aspects directly in Gardener it will deploy some CRDs to the Seed cluster which will be watched by dedicated controllers (also running in the Seed clusters), each one implementing one aspect of cluster management. This way one complex strongly coupled Gardener implementation covering all infrastructures is decomposed into a set of loosely coupled controllers implementing aspects of APIs defined by Gardener.
Gardener will just wait until the controllers report that they are done (or have faced an error) in the CRD&amp;rsquo;s &lt;code>.status&lt;/code> field instead of doing the respective tasks itself.
We will have one specific CRD for every specific operation (e.g., DNS, infrastructure provisioning, machine cloud config generation, &amp;hellip;).
However, there are also parts inside Gardener which can be handled generically (not by cloud botanists) because they are the same or very similar for all the environments.
One example of those is the deployment of a &lt;code>Namespace&lt;/code> in the Seed which will run the Shoot&amp;rsquo;s control plane
Another one is the deployment of a &lt;code>Service&lt;/code> for the Shoot&amp;rsquo;s kube-apiserver.
In case a cloud botanist needs to cooperate and react on those operations it should register a &lt;code>ValidatingWebhookConfiguration&lt;/code>, a &lt;code>MutatingWebhookConfiguration&lt;/code>, or a &lt;code>InitializerConfiguration&lt;/code>.
With this approach it can validate, modify, or react on any resource created by Gardener to make it cloud infrastructure specific.&lt;/p>
&lt;p>The web hooks should be registered with &lt;code>failurePolicy=Fail&lt;/code> to ensure that a request made by Gardener fails if the respective web hook is not available.&lt;/p>
&lt;h3 id="modification-of-existing-cloudprofile-and-shoot-resources">Modification of existing &lt;code>CloudProfile&lt;/code> and &lt;code>Shoot&lt;/code> resources&lt;/h3>
&lt;p>We will introduce the new API group &lt;code>gardener.cloud&lt;/code>:&lt;/p>
&lt;h4 id="cloudprofiles">CloudProfiles&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: CloudProfile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># caBundle: |&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># -----BEGIN CERTIFICATE-----&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># -----END CERTIFICATE-----&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dnsProviders:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: aws-route53
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: unmanaged
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kubernetes:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> versions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 1.12.1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 1.11.0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 1.10.5
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> machineTypes:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: m4.large
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cpu: &lt;span style="color:#a31515">&amp;#34;2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gpu: &lt;span style="color:#a31515">&amp;#34;0&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> memory: 8Gi
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># storage: 20Gi # optional (not needed in every environment, may only be specified if no volumeTypes have been specified)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> volumeTypes: &lt;span style="color:#008000"># optional (not needed in every environment, may only be specified if no machineType has a `storage` field)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: gp2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> class: standard
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: io1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> class: premium
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: aws.cloud.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: CloudProfileConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> constraints:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> minimumVolumeSize: 20Gi
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> machineImages:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: coreos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> regions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ami: ami-32d1474b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: us-east-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ami: ami-e582d29f
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> zones:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> zones:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: eu-west-1a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> unavailableMachineTypes: &lt;span style="color:#008000"># list of machine types defined above that are not available in this zone&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: m4.large
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> unavailableVolumeTypes: &lt;span style="color:#008000"># list of volume types defined above that are not available in this zone&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: gp2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: eu-west-1b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: eu-west-1c
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="shoots">Shoots&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: johndoe-aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden-dev
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cloudProfileName: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretBindingName: core-aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cloud:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: aws.cloud.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: InfrastructureConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> networks:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> vpc: &lt;span style="color:#008000"># specify either &amp;#39;id&amp;#39; or &amp;#39;cidr&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># id: vpc-123456&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cidr: 10.250.0.0/16
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> internal:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 10.250.112.0/22
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> public:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 10.250.96.0/22
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> workers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 10.250.0.0/19
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> zones:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - eu-west-1a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> workerPools:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: pool-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Taints, labels, and annotations are not yet implemented. This requires interaction with the machine-controller-manager, see&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># https://github.com/gardener/machine-controller-manager/issues/174. It is only mentioned here as future proposal.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># taints:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># - key: foo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># value: bar&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># effect: PreferNoSchedule&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># labels:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># - key: bar&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># value: baz&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># annotations:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># - key: foo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># value: hugo&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> machineType: m4.large
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> volume: &lt;span style="color:#008000"># optional, not needed in every environment, may only be specified if the referenced CloudProfile contains the volumeTypes field&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: gp2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> size: 20Gi
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: aws.cloud.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: WorkerPoolConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> machineImage:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: coreos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ami: ami-d0dcef3
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> zones:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - eu-west-1a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> minimum: 2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> maximum: 2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> maxSurge: 1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> maxUnavailable: 0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kubernetes:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> version: 1.11.0
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dns:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provider: aws-route53
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> domain: johndoe-aws.garden-dev.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> maintenance:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> timeWindow:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> begin: 220000+0100
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> end: 230000+0100
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> autoUpdate:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kubernetesVersion: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backup:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> schedule: &lt;span style="color:#a31515">&amp;#34;*/5 * * * *&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> maximum: 7
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> addons:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kube2iam:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kubernetes-dashboard:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster-autoscaler:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> nginx-ingress:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loadBalancerSourceRanges: []
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kube-lego:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> email: john.doe@example.com
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>ℹ The specifications for the other cloud providers Gardener already has an implementation for looks similar.&lt;/p>
&lt;h3 id="crd-definitions-and-workflow-adaptation">CRD definitions and workflow adaptation&lt;/h3>
&lt;p>In the following we are outlining the CRD definitions which define the API between Gardener and the dedicated controllers.
After that we will take a look at the current &lt;a href="https://github.com/gardener/gardener/blob/master/pkg/gardenlet/controller/shoot/shoot_control_reconcile.go">reconciliation&lt;/a>/&lt;a href="https://github.com/gardener/gardener/blob/master/pkg/gardenlet/controller/shoot/shoot_control_delete.go">deletion&lt;/a> flow and describe how it would look like in case we would implement this proposal.&lt;/p>
&lt;h4 id="custom-resource-definitions">Custom resource definitions&lt;/h4>
&lt;p>Every CRD has a &lt;code>.spec.type&lt;/code> field containing the respective instance of the dimension the CRD represents, e.g. the cloud provider, the DNS provider or the operation system name.
Moreover, the &lt;code>.status&lt;/code> field must contain&lt;/p>
&lt;ul>
&lt;li>&lt;code>observedGeneration&lt;/code> (&lt;code>int64&lt;/code>), a field indicating on which generation the controller last worked on.&lt;/li>
&lt;li>&lt;code>state&lt;/code> (&lt;code>*runtime.RawExtension&lt;/code>), a field which is not interpreted by Gardener but persisted; it should be treated opaque and only be used by the respective CRD-specific controller (it can store anything it needs to re-construct its own state).&lt;/li>
&lt;li>&lt;code>lastError&lt;/code> (&lt;code>object&lt;/code>), a field which is optional and only present if the last operation ended with an error state.&lt;/li>
&lt;li>&lt;code>lastOperation&lt;/code> (&lt;code>object&lt;/code>), a field which always exists and which indicates what the last operation of the controller was.&lt;/li>
&lt;li>&lt;code>conditions&lt;/code> (&lt;code>list&lt;/code>), a field allowing the controller to report health checks for its area of responsibility.&lt;/li>
&lt;/ul>
&lt;p>Some CRDs might have a &lt;code>.spec.providerConfig&lt;/code> or a &lt;code>.status.providerStatus&lt;/code> field containing controller-specific information that is treated opaque by Gardener and will only be copied to dependent or depending CRDs.&lt;/p>
&lt;h5 id="dns-records">DNS records&lt;/h5>
&lt;p>Every Shoot needs two DNS records (or three, depending on whether nginx-ingress addon is enabled), one so-called &amp;ldquo;internal&amp;rdquo; record that Gardener uses in the kubeconfigs of the Shoot cluster&amp;rsquo;s system components, and one so-called &amp;ldquo;external&amp;rdquo; record which is used in the kubeconfig provided to the user.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: dns.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: DNSProvider
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: alicloud
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: alicloud-dns
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: alicloud-credentials
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> domains:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> include:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - my.own.domain.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: dns.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: DNSEntry
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: dns
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: default
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dnsName: dns.my.own.domain.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ttl: 600
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> targets:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 8.8.8.8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: 4
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: some-state
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastUpdateTime: 2018-04-04T07:08:51Z
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> description: some-error message
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> codes:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - ERR_UNAUTHORIZED
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastUpdateTime: 2018-04-04T07:24:51Z
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> progress: 70
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: Reconcile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: Processing
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> description: Currently provisioning ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> conditions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - lastTransitionTime: 2018-07-11T10:18:25Z
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> message: DNS record has been created and is available.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reason: RecordResolvable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> status: &lt;span style="color:#a31515">&amp;#34;True&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: Available
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> propagate: &lt;span style="color:#00f">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerStatus:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: aws.extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: DNSStatus
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h5 id="infrastructure-provisioning">Infrastructure provisioning&lt;/h5>
&lt;p>The &lt;code>Infrastructure&lt;/code> CRD contains the information about VPC, networks, security groups, availability zones, &amp;hellip;, basically, everything that needs to be prepared before an actual VMs/load balancers/&amp;hellip; can be provisioned.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Infrastructure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: infrastructure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--core--aws-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: aws.extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: InfrastructureConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> networks:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> vpc:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cidr: 10.250.0.0/16
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> internal:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 10.250.112.0/22
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> public:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 10.250.96.0/22
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> workers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 10.250.0.0/19
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> zones:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - eu-west-1a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dns:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiserver: api.aws-01.core.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-aws-credentials
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sshPublicKey: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> &lt;/span> base64(key)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerStatus:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: aws.extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: InfrastructureStatus
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> vpc:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> id: vpc-1234
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> subnets:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - id: subnet-acbd1234
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: workers
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> zone: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> securityGroups:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - id: sg-xyz12345
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: workers
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> iam:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> nodesRoleARN: &amp;lt;some-arn&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> instanceProfileName: foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ec2:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> keyName: bar
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h5 id="backup-infrastructure-provisioning">Backup infrastructure provisioning&lt;/h5>
&lt;p>The &lt;code>BackupInfrastructure&lt;/code> CRD in the Seeds tells the cloud-specific controller to prepare a blob store bucket/container which can later be used to store etcd backups.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: BackupInfrastructure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: etcd-backup
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--core--aws-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> storageContainerName: asdasjndasd-1293912378a-2213
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-aws-credentials
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h5 id="cloud-config-user-data-for-bootstrapping-machines">Cloud config (user-data) for bootstrapping machines&lt;/h5>
&lt;p>Gardener will continue to keep knowledge about the content of the cloud config scripts, but it will hand over it to the respective OS-specific controller which will generate the specific valid representation.
Gardener creates two &lt;code>MachineCloudConfig&lt;/code> CRDs, one for the cloud-config-downloader (which will later flow into the &lt;code>WorkerPool&lt;/code> CRD) and one for the real cloud-config (which will be stored as a &lt;code>Secret&lt;/code> in the Shoot&amp;rsquo;s &lt;code>kube-system&lt;/code> namespace, and downloaded and executed from the cloud-config-downloader on the machines).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: MachineCloudConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: pool-01-downloader
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--core--aws-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: CoreOS
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> units:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: cloud-config-downloader.service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> command: start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enable: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Unit]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Description=Downloads the original cloud-config from Shoot API Server and executes it
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> After=docker.service docker.socket
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Wants=docker.socket
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Service]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Restart=always
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> RestartSec=30
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> EnvironmentFile=/etc/environment
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ExecStart=/bin/sh /var/lib/cloud-config-downloader/download-cloud-config.sh&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> files:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - path: /var/lib/cloud-config-downloader/credentials/kubeconfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> permissions: 0644
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: cloud-config-downloader
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dataKey: kubeconfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - path: /var/lib/cloud-config-downloader/download-cloud-config.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> permissions: 0644
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inline:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> encoding: b64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data: IyEvYmluL2Jhc2ggL...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cloudConfig: | &lt;span style="color:#008000"># base64-encoded&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">#cloud-config&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> coreos:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> update:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reboot-strategy: &lt;span style="color:#00f">off&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> units:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: cloud-config-downloader.service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> command: start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enable: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Unit]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Description=Downloads the original cloud-config from Shoot API Server and execute it
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> After=docker.service docker.socket
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Wants=docker.socket
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Service]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Restart=always
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> RestartSec=30
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>ℹ The cloud-config-downloader script does not only download the cloud-config initially but at regular intervals, e.g., every &lt;code>30s&lt;/code>.
If it sees an updated cloud-config then it applies it again by reloading and restarting all systemd units in order to reflect the changes.
The way how this reloading of the cloud-config happens is OS-specific as well and not known to Gardener anymore, however, it must be part of the script already.
On CoreOS, you have to execute &lt;code>/usr/bin/coreos-cloudinit --from-file=&amp;lt;path&amp;gt;&lt;/code> whereas on SLES you execute &lt;code>cloud-init --file &amp;lt;path&amp;gt; single -n write_files --frequency=once&lt;/code>.
As Gardener doesn&amp;rsquo;t know these commands it will write a placeholder expression instead (e.g., &lt;code>{RELOAD-CLOUD-CONFIG-WITH-PATH:&amp;lt;path&amp;gt;}&lt;/code>) and the OS-specific controller is asked to replace it with the proper expression.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: MachineCloudConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: pool-01-original &lt;span style="color:#008000"># stored as secret and downloaded later&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--core--aws-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: CoreOS
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> units:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: docker.service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> drop-ins:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: 10-docker-opts.conf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Service]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Environment=&amp;#34;DOCKER_OPTS=--log-opt max-size=60m --log-opt max-file=3&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: docker-monitor.service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> command: start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enable: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Unit]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Description=Docker-monitor daemon
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> After=kubelet.service
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Service]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Restart=always
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> EnvironmentFile=/etc/environment
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ExecStart=/opt/bin/health-monitor docker&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: kubelet.service
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> command: start
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enable: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Unit]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Description=kubelet daemon
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Documentation=https://kubernetes.io/docs/admin/kubelet
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> After=docker.service
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Wants=docker.socket rpc-statd.service
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Service]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> Restart=always
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> RestartSec=10
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> EnvironmentFile=/etc/environment
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ExecStartPre=/bin/docker run --rm -v /opt/bin:/opt/bin:rw k8s.gcr.io/hyperkube:v1.11.2 cp /hyperkube /opt/bin/
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ExecStartPre=/bin/sh -c &amp;#39;hostnamectl set-hostname $(cat /etc/hostname | cut -d &amp;#39;.&amp;#39; -f 1)&amp;#39;
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ExecStart=/opt/bin/hyperkube kubelet \
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> --allow-privileged=true \
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> --bootstrap-kubeconfig=/var/lib/kubelet/kubeconfig-bootstrap \
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> files:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - path: /var/lib/kubelet/ca.crt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> permissions: 0644
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: ca-kubelet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> dataKey: ca.crt
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - path: /var/lib/cloud-config-downloader/download-cloud-config.sh
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> permissions: 0644
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inline:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> encoding: b64
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data: IyEvYmluL2Jhc2ggL...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - path: /etc/sysctl.d/99-k8s-general.conf
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> permissions: 0644
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inline:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> vm.max_map_count = 135217728
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> kernel.softlockup_panic = 1
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> kernel.softlockup_all_cpu_backtrace = 1
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - path: /opt/bin/health-monitor
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> permissions: 0755
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> content:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inline:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> #!/bin/bash
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> set -o nounset
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> set -o pipefail
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> function docker_monitoring {
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cloudConfig: ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Cloud-specific controllers which might need to add another kernel option or another flag to the kubelet, maybe even another file to the disk, can register a &lt;code>MutatingWebhookConfiguration&lt;/code> to that resource and modify it upon creation/update.
The task of the &lt;code>MachineCloudConfig&lt;/code> controller is to only generate the OS-specific cloud-config based on the &lt;code>.spec&lt;/code> field, but not to add or change any logic related to Shoots.&lt;/p>
&lt;h5 id="worker-pools-definition">Worker pools definition&lt;/h5>
&lt;p>For every worker pool defined in the &lt;code>Shoot&lt;/code> Gardener will create a &lt;code>WorkerPool&lt;/code> CRD which shall be picked up by a cloud-specific controller and be translated to &lt;code>MachineClass&lt;/code>es and &lt;code>MachineDeployment&lt;/code>s.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: WorkerPool
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: pool-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--core--aws-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cloudConfig: base64(downloader-cloud-config)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> infrastructureProviderStatus:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: aws.extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: InfrastructureStatus
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> vpc:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> id: vpc-1234
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> subnets:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - id: subnet-acbd1234
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: workers
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> zone: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> securityGroups:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - id: sg-xyz12345
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: workers
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> iam:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> nodesRoleARN: &amp;lt;some-arn&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> instanceProfileName: foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ec2:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> keyName: bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: aws.cloud.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: WorkerPoolConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> machineImage:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: CoreOS
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ami: ami-d0dcef3b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> machineType: m4.large
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> volumeType: gp2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> volumeSize: 20Gi
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> zones:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - eu-west-1a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-aws-credentials
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> minimum: 2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> maximum: 2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h5 id="generic-resources">Generic resources&lt;/h5>
&lt;p>Some components are cloud-specific and must be deployed by the cloud-specific botanists.
Others might need to deploy another pod next to the shoot&amp;rsquo;s control plane or must do anything else.
Some of these might be important for a functional cluster (e.g., the cloud-controller-manager, or a CSI plugin in the future), and controllers should be able to report errors back to the user.
Consequently, in order to trigger the controllers to deploy these components Gardener would write a &lt;code>Generic&lt;/code> CRD to the Seed to trigger the deployment.
No operation is depending on the status of these resources, however, the entire reconciliation flow is.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Generic
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: cloud-components
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--core--aws-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: cloud-components
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-aws-credentials
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootSpec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="shoot-state">Shoot state&lt;/h4>
&lt;p>In order to enable moving the control plane of a Shoot between Seed clusters (e.g., if a Seed cluster is not available anymore or entirely broken) Gardener must store some non-reconstructable state, potentially also the state written by the controllers.
Gardener watches these extension CRDs and copies the &lt;code>.status.state&lt;/code> in a &lt;code>ShootState&lt;/code> resource into the Garden cluster.
Any observed status change of the respective CRD-controllers must be immediately reflected in the &lt;code>ShootState&lt;/code> resource.
The contract between Gardener and those controllers is: &lt;strong>Every controller must be capable of reconstructing its own environment based on both the state it has written before and on the real world&amp;rsquo;s conditions/state.&lt;/strong>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ShootState
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: shoot--core--aws-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>shootRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: aws-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> project: core
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>state:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secrets:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: ca
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: kube-apiserver-cert
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resources:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kind: DNS
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: record-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: &amp;lt;copied-state-of-dns-crd&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kind: Infrastructure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: networks
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: &amp;lt;copied-state-of-infrastructure-crd&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;other fields required to keep track of&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>We cannot assume that Gardener is always online to observe the most recent states the controllers have written to their resources.
Consequently, the information stored here must not be used as &amp;ldquo;single point of truth&amp;rdquo;, but the controllers must potentially check the real world&amp;rsquo;s status to reconstruct themselves.
However, this must anyway be part of their normal reconciliation logic and is a general best practice for Kubernetes controllers.&lt;/p>
&lt;h4 id="shoot-health-checksconditions">Shoot health checks/conditions&lt;/h4>
&lt;p>Some of the existing conditions already contain specific code which shall be simplified as well.
All of the CRDs described above have a &lt;code>.status.conditions&lt;/code> field to which the controllers may write relevant health information of their function area.
Gardener will pick them up and copy them over to the Shoots &lt;code>.status.conditions&lt;/code> (only those conditions setting &lt;code>propagate=true&lt;/code>).&lt;/p>
&lt;h4 id="reconciliation-flow">Reconciliation flow&lt;/h4>
&lt;p>We are now examining the current Shoot creation/reconciliation flow and describe how it could look like when applying this proposal:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Operation&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>botanist.DeployNamespace&lt;/td>
&lt;td>Gardener creates the namespace for the Shoot in the Seed cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeployKubeAPIServerService&lt;/td>
&lt;td>Gardener creates a Service of type &lt;code>LoadBalancer&lt;/code> in the Seed.&lt;br>AWS Botanist registers a Mutating Webhook and adds its AWS-specific annotation.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.WaitUntilKubeAPIServerServiceIsReady&lt;/td>
&lt;td>Gardener checks the &lt;code>.status&lt;/code> object of the just created &lt;code>Service&lt;/code> in the Seed. The contract is that also clouds not supporting load balancers must react on the &lt;code>Service&lt;/code> object and modify the &lt;code>.status&lt;/code> to correctly reflect the kube-apiserver&amp;rsquo;s ingress IP.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeploySecrets&lt;/td>
&lt;td>Gardener creates the secrets/certificates it needs like it does today, but it provides utility functions that can be adopted by Botanists/other controllers if they need additional certificates/secrets created on their own. (We should also add labels to all secrets)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.Shoot.Components.DNS.Internal{Provider/Entry}.Deploy&lt;/td>
&lt;td>Gardener creates a DNS-specific CRD in the Seed, and the responsible DNS-controller picks it up and creates a corresponding DNS record (see CRD specification above).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.Shoot.Components.DNS.External{Provider/Entry}.Deploy&lt;/td>
&lt;td>Gardener creates a DNS-specific CRD in the Seed, and the responsible DNS-controller picks it up and creates a corresponding DNS record: (see CRD specification above).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shootCloudBotanist.DeployInfrastructure&lt;/td>
&lt;td>Gardener creates a Infrastructure-specific CRD in the Seed, and the responsible Botanist picks it up and does its job: (see CRD above).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeployBackupInfrastructure&lt;/td>
&lt;td>Gardener creates a &lt;code>BackupInfrastructure&lt;/code> resource in the Garden cluster.&lt;br>(The BackupInfrastructure controller creates a BackupInfrastructure-specific CRD in the Seed, and the responsible Botanist picks it up and does its job: (see CRD above).)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.WaitUntilBackupInfrastructureReconciled&lt;/td>
&lt;td>Gardener checks the &lt;code>.status&lt;/code> object of the just created &lt;code>BackupInfrastructure&lt;/code> resource.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.DeployETCD&lt;/td>
&lt;td>Gardener does only deploy the etcd &lt;code>StatefulSet&lt;/code> without backup-restore sidecar at all.&lt;br>The cloud-specific Botanist registers a Mutating Webhook and adds the backup-restore sidecar, and it also creates the &lt;code>Secret&lt;/code> needed by the backup-restore sidecar.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.WaitUntilEtcdReady&lt;/td>
&lt;td>Gardener checks the &lt;code>.status&lt;/code> object of the etcd &lt;code>Statefulset&lt;/code> and waits until readiness is indicated.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.DeployCloudProviderConfig&lt;/td>
&lt;td>Gardener does not execute this anymore because it doesn&amp;rsquo;t know anything about cloud-specific configuration.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.DeployKubeAPIServer&lt;/td>
&lt;td>Gardener does only deploy the kube-apiserver &lt;code>Deployment&lt;/code> without any cloud-specific flags/configuration.&lt;br> The cloud-specific Botanist registers a Mutating Webhook and adds whatever is needed for the kube-apiserver to run in its cloud environment.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.DeployKubeControllerManager&lt;/td>
&lt;td>Gardener does only deploy the kube-controller-manager &lt;code>Deployment&lt;/code> without any cloud-specific flags/configuration.&lt;br>The cloud-specific Botanist registers a Mutating Webhook and adds whatever is needed for the kube-controller-manager to run in its cloud environment (e.g., the cloud-config).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.DeployKubeScheduler&lt;/td>
&lt;td>Gardener does only deploy the kube-scheduler &lt;code>Deployment&lt;/code> without any cloud-specific flags/configuration.&lt;br>The cloud-specific Botanist registers a Mutating Webhook and adds whatever is needed for the kube-scheduler to run in its cloud environment.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.DeployCloudControllerManager&lt;/td>
&lt;td>Gardener does not execute this anymore because it doesn&amp;rsquo;t know anything about cloud-specific configuration. The Botanists would be responsible to deploy their own cloud-controller-manager now.&lt;br>They would watch for the kube-apiserver Deployment to exist, and as soon as it does, they deploy the CCM.&lt;br> (Side note: The Botanist would also be responsible to deploy further controllers needed for this cloud environment, e.g. F5-controllers or CSI plugins).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.WaitUntilKubeAPIServerReady&lt;/td>
&lt;td>Gardener checks the &lt;code>.status&lt;/code> object of the kube-apiserver &lt;code>Deployment&lt;/code> and waits until readiness is indicated.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.InitializeShootClients&lt;/td>
&lt;td>Unchanged; Gardener creates a Kubernetes client for the Shoot cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeployMachineControllerManager&lt;/td>
&lt;td>Deleted, Gardener does no longer deploy MCM itself. See below.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.ReconcileMachines&lt;/td>
&lt;td>Gardener creates a &lt;code>Worker&lt;/code> CRD in the Seed, and the responsible &lt;code>Worker&lt;/code> controller picks it up and does its job (see CRD above). It also deploys the machine-controller-manager.&lt;br>Gardener waits until the status indicates that the controller is done.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.DeployKubeAddonManager&lt;/td>
&lt;td>This function also computes the CoreOS cloud-config (because the secret storing it is managed by the kube-addon-manager).&lt;br>Gardener would deploy the CloudConfig-specific CRD in the Seed, and the responsible OS controller picks it up and does its job (see CRD above).&lt;br>The Botanists which would have to modify something would register a Webhook for this CloudConfig-specific resource and apply their changes.&lt;br>The rest is mostly unchanged, Gardener generates the manifests for the addons and deploys the kube-addon-manager into the Seed.&lt;br>AWS Botanist registers a Webhook for nginx-ingress.&lt;br>Azure Botanist registers a Webhook for calico.&lt;br>Gardener will no longer deploy the &lt;code>StorageClass&lt;/code>es. Instead, the Botanists wait until the kube-apiserver is available and deploy them.&lt;br>&lt;br>In the long term we want to get rid of optional addons inside the Gardener core and implement a sophisticated addon concept (see &lt;a href="https://github.com/gardener/gardener/issues/246">#246&lt;/a>).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shootCloudBotanist.DeployKube2IAMResources&lt;/td>
&lt;td>This function would be removed (currently Gardener would execute a Terraform job creating the IAM roles specified in the Shoot manifest). We cannot keep this behavior, the user would be responsible to create the needed IAM roles on its own.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.Shoot.Components.Nginx.DNSEtnry&lt;/td>
&lt;td>Gardener creates a DNS-specific CRD in the Seed, and the responsible DNS-controller picks it up and creates a corresponding DNS record (see CRD specification above).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.WaitUntilVPNConnectionExists&lt;/td>
&lt;td>Unchanged, Gardener checks that it is possible to port-forward to a Shoot pod.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>seedCloudBotanist.ApplyCreateHook&lt;/td>
&lt;td>This function would be removed (actually, only the AWS Botanist implements it).&lt;br>AWS Botanist deploys the aws-lb-readvertiser once the API Server is deployed and updates the ELB health check protocol one the load balancer pointing to the API server is created.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeploySeedMonitoring&lt;/td>
&lt;td>Unchanged, Gardener deploys the monitoring stack into the Seed.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeployClusterAutoscaler&lt;/td>
&lt;td>Unchanged, Gardener deploys the cluster-autoscaler into the Seed.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>ℹ We can easily lift the contract later and allow dynamic network plugins or not using the VPN solution at all.
We could also introduce a dedicated &lt;code>ControlPlane&lt;/code> CRD and leave the complete responsibility of deploying kube-apiserver, kube-controller-manager, etc. to other controllers (if we need it at some point in time).&lt;/p>
&lt;h4 id="deletion-flow">Deletion flow&lt;/h4>
&lt;p>We are now examining the current Shoot deletion flow and describe shortly how it could look like when applying this proposal:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Operation&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>botanist.DeploySecrets&lt;/td>
&lt;td>This is just refreshing the cloud provider secret in the Shoot namespace in the Seed (in case the user has changed it before triggering the deletion). This function would stay as it is.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.RefreshMachineClassSecrets&lt;/td>
&lt;td>This function would disappear.&lt;br>Worker Pool controller needs to watch the referenced secret and update the generated MachineClassSecrets immediately.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.RefreshCloudProviderConfig&lt;/td>
&lt;td>This function would disappear. Botanist needs to watch the referenced secret and update the generated cloud-provider-config immediately.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.RefreshCloudControllerManagerChecksums&lt;/td>
&lt;td>See &amp;ldquo;hybridBotanist.RefreshCloudProviderConfig&amp;rdquo;.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.RefreshKubeControllerManagerChecksums&lt;/td>
&lt;td>See &amp;ldquo;hybridBotanist.RefreshCloudProviderConfig&amp;rdquo;.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.InitializeShootClients&lt;/td>
&lt;td>Unchanged; Gardener creates a Kubernetes client for the Shoot cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeleteSeedMonitoring&lt;/td>
&lt;td>Unchanged; Gardener deletes the monitoring stack.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeleteKubeAddonManager&lt;/td>
&lt;td>Unchanged; Gardener deletes the kube-addon-manager.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeleteClusterAutoscaler&lt;/td>
&lt;td>Unchanged; Gardener deletes the cluster-autoscaler.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.WaitUntilKubeAddonManagerDeleted&lt;/td>
&lt;td>Unchanged; Gardener waits until the kube-addon-manager is deleted.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.CleanCustomResourceDefinitions&lt;/td>
&lt;td>Unchanged, Gardener cleans the CRDs in the Shoot.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.CleanKubernetesResources&lt;/td>
&lt;td>Unchanged, Gardener cleans all remaining Kubernetes resources in the Shoot.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>hybridBotanist.DestroyMachines&lt;/td>
&lt;td>Gardener deletes the WorkerPool-specific CRD in the Seed, and the responsible WorkerPool-controller picks it up and does its job.&lt;br>Gardener waits until the CRD is deleted.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shootCloudBotanist.DestroyKube2IAMResources&lt;/td>
&lt;td>This function would disappear (currently Gardener would execute a Terraform job deleting the IAM roles specified in the &lt;code>Shoot&lt;/code> manifest). We cannot keep this behavior, the user would be responsible to delete the needed IAM roles on its own.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>shootCloudBotanist.DestroyInfrastructure&lt;/td>
&lt;td>Gardener deletes the Infrastructure-specific CRD in the Seed, and the responsible Botanist picks it up and does its job.&lt;br>Gardener waits until the CRD is deleted.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.Shoot.Components.DNS.External{Provider/Entry}.Destroy&lt;/td>
&lt;td>Gardener deletes the DNS-specific CRD in the Seed, and the responsible DNS-controller picks it up and does its job.&lt;br>Gardener waits until the CRD is deleted.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeleteKubeAPIServer&lt;/td>
&lt;td>Unchanged; Gardener deletes the kube-apiserver.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeleteBackupInfrastructure&lt;/td>
&lt;td>Unchanged; Gardener deletes the &lt;code>BackupInfrastructure&lt;/code> object in the Garden cluster.&lt;br>(The BackupInfrastructure controller deletes the BackupInfrastructure-specific CRD in the Seed, and the responsible Botanist picks it up and does its job.&lt;br>The BackupInfrastructure controller waits until the CRD is deleted.)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.Shoot.Components.DNS.Internal{Provider/Entry}.Destroy&lt;/td>
&lt;td>Gardener deletes the DNS-specific CRD in the Seed, and the responsible DNS-controller picks it up and does its job.&lt;br>Gardener waits until the CRD is deleted.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeleteNamespace&lt;/td>
&lt;td>Unchanged; Gardener deletes the Shoot namespace in the Seed cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.WaitUntilSeedNamespaceDeleted&lt;/td>
&lt;td>Unchanged; Gardener waits until the Shoot namespace in the Seed has been deleted.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>botanist.DeleteGardenSecrets&lt;/td>
&lt;td>Unchanged; Gardener deletes the kubeconfig/ssh-keypair &lt;code>Secret&lt;/code> in the project namespace in the Garden.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="gardenlet">Gardenlet&lt;/h3>
&lt;p>One part of the whole extensibility work will also to further split Gardener itself.
Inspired from Kubernetes itself we plan to move the &lt;code>Shoot&lt;/code> reconciliation/deletion controller loops as well as the &lt;code>BackupInfrastructure&lt;/code> reconciliation/deletion controller loops into a dedicated &amp;ldquo;gardenlet&amp;rdquo; component that will run in the Seed cluster.
With that, it can talk locally to the responsible kube-apiserver and we do no longer need to perform every operation out of the Garden cluster.
This approach will also help us with scalability, performance, maintainability, testability in general.&lt;/p>
&lt;p>This architectural change implies that the Kubernetes API server of the Garden cluster must be exposed publicly (or at least be reachable by the registered Seeds). The Gardener controller-manager will remain and will keep its &lt;code>CloudProfile&lt;/code>, &lt;code>SecretBinding&lt;/code>, &lt;code>Quota&lt;/code>, &lt;code>Project&lt;/code>, and &lt;code>Seed&lt;/code> controller loops. One part of the seed controller could be to deploy the &amp;ldquo;gardenlet&amp;rdquo; into the Seeds, however, this would require network connectivity to the Seed cluster.&lt;/p>
&lt;h3 id="shoot-control-plane-movementmigration">Shoot control plane movement/migration&lt;/h3>
&lt;p>Automatically moving control planes is difficult with the current implementation as some resources created in the old Seed must be moved to the new one. However, some of them are not under Gardener&amp;rsquo;s control (e.g., &lt;code>Machine&lt;/code> resources). Moreover, the old control plane must be deactivated somehow to ensure that not two controllers work on the same things (e.g., virtual machines) from different environments.&lt;/p>
&lt;p>Gardener does not only deploy a DNS controller into the Seeds but also into its own Garden cluster.
For every Shoot cluster, Gardener commissions it to create a DNS &lt;code>TXT&lt;/code> record containing the name of the Seed responsible for the Shoot (holding the control plane), e.g.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>dig -t txt aws-01.core.garden.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>;; ANSWER SECTION:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>aws-01.core.garden.example.com. 120 IN TXT &lt;span style="color:#a31515">&amp;#34;Seed=seed-01&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Gardener always keeps the DNS record up-to-date based on which Seed is responsible.&lt;/p>
&lt;p>In the above CRD examples one object in the &lt;code>.spec&lt;/code> section was omitted as it is needed to get Shoot control plane movement/migration working (the field is only explained now in this section and not before; it was omitted on purpose to support focusing on the relevant specifications first).
Every CRD also has the following section in its &lt;code>.spec&lt;/code>:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>leadership:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> record: aws-01.core.garden.example.com
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> value: seed-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> leaseSeconds: 60
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Before every operation the CRD-controllers check this DNS record (based on the &lt;code>.spec.leadership.leaseSeconds&lt;/code> configuration) and verify that its result is equal to the &lt;code>.spec.leadership.value&lt;/code> field.
If both match they know that they should act on the resource, otherwise they stop doing anything.&lt;/p>
&lt;p>ℹ We will provide an easy-to-use framework for the controllers containing all of these features out-of-the-box in order to allow the developers to focus on writing the actual controller logic.&lt;/p>
&lt;p>When a Seed control plane move is triggered, the &lt;code>.spec.cloud.seed&lt;/code> field of the respective &lt;code>Shoot&lt;/code> is changed.
Gardener will change the respective DNS record&amp;rsquo;s value (&lt;code>aws-01.core.garden.example.com&lt;/code>) to contain the new Seed name.
After that it will wait &lt;code>2*60s&lt;/code> to be sure that all controllers have observed the change.
Then it starts reconciling and applying the CRDs together with a preset &lt;code>.status.state&lt;/code> into the new Seed (based on its last observations which were stored in the respective &lt;code>ShootState&lt;/code> object stored in the Garden cluster).
The controllers are - as per contract - asked to reconstruct their own environment based on the &lt;code>.status.state&lt;/code> they have written before and the real world&amp;rsquo;s status.
Apart from that, the normal reconciliation flow gets executed.&lt;/p>
&lt;p>Gardener stores the list of Seeds that were responsible for hosting a Shoots control plane at some time in the Shoots &lt;code>.status.seeds&lt;/code> list so that it knows which Seeds must be cleaned up (i.e., where the control plane must be deleted because it has been moved).
Once cleaned up, the Seed&amp;rsquo;s name will be removed from that list.&lt;/p>
&lt;h3 id="backupinfrastructure-migration">BackupInfrastructure migration&lt;/h3>
&lt;p>One part of the reconciliation flow above is the provisioning of the infrastructure for the Shoot&amp;rsquo;s etcd backups (usually, this is a blob store bucket/container).
Gardener already uses a separate &lt;code>BackupInfrastructure&lt;/code> resource that is written into the Garden cluster and picked up by a dedicated &lt;code>BackupInfrastructure&lt;/code> controller (bundled into the Gardener controller manager).
This dedicated resource exists mainly for the reason to allow keeping backups for a certain &amp;ldquo;grace period&amp;rdquo; even after the Shoot deletion itself:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: BackupInfrastructure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: aws-01-bucket
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden-core
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seed: seed-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootUID: uuid-of-shoot
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The actual provisioning is executed in a corresponding Seed cluster as Gardener can only assume network connectivity to the underlying cloud environment in the Seed.
We would like to keep the created artifacts in the Seed (e.g., Terraform state) near to the control plane.
Consequently, when Gardener moves a control plane, it will update the &lt;code>.spec.seed&lt;/code> field of the &lt;code>BackupInfrastructure&lt;/code> resource as well.
With the exact same logic described above the &lt;code>BackupInfrastructure&lt;/code> controller inside the Gardener will move to the new Seed.&lt;/p>
&lt;h2 id="registration-of-external-controllers-at-gardener">Registration of external controllers at Gardener&lt;/h2>
&lt;p>We want to have a dynamic registration process, i.e. we don&amp;rsquo;t want to hard-code any information about which controllers shall be deployed.
The ideal solution would be to not even requiring a restart of Gardener when a new controller registers.&lt;/p>
&lt;p>Every controller is registered by a &lt;code>ControllerRegistration&lt;/code> resource that introduces every controller together with its supported resources (dimension (&lt;code>kind&lt;/code>) and shape (&lt;code>type&lt;/code>) combination) to Gardener:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ControllerRegistration
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: dns-aws-route53
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resources:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kind: DNS
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: aws-route53
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># deployment:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># type: helm&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># providerConfig:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># chart.tgz: base64(helm-chart)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># values.yaml: |&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># foo: bar&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Every &lt;code>.kind&lt;/code>/&lt;code>.type&lt;/code> combination may only exist once in the system.&lt;/p>
&lt;p>When a &lt;code>Shoot&lt;/code> shall be reconciled Gardener can identify based on the referenced &lt;code>Seed&lt;/code> and the content of the &lt;code>Shoot&lt;/code> specification which controllers are needed in the respective Seed cluster.
It will demand the operators in the Garden cluster to deploy the controllers they are responsible for to a specific Seed.
This kind of communication happens via CRDs as well:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ControllerInstallation
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: dns-aws-route53
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> registrationRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: dns-aws-route53
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seedRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: seed-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> conditions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - lastTransitionTime: 2018-08-07T15:09:23Z
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> message: The controller has been successfully deployed to the seed.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reason: ControllerDeployed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> status: &lt;span style="color:#a31515">&amp;#34;True&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: Available
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The default scenario is that every controller is gets deployed by a dedicated operator that knows how to handle its lifecycle operations like deployment, update, upgrade, deletion.
This operator watches &lt;code>ControllerInstallation&lt;/code> resources and reacts on those it is responsible for (that it has created earlier).
Gardener is responsible for writing the &lt;code>.spec&lt;/code> field, the operator is responsible for providing information in the &lt;code>.status&lt;/code> indicating whether the controller was successfully deployed and is ready to be used.
Gardener will be also able to ask for deletion of controllers from Seeds when they are not needed there anymore by deleting the corresponding &lt;code>ControllerInstallation&lt;/code> object.&lt;/p>
&lt;p>ℹ The provided easy-to-use framework for the controllers will also contain these needed features to implement corresponding operators.&lt;/p>
&lt;p>For most cases the controller deployment is very simple (just deploying it into the seed with some static configuration).
In these cases it would produce unnecessary effort to ask for providing another component (the operator) that deploys the controller.
To simplify this situation Gardener will be able to react on &lt;code>ControllerInstallation&lt;/code>s specifying &lt;code>.spec.registration.deployment.type=helm&lt;/code>.
The controller would be registered with the &lt;code>ControllerRegistration&lt;/code> resources that would contain a Helm chart with all resources needed to deploy this controller into a seed (plus some static values).
Gardener would render the Helm chart and deploy the resources into the seed.
It will not react if &lt;code>.spec.registration.deployment.type!=helm&lt;/code> which allows to also use any other deployment mechanism. Controllers that are getting deployed by operators would not specify the &lt;code>.spec.deployment&lt;/code> section in the &lt;code>ControllerRegistration&lt;/code> at all.&lt;/p>
&lt;p>ℹ Any controller requiring dynamic configuration values (e.g., based on the cloud provider or the region of the seed) must be installed with the operator approach.&lt;/p>
&lt;h2 id="other-cloud-specific-parts">Other cloud-specific parts&lt;/h2>
&lt;p>The Gardener API server has a few admission controllers that contain cloud-specific code as well. We have to replace these parts as well.&lt;/p>
&lt;h3 id="defaulting-and-validation-admission-plugins">Defaulting and validation admission plugins&lt;/h3>
&lt;p>Right now, the admission controllers inside the Gardener API server do perform a lot of validation and defaulting of fields in the Shoot specification.
The cloud-specific parts of these admission controllers will be replaced by mutating admission webhooks that will get called instead.
As we will have a dedicated operator running in the Garden cluster anyway it will also get the responsibility to register this webhook if it needs to validate/default parts of the Shoot specification.&lt;/p>
&lt;p>Example: The &lt;code>.spec.cloud.workerPools[*].providerConfig.machineImage&lt;/code> field in the new Shoot manifest mentioned above could be omitted by the user and would get defaulted by the cloud-specific operator.&lt;/p>
&lt;h3 id="dns-hosted-zone-admission-plugin">DNS Hosted Zone admission plugin&lt;/h3>
&lt;p>For the same reasons the existing DNS Hosted Zone admission plugin will be removed from the Gardener core and moved into the responsibility of the respective DNS-specific operators running in the Garden cluster.&lt;/p>
&lt;h3 id="shoot-quota-admission-plugin">Shoot Quota admission plugin&lt;/h3>
&lt;p>The Shoot quota admission plugin validates create or update requests on Shoots and checks that the specified machine/storage configuration is defined as per referenced &lt;code>Quota&lt;/code> objects.
The cloud-specifics in this controller are no longer needed as the &lt;code>CloudProfile&lt;/code> and the &lt;code>Shoot&lt;/code> resource have been adapted:
The machine/storage configuration is no longer in cloud-specific sections but hard-wired fields in the general &lt;code>Shoot&lt;/code> specification (see example resources above).
The quota admission plugin will be simplified and remains in the Gardener core.&lt;/p>
&lt;h3 id="shoot-maintenance-controller">Shoot maintenance controller&lt;/h3>
&lt;p>Every Shoot cluster can define a maintenance time window in which Gardener will update the Kubernetes patch version (if enabled) and the used machine image version in the Shoot resource.
While the Kubernetes version is not part of the &lt;code>providerConfig&lt;/code> section in the &lt;code>CloudProfile&lt;/code> resource, the &lt;code>machineImage&lt;/code> field is, and thus Gardener can&amp;rsquo;t understand it any longer.
In the future Gardener has to rely on the cloud-specific operator (probably the same doing the defaulting/validation mentioned before) to update this field.
In the maintenance time window the maintenance controller will update the Kubernetes patch version (if enabled) and add a &lt;code>trigger.gardener.cloud=maintenance&lt;/code> annotation in the Shoot resource.
The already registered mutating web hook will call the operator who has to remove this annotation and update the &lt;code>machineImage&lt;/code> in the &lt;code>.spec.cloud.workerPools[*].providerConfig&lt;/code> sections.&lt;/p>
&lt;h2 id="alternatives">Alternatives&lt;/h2>
&lt;ul>
&lt;li>Alternative to DNS approach for Shoot control plane movement/migration: We have thought about rotating the credentials when a move is triggered which would make all controllers ineffective immediately. However, one problem with this is that we require IAM privileges for the users infrastructure account which might be not desired. Another, more complicated problem is that we cannot assume API access in order to create technical users for all cloud environments that might be supported.&lt;/li>
&lt;/ul></description></item><item><title>Docs: 02 Backupinfra</title><link>https://gardener.cloud/docs/gardener/proposals/02-backupinfra/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/02-backupinfra/</guid><description>
&lt;h1 id="backup-infrastructure-crd-and-controller-redesign">Backup Infrastructure CRD and Controller Redesign&lt;/h1>
&lt;h2 id="goal">Goal&lt;/h2>
&lt;ul>
&lt;li>As an operator, I would like to efficiently use the backup bucket for multiple clusters, thereby limiting the total number of buckets required.&lt;/li>
&lt;li>As an operator, I would like to use different cloud provider for backup bucket provisioning other than cloud provider used for seed infrastructure.&lt;/li>
&lt;li>Have seed independent backups, so that we can easily migrate a shoot from one seed to another.&lt;/li>
&lt;li>Execute the backup operations (including bucket creation and deletion) from a seed, because network connectivity may only be ensured from the seeds (not necessarily from the garden cluster).&lt;/li>
&lt;li>Preserve the garden cluster as source of truth (no information is missing in the garden cluster to reconstruct the state of the backups even if seed and shoots are lost completely).&lt;/li>
&lt;li>Do not violate the infrastructure limits in regards to blob store limits/quotas.&lt;/li>
&lt;/ul>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Currently, every shoot cluster has its own etcd backup bucket with a centrally configured retention period. With the growing number of clusters, we are soon running out of the &lt;a href="https://gist.github.com/swapnilgm/5c4d5506811e63c32ab3d73c4171d30f">quota limits of buckets on the cloud provider&lt;/a>. Moreover, even if the clusters are deleted, the backup buckets do exist, for a configured period of retention. Hence, there is need of minimizing the total count of buckets.&lt;/p>
&lt;p>In addition, currently we use seed infrastructure credentials to provision the bucket for etcd backups. This results in binding backup bucket provider to seed infrastructure provider.&lt;/p>
&lt;h2 id="terminology">Terminology&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Bucket&lt;/strong> : It is equivalent to s3 bucket, abs container, gcs bucket, swift container, alicloud bucket&lt;/li>
&lt;li>&lt;strong>Object&lt;/strong> : It is equivalent s3 object, abs blob, gcs object, swift object, alicloud object, snapshot/backup of etcd on object store.&lt;/li>
&lt;li>&lt;strong>Directory&lt;/strong> : As such there is no concept of directory in object store but usually the use directory as &lt;code>/&lt;/code> separate common prefix for set of objects. Alternatively they use term folder for same.&lt;/li>
&lt;li>&lt;strong>deletionGracePeriod&lt;/strong>: This means grace period or retention period for which backups will be persisted post deletion of shoot.&lt;/li>
&lt;/ul>
&lt;h2 id="current-spec">Current Spec:&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-YAML" data-lang="YAML">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">#BackupInfra spec&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Kind: BackupInfrastructure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seed: seedName
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootUID : shoot.status.uid
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="current-naming-conventions">Current naming conventions&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;/th>
&lt;th>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>SeedNamespace :&lt;/td>
&lt;td>Shoot&amp;ndash;projectname&amp;ndash;shootname&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>seed:&lt;/td>
&lt;td>seedname&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ShootUID :&lt;/td>
&lt;td>shoot.status.UID&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BackupInfraname:&lt;/td>
&lt;td>seednamespce+sha(uid)[:5]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Backup-bucket-name:&lt;/td>
&lt;td>BackupInfraName&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>BackupNamespace:&lt;/td>
&lt;td>backup&amp;ndash;BackupInfraName&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="proposal">Proposal&lt;/h2>
&lt;p>Considering &lt;a href="https://gardener.cloud/docs/gardener/proposals/01-extensibility/#backup-infrastructure-provisioning">Gardener extension proposal&lt;/a> in mind, the backup infrastructure controller can be divided in two parts. There will be basically four backup infrastructure related CRD&amp;rsquo;s. Two on the garden apiserver. And two on the seed cluster. Before going into to workflow, let&amp;rsquo;s just first have look at the CRD.&lt;/p>
&lt;h3 id="crd-on-garden-cluster">CRD on Garden cluster&lt;/h3>
&lt;p>Just to give brief before going into the details, we will be sticking to the fact that Garden apiserver is always source of truth. Since backupInfra will be maintained post deletion of shoot, the info regarding this should always come from garden apiserver, we will continue to have BackupInfra resource on garden apiserver with some modifications.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: garden.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: BackupBucket
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: packet-region1-uid[:5]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># No namespace needed. This will be cluster scope resource.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ownerReferences:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kind: CloudProfile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: packet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provider: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef: &lt;span style="color:#008000"># Required for root&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: backup-operator-aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seed: ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: garden.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: BackupEntry
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: shoot--dev--example--3ef42 &lt;span style="color:#008000"># Naming convention explained before&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden-dev
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ownerReferences:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - apiVersion: core.gardener.cloud/v1beta1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> blockOwnerDeletion: &lt;span style="color:#00f">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> controller: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: Shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: example
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> uid: 19a9538b-5058-11e9-b5a6-5e696cab3bc8
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootUID: 19a9538b-5058-11e9-b5a6-5e696cab3bc8 &lt;span style="color:#008000"># Just for reference to find back associated shoot.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Following section comes from cloudProfile or seed yaml based on granularity decision.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bucketName: packet-region1-uid[:5]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seed: ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="crd-on-seed-cluster">CRD on Seed cluster&lt;/h3>
&lt;p>Considering the extension proposal, we want individual component to be handled by controller inside seed cluster. We will have Backup related resource in registered seed cluster as well.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: BackupBucket
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: packet-random[:5]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># No namespace need. This will be cluster scope resource&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: backup-operator-aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: backup-garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>There are two points for introducing BackupEntry resource.&lt;/p>
&lt;ol>
&lt;li>Cloud provider specific code goes completely in seed cluster.&lt;/li>
&lt;li>Network issue is also handled by moving deletion part to backup-extension-controller in seed cluster.&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: BackupEntry
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: shoot--dev--example--3ef42 &lt;span style="color:#008000"># Naming convention explained later&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># No namespace need. This will be cluster scope resource&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef: &lt;span style="color:#008000"># Required for root&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: backup-operator-aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: backup-garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="workflow">Workflow&lt;/h3>
&lt;ul>
&lt;li>Gardener administrator will configure the cloudProfile with backup infra credentials and provider config as follows.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># CloudProfile.yaml:&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backup:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provider: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: backup-operator-aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Here CloudProfileController will interpret this spec as follows:&lt;/p>
&lt;ul>
&lt;li>If &lt;code>spec.backup&lt;/code> is nil
&lt;ul>
&lt;li>No backup for any shoot.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>If &lt;code>spec.backup.region&lt;/code> is not nil,
&lt;ul>
&lt;li>Then respect it, i.e. use the provider and unique region field mentioned there for BackupBucket.&lt;/li>
&lt;li>Here Preferably, &lt;code>spec.backup.region&lt;/code> field will be unique, since for cross provider, it doesn’t make much sense. Since region name will be different for different providers.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Otherwise, spec.backup.region is nil then,
&lt;ul>
&lt;li>If same provider case i.e. spec.backup.provider = spec.(type-of-provider) or nil,
&lt;ul>
&lt;li>Then, for each region from &lt;code>spec.(type-of-provider).constraints.regions&lt;/code> create a &lt;code>BackupBucket&lt;/code> instance. This can be done lazily i.e. create &lt;code>BackupBucket&lt;/code> instance for region only if some seed actually spawned in the region has been registered. This will avoid creating IaaS bucket even if no seed is registered in that region, but region is listed in &lt;code>cloudprofile&lt;/code>.&lt;/li>
&lt;li>Shoot controller will choose backup container as per the seed region. (With shoot control plane migration also, seed’s availability zone might change but the region will be remaining same as per current scope.)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Otherwise cross provider case i.e. spec.backup.provider != spec.(type-of-provider)
&lt;ul>
&lt;li>Report validation error: Since, for example, we can’t expect &lt;code>spec.backup.provider&lt;/code> = &lt;code>aws&lt;/code> to support region in, &lt;code>spec.packet.constraint.region&lt;/code>. Where type-of-provider is &lt;code>packet&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Following diagram represent overall flow in details:&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/02-backupinfra-provisioning-sequence-diagram_c08a3e.svg" alt="sequence-diagram">&lt;/p>
&lt;h4 id="reconciliation">Reconciliation&lt;/h4>
&lt;p>Reconciliation on backup entry in seed cluster mostly comes in picture at the time of deletion. But we can add initialization steps like creation of &lt;a href="#terminology">directory&lt;/a> specific to shoot in backup bucket. We can simply create BackupEntry at the time of shoot deletion as well.&lt;/p>
&lt;h4 id="deletion">Deletion&lt;/h4>
&lt;ul>
&lt;li>On shoot deletion, the BackupEntry instance i.e. shoot specific instance will get deletion timestamp because of ownerReference.&lt;/li>
&lt;li>If &lt;code>deletionGracePeriod&lt;/code> configured in GCM component configuration is expired, BackupInfrastructure Controller will delete the backup folder associated with it from backup object store.&lt;/li>
&lt;li>Finally, it will remove the &lt;code>finalizer&lt;/code> from backupEntry instance.&lt;/li>
&lt;/ul>
&lt;h3 id="alternative">Alternative&lt;/h3>
&lt;p>&lt;img src="https://gardener.cloud/__resources/02-backupinfra-provisioning-with-deletion-job_e51f05.svg" alt="sequence-diagram">&lt;/p>
&lt;h2 id="discussion-points--variations">Discussion points / variations&lt;/h2>
&lt;h3 id="manual-vs-dynamic-bucket-creation">Manual vs dynamic bucket creation&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>As per limit observed on different cloud providers, we can have single bucket for backups on one cloud providers. So, we could avoid the little complexity introduced in above approach by pre-provisioning buckets as a part of landscape setup. But there won&amp;rsquo;t be anybody to detect bucket existence and its reconciliation. Ideally this should be avoided.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Another thing we can have is, we can let administrator register the pool of root backup infra resource and let the controller schedule backup on one of this.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>One more variation here could be to create bucket dynamically per hash of shoot UID.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="sdk-vs-terraform">SDK vs Terraform&lt;/h3>
&lt;p>Initial reason for going for terraform script is its stability and the provided parallelism/concurrency in resource creation. For backup infrastructure, Terraform scripts are very minimal right now. Its simply have bucket creation script. With shared bucket logic, if possible we might want to isolate access at &lt;a href="#terminology">directory&lt;/a> level but again its additional one call. So, we will prefer switching to SDK for all object store operations.&lt;/p>
&lt;h3 id="limiting-the-number-of-shoots-per-bucket">Limiting the number of shoots per bucket&lt;/h3>
&lt;p>Again as per limit observed on different cloud providers, we can have single bucket for backups on one cloud providers. But if we want to limit the number of shoots associated with bucket, we can have central map of configuration in &lt;code>gardener-controller-component-configuration.yaml&lt;/code>.
Where we will mark supported count of shoots per cloud provider. Most probable space could be,
&lt;code>controller.backupInfrastructures.quota&lt;/code>. If limit is reached we can create new &lt;code>BucketBucket&lt;/code> instance.&lt;/p>
&lt;p>e.g.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: controllermanager.config.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ControllerManagerConfiguration
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>controllers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backupInfrastructure:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> quota:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - provider: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> limit: 100 &lt;span style="color:#008000"># Number mentioned here are random, just for example purpose.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - provider: azure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> limit: 80
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - provider: openstack
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> limit: 100
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="backward-compatibility">Backward compatibility&lt;/h2>
&lt;h3 id="migration">Migration&lt;/h3>
&lt;ul>
&lt;li>Create shoot specific folder.&lt;/li>
&lt;li>Transfer old objects.&lt;/li>
&lt;li>Create manifest of objects on new bucket
&lt;ul>
&lt;li>Each entry will have status: None,Copied, NotFound.&lt;/li>
&lt;li>Copy objects one by one.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Scale down etcd-main with old config. ⚠️ Cluster down time&lt;/li>
&lt;li>Copy remaining objects&lt;/li>
&lt;li>Scale up etcd-main with new config.&lt;/li>
&lt;li>Destroy Old bucket and old backup namespace. It can be immediate or preferably &lt;strong>lazy&lt;/strong> deletion.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gardener.cloud/__resources/02-backupinfra-migration_a671d5.svg" alt="backup-migration-sequence-diagram">&lt;/p>
&lt;h3 id="legacy-mode-alternative">Legacy Mode alternative&lt;/h3>
&lt;ul>
&lt;li>If Backup namespace present in seed cluster, then follow the legacy approach.&lt;/li>
&lt;li>i.e. reconcile creation/existence of shoot specific bucket and backup namespace.&lt;/li>
&lt;li>If backup namespace is not created, use shared bucket.&lt;/li>
&lt;li>&lt;strong>Limitation&lt;/strong> Never know when the existing cluster will be deleted, and hence, it might be little difficult to maintain with next release of gardener. This might look simple and straight-forward for now but may become pain point in future, if in worst case, because of some new use cases or refactoring, we have to change the design again. Also, even after multiple garden release we won&amp;rsquo;t be able to remove deprecated existing BackupInfrastructure CRD&lt;/li>
&lt;/ul>
&lt;!--
## Extension
☑️ _TODO:_ Out-of-tree object store interface library.
-->
&lt;h3 id="references">References&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://gardener.cloud/docs/gardener/proposals/01-extensibility/#backup-infrastructure-provisioning">Gardener extension proposal&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gist.github.com/swapnilgm/5c4d5506811e63c32ab3d73c4171d30f">Cloud providers object store limit comparison&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: 03 Networking Extensibility</title><link>https://gardener.cloud/docs/gardener/proposals/03-networking-extensibility/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/03-networking-extensibility/</guid><description>
&lt;h1 id="network-extensibility">Network Extensibility&lt;/h1>
&lt;p>Currently Gardener follows a mono network-plugin support model (i.e., Calico). Although this can seem to be the more stable approach, it does not completely reflect the real use-case. This proposal brings forth an effort to add an extra level of customizability to Gardener networking.&lt;/p>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Gardener is an open-source project that provides a nested user model. Basically, there are two types of services provided by Gardener to its users:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Managed&lt;/strong>: users only request a Kubernetes cluster (Clusters-as-a-Service)&lt;/li>
&lt;li>&lt;strong>Hosted&lt;/strong>: users utilize Gardener to provide their own managed version of Kubernetes (Cluster-Provisioner-as-a-service)&lt;/li>
&lt;/ul>
&lt;p>For the first set of users, the choice of network plugin might not be so important, however, for the second class of users (i.e., Hosted) it is important to be able to customize networking based on their needs.&lt;/p>
&lt;p>Furthermore, Gardener provisions clusters on different cloud-providers with different networking requirements. For example, Azure does not support Calico Networking [1], this leads to the introduction of manual exceptions in static add-on charts which is error prune and can lead to failures during upgrades.&lt;/p>
&lt;p>Finally, every provider is different, and thus the network always needs to adapt to the infrastructure needs to provider better performance. Consistency does not necessarily lie in the implementation but in the interface.&lt;/p>
&lt;h2 id="gardener-network-extension">Gardener Network Extension&lt;/h2>
&lt;p>The goal of the Gardener Network Extensions is to support different network plugin, therefore, the specification for the network resource won&amp;rsquo;t be fixed and will be customized based on the underlying network plugin. To do so, a &lt;code>NetworkConfig&lt;/code> field in the spec will be provided where each plugin will define. Below is an example for deploy Calico as the cluster network plugin.&lt;/p>
&lt;h3 id="long-term-spec">Long Term Spec&lt;/h3>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Network
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: calico-network
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--core--test-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: calico
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> clusterCIDR: 192.168.0.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> serviceCIDR: 10.96.0.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: calico.extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: NetworkConfig
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ipam:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: host-local
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cidr: usePodCIDR
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backend: bird
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> typha:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ..
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerStatus:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: calico.extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: NetworkStatus
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> components:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kubeControllers: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> calicoNodes: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> connectivityTests:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pods: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> services: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> networkModules:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> arp_proxy: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> config:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> clusterCIDR: 192.168.0.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> serviceCIDR: 10.96.0.0/24
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ipam:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: host-local
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cidr: usePodCIDR
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="first-implementation-short-term">First Implementation (Short Term)&lt;/h3>
&lt;p>As an initial implementation the network plugin type will be specified by the user e.g., Calico (without further configuration in the provider spec). This will then be used to generate
the &lt;code>Network&lt;/code> resource in the seed. The Network operator will pick it up, and apply the configuration based on the &lt;code>spec.cloudProvider&lt;/code> specified directly to the shoot or via the
Gardener resource manager (still in the works).&lt;/p>
&lt;p>The &lt;code>cloudProvider&lt;/code> field in the spec is just an initial catalyst but not meant to be stay long-term. In the future, the network provider configuration will be customized to match the best
needs of the infrastructure.&lt;/p>
&lt;p>Here is how the simplified initial spec would look like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Network
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: calico-network
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--core--test-01
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: calico
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cloudProvider: {aws,azure,...}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: 2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastOperation: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastError: ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="functionality">Functionality&lt;/h2>
&lt;p>The network resource need to be created early-on during cluster provisioning. Once created, the Network operator residing in every seed will create all the necessary networking resources and apply them to the shoot cluster.&lt;/p>
&lt;p>The status of the Network resource should reflect the health of the networking components as well as additional tests if required.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;p>[1] &lt;a href="https://docs.projectcalico.org/v3.0/reference/public-cloud/azure">Azure support for Calico Networking&lt;/a>&lt;/p></description></item><item><title>Docs: 05 Versioning Policy</title><link>https://gardener.cloud/docs/gardener/proposals/05-versioning-policy/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/05-versioning-policy/</guid><description>
&lt;h1 id="gardener-versioning-policy">Gardener Versioning Policy&lt;/h1>
&lt;p>Please refer to &lt;a href="https://gardener.cloud/docs/gardener/usage/shoot_versions/">this document&lt;/a> for the documentation of the implementation of this GEP.&lt;/p>
&lt;h2 id="goal">Goal&lt;/h2>
&lt;ul>
&lt;li>As a Garden operator I would like to define a clear Kubernetes version policy, which informs my users about deprecated or expired Kubernetes versions.&lt;/li>
&lt;li>As an user of Gardener, I would like to get information which Kubernetes version is supported for how long. I want to be able to get this information via API (cloudprofile) and also in the Dashboard.&lt;/li>
&lt;/ul>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>The Kubernetes community releases &lt;strong>minor&lt;/strong> versions roughly every three months and usually maintains &lt;strong>three minor&lt;/strong> versions (the actual and the last two) with bug fixes and security updates. Patch releases are done more frequently. Operators of Gardener should be able to define their own Kubernetes version policy. This GEP suggests the possibility for operators to classify Kubernetes versions, while they are going through their &amp;ldquo;maintenance life-cycle&amp;rdquo;.&lt;/p>
&lt;h2 id="kubernetes-version-classifications">Kubernetes Version Classifications&lt;/h2>
&lt;p>An operator should be able to classify Kubernetes versions differently while they go through their &amp;ldquo;maintenance life-cycle&amp;rdquo;, starting with &lt;strong>preview&lt;/strong>, &lt;strong>supported&lt;/strong>, &lt;strong>deprecated&lt;/strong>, and finally &lt;strong>expired&lt;/strong>. This information should be programmatically available in the &lt;code>cloudprofiles&lt;/code> of the Garden cluster as well as in the Dashboard. Please also note, that Gardener keeps the control plane and the workers on the same Kubernetes version.&lt;/p>
&lt;p>For further explanation of the possible classifications, we assume that an operator wants to support four minor versions e.g. v1.16, v1.15, v1.14 and v1.13.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>preview:&lt;/strong> After a fresh release of a new Kubernetes &lt;strong>minor&lt;/strong> version (e.g. v1.17.0) the operator could tag it as &lt;em>preview&lt;/em> until he has gained sufficient experience. It will not become the default in the Gardener Dashboard until he promotes that minor version to &lt;em>supported&lt;/em>, which could happen a few weeks later with the first patch version.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>supported:&lt;/strong> The operator would tag the latest Kubernetes patch versions of the actual (if not still in &lt;em>preview&lt;/em>) and the last three minor Kubernetes versions as &lt;em>supported&lt;/em> (e.g. v1.16.1, v1.15.4, v1.14.9 and v1.13.12). The latest of these becomes the default in the Gardener Dashboard (e.g. v1.16.1).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>deprecated:&lt;/strong> The operator could decide, that he generally wants to classify every version that is not the latest patch version as &lt;em>deprecated&lt;/em> and flag this versions accordingly (e.g. v1.16.0 and older, v1.15.3 and older, 1.14.8 and older as well as v1.13.11 and older). He could also tag all versions (latest or not) of every Kubernetes minor release that is neither the actual nor one of the last three minor Kubernetes versions as &lt;em>deprecated&lt;/em>, too (e.g. v1.12.x and older). Deprecated versions will eventually expire (i.e., removed).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>expired:&lt;/strong> This state is a &lt;em>logical&lt;/em> state only. It doesn&amp;rsquo;t have to be maintained in the &lt;code>cloudprofile&lt;/code>. All cluster versions whose &lt;code>expirationDate&lt;/code> as defined in the &lt;code>cloudprofile&lt;/code> is expired, are automatically in this &lt;em>logical&lt;/em> state. After that date has passed, users cannot create new clusters with that version anymore and any cluster that is on that version will be forcefully migrated in its next maintenance time window, even if the owner has opted out of automatic cluster updates! The forceful update will pick the latest patch version of the current minor Kubernetes version. If the cluster was already on that latest patch version and the latest patch version is also expired, it will continue with latest patch version of the &lt;strong>next minor Kubernetes version&lt;/strong>, so &lt;strong>it will result in an update of a minor Kubernetes version, which is potentially harmful to your workload, so you should avoid that/plan ahead!&lt;/strong> If that&amp;rsquo;s expired as well, the update process repeats until a non-expired Kubernetes version is reached, so &lt;strong>depending on the circumstances described above, it can happen that the cluster receives multiple consecutive minor Kubernetes version updates!&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>To fulfill his specific versioning policy, the Garden operator should be able to classify his versions as well set the expiration date in the &lt;code>cloudprofiles&lt;/code>. The user should see this classifiers as well as the expiration date in the dashboard.&lt;/p></description></item><item><title>Docs: 06 Etcd Druid</title><link>https://gardener.cloud/docs/gardener/proposals/06-etcd-druid/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/06-etcd-druid/</guid><description>
&lt;h1 id="integrating-etcd-druid-with-gardener">Integrating etcd-druid with Gardener&lt;/h1>
&lt;p>Etcd is currently deployed by garden-controller-manager as a Statefulset. The sidecar container spec contains details pertaining to cloud-provider object-store which is injected into the statefulset via a mutable webhook running as part of the gardener extension &lt;a href="https://gardener.cloud/docs/gardener/extensions/controlplane-webhooks/#what-needs-to-be-implemented-to-support-a-new-cloud-provider">story&lt;/a>. This approach restricts the operations on etcd such as scale-up and upgrade. Etcd-druid will eliminate the need to hijack statefulset creation to add cloudprovider details. It has been designed to provide an intricate control over the procedure of deploying and maintaining etcd. The roadmap for etcd-druid can be found &lt;a href="https://github.com/gardener/etcd-druid/issues/2">here&lt;/a>.&lt;/p>
&lt;p>This document explains how Gardener deploys etcd and what resources it creates for etcd-druid to deploy an etcd cluster.&lt;/p>
&lt;h2 id="resources-required-by-etcd-druid-created-by-gardener">Resources required by etcd-druid (created by Gardener)&lt;/h2>
&lt;ul>
&lt;li>Secret containing credentials to access backup bucket in Cloud provider object store.&lt;/li>
&lt;li>TLS server and client secrets for etcd and backup-sidecar&lt;/li>
&lt;li>Etcd CRD resource that contains parameters pertaining to etcd, backup-sidecar and cloud-provider object store.&lt;/li>
&lt;/ul>
&lt;p>When an etcd resource is created in the cluster, the druid acts on it by creating an etcd statefulset, a service and a configmap containing etcd bootstrap script. The secrets containing the infrastructure credentials and the TLS certificates are mounted as volumes. If no secret/information regarding backups is stated then etcd data backups are not taken. Only data corruption checks are performed prior to starting etcd.&lt;/p>
&lt;p>Garden-controller-manager, being cloud agnostic, deploys the etcd resource. This will not contain any cloud-specific information other than the cloud-provider. The extension controller that contains the cloud specific implementation to create the backup bucket will create it if needed and create a secret containing the credentials to access the bucket. The etcd backup secret name should be exposed in the BackupEntry status. Then, Gardener can read it and write it into the ETCD resource. The secret will have to be made available in the namespace the etcd statefulset will be deployed. If etcd and backup-sidecar communicates over TLS then the CA certificates, server and client certificates, and keys will also have to be made available in the namespace as well. The etcd resource will have reference to these aforementioned secrets. etcd-druid will deploy the statefulset only if the secrets are available.&lt;/p>
&lt;h2 id="workflow">Workflow&lt;/h2>
&lt;ul>
&lt;li>etcd-druid will be deployed and etcd CRD will be created as part of the seed bootstrap.&lt;/li>
&lt;li>Garden-controller-manager creates backupBucket extension resource. Extension controller creates the backup bucket associated with the seed.&lt;/li>
&lt;li>Garden-controller-manager creates backupentry associated with each shoot in the seed namespace.&lt;/li>
&lt;li>Garden-controller-manager creates etcd resource with secretRefs and etcd information populated appropriately.&lt;/li>
&lt;li>etcd-druid acts on the etcd resource; druid creates the statefulset, the service and the configmap.&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://gardener.cloud/__resources/druid_integration_539d05.png" alt="etcd-druid">&lt;/p></description></item><item><title>Docs: 07 Shoot Control Plane Migration</title><link>https://gardener.cloud/docs/gardener/proposals/07-shoot-control-plane-migration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/07-shoot-control-plane-migration/</guid><description>
&lt;h1 id="shoot-control-plane-migration">Shoot Control Plane Migration&lt;/h1>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Currently moving the control plane of a shoot cluster can only be done manually and requires deep knowledge of how exactly to transfer the resources and state from one seed to another. This can make it slow and prone to errors.&lt;/p>
&lt;p>Automatic migration can be very useful in a couple of scenarios:&lt;/p>
&lt;ul>
&lt;li>Seed goes down and can&amp;rsquo;t be repaired (fast enough or at all) and it&amp;rsquo;s control planes need to be brought to another seed&lt;/li>
&lt;li>Seed needs to be changed, but this operation requires the recreation of the seed (e.g. turn a single-AZ seed into a multi-AZ seed)&lt;/li>
&lt;li>Seeds need to be rebalanced&lt;/li>
&lt;li>New seeds become available in a region closer to/in the region of the workers and the control plane should be moved there to improve latency&lt;/li>
&lt;li>Gardener ring, which is a self-supporting setup/underlay for a highly available (usually cross-region) Gardener deployment&lt;/li>
&lt;/ul>
&lt;h2 id="goals">Goals&lt;/h2>
&lt;ul>
&lt;li>Provide a mechanism to migrate the control plane of a shoot cluster from one seed to another&lt;/li>
&lt;li>The mechanism should support migration from a seed which is no longer reachable (Disaster Recovery)&lt;/li>
&lt;li>The shoot cluster nodes are preserved and continue to run the workload, but will talk to the new control plane after the migration completes&lt;/li>
&lt;li>Extension controllers implement a mechanism which allows them to store their state or to be restored from an already existing state on a different seed cluster.&lt;/li>
&lt;li>The already existing shoot reconciliation flow is reused for migration with minimum changes&lt;/li>
&lt;/ul>
&lt;h2 id="terminology">Terminology&lt;/h2>
&lt;p>&lt;strong>Source Seed&lt;/strong> is the seed which currently hosts the control plane of a Shoot Cluster&lt;/p>
&lt;p>&lt;strong>Destination Seed&lt;/strong> is the seed to which the control plane is being migrated&lt;/p>
&lt;h2 id="resources-and-controller-state-which-have-to-be-migrated-between-two-seeds">Resources and controller state which have to be migrated between two seeds:&lt;/h2>
&lt;p>&lt;strong>Note:&lt;/strong> The following lists are just FYI and are meant to show the current resources which need to be moved to the &lt;strong>Destination Seed&lt;/strong>&lt;/p>
&lt;h3 id="secrets">Secrets&lt;/h3>
&lt;p>Gardener has preconfigured lists of needed secrets which are generated when a shoot is created and deployed in the seed. Following is a minimum set of secrets which must be migrated to the &lt;strong>Destination Seed&lt;/strong>. Other secrets can be regenerated from them.&lt;/p>
&lt;ul>
&lt;li>ca&lt;/li>
&lt;li>ca-front-proxy&lt;/li>
&lt;li>static-token&lt;/li>
&lt;li>ca-kubelet&lt;/li>
&lt;li>ca-metrics-server&lt;/li>
&lt;li>etcd-encryption-secret&lt;/li>
&lt;li>kube-aggregator&lt;/li>
&lt;li>kube-apiserver-basic-auth&lt;/li>
&lt;li>kube-apiserver&lt;/li>
&lt;li>service-account-key&lt;/li>
&lt;li>ssh-keypair&lt;/li>
&lt;/ul>
&lt;h3 id="custom-resources-and-state-of-extension-controllers">Custom Resources and state of extension controllers&lt;/h3>
&lt;p>Gardenlet deploys custom resources in the &lt;strong>Source Seed&lt;/strong> cluster during shoot reconciliation which are reconciled by extension controllers. The state of these controllers and any additional resources they create is independent of the gardenlet and must also be migrated to the &lt;strong>Destination Seed&lt;/strong>. Following is a list of custom resources, and the state which is generated by them that has to be migrated.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>BackupBucket&lt;/strong>: nothing relevant for migration&lt;/li>
&lt;li>&lt;strong>BackupEntry&lt;/strong>: nothing relevant for migration&lt;/li>
&lt;li>&lt;strong>ControlPlane&lt;/strong>: nothing relevant for migration&lt;/li>
&lt;li>&lt;strong>DNSProvider&lt;/strong>/DNSEntry: nothing relevant for migration&lt;/li>
&lt;li>&lt;strong>Extensions&lt;/strong>: migration of state needs to be handled individually&lt;/li>
&lt;li>&lt;strong>Infrastructure&lt;/strong>: terraform state&lt;/li>
&lt;li>&lt;strong>Network&lt;/strong>: nothing relevant for migration&lt;/li>
&lt;li>&lt;strong>OperatingSystemConfig&lt;/strong>: nothing relevant for migration&lt;/li>
&lt;li>&lt;strong>Worker&lt;/strong>: Machine-Controller-Manager related objects: machineclasses, machinedeployments, machinesets, machines&lt;/li>
&lt;/ul>
&lt;p>This list depends on the currently installed extensions and can change in the future&lt;/p>
&lt;h2 id="proposal">Proposal&lt;/h2>
&lt;h3 id="custom-resource-on-the-garden-cluster">Custom Resource on the garden cluster&lt;/h3>
&lt;p>The Garden cluster has a new Custom Resource which is stored in the project namespace of the Shoot called &lt;code>ShootState&lt;/code>. It contains all the required data described above so that the control plane can be recreated on the &lt;strong>Destination Seed&lt;/strong>.&lt;/p>
&lt;p>This data is separated into two sections. The first is generated by the gardenlet and then either used to generate new resources (e.g secrets) or is directly deployed to the Shoot&amp;rsquo;s control plane on the &lt;strong>Destination Seed&lt;/strong>.&lt;/p>
&lt;p>The second is generated by the extension controllers in the seed.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: core.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ShootState
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden-core
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ownerReference:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: core.gardener.cloud/v1beta1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> blockOwnerDeletion: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> controller: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: Shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> uid: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> finalizers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - gardener
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>gardenlet:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secrets:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: ca
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ca.crt: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ca.key: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: ssh-keypair
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> data:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> id_rsa: ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>extensions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- kind: Infrastructure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ... (Terraform state)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- kind: ControlPlane
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> purpose: normal
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ... (Certificates generated by the extension)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- kind: Worker
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> state: ... (Machine objects)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The state data is saved as a &lt;code>runtime.RawExtension&lt;/code> type, which can be encoded/decoded by the corresponding extension controller.&lt;/p>
&lt;p>There can be sensitive data in the &lt;code>ShootState&lt;/code> which has to be hidden from the end-users. Hence, it will be recommended to provide an etcd encryption configuration to the Gardener API server in order to encrypt the &lt;code>ShootState&lt;/code> resource.&lt;/p>
&lt;h4 id="size-limitations">Size limitations&lt;/h4>
&lt;p>There are limits on the size of the request bodies sent to the kubernetes API server when creating or updating resources: by default ETCD can only accept request bodies which do not exceed 1.5 MiB (this can be configured with the &lt;code>--max-request-bytes&lt;/code> flag); the kubernetes API Server has a request body limit of 3 MiB which cannot be set from the outside (with a command line flag); the gRPC configuration used by the API server to talk to ETCD has a limit of 2 MiB per request body which cannot be configured from the outside; and &lt;code>watch&lt;/code> requests have a 16 MiB limit on the buffer used to stream resources.&lt;/p>
&lt;p>This means that if &lt;code>ShootState&lt;/code> is bigger than 1.5 MiB, the ETCD max request bytes will have to be increased. However, there is still an upper limit of 2 MiB imposed by the gRPC configuration.&lt;/p>
&lt;p>If &lt;code>ShootState&lt;/code> exceeds this size limitation it must make use of configmap/secret references to store the state of extension controllers. This is an implementation detail of Gardener and can be done at a later time if necessary as extensions will not be affected.&lt;/p>
&lt;p>Splitting the &lt;code>ShootState&lt;/code> into multiple resources could have a positive benefit on performance as the Gardener API Server and Gardener Controller Manager would handle multiple small resources instead of one big resource.&lt;/p>
&lt;h3 id="gardener-extensions-changes">Gardener extensions changes&lt;/h3>
&lt;p>All extension controllers which require state migration must save their state in a new &lt;code>status.state&lt;/code> field and act on an annotation &lt;code>gardener.cloud/operation=restore&lt;/code> in the respective Custom Resources which should trigger a restoration operation instead of reconciliation. A restoration operation means that the extension has to restore its state in the Shoot&amp;rsquo;s namespace on the &lt;strong>Destination Seed&lt;/strong> from the &lt;code>status.state&lt;/code> field.&lt;/p>
&lt;p>As an example: the &lt;code>Infrastructure&lt;/code> resource must save the terraform state.&lt;/p>
&lt;pre tabindex="0">&lt;code>apiVersion: extensions.gardener.cloud/v1alpha1
kind: Infrastructure
metadata:
name: infrastructure
namespace: shoot--foo--bar
spec:
type: azure
region: eu-west-1
secretRef:
name: cloudprovider
namespace: shoot--foo--bar
providerConfig:
apiVersion: azure.provider.extensions.gardener.cloud/v1alpha1
kind: InfrastructureConfig
resourceGroup:
name: mygroup
networks:
vnet: # specify either &amp;#39;name&amp;#39; or &amp;#39;cidr&amp;#39;
# name: my-vnet
cidr: 10.250.0.0/16
workers: 10.250.0.0/19
status:
state: |
{
&amp;#34;version&amp;#34;: 3,
&amp;#34;terraform_version&amp;#34;: &amp;#34;0.11.14&amp;#34;,
&amp;#34;serial&amp;#34;: 2,
&amp;#34;lineage&amp;#34;: &amp;#34;3a1e2faa-e7b6-f5f0-5043-368dd8ea6c10&amp;#34;,
&amp;#34;modules&amp;#34;: [
{
}
]
...
}
&lt;/code>&lt;/pre>&lt;p>Extensions which do not require state migration should set &lt;code>status.state=nil&lt;/code> in their Custom Resources and trigger a normal reconciliation operation if the CR contains the &lt;code>core.gardener.cloud/operation=restore&lt;/code> annotation.&lt;/p>
&lt;p>Similar to the contract for the &lt;a href="https://gardener.cloud/docs/gardener/extensions/reconcile-trigger/">reconcile operation&lt;/a>, the extension controller has to remove the &lt;code>restore&lt;/code> annotation after the restoration operation has finished.&lt;/p>
&lt;p>An additional annotation &lt;code>gardener.cloud/operation=migrate&lt;/code> is added to the Custom Resources. It is used to tell the extension controllers in the &lt;strong>Source Seed&lt;/strong> that they must stop reconciling resources (in case they are requeued due to errors) and should perform cleanup activities in the Shoot&amp;rsquo;s control plane. These cleanup activities involve removing the finalizers on Custom Resources and deleting them without actually deleting any infrastructure resources.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> The same size limitations from the previous section are relevant here as well.&lt;/p>
&lt;h3 id="shoot-reconciliation-flow-changes">Shoot reconciliation flow changes&lt;/h3>
&lt;p>The only data which must be stored in the &lt;code>ShootState&lt;/code> by the gardenlet is secrets (e.g ca for the API server). Therefore the &lt;code>botanist.DeploySecrets&lt;/code> step is changed. It is split into two functions which take a list of secrets that have to be generated.&lt;/p>
&lt;ul>
&lt;li>&lt;code>botanist.GenerateSecretState&lt;/code> Generates certificate authorities and other secrets which have to be persisted in the ShootState and must not be regenerated on the &lt;strong>Destination Seed&lt;/strong>.&lt;/li>
&lt;li>&lt;code>botanist.DeploySecrets&lt;/code> Takes secret data from the &lt;code>ShootState&lt;/code>, generates new ones (e.g. client tls certificates from the saved certificate authorities) and deploys everything in the Shoot&amp;rsquo;s control plane on the &lt;strong>Destination Seed&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h3 id="shootstate-synchronization-controller">ShootState synchronization controller&lt;/h3>
&lt;p>The ShootState synchronization controller will become part of the gardenlet. It syncs the state of extension custom resources from the shoot namespace to the garden cluster and updates the corresponding &lt;code>spec.extension.state&lt;/code> field in the &lt;code>ShootState&lt;/code> resource. The controller can &lt;code>watch&lt;/code> Custom Resources used by the extensions and update the &lt;code>ShootState&lt;/code> only when changes occur.&lt;/p>
&lt;h3 id="migration-workflow">Migration workflow&lt;/h3>
&lt;ol>
&lt;li>Starting migration
&lt;ul>
&lt;li>Migration can only be started after a Shoot cluster has been successfully created so that the &lt;code>status.seed&lt;/code> field in the &lt;code>Shoot&lt;/code> resource has been set&lt;/li>
&lt;li>The &lt;code>Shoot&lt;/code> resource&amp;rsquo;s field &lt;code>spec.seedName=&amp;quot;new-seed&amp;quot;&lt;/code> is edited to hold the name of the &lt;strong>Destination Seed&lt;/strong> and reconciliation is automatically triggered&lt;/li>
&lt;li>The Garden Controller Manager checks if the equality between &lt;code>spec.seedName&lt;/code> and &lt;code>status.seed&lt;/code>, detects that they are different and triggers migration.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>The Garden Controller Manager waits for the &lt;strong>Destination Seed&lt;/strong> to be ready&lt;/li>
&lt;li>Shoot&amp;rsquo;s API server is stopped&lt;/li>
&lt;li>Backup the Shoot&amp;rsquo;s ETCD.&lt;/li>
&lt;li>Extension resources in the &lt;strong>Source Seed&lt;/strong> are annotated with &lt;code>gardener.cloud/operation=migrate&lt;/code>&lt;/li>
&lt;li>Scale Down the Shoot&amp;rsquo;s control plane in the &lt;strong>Source Seed&lt;/strong>.&lt;/li>
&lt;li>The gardenlet in the &lt;strong>Destination Seed&lt;/strong> fetches the state of extension resources from the &lt;code>ShootState&lt;/code> resource in the garden cluster.&lt;/li>
&lt;li>Normal reconciliation flow is resumed in the &lt;strong>Destination Seed&lt;/strong>. Extension resources are annotated with &lt;code>gardener.cloud/operation=restore&lt;/code> to instruct the extension controllers to reconstruct their state.&lt;/li>
&lt;li>The Shoot&amp;rsquo;s namespace in &lt;strong>Source Seed&lt;/strong> is deleted.&lt;/li>
&lt;/ol></description></item><item><title>Docs: 09 Test Framework</title><link>https://gardener.cloud/docs/gardener/proposals/09-test-framework/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/09-test-framework/</guid><description>
&lt;h1 id="gardener-integration-test-framework">Gardener integration test framework&lt;/h1>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>As we want to improve our code coverage in the next months we will need a simple and easy to use test framework.
The current testframework already contains a lot of general test functions that ease the work for writing new tests.
However there are multiple disadvantages with the current structure of the tests and the testframework:&lt;/p>
&lt;ol>
&lt;li>Every new test is an own testsuite and therefore needs its own &lt;code>TestDef&lt;/code> (&lt;a href="https://github.com/gardener/gardener/tree/master/.test-defs">https://github.com/gardener/gardener/tree/master/.test-defs&lt;/a>). With this approach there will be hundreds of test definitions, growing with every new test (or at least new test suite).
But in most cases new tests do not need their own special &lt;code>TestDef&lt;/code>: it&amp;rsquo;s just the wrong scope for the testmachinery and will result in unnecessary complex testruns and configurations. In addition it would result in additional maintenance for a huge number of &lt;code>TestDefs&lt;/code>.&lt;/li>
&lt;li>The testsuites currently have their own specific interface/configuration that they need in order to be executed correctly (see &lt;a href="https://github.com/gardener/gardener/blob/master/.test-defs/ShootKubernetesUpdateTest.yaml#L14">K8s Update test&lt;/a>).
Consequently the configuration has to be defined in the testruns which result in one step per test with their very own configuration which means that the testmachinery cannot simply select testdefinitions by label.
As the testmachinery cannot make use of its ability to run labeled tests (e.g. run all tests labeled &lt;code>default&lt;/code>), the testflow size increases with every new tests and the testruns have to be manually adjusted with every new test.&lt;/li>
&lt;li>The current gardener test framework contains multiple test operations where some are just used for specific tests (e.g. &lt;code>plant_operations&lt;/code>) and some are more general (&lt;code>garden_operation&lt;/code>). Also the functions offered by the operations vary in their specialization as some are really specific to just one test e.g. shoot test operation with &lt;code>WaitUntilGuestbookAppIsAvailable&lt;/code> whereas others are more general like &lt;code>WaitUntilPodIsRunning&lt;/code>.&lt;br>
This structure makes it hard for developers to find commonly used functions and also hard to integrate as the common framework grows with specialized functions.&lt;/li>
&lt;/ol>
&lt;h2 id="goals">Goals&lt;/h2>
&lt;p>In order to clean the testframework, make it easier for new developers to write tests and easier to add and maintain test execution within the testmachinery, the following goals are defined:&lt;/p>
&lt;ul>
&lt;li>Have a small number of test suites (gardener, shoots see &lt;a href="#test_flavors">test flavors&lt;/a>) to only maintain a fixed number of testdefinitions.&lt;/li>
&lt;li>Use ginkgo test labels (inspired by the k8s e2e tests) to differentiate test behavior, test execution and test importance.&lt;/li>
&lt;li>Use standardized configuration for all tests (differ depending on the test suite) but provide better tooling to dynamically read additional configuration from configuration files like the &lt;code>cloudprofile&lt;/code>.&lt;/li>
&lt;li>Clean the testframework to only contain general functionality and keep specific functions inside the tests&lt;/li>
&lt;/ul>
&lt;h2 id="proposal">Proposal&lt;/h2>
&lt;p>The proposed new test framework consists of the following changes to tackle the above described goals.
​&lt;/p>
&lt;h4 id="test-flavors">Test Flavors&lt;/h4>
&lt;p>Reducing the number of test definitions is done by ​combining the current specified test suites into the following 3 general ones:&lt;/p>
&lt;ul>
&lt;li>&lt;em>System test suite&lt;/em>
&lt;ul>
&lt;li>e.g. create-shoot, delete-shoot, hibernate&lt;/li>
&lt;li>need their own testdef because they have a special meaning in the context of the testmachinery&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;em>Gardener test suite&lt;/em>
&lt;ul>
&lt;li>e.g. RBAC, scheduler&lt;/li>
&lt;li>All tests that only need a gardener installation but no shoot cluster&lt;/li>
&lt;li>Possible functions/environment:
&lt;ul>
&lt;li>New project for test suite (copy secret binding, cleanup)?&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;em>Shoot test suite&lt;/em>
&lt;ul>
&lt;li>e.g. shoot app, network&lt;/li>
&lt;li>Test that require a running shoot&lt;/li>
&lt;li>Possible functions:
&lt;ul>
&lt;li>Namespace per test&lt;/li>
&lt;li>cleanup of ns&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>As inspired by the k8s e2e tests, test labels are used to differentiate the tests by their behavior, their execution and their importance.
Test labels means that tests are described using predefined labels in the test&amp;rsquo;s text (e.g &lt;code>ginkgo.It(&amp;quot;[BETA] this is a test&amp;quot;)&lt;/code>).
With this labeling strategy, it is also possible to see the test properties directly in the code and promoting a test can be done via a pullrequest and will then be automatically recognized by the testmachinery with the next release.&lt;/p>
&lt;p>Using ginkgo focus to only run desired tests and combined testsuites, an example test definition will look like the following.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>kind: TestDefinition
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: gardener-beta-suite
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> description: Test suite that runs all gardener tests that are labeled as beta
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> activeDeadlineSeconds: 7200
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels: [&lt;span style="color:#a31515">&amp;#34;gardener&amp;#34;&lt;/span>, &lt;span style="color:#a31515">&amp;#34;beta&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>​
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> command: [bash, -c]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> args:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &amp;gt;-&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> go test -timeout=0 -mod=vendor ./test/integration/suite
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> --v -ginkgo.v -ginkgo.progress -ginkgo.no-color
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> -ginkgo.focus=&amp;#34;[GARDENER] [BETA]&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Using this approach, the overall number of testsuites is then reduced to a fixed number (excluding the system steps) of &lt;code>test suites * labelCombinations&lt;/code>.&lt;/p>
&lt;h4 id="framework">Framework&lt;/h4>
&lt;p>The new framework will consist of a common framework, a gardener framework (integrating the commom framework) and a shoot framework (integrating the gardener framework).&lt;/p>
&lt;p>All of these frameworks will have their own configuration that is exposed via commandline flags so that for example the shoot test framework can be executed by &lt;code>go test -timeout=0 -mod=vendor ./test/integration/suite --v -ginkgo.v -ginkgo.focus=&amp;quot;[SHOOT]&amp;quot; --kubecfg=/path/to/config --shoot-name=xx&lt;/code>.&lt;/p>
&lt;p>The available test labels should be declared in the code with predefined values and in a predefined order so that everyone is aware about possible labels and the tests are labeled similarly across all integration tests. This approach is somehow similar to what kubernetes is doing in their e2e test suite but with some more restrictions (compare &lt;a href="https://github.com/kubernetes/kubernetes/blob/master/test/e2e/apps/deployment.go#L84">example k8s e2e test&lt;/a>).&lt;br>
A possible solution to have consistent labeling would be to define them with every new &lt;code>ginkgo.It&lt;/code> definition: &lt;code>f.Beta().Flaky().It(&amp;quot;my test&amp;quot;)&lt;/code> which internally orders them and would produce a ginkgo test with the text : &lt;code>[BETA] [FLAKY] my test&lt;/code>.&lt;/p>
&lt;p>&lt;strong>General Functions&lt;/strong>
The test framework should include some general functions that can and will be reused by every test.
These general functions may include:
​&lt;/p>
&lt;ul>
&lt;li>Logging&lt;/li>
&lt;li>State Dump&lt;/li>
&lt;li>Detailed test output (status, duration, etc..)&lt;/li>
&lt;li>Cleanup handling per test (&lt;code>It&lt;/code>)&lt;/li>
&lt;li>General easy to use functions like &lt;code>WaitUntilDeploymentCompleted&lt;/code>, &lt;code>GetLogs&lt;/code>, &lt;code>ExecCommand&lt;/code>, &lt;code>AvailableCloudprofiles&lt;/code>, etc..
​&lt;/li>
&lt;/ul>
&lt;h4 id="example">Example&lt;/h4>
&lt;p>A possible test with the new test framework would look like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00f">var&lt;/span> _ = ginkgo.Describe(&lt;span style="color:#a31515">&amp;#34;Shoot network testing&amp;#34;&lt;/span>, &lt;span style="color:#00f">func&lt;/span>() {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// the testframework registers some cleanup handling for a state dump on failure and maybe cleanup of created namespaces
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> f := framework.NewShootFramework()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f.CAfterEach(&lt;span style="color:#00f">func&lt;/span>(ctx context.Context) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ginkgo.By(&lt;span style="color:#a31515">&amp;#34;cleanup network test daemonset&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> err := f.ShootClient.Client().Delete(ctx, &amp;amp;appsv1.DaemonSet{ObjectMeta: metav1.ObjectMeta{Name: name, Namespace: namespace}})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00f">if&lt;/span> err != &lt;span style="color:#00f">nil&lt;/span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00f">if&lt;/span> !apierrors.IsNotFound(err) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Expect(err).To(HaveOccurred())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }, FinalizationTimeout)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> f.Release().Default().CIt(&lt;span style="color:#a31515">&amp;#34;should reach all webservers on all nodes&amp;#34;&lt;/span>, &lt;span style="color:#00f">func&lt;/span>(ctx context.Context) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ginkgo.By(&lt;span style="color:#a31515">&amp;#34;Deploy the net test daemon set&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> templateFilepath := filepath.Join(f.ResourcesDir, &lt;span style="color:#a31515">&amp;#34;templates&amp;#34;&lt;/span>, nginxTemplateName)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> err := f.RenderAndDeployTemplate(f.Namespace(), tempalteFilepath)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Expect(err).ToNot(HaveOccurred())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> err = f.WaitUntilDaemonSetIsRunning(ctx, f.ShootClient.Client(), name, namespace)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Expect(err).NotTo(HaveOccurred())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pods := &amp;amp;corev1.PodList{}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> err = f.ShootClient.Client().List(ctx, pods, client.MatchingLabels{&lt;span style="color:#a31515">&amp;#34;app&amp;#34;&lt;/span>: &lt;span style="color:#a31515">&amp;#34;net-nginx&amp;#34;&lt;/span>})
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Expect(err).NotTo(HaveOccurred())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// check if all webservers can be reached from all nodes
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> ginkgo.By(&lt;span style="color:#a31515">&amp;#34;test connectivity to webservers&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootRESTConfig := f.ShootClient.RESTConfig()
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00f">var&lt;/span> res &lt;span style="color:#2b91af">error&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00f">for&lt;/span> _, from := &lt;span style="color:#00f">range&lt;/span> pods.Items {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00f">for&lt;/span> _, to := &lt;span style="color:#00f">range&lt;/span> pods.Items {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// test pods
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> f.Logger.Infof(&lt;span style="color:#a31515">&amp;#34;%s to %s: %s&amp;#34;&lt;/span>, from.GetName(), to.GetName(), data)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Expect(res).ToNot(HaveOccurred())
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }, NetworkTestTimeout)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>})
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="future-plans">Future Plans&lt;/h2>
&lt;h4 id="ownership">Ownership&lt;/h4>
&lt;p>When the test coverage is increased and there will be more tests, we will need to track ownership for tests.
At the beginning the ownership will be shared across all maintainers of the residing repository but this is not suitable anymore as tests will grow and get more complex.&lt;/p>
&lt;p>Therefore the test ownership should be tracked via subgroups (in kubernetes this would be a SIG (comp. &lt;a href="https://github.com/kubernetes/kubernetes/blob/master/test/e2e/apps/framework.go#L22">sig apps e2e test&lt;/a>)). These subgroup will then be tracked via labels and the members of these groups will then be notified if tests fail.&lt;/p></description></item><item><title>Docs: 10 Shoot Additional Container Runtimes</title><link>https://gardener.cloud/docs/gardener/proposals/10-shoot-additional-container-runtimes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/10-shoot-additional-container-runtimes/</guid><description>
&lt;h1 id="gardener-extensibility-to-support-shoot-additional-container-runtimes">Gardener extensibility to support shoot additional container runtimes&lt;/h1>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#gardener-extensibility-to-support-shoot-additional-container-runtimes">Gardener extensibility to support shoot additional container runtimes&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#table-of-contents">Table of Contents&lt;/a>&lt;/li>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#goals">Goals&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#proposal">Proposal&lt;/a>&lt;/li>
&lt;li>&lt;a href="#design-details">Design Details&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;p>Gardener-managed Kubernetes clusters are sometimes used to run sensitive workloads, which sometimes are comprised of OCI images originating from untrusted sources. Additional use-cases want to leverage economy-of-scale to run workloads for multiple tenants on the same cluster. In some cases, Gardener users want to use operating systems which do not easily support the Docker engine.&lt;/p>
&lt;p>This proposal aims to allow Gardener Shoot clusters to use CRI instead of the legacy Docker API, and to provide extension type for adding CRI shims (like &lt;a href="https://gvisor.dev/">GVisor&lt;/a> and &lt;a href="https://katacontainers.io/">Kata Containers&lt;/a>) which can be used to add support in Gardener Shoot clusters for these runtimes.&lt;/p>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>While pods and containers are intended to create isolated areas for concurrently running workloads on nodes, this isolation is not as robust as could be expected. Containers leverage the core Linux CGroup and Namespace features to isolate workloads, and many kernel vulnerabilities have the potential to allow processes to escape from their isolation. Once a process has escaped from its container, any other process running on the same node is compromised. Several projects try to mitigate this problem; for example Kata Containers allow isolating a Kubernetes Pod in a micro-vm, gVisor reduces the kernel attack surface by adding another level of indirection between the actual payload and the real kernel.&lt;/p>
&lt;p>Kubernetes supports running pods using these alternate runtimes via the &lt;a href="https://kubernetes.io/docs/concepts/containers/runtime-class/">RuntimeClass&lt;/a> concept, which was promoted to Beta in Kubernetes 1.14. Once Kubernetes is configured to use the Container Runtime Interface to control pods, it becomes possible to leverage CRI and run specific pods using different Runtime Classes. Additionally, configuring Kubernetes to use CRI instead of the legacy Dockershim is &lt;a href="https://events19.linuxfoundation.org/wp-content/uploads/2017/11/How-Container-Runtime-Matters-in-Kubernetes_-OSS-Kunal-Kushwaha.pdf">faster&lt;/a>.&lt;/p>
&lt;p>The motivation behind this proposal is to make all of this functionality accessible to Shoot clusters managed by Gardener.&lt;/p>
&lt;h3 id="goals">Goals&lt;/h3>
&lt;ul>
&lt;li>Gardener must allow to configue its managed clusters with the CRI interface instead of the legacy Dockershim.&lt;/li>
&lt;li>Low-level runtimes like gVisor or Kata Containers are provided as gardener extensions which are (optionally) installed into a landscape by the Gardener operator. There must be no runtime-specific knowledge in the core Gardener code.&lt;/li>
&lt;li>It shall be possible to configure multiple low-level runtimes in Shoot clusters, on the Worker Group level.&lt;/li>
&lt;/ul>
&lt;h2 id="proposal">Proposal&lt;/h2>
&lt;p>Gardener today assumes that all supported operating systems have Docker pre-installed in the base image. Starting with Docker Engine 1.11, Docker itself was refactored and cleaned-up to be based on the &lt;a href="https://containerd.io/">containerd&lt;/a> library. The first phase would be to allow the change of the Kubelet configuration as described &lt;a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd">here&lt;/a> so that Kubernetes would use containerd instead of the default Dockershim. This will be implemented for CoreOS, Ubuntu, and SuSE-CHost.&lt;/p>
&lt;p>We will implement two Gardener extensions, providing gVisor and Kata Containers as options for Gardener landscapes.
The &lt;code>WorkerGroup&lt;/code> specification will be extended to allow specifying the CRI name and a list of additional required Runtimes for nodes in that group. For example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>workers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- name: worker-b8jg5
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> machineType: m5.large
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> volumeType: gp2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> volumeSize: 50Gi
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> autoScalerMin: 1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> autoScalerMax: 2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> maxSurge: 1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cri:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: containerd
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> containerRuntimes:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: gvisor
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: kata-containers
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> machineImage:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: coreos
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> version: 2135.6.0
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Each extension will need to address the following concern:&lt;/p>
&lt;ol>
&lt;li>Add the low-level runtime binaries to the worker nodes. Each extension should get the runtime binaries from a container.&lt;/li>
&lt;li>Hook the runtime binary into the containerd configuration file, so that the runtime becomes available to containerd.&lt;/li>
&lt;li>Apply a label to each node that allows identifying nodes where the runtime is available.&lt;/li>
&lt;li>Apply the relevant &lt;code>RuntimeClass&lt;/code> to the Shoot cluster, to expose the functionality to users.&lt;/li>
&lt;li>Provide a separate binary with a &lt;code>ValidatingWebhook&lt;/code> (deployable to the garden cluster) to catch invalid configurations. For example, Kata Containers on AWS requires a &lt;code>machineType&lt;/code> of &lt;code>i3.metal&lt;/code>, so any &lt;code>Shoot&lt;/code> requests with a Kata Containers runtime and a different machine type on AWS should be rejected.&lt;/li>
&lt;/ol>
&lt;h2 id="design-details">Design Details&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Change the nodes container runtime to work with CRI and ContainerD (Only if specified in the Shoot spec):&lt;/p>
&lt;ol>
&lt;li>
&lt;p>In order to configure each worker machine in the cluster to work with CRI, the following configurations should be done:&lt;/p>
&lt;ol>
&lt;li>Add kubelet execution flags:
&lt;ol>
&lt;li>&amp;ndash;container-runtime=remote&lt;/li>
&lt;li>&amp;ndash;container-runtime-endpoint=unix:///run/containerd/containerd.sock&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Make sure that default containerd configuration file exist in path /etc/containerd/config.toml.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>ContainerD and Docker configurations are different for each OS. To make sure the default configurations above works well in each worker machine, each OS extension would be responsible to configure them during the reconciliation of the
OperatingSystemConfig:&lt;/p>
&lt;ol>
&lt;li>os-ubuntu -
&lt;ol>
&lt;li>Create ContainerD unit Drop-In to execute ContainerD with the default configurations file in path /etc/containerd/config.toml.&lt;/li>
&lt;li>Create the container runtime metadata file with a OS path for binaries installations: /usr/bin.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>os-coreos -
&lt;ol>
&lt;li>Create ContainerD unit Drop-In to execute ContainerD with the default configurations file in path /etc/containerd/config.toml.&lt;/li>
&lt;li>Create Docker Drop-In unit to execute Docker with the correct socket path of ContainerD.&lt;/li>
&lt;li>Create the container runtime metadata file with a OS path for binaries installations: /var/bin.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>os-suse-chost -
&lt;ol>
&lt;li>Create ContainerD service unit and execute ContainerD with the default configurations file in path /etc/containerd/config.toml.&lt;/li>
&lt;li>Download and install ctr-cli which is not shipped with the current SuSe image.&lt;/li>
&lt;li>Create the container runtime metadata file with a OS path for binaries installations /usr/sbin.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>To rotate the ContainerD (CRI) logs we will activate the kubelet feature flag: CRIContainerLogRotation=true.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Docker monitor service will be replaced with equivalent ContainerD monitor service.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Validate workers additional runtime configurations:&lt;/p>
&lt;ol>
&lt;li>Disallow additional runtimes with shoots &amp;lt; 1.14&lt;/li>
&lt;li>kata-container validation: Machine type support nested virtualization.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>Add support for each additional container runtime in the cluster.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>In order to install each additional available runtime in the cluster we should:&lt;/p>
&lt;ol>
&lt;li>Install the runtime binaries in each Worker&amp;rsquo;s pool nodes that specified the runtime support.&lt;/li>
&lt;li>Apply the relevant RuntimeClass to the cluster.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>The installation above should be done by a new kind of extension: ContainerRuntime resource. For each container runtime type (Kata-container/gvisor) a dedicate extension controller will be created.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>A label for each container runtime support will be added to every node that belongs to the worker pool. This should be done similar
to the way labels created today for each node, through kubelet execution parameters (_kubelet.flags: &amp;ndash;node-labels). When creating the OperatingSystemConfig (original) for the worker each container runtime support should be mapped to a label on the node.
For Example:
label: container.runtime.kata-containers=true (shoot.spec.cloud.&lt;IAAS>.worker.containerRuntimes.kata-container)
label: container.runtime.gvisor=true (shoot.spec.cloud.&lt;IAAS>.worker.containerRuntimes.gvisor)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>During the Shoot reconciliation (Similar steps to the Extensions today) Gardener will create new ContainerRuntime resource if a container runtime exist in at least one worker spec:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ContainerRuntime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: kata-containers-runtime-extention
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--foo--bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: kata-containers
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Gardener will wait that all ContainerRuntimes extensions will be reconciled by the appropriate extensions controllers.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Each runtime extension controller will be responsible to reconcile it&amp;rsquo;s RuntimeContainer resource type.
rc-kata-containers extension controller will reconcile RuntimeContainer resource from type kata-container and rc-gvisor will reconcile RuntimeContainer resource from gvisor.
Reconciliation process by container runtime extension controllers:&lt;/p>
&lt;ol>
&lt;li>Runtime extension controller from specific type should apply a chart which responsible for the installation of the runtime container in the cluster:
&lt;ol>
&lt;li>DaemonSet which will run a privileged pod on each node with the label: container.runtime.&lt;type of the resource>:true The pod will be responsible for:
&lt;ol>
&lt;li>Copy the runtime container binaries (From extension package ) to the relevant path in the host OS.&lt;/li>
&lt;li>Add the relevant container runtime plugin section to the containerd configuration file (/etc/containerd/config.toml).&lt;/li>
&lt;li>Restart containerd in the node.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>RuntimeClasses in the cluster to support the runtime class. for example:
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: node.k8s.io/v1beta1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: RuntimeClass
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: gvisor
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>handler: runsc
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>Update the status of the relevant RuntimeContainer resource to succeeded.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ol></description></item><item><title>Docs: 12 Oidc Webhook Authenticator</title><link>https://gardener.cloud/docs/gardener/proposals/12-oidc-webhook-authenticator/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/12-oidc-webhook-authenticator/</guid><description>
&lt;h1 id="oidc-webhook-authenticator">OIDC Webhook Authenticator&lt;/h1>
&lt;h2 id="problem">Problem&lt;/h2>
&lt;p>In Kubernetes you can authenticate via several authentication strategies:&lt;/p>
&lt;ul>
&lt;li>x509 Client Certificates&lt;/li>
&lt;li>Static Token Files&lt;/li>
&lt;li>Bootstrap Tokens&lt;/li>
&lt;li>Static Password File (Basic authentication - deprecated and removed in 1.19)&lt;/li>
&lt;li>Service Account Tokens&lt;/li>
&lt;li>OpenID Connect Tokens&lt;/li>
&lt;li>Webhook Token Authentication&lt;/li>
&lt;li>Authenticating Proxy&lt;/li>
&lt;/ul>
&lt;p>End-users should use &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/#openid-connect-tokens">OpenID Connect (OIDC) Tokens&lt;/a> created by OIDC-compatible Identity Provider (IDP) and present &lt;a href="https://openid.net/specs/openid-connect-core-1_0.html#IDToken">id_token&lt;/a> to the &lt;code>kube-apiserver&lt;/code>. If the &lt;code>kube-apiserver&lt;/code> is configured to trust the IDP and the token is valid, then the user is authenticated and the &lt;a href="https://github.com/kubernetes/kubernetes/blob/99019502bd6ed038dbd1c444974d5e8c6a8dda19/staging/src/k8s.io/api/authentication/v1/types.go#L100-L117">UserInfo&lt;/a> is send to the authorization stack.&lt;/p>
&lt;p>Ideally, operators of the Gardener cluster should be able to authenticate to end-user Shoot clusters with &lt;code>id_token&lt;/code> generated by OIDC IDP, but in many cases, end-users might have already configured OIDC for their cluster and more than one OIDC configurations are not allowed.&lt;/p>
&lt;p>Another interesting application of multiple OIDC providers would be per &lt;code>Project&lt;/code> OIDC provider where end-users of Gardener can add their own OIDC-compatible IDPs.&lt;/p>
&lt;p>To workaround the one OIDC per &lt;code>kube-apiserver&lt;/code> limitation, a new &lt;code>OIDC Webhook Authenticator&lt;/code> (OWA) could be implemented.&lt;/p>
&lt;h2 id="goals">Goals&lt;/h2>
&lt;ul>
&lt;li>Dynamic registrations of OpenID Connect configurations.&lt;/li>
&lt;li>Close as possible to the Kubernetes build-in OIDC Authenticator.&lt;/li>
&lt;li>Build as an optional extension and not required for functional Shoot or Gardener cluster.&lt;/li>
&lt;/ul>
&lt;h2 id="non-goals">Non-goals&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/webhook/">Dynamic Authorization&lt;/a> is out of scope.&lt;/li>
&lt;/ul>
&lt;h2 id="proposal">Proposal&lt;/h2>
&lt;p>The &lt;code>kube-apiserver&lt;/code> can use &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/#webhook-token-authentication">Webhook Token Authentication&lt;/a> to send a &lt;a href="https://tools.ietf.org/html/rfc6750#section-2.1">Bearer Tokens (id_token)&lt;/a> to external webhook for validation:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;apiVersion&amp;#34;: &lt;span style="color:#a31515">&amp;#34;authentication.k8s.io/v1beta1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;kind&amp;#34;: &lt;span style="color:#a31515">&amp;#34;TokenReview&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;spec&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;token&amp;#34;: &lt;span style="color:#a31515">&amp;#34;(BEARERTOKEN)&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Where upon verification, the remote webhook returns the identity of the user (if authentication succeeds):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;apiVersion&amp;#34;: &lt;span style="color:#a31515">&amp;#34;authentication.k8s.io/v1beta1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;kind&amp;#34;: &lt;span style="color:#a31515">&amp;#34;TokenReview&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;status&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;authenticated&amp;#34;: &lt;span style="color:#00f">true&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;user&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;username&amp;#34;: &lt;span style="color:#a31515">&amp;#34;janedoe@example.com&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;uid&amp;#34;: &lt;span style="color:#a31515">&amp;#34;42&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;groups&amp;#34;: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;developers&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;qa&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;extra&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;extrafield1&amp;#34;: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;extravalue1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;extravalue2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="registration-of-new-openidconnect">Registration of new OpenIDConnect&lt;/h3>
&lt;p>This new OWA can be configured with multiple OIDC providers and the entire flow can look like this:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Admin adds a new &lt;code>OpenIDConnect&lt;/code> resource (via CRD) to the cluster.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: authentication.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: OpenIDConnect
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> issuerURL: https://foo.bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> clientID: some-client-id
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> usernameClaim: email
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> usernamePrefix: &lt;span style="color:#a31515">&amp;#34;test-&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> groupsClaim: groups
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> groupsPrefix: &lt;span style="color:#a31515">&amp;#34;baz-&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> supportedSigningAlgs:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - RS256
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> requiredClaims:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> baz: bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> caBundle: LS0tLS1CRUdJTiBDRVJU...base64-encoded CA certs for issuerURL.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>OWA watches for changes on this resource and does &lt;a href="https://openid.net/specs/openid-connect-discovery-1_0.html">OIDC discovery&lt;/a>. The &lt;a href="https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfigurationResponse">OIDC provider&amp;rsquo;s configuration&lt;/a> has to be accessible under the &lt;code>spec.issuerURL&lt;/code> with a &lt;a href="https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig">well-known path (.well-known/openid-configuration)&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>OWA uses the &lt;code>jwks_uri&lt;/code> obtained from the OIDC providers configuration, to fetch the OIDC provider&amp;rsquo;s public keys from that endpoint.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>OWA uses those keys, issuer, client_id and other settings to add an OIDC authenticator to an in-memory list of &lt;a href="https://pkg.go.dev/k8s.io/apiserver/pkg/authentication/authenticator?tab=doc#Token">Token Authenticators&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="https://gardener.cloud/__resources/registration_4bbe69.svg" alt="alt text" title="Authentication with OIDC webhook">&lt;/p>
&lt;h3 id="end-user-authentication-via-new-openidconnect-idp">End-user authentication via new OpenIDConnect IDP&lt;/h3>
&lt;p>When a user presents an &lt;code>id_token&lt;/code> obtained from a OpenID Connect the flow looks like this:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>The user authenticates against a Custom IDP.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>id_token&lt;/code> is obtained from the Custom IDP.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The user uses &lt;code>id_token&lt;/code> to perform an API call to &lt;code>kube-apiserver&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>As the &lt;code>id_token&lt;/code> is not matched by any build-in or configured authenticators in the &lt;code>kube-apiserver&lt;/code>, it is send to OWA for validation.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;TokenReview&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;kind&amp;#34;: &lt;span style="color:#a31515">&amp;#34;TokenReview&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;apiVersion&amp;#34;: &lt;span style="color:#a31515">&amp;#34;authentication.k8s.io/v1beta1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;spec&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;token&amp;#34;: &lt;span style="color:#a31515">&amp;#34;ddeewfwef...&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>OWA uses &lt;code>TokenReview&lt;/code> to authenticate the calling API server (the &lt;code>kube-apiserver&lt;/code> for delegation of authentication and authorization may be different from the calling &lt;code>kube-apiserver&lt;/code>).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;TokenReview&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;kind&amp;#34;: &lt;span style="color:#a31515">&amp;#34;TokenReview&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;apiVersion&amp;#34;: &lt;span style="color:#a31515">&amp;#34;authentication.k8s.io/v1beta1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;spec&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;token&amp;#34;: &lt;span style="color:#a31515">&amp;#34;api-server-token...&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>After the Authentication API server returns the identity of the calling API server:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;apiVersion&amp;#34;: &lt;span style="color:#a31515">&amp;#34;authentication.k8s.io/v1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;kind&amp;#34;: &lt;span style="color:#a31515">&amp;#34;TokenReview&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;metadata&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;creationTimestamp&amp;#34;: &lt;span style="color:#00f">null&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;spec&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;token&amp;#34;: &lt;span style="color:#a31515">&amp;#34;eyJhbGciOiJSUzI1NiIsImtpZCI6InJocEdLTXZlYjV1OE5heD...&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;status&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;authenticated&amp;#34;: &lt;span style="color:#00f">true&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;user&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;groups&amp;#34;: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;system:serviceaccounts&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;system:serviceaccounts:shoot--abcd&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;system:authenticated&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;uid&amp;#34;: &lt;span style="color:#a31515">&amp;#34;14db103e-88bb-4fb3-8efd-ca9bec91c7bf&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;username&amp;#34;: &lt;span style="color:#a31515">&amp;#34;system:serviceaccount:shoot--abcd:kube-apiserver&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>OWA makes a &lt;code>SubjectAccessReview&lt;/code> call to the Authorization API server to ensure that calling API server is allowed to validate tokens:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;apiVersion&amp;#34;: &lt;span style="color:#a31515">&amp;#34;authorization.k8s.io/v1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;kind&amp;#34;: &lt;span style="color:#a31515">&amp;#34;SubjectAccessReview&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;spec&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;groups&amp;#34;: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;system:serviceaccounts&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;system:serviceaccounts:shoot--abcd&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;system:authenticated&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;nonResourceAttributes&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;path&amp;#34;: &lt;span style="color:#a31515">&amp;#34;/validate-token&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;verb&amp;#34;: &lt;span style="color:#a31515">&amp;#34;post&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;user&amp;#34;: &lt;span style="color:#a31515">&amp;#34;system:serviceaccount:shoot--abcd:kube-apiserver&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;status&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;allowed&amp;#34;: &lt;span style="color:#00f">true&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;reason&amp;#34;: &lt;span style="color:#a31515">&amp;#34;RBAC: allowed by RoleBinding \&amp;#34;kube-apiserver\&amp;#34; of ClusterRole \&amp;#34;kube-apiserver\&amp;#34; to ServiceAccount \&amp;#34;system:serviceaccount:shoot--abcd:kube-apiserver\&amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>OWA then iterates over all registered &lt;code>OpenIDConnect&lt;/code> Token authenticators and tries to validate the token.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Upon a successful validation it returns the &lt;code>TokeReview&lt;/code> with user, groups and extra parameters:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-json" data-lang="json">&lt;span style="display:flex;">&lt;span>{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;TokenReview&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;kind&amp;#34;: &lt;span style="color:#a31515">&amp;#34;TokenReview&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;apiVersion&amp;#34;: &lt;span style="color:#a31515">&amp;#34;authentication.k8s.io/v1beta1&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;spec&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;token&amp;#34;: &lt;span style="color:#a31515">&amp;#34;ddeewfwef...&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;status&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;authenticated&amp;#34;: &lt;span style="color:#00f">true&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;user&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;username&amp;#34;: &lt;span style="color:#a31515">&amp;#34;test-foo@bar.com&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;groups&amp;#34;: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;baz-employee&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;extra&amp;#34;: {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;gardener.cloud/authenticator/name&amp;#34;: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;foo&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;#34;gardener.cloud/authenticator/uid&amp;#34;: [
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a31515">&amp;#34;e5062528-e5a4-4b97-ad83-614d015b0979&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>It also adds some extra information which can be used by custom authorizers later on:&lt;/p>
&lt;ol>
&lt;li>&lt;code>gardener.cloud/authenticator/name&lt;/code> contains the name of the &lt;code>OpenIDConnect&lt;/code> authenticator which was used.&lt;/li>
&lt;li>&lt;code>gardener.cloud/authenticator/uid&lt;/code> contains the &lt;code>metadata.uid&lt;/code> of the &lt;code>OpenIDConnect&lt;/code> authenticator which was used.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>
&lt;p>The &lt;code>kube-apiserver&lt;/code> proceeds with authorization checks and returns response.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>An overview of the flow:&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/authentication_eac090.svg" alt="alt text" title="Authentication with OIDC webhook">&lt;/p>
&lt;h2 id="deployment-for-shoot-clusters">Deployment for Shoot clusters&lt;/h2>
&lt;p>OWA can be deployed per Shoot cluster via the &lt;a href="https://github.com/gardener/gardener-extension-shoot-oidc-service">Shoot OIDC Service Extension&lt;/a>. The shoot&amp;rsquo;s &lt;code>kube-apiserver&lt;/code> is mutated so that it has the following flag configured.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-text" data-lang="text">&lt;span style="display:flex;">&lt;span>--authentication-token-webhook-config-file=/etc/webhook/kubeconfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>OWA on the other hand uses the shoot&amp;rsquo;s &lt;code>kube-apiserver&lt;/code> and delegates auth capabilities to it. This means that the needed RBAC is managed in the shoot cluster. By default only the shoot&amp;rsquo;s &lt;code>kube-apiserver&lt;/code> has permissions to validate tokens against OWA.&lt;/p></description></item><item><title>Docs: 13 Automated Seed Management</title><link>https://gardener.cloud/docs/gardener/proposals/13-automated-seed-management/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/13-automated-seed-management/</guid><description>
&lt;h1 id="automated-seed-management">Automated Seed Management&lt;/h1>
&lt;p>Automated seed management involves automating certain aspects of managing seeds in Garden clusters, such as:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#ensuring-seeds-capacity-for-shoots-is-not-exceeded">Ensuring that the seeds capacity for shoots is not exceeded&lt;/a>&lt;/li>
&lt;li>&lt;a href="#managedseeds">Creating, deleting, and updating seeds declaratively as &amp;ldquo;managed seeds&amp;rdquo;&lt;/a>&lt;/li>
&lt;li>&lt;a href="#managedseedsets">Declaratively managing sets of similar &amp;ldquo;managed seeds&amp;rdquo; as &amp;ldquo;managed seed sets&amp;rdquo; which can be scaled up/down&lt;/a>&lt;/li>
&lt;li>&lt;a href="#auto-scaling-seeds">Auto-scaling seeds upon reaching capacity thresholds&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Implementing the above features would involve changes to various existing Gardener components, as well as perhaps introducing new ones. This document describes these features in more detail and proposes a design approach for some of them.&lt;/p>
&lt;p>In Gardener, scheduling shoots onto seeds is quite similar to scheduling pods onto nodes in Kubernetes. Therefore, a guiding principle behind the proposed design approaches is taking advantage of best practices and existing components already used in Kubernetes.&lt;/p>
&lt;h2 id="ensuring-seeds-capacity-for-shoots-is-not-exceeded">Ensuring Seeds Capacity for Shoots Is Not Exceeded&lt;/h2>
&lt;p>Seeds have a practical limit of how many shoots they can accommodate. Exceeding this limit is undesirable as the system performance will be noticeably impacted. Therefore, it is important to ensure that a seed&amp;rsquo;s capacity for shoots is not exceeded by introducing a maximum number of shoots that can be scheduled onto a seed and making sure that it is taken into account by the scheduler.&lt;/p>
&lt;p>An initial discussion of this topic is available in &lt;a href="https://github.com/gardener/gardener/issues/2938">Issue #2938&lt;/a>. The proposed solution is based on the following flow:&lt;/p>
&lt;ul>
&lt;li>The &lt;code>gardenlet&lt;/code> is configured with certain &lt;em>resources&lt;/em> and their total &lt;em>capacity&lt;/em> (and, for certain resources, the amount reserved for Gardener).&lt;/li>
&lt;li>The &lt;code>gardenlet&lt;/code> seed controller updates the Seed status with the capacity of each resource and how much of it is actually available to be consumed by shoots, using &lt;code>capacity&lt;/code> and &lt;code>allocatable&lt;/code> fields that are very similar to the corresponding fields in &lt;a href="https://github.com/kubernetes/api/blob/2c3c141c931c0ab1ce1396c3152c72852b3d37ee/core/v1/types.go#L4582-L4593">the Node status&lt;/a>.&lt;/li>
&lt;li>When scheduling shoots, &lt;code>gardener-scheduler&lt;/code> is influenced by the remaining capacity of the seed. In the simplest possible implementation, it never schedules shoots onto a seed that has already reached its capacity for a resource needed by the shoot.&lt;/li>
&lt;/ul>
&lt;p>Initially, the only resource considered would be the maximum number of shoots that can be scheduled onto a seed. Later, more resources could be added to make more precise scheduling calculations.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> Resources could also be requested by shoots, similarly to how pods can request node resources, and the scheduler could then ensure that such requests are taken into account when scheduling shoots onto seeds. However, the user is rarely, if at all, concerned with what resources does a shoot consume from a seed, and this should also be regarded as an implementation detail that could change in the future. Therefore, such resource requests are not included in this GEP.&lt;/p>
&lt;p>In addition, an extensibility plugin framework could be introduced in the future in order to advertise custom resources, including provider-specific resources, so that &lt;code>gardenlet&lt;/code> would be able to update the seed status with their capacity and allocatable values, for example load balancers on Azure. Such a concept is not described here in further details as it is sufficiently complex to require a separate GEP.&lt;/p>
&lt;p>Example Seed status with &lt;code>capacity&lt;/code> and &lt;code>allocatable&lt;/code> fields:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> capacity:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shoots: &lt;span style="color:#a31515">&amp;#34;100&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> persistent-volumes: &lt;span style="color:#a31515">&amp;#34;200&amp;#34;&lt;/span> &lt;span style="color:#008000"># Built-in resource&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> azure.provider.extensions.gardener.cloud/load-balancers: &lt;span style="color:#a31515">&amp;#34;30&amp;#34;&lt;/span> &lt;span style="color:#008000"># Custom resource advertised by an Azure-specific plugin&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> allocatable:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shoots: &lt;span style="color:#a31515">&amp;#34;100&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> persistent-volumes: &lt;span style="color:#a31515">&amp;#34;197&amp;#34;&lt;/span> &lt;span style="color:#008000"># 3 persistent volumes are reserved for Gardener&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> azure.provider.extensions.gardener.cloud/load-balancers: &lt;span style="color:#a31515">&amp;#34;300&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="gardenlet-configuration">Gardenlet Configuration&lt;/h3>
&lt;p>As mentioned above, the total resource capacity for built-in resources such as the number of shoots is specified as part of the &lt;code>gardenlet&lt;/code> configuration, not in the Seed spec. The &lt;code>gardenlet&lt;/code> configuration itself could be specified in the spec of the newly introduced &lt;a href="#managedseeds">ManagedSeed&lt;/a> resource. Here it is assumed that in the future this could become the recommended and most widely used way to manage seeds. If the same &lt;code>gardenlet&lt;/code> is responsible for multiple seeds, they would all share the same capacity settings.&lt;/p>
&lt;p>To specify the total resource capacity for built-in resources, as well as the amount of such resources reserved for Gardener, the 2 new fields &lt;code>resources.capacity&lt;/code> and &lt;code>resources.reserved&lt;/code> are introduced in the &lt;code>GardenletConfiguration&lt;/code> resource. The &lt;code>gardenlet&lt;/code> seed controller would then initialize the &lt;code>capacity&lt;/code> and &lt;code>allocatable&lt;/code> fields in the seed status as follows:&lt;/p>
&lt;ul>
&lt;li>The &lt;code>capacity&lt;/code> value is set to the configured &lt;code>resources.capacity&lt;/code>.&lt;/li>
&lt;li>The &lt;code>allocatable&lt;/code> value is set to the configured &lt;code>resources.capacity&lt;/code> minus &lt;code>resources.reserved&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>Example &lt;code>GardenletConfiguration&lt;/code> with &lt;code>resources.capacity&lt;/code> and &lt;code>resources.reserved&lt;/code> field:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>resources:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> capacity:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shoots: 100
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> persistent-volumes: 200
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reserved:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> persistent-volumes: 3
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="scheduling-algorithm">Scheduling Algorithm&lt;/h3>
&lt;p>Currently &lt;code>gardener-scheduler&lt;/code> uses a simple non-extensible algorithm in order to schedule shoots onto seeds. It goes through the following stages:&lt;/p>
&lt;ul>
&lt;li>Filter out seeds that don&amp;rsquo;t meet scheduling requirements such as being ready, matching cloud profile and shoot label selectors, matching the shoot provider, and not having taints that are not tolerated by the shoot.&lt;/li>
&lt;li>From the remaining seeds, determine candidates that are considered best based on their region, by using a strategy that can be either &amp;ldquo;same region&amp;rdquo; or &amp;ldquo;minimal distance&amp;rdquo;.&lt;/li>
&lt;li>Among these candidates, choose the one with the least number of shoots.&lt;/li>
&lt;/ul>
&lt;p>This scheduling algorithm should be adapted in order to properly take into account resources capacity and requests. As a first step, during the filtering stage, any seeds that would exceed their capacity for shoots, or their capacity for any resources requested by the shoot, should simply be filtered out and not considered during the next stages.&lt;/p>
&lt;p>Later, the scheduling algorithm could be further enhanced by replacing the step in which the region strategy is applied by a scoring step similar to the one in &lt;a href="https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/">Kubernetes Scheduler&lt;/a>. In this scoring step, the scheduler would rank the remaining seeds to choose the most suitable shoot placement. It would assign a score to each seed that survived filtering based on a list of scoring rules. These rules might include for example &lt;code>MinimalDistance&lt;/code> and &lt;code>SeedResourcesLeastAllocated&lt;/code>, among others. Each rule would produce its own score for the seed, and the overall seed score would be calculated as a weighted sum of all such scores. Finally, the scheduler would assign the shoot to the seed with the highest ranking.&lt;/p>
&lt;h2 id="managedseeds">ManagedSeeds&lt;/h2>
&lt;p>When all or most of the existing seeds are near capacity, new seeds should be created in order to accommodate more shoots. Conversely, sometimes there could be too many seeds for the number of shoots, and so some of the seeds could be deleted to save resources. Currently, the process of creating a new seed involves a number of manual steps, such as creating a new shoot that meets certain criteria, and then registering it as a seed in Gardener. This could be automated to some extent by &lt;a href="https://github.com/gardener/gardener/blob/master/docs/usage/shooted_seed.md">annotating a shoot with the &lt;code>use-as-seed&lt;/code> annotation&lt;/a>, in order to create a &amp;ldquo;shooted seed&amp;rdquo;. However, adding more than one similar seeds still requires manually creating all needed shoots, annotating them appropriately, and making sure that they are successfully reconciled and registered.&lt;/p>
&lt;p>To create, delete, and update seeds effectively in a declarative way and allow auto-scaling, a &amp;ldquo;creatable seed&amp;rdquo; resource along with a &amp;ldquo;set&amp;rdquo; (and in the future, perhaps also a &amp;ldquo;deployment&amp;rdquo;) of such creatable seeds should be introduced, similar to Kubernetes &lt;code>Pod&lt;/code>, &lt;code>ReplicaSet&lt;/code>, and &lt;code>Deployment&lt;/code> (or to MCM &lt;code>Machine&lt;/code>, &lt;code>MachineSet&lt;/code>, and &lt;code>MachineDeployment&lt;/code>) resources. With such resources (and their respective controllers), creating a new seed based on a template would become as simple as increasing the &lt;code>replicas&lt;/code> field in the &amp;ldquo;set&amp;rdquo; resource.&lt;/p>
&lt;p>In &lt;a href="https://github.com/gardener/gardener/issues/2181">Issue #2181&lt;/a> it is already proposed that the &lt;code>use-as-seed&lt;/code> annotation is replaced by a dedicated &lt;code>ShootedSeed&lt;/code> resource. The solution proposed here further elaborates on this idea.&lt;/p>
&lt;h3 id="managedseed-resource">ManagedSeed Resource&lt;/h3>
&lt;p>The &lt;code>ManagedSeed&lt;/code> resource is a dedicated custom resource that represents an evolution of the &amp;ldquo;shooted seed&amp;rdquo; and properly replaces the &lt;code>use-as-seed&lt;/code> annotation. This resource contains:&lt;/p>
&lt;ul>
&lt;li>The name of the Shoot that should be registered as a Seed.&lt;/li>
&lt;li>An optional &lt;code>seedTemplate&lt;/code> section that contains the Seed spec and parts of the metadata, such as labels and annotations.&lt;/li>
&lt;li>An optional &lt;code>gardenlet&lt;/code> section that contains:
&lt;ul>
&lt;li>&lt;code>gardenlet&lt;/code> deployment parameters, such as the number of replicas, the image, etc.&lt;/li>
&lt;li>The &lt;code>GardenletConfiguration&lt;/code> resource that contains controllers configuration, feature gates, and a &lt;code>seedConfig&lt;/code> section that contains the &lt;code>Seed&lt;/code> spec and parts of its metadata.&lt;/li>
&lt;li>Additional configuration parameters, such as the garden connection bootstrap mechanism (see &lt;a href="https://gardener.cloud/docs/gardener/concepts/gardenlet/#tls-bootstrapping">TLS Bootstrapping&lt;/a>), and whether to merge the provided configuration with the configuration of the parent &lt;code>gardenlet&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Either the &lt;code>seedTemplate&lt;/code> or the &lt;code>gardenlet&lt;/code> section must be specified, but not both:&lt;/p>
&lt;ul>
&lt;li>If the &lt;code>seedTemplate&lt;/code> section is specified, &lt;code>gardenlet&lt;/code> is not deployed to the shoot, and a new &lt;code>Seed&lt;/code> resource is created based on the template.&lt;/li>
&lt;li>If the &lt;code>gardenlet&lt;/code> section is specified, &lt;code>gardenlet&lt;/code> is deployed to the shoot, and it registers a new seed upon startup based on the &lt;code>seedConfig&lt;/code> section of the &lt;code>GardenletConfiguration&lt;/code> resource.&lt;/li>
&lt;/ul>
&lt;p>A ManagedSeed allows fine-tuning the seed and the &lt;code>gardenlet&lt;/code> configuration of shooted seeds in order to deviate from the global defaults, e.g. lower the concurrent sync for some of the seed&amp;rsquo;s controllers or enable a feature gate only on certain seeds. Also, it simplifies the deletion protection of such seeds.&lt;/p>
&lt;p>Also, the &lt;code>ManagedSeed&lt;/code> resource is a more powerful alternative to the &lt;code>use-as-seed&lt;/code> annotation. The implementation of the &lt;code>use-as-seed&lt;/code> annotation itself could be refactored to use a &lt;code>ManagedSeed&lt;/code> resource extracted from the annotation by a controller.&lt;/p>
&lt;p>Although in this proposal a ManagedSeed is always a &amp;ldquo;shooted seed&amp;rdquo;, that is a Shoot that is registered as a Seed, this idea could be further extended in the future by adding a &lt;code>type&lt;/code> field that could be either &lt;code>Shoot&lt;/code> (implied in this proposal), or something different. Such an extension would allow to register and manage as Seed a cluster that is not a Shoot, e.g. a GKE cluster.&lt;/p>
&lt;p>Last but not least, ManagedSeeds could be used as the basis for creating and deleting seeds automatically via the &lt;code>ManagedSeedSet&lt;/code> resource that is described in &lt;a href="#managedseedsets">ManagedSeedSets&lt;/a>.&lt;/p>
&lt;p>Unlike the &lt;code>Seed&lt;/code> resource, the &lt;code>ManagedSeed&lt;/code> resource is namespaced. If created in the &lt;code>garden&lt;/code> namespace, the resulting seed is globally available. If created in a project namespace, the resulting seed can be used as a &amp;ldquo;private seed&amp;rdquo; by shoots in the project, either by being decorated with project-specific taints and labels, or by being of the special &lt;code>PrivateSeed&lt;/code> kind that is also namespaced. The concept of private seeds / cloudprofiles is described in &lt;a href="https://github.com/gardener/gardener/issues/2874">Issue #2874&lt;/a>. Until this concept is implemented, &lt;code>ManagedSeed&lt;/code> resources might need to be restricted to the &lt;code>garden&lt;/code> namespace, similarly to how shoots with the &lt;code>use-as-seed&lt;/code> annotation currently are.&lt;/p>
&lt;p>Example &lt;code>ManagedSeed&lt;/code> resource with a &lt;code>seedTemplate&lt;/code> section:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: seedmanagement.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ManagedSeed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: crazy-botany
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shoot:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: crazy-botany &lt;span style="color:#008000"># Shoot that should be registered as a Seed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seedTemplate: &lt;span style="color:#008000"># Seed template, including spec and parts of the metadata&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> foo: bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provider:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: gcp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: europe-west1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> taints:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - key: seed.gardener.cloud/protected
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Example &lt;code>ManagedSeed&lt;/code> resource with a &lt;code>gardenlet&lt;/code> section:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: seedmanagement.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ManagedSeed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: crazy-botany
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shoot:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: crazy-botany &lt;span style="color:#008000"># Shoot that should be registered as a Seed&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gardenlet:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> deployment: &lt;span style="color:#008000"># Gardenlet deployment configuration&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> replicaCount: 1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> revisionHistoryLimit: 10
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> serviceAccountName: gardenlet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> image:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> repository: eu.gcr.io/gardener-project/gardener/gardenlet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tag: latest
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> pullPolicy: IfNotPresent
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resources:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> podLabels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> podAnnotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> additionalVolumes:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> additionalVolumeMounts:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> env:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> vpa: &lt;span style="color:#00f">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> config: &lt;span style="color:#008000"># GardenletConfiguration resource&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: gardenlet.config.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: GardenletConfiguration
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seedConfig: &lt;span style="color:#008000"># Seed template, including spec and parts of the metadata&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> foo: bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provider:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: gcp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: europe-west1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> taints:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - key: seed.gardener.cloud/protected
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> controllers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shoot:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> concurrentSyncs: 20
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> featureGates:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bootstrap: BootstrapToken
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mergeWithParent: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="managedseed-controller">ManagedSeed Controller&lt;/h3>
&lt;p>ManagedSeeds are reconciled by a new &lt;em>managed seed controller&lt;/em> in &lt;code>gardenlet&lt;/code>. Its implementation is very similar to the current &lt;a href="https://github.com/gardener/gardener/blob/master/pkg/gardenlet/controller/shoot/seed_registration_control.go">seed registration controller&lt;/a>, and in fact could be regarded as a refactoring of the latter, with the difference that it uses the &lt;code>ManagedSeed&lt;/code> resource rather than the &lt;code>use-as-seed&lt;/code> annotation on a Shoot. The &lt;code>gardenlet&lt;/code> only reconciles ManagedSeeds that refer to Shoots scheduled on Seeds the &lt;code>gardenlet&lt;/code> is responsible for.&lt;/p>
&lt;p>Once this controller is considered sufficiently stable, the current &lt;code>use-as-seed&lt;/code> annotation and the controller mentioned above should be marked as deprecated and eventually removed.&lt;/p>
&lt;p>A &lt;code>ManagedSeed&lt;/code> that is in use by shoots cannot be deleted, unless the shoots are either deleted or moved to other seeds first. The managed seed controller ensures that this is the case by only allowing a ManagedSeed to be deleted if its Seed has been already deleted.&lt;/p>
&lt;h3 id="managedseed-admission-plugins">ManagedSeed Admission Plugins&lt;/h3>
&lt;p>In addition to the managed seed controller mentioned above, new &lt;code>gardener-apiserver&lt;/code> admission plugins should be introduced to properly validate the creation and update of ManagedSeeds, as well as the deletion of shoots registered as seeds. These plugins should ensure that:&lt;/p>
&lt;ul>
&lt;li>A &lt;code>Shoot&lt;/code> that is being referred to by a &lt;code>ManagedSeed&lt;/code> cannot be deleted.&lt;/li>
&lt;li>Certain &lt;code>Seed&lt;/code> spec fields, for example the provider type and region, networking CIDRs for pods, services, and nodes, etc., are the same as (or compatible with) the corresponding &lt;code>Shoot&lt;/code> spec fields of the shoot that is being registered as seed.&lt;/li>
&lt;li>If such &lt;code>Seed&lt;/code> spec fields are omitted or empty, the plugins should supply proper defaults based on the values in the &lt;code>Shoot&lt;/code> resource.&lt;/li>
&lt;/ul>
&lt;h3 id="provider-specific-seed-bootstrapping-actions">Provider-specific Seed Bootstrapping Actions&lt;/h3>
&lt;p>Bootstrapping a new seed might require additional provider-specific actions to the ones performed automatically by the managed seed controller. For example, on Azure this might include getting a new subscription, extending quotas, etc. This could eventually be automated by introducing an extension mechanism for the Gardener seed bootstrapping flow, to be handled by a new type of controller in the provider extensions. However, such an extension mechanism is not in the scope of this proposal and might require a separate GEP.&lt;/p>
&lt;p>One idea that could be further explored is the use &lt;em>shoot readiness gates&lt;/em>, similar to Kubernetes &lt;a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-readiness-gate">pod readiness gates&lt;/a>, in order to control whether a Shoot is considered &lt;code>Ready&lt;/code> before it could be registered as a Seed. A provider-specific extension could set the special condition that is specified as a readiness gate to &lt;code>True&lt;/code> only after it has successfully performed the provider-specific actions needed.&lt;/p>
&lt;h3 id="changes-to-existing-controllers">Changes to Existing Controllers&lt;/h3>
&lt;p>Since the Shoot registration as a Seed is decoupled from the Shoot reconciliation, existing &lt;code>gardenlet&lt;/code> controllers would not have to be changed in order to properly support ManagedSeeds. The main change to &lt;code>gardenlet&lt;/code> that would be needed is introducing the new &lt;em>managed seed controller&lt;/em> mentioned above, and possibly retiring the old one at some point. In addition, the Shoot controller would need to be adapted as it currently performs certain actions differently if the shoot has a &amp;ldquo;shooted seed&amp;rdquo;.&lt;/p>
&lt;p>The introduction of the &lt;code>ManagedSeed&lt;/code> resource would also require no changes to existing &lt;code>gardener-controller-manager&lt;/code> controllers that operate on Shoots (for example, shoot hibernation and maintenance controllers).&lt;/p>
&lt;h2 id="managedseedsets">ManagedSeedSets&lt;/h2>
&lt;p>Similarly to a &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">ReplicaSet&lt;/a>, the purpose of a ManagedSeedSet is to maintain a stable set of replica &lt;a href="#managedseeds">ManagedSeeds&lt;/a> available at any given time. As such, it is used to guarantee the availability of a specified number of identical ManagedSeeds, on an equal number of identical Shoots.&lt;/p>
&lt;h3 id="managedseedset-resource">ManagedSeedSet Resource&lt;/h3>
&lt;p>The &lt;code>ManagedSeedSet&lt;/code> resource has a &lt;code>selector&lt;/code> field that specifies how to identify ManagedSeeds it can acquire, a number of &lt;code>replicas&lt;/code> indicating how many ManagedSeeds (and their corresponding Shoots) it should be maintaining, and a two templates:&lt;/p>
&lt;ul>
&lt;li>A ManagedSeed template (&lt;code>template&lt;/code>) specifying the data of new ManagedSeeds it should create to meet the number of replicas criteria.&lt;/li>
&lt;li>A Shoot template (&lt;code>shootTemplate&lt;/code>) specifying the data of new Shoots it should create to host the ManagedSeeds.&lt;/li>
&lt;/ul>
&lt;p>A ManagedSeedSet then fulfills its purpose by creating and deleting ManagedSeeds (and their corresponding Shoots) as needed to reach the desired number.&lt;/p>
&lt;p>A ManagedSeedSet is linked to its ManagedSeeds and Shoots via the &lt;code>metadata.ownerReferences&lt;/code> field, which specifies what resource the current object is owned by. All ManagedSeeds and Shoots acquired by a ManagedSeedSet have their owning ManagedSeedSet&amp;rsquo;s identifying information within their &lt;code>ownerReferences&lt;/code> field.&lt;/p>
&lt;p>Example &lt;code>ManagedSeedSet&lt;/code> resource:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: seedmanagement.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ManagedSeedSet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: crazy-botany
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> replicas: 3
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> selector:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> matchLabels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> foo: bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> updateStrategy:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: RollingUpdate &lt;span style="color:#008000"># Update strategy, must be `RollingUpdate`&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> rollingUpdate:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> partition: 2 &lt;span style="color:#008000"># Only update the last replica (#2), assuming there are no gaps (&amp;#34;rolling out a canary&amp;#34;)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> template: &lt;span style="color:#008000"># ManagedSeed template, including spec and parts of the metadata&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> foo: bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># shoot.name is not specified since it&amp;#39;s filled automatically by the controller&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seedTemplate: &lt;span style="color:#008000"># Either a seed or a gardenlet section must be specified, see above&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> foo: bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provider:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: gcp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: europe-west1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> taints:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - key: seed.gardener.cloud/protected
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootTemplate: &lt;span style="color:#008000"># Shoot template, including spec and parts of the metadata&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> foo: bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cloudProfileName: gcp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretBindingName: shoot-operator-gcp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: europe-west1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> provider:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: gcp
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="managedseedset-controller">ManagedSeedSet Controller&lt;/h3>
&lt;p>ManagedSeedSets are reconciled by a new &lt;em>managed seed set controller&lt;/em> in &lt;code>gardener-controller-manager&lt;/code>. During the reconciliation this controller creates and deletes ManagedSeeds and Shoots in response to changes to the &lt;code>replicas&lt;/code> and &lt;code>selector&lt;/code> fields.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> The introduction of the &lt;code>ManagedSeedSet&lt;/code> resource would not require any changes to &lt;code>gardenlet&lt;/code> or to existing &lt;code>gardener-controller-manager&lt;/code> controllers.&lt;/p>
&lt;h3 id="managing-managedseed-updates">Managing ManagedSeed Updates&lt;/h3>
&lt;p>To manage ManagedSeed updates, we considered two possible approaches:&lt;/p>
&lt;ul>
&lt;li>A ManagedSeedSet, similarly to a ReplicaSet, does not manage updates to its replicas in any way. In the future, we might introduce ManagedSeedDeployments, a higher-level concept that manages ManagedSeedSets and provides declarative updates to ManagedSeeds along with other useful features, similarly to a &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">Deployment&lt;/a>. Such a mechanism would involve creating new ManagedSeedSets, and therefore new seeds, behind the scenes, and moving existing shoots to them.&lt;/li>
&lt;li>A ManagedSeedSet does manage updates to its replicas, similarly to a &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">StatefulSet&lt;/a>. Updates are performed &amp;ldquo;in-place&amp;rdquo;, without creating new seeds and moving existing shoots to them. Such a mechanism could also take advantage of other StatefulSet features, such as ordered rolling updates and phased rollouts.&lt;/li>
&lt;/ul>
&lt;p>There is an important difference between seeds and pods or nodes in that seeds are more &amp;ldquo;heavyweight&amp;rdquo; and therefore updating a set of seeds by introducing new seeds and moving shoots to them tends to be much more complex, time-consuming, and prone to failures compared to updating the seeds &amp;ldquo;in place&amp;rdquo;. Furthermore, updating seeds in this way depends on a mature implementation of &lt;a href="https://gardener.cloud/docs/gardener/proposals/07-shoot-control-plane-migration/">GEP-7: Shoot Control Plane Migration&lt;/a>, which is not available right now. Due to these considerations, we favor the second approach over the first one.&lt;/p>
&lt;h4 id="managedseed-identity-and-order">ManagedSeed Identity and Order&lt;/h4>
&lt;p>A StatefulSet manages the deployment and scaling of a set of Pods, and provides guarantees about the ordering and uniqueness of these Pods. It maintains a &lt;em>stable identity&lt;/em> (including network identity) for each of their Pods. These pods are created from the same spec, but are not interchangeable: each has a persistent identifier that it maintains across any rescheduling.&lt;/p>
&lt;p>A StatefulSet achieves the above by associating each replica with an &lt;em>ordinal number&lt;/em>. With n replicas, these ordinal numbers range from 0 to n-1. When scaling out, newly added replicas always have ordinal numbers larger than those of previously existing replicas. When scaling in, it is the replicas with the largest original numbers that are removed.&lt;/p>
&lt;p>Besides stable identity and persistent storage, these ordinal numbers are also used to implement the following StatefulSet features:&lt;/p>
&lt;ul>
&lt;li>Ordered, graceful deployment and scaling.&lt;/li>
&lt;li>Ordered, automated rolling updates. Such rolling updates can be &lt;em>partitioned&lt;/em> (limited to replicas with ordinal numbers greater than or equal to the &amp;ldquo;partition&amp;rdquo;) to achieve &lt;em>phased rollouts&lt;/em>.&lt;/li>
&lt;/ul>
&lt;p>A ManagedSeedSet, unlike a StatefulSet, does not need to maintain a stable identity for its ManagedSeeds. Furthermore, it would not be practical to always remove the replicas with the largest ordinal numbers when scaling in, since the corresponding seeds may have shoots scheduled onto them, while other seeds, with lower ordinals, may have fewer shoots (or none), and therefore be much better candidates for being removed.&lt;/p>
&lt;p>On the other hand, it would be beneficial if a ManagedSeedSet, like a StatefulSet, provides ordered deployment and scaling, ordered rolling updates, and phased rollouts. The main advantage of these features is that a deployment or update failure would affect fewer replicas (ideally just one), containing any potential damage and making the situation easier to handle, thus achieving some of the goals stated in &lt;a href="https://github.com/gardener/gardener/issues/87">Issue #87&lt;/a>. They could also help to contain seed rolling updates outside business hours.&lt;/p>
&lt;p>Based on the above considerations, we propose the following mechanism for handling ManagedSeed identity and order:&lt;/p>
&lt;ul>
&lt;li>A ManagedSeedSet uses &lt;em>ordinal numbers generated by an increasing sequence&lt;/em> to identify ManagedSeeds and Shoots it creates and manages. These numbers always start from 0 and are incremented by 1 for each newly added replica.&lt;/li>
&lt;li>Replicas (both ManagedSeeds and Shoots) are named after the ManagedSeedSet with the ordinal number appended. For example, for a ManagedSeedSet named &lt;code>test&lt;/code> its replicas are named &lt;code>test-0&lt;/code>, &lt;code>test-1&lt;/code>, etc.&lt;/li>
&lt;li>Gaps in the sequence created by removing replicas with ordinal numbers in the middle of the range are never filled in. A newly added replica always receives a number that is not only free, but also unique to itself. For example, if there are 2 replicas named &lt;code>test-0&lt;/code> and &lt;code>test-1&lt;/code> and any one of them is removed, a newly added replica will still be named &lt;code>test-2&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>Although such ordinal numbers can also provide some form of stable identity, in this case it is much more important that they can provide a predictable ordering for deployments and updates, and can also be used to partition rolling updates similarly to StatefulSet ordinal numbers.&lt;/p>
&lt;h4 id="update-strategies">Update Strategies&lt;/h4>
&lt;p>The ManagedSeedSet&amp;rsquo;s &lt;code>.spec.updateStrategy&lt;/code> field allows configuring automated rolling updates for the ManagedSeeds and Shoots in a ManagedSeedSet.&lt;/p>
&lt;p>&lt;strong>Rolling Updates&lt;/strong>&lt;/p>
&lt;p>The &lt;code>RollingUpdate&lt;/code> update strategy implements automated, rolling update for the ManagedSeeds and Shoots in a ManagedSeedSet. With this strategy, the ManagedSeedSet controller will update each ManagedSeed and Shoot in the ManagedSeedSet. It will proceed from the largest number to the smallest, updating each ManagedSeed and its corresponding Shoot one at a time. It will wait until both the Shoot and the Seed of an updated ManagedSeed are Ready prior to updating its predecessor.&lt;/p>
&lt;p>As a further improvement upon the above, the controller could check not only the ManagedSeeds and their corresponding Shoots for readiness, but also the Shoots scheduled onto these ManagedSeeds. The rollout would then only continue if no more than X percent of these Shoots are not reconciled and Ready. Since checking all these additional conditions might require some complex logic, it should be performed by an independent &lt;em>managed seed care controller&lt;/em> that updates the ManagedSeed resource with the readiness of its Seed and all Shoots scheduled onto the Seed.&lt;/p>
&lt;p>Note that unlike a StatefulSet, an &lt;code>OnDelete&lt;/code> update strategy is not supported.&lt;/p>
&lt;p>&lt;strong>Partitions&lt;/strong>&lt;/p>
&lt;p>The &lt;code>RollingUpdate&lt;/code> update strategy can be partitioned, by specifying a &lt;code>.spec.updateStrategy.rollingUpdate.partition&lt;/code>. If a partition is specified, only ManagedSeeds and Shoots with ordinals greater than or equal to the partition will be updated when any of the ManagedSeedSet&amp;rsquo;s templates is updated. All remaining ManagedSeeds and Shoots will not be updated. If a ManagedSeedSet&amp;rsquo;s &lt;code>.spec.updateStrategy.rollingUpdate.partition&lt;/code> is greater than the largest ordinal number in use by a replica, updates to its templates will not be propagated to its replicas (but newly added replicas may still use the updated templates depending on the partition value).&lt;/p>
&lt;h4 id="keeping-track-of-revision-history-and-performing-rollbacks">Keeping Track of Revision History and Performing Rollbacks&lt;/h4>
&lt;p>Similarly to a StatefulSet, the ManagedSeedSet controller uses &lt;a href="https://pkg.go.dev/k8s.io/api/apps/v1#ControllerRevision">ControllerRevisions&lt;/a> to keep track of the revision history, and &lt;code>controller-revision-hash&lt;/code> labels to maintain an association between a ManagedSeed or a Shoot and the concrete template revisions based on which they were created or last updated. These are used for the following purposes:&lt;/p>
&lt;ul>
&lt;li>During an update, determine which replicas are still not on the latest revision and therefore should be updated.&lt;/li>
&lt;li>Display the revision history of a ManagedSeedSet via &lt;code>kubectl rollout history&lt;/code>.&lt;/li>
&lt;li>Roll back all ManagedSeedSet replicas to a specific revision via &lt;code>kubectl rollout undo&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note:&lt;/strong> The above &lt;code>kubectl rollout&lt;/code> commands will not work with custom resources such as ManagedSeedSets out of the box (the &lt;a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#rollout">documentation&lt;/a> says explicitly that valid resource types are only deployments, daemonsets, and statefulsets), but it should be possible to eventually support such commands for ManagedSeedSets via a &lt;a href="https://kubernetes.io/docs/tasks/extend-kubectl/kubectl-plugins/">kubectl plugin&lt;/a>.&lt;/p>
&lt;h3 id="scaling-in-managedseedsets">Scaling-in ManagedSeedSets&lt;/h3>
&lt;p>Deleting ManagedSeeds in response to decreasing the replicas of a ManagedSeedSet deserves special attention for two reasons:&lt;/p>
&lt;ul>
&lt;li>A seed that is already in use by shoots cannot be deleted, unless the shoots are either deleted or moved to other seeds first.&lt;/li>
&lt;li>When there are more empty seeds than requested for deletion, determining which seeds to delete might not be as straightforward as with pods or nodes.&lt;/li>
&lt;/ul>
&lt;p>The above challenges could be addressed as follows:&lt;/p>
&lt;ul>
&lt;li>In order to scale in a ManagedSeedSet successfully, there should be at least as many empty ManagedSeeds as the difference between the old and the new replicas. In some cases, the user might need to ensure that this is the case by draining some seeds manually before decreasing the replicas field.&lt;/li>
&lt;li>It should be possible to protect ManagedSeeds from deletion even if they are empty, perhaps via an annotation such as &lt;code>seedmanagement.gardener.cloud/protect-from-deletion&lt;/code>. Such seeds are not taken into account when determining whether the scale in operation can succeed.&lt;/li>
&lt;li>The decision which seeds to delete among the ManagedSeeds that are empty and not protected should be based on hints, perhaps again in the form of annotations, that could be added manually by the user, as well as other factors, see &lt;a href="#prioritizing-managedseed-deletion">Prioritizing ManagedSeed Deletion&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h4 id="prioritizing-managedseed-deletion">Prioritizing ManagedSeed Deletion&lt;/h4>
&lt;p>To help the controller decide which empty ManagedSeeds are to be deleted first, the user could manually annotate ManagedSeeds with a &lt;em>seed priority annotation&lt;/em> such as &lt;code>seedmanagement.gardener.cloud/priority&lt;/code>. ManagedSeeds with lower priority are more likely to be deleted first. If not specified, a certain default value is assumed, for example 3.&lt;/p>
&lt;p>Besides this annotation, the controller should take into account also other factors, such as the current seed conditions (&lt;code>NotReady&lt;/code> should be preferred for deletion over &lt;code>Ready&lt;/code>), as well as its age (older should be preferred for deletion over newer).&lt;/p>
&lt;h2 id="auto-scaling-seeds">Auto-scaling Seeds&lt;/h2>
&lt;p>The most interesting and advanced automated seed management feature is making sure that a Garden cluster has enough seeds registered to schedule new shoots (and, in the future, reschedule shoots from drained seeds) without exceeding the seeds capacity for shoots, but not more than actually needed at any given moment. This would involve introducing an auto-scaling mechanism for seeds in Garden clusters.&lt;/p>
&lt;p>The proposed solution builds upon the ideas introduced earlier. The &lt;a href="#managedseeds">&lt;code>ManagedSeedSet&lt;/code>&lt;/a> resource (and in the future, also the &lt;code>ManagedSeedDeployment&lt;/code> resource) could have a &lt;code>scale&lt;/code> subresource that changes the &lt;code>replicas&lt;/code> field. This would allow a new &amp;ldquo;seed autoscaler&amp;rdquo; controller to scale these resources via a special &amp;ldquo;autoscaler&amp;rdquo; resource (for example &lt;code>SeedAutoscaler&lt;/code>), similarly to how the Kubernetes &lt;a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">Horizontal Pod Autoscaler&lt;/a> controller scales pods, as described in &lt;a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/">Horizontal Pod Autoscaler Walkthrough&lt;/a>.&lt;/p>
&lt;p>The primary metric used for scaling should be the number of shoots already scheduled onto that seed either as a direct value or as a percentage of the seed&amp;rsquo;s capacity for shoots introduced in &lt;a href="#ensuring-seeds-capacity-for-shoots-is-not-exceeded">Ensuring Seeds Capacity for Shoots Is Not Exceeded&lt;/a> (&lt;em>utilization&lt;/em>). Later, custom metrics based on other resources, including provider-specific resources, could be considered as well.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> Even if the controller is called &lt;em>Horizontal Pod Autoscaler&lt;/em>, it is capable of scaling any resource with a &lt;code>scale&lt;/code> subresource, using any custom metric. Therefore, initially it was proposed to use this controller directly. However, a number of important drawbacks were identified with this approach, and so it is no longer proposed here.&lt;/p>
&lt;h3 id="seedautoscaler-resource">SeedAutoscaler Resource&lt;/h3>
&lt;p>The SeedAutoscaler automatically scales the number of &lt;a href="#managedseeds">ManagedSeeds&lt;/a> in a &lt;a href="#managedseedsets">ManagedSeedSet&lt;/a> based on observed resource utilization. The resource could be any resource that is tracked via the &lt;code>capacity&lt;/code> and &lt;code>allocatable&lt;/code> fields in the Seed status, including in particular the number of shoots already scheduled onto the seed.&lt;/p>
&lt;p>The SeedAutoscaler is implemented as a custom resource and a new controller. The resource determines the behavior of the controller. The &lt;code>SeedAutoscaler&lt;/code> resource has a &lt;code>scaleTargetRef&lt;/code> that specifies the target resource to be scaled, the minimum and maximum number of replicas, as well as a list of metrics. The only supported metric type initially is &lt;code>Resource&lt;/code> for resources that are tracked via the &lt;code>capacity&lt;/code> and &lt;code>allocatable&lt;/code> fields in the Seed status. The resource target can be of type &lt;code>Utilization&lt;/code> or &lt;code>AverageValue&lt;/code>.&lt;/p>
&lt;p>Example &lt;code>SeedAutoscaler&lt;/code> resource:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: seedmanagement.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: SeedAutoscaler
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: crazy-botany
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> scaleTargetRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: seedmanagement.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: ManagedSeedSet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: crazy-botany
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> minReplicas: 1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> maxReplicas: 10
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metrics:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: Resource &lt;span style="color:#008000"># Only Resource is supported&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resource:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: shoots
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: Utilization &lt;span style="color:#008000"># Utilization or AverageValue&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> averageUtilization: 50
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="seedautoscaler-controller">SeedAutoscaler Controller&lt;/h3>
&lt;p>&lt;code>SeedAutoscaler&lt;/code> resources are reconciled by a new &lt;em>seed autoscaler controller&lt;/em>, either in &lt;code>gardener-controller-manager&lt;/code> or out-of-tree, similarly to &lt;a href="https://github.com/gardener/autoscaler">cluster-autoscaler&lt;/a>. The controller periodically adjusts the number of replicas in a ManagedSeedSet to match the observed average resource utilization to the target specified by user.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> The SeedAutoscaler controller should perhaps not be limited to evaluating only metrics, it could also take into account also taints, label selectors, etc. This is not yet reflected in the example &lt;code>SeedAutoscaler&lt;/code> resource above. Such details are intentionally not specified in this GEP, they should be further explored in the issues created to track the actual implementation.&lt;/p>
&lt;h4 id="evaluating-metrics-for-autoscaling">Evaluating Metrics for Autoscaling&lt;/h4>
&lt;p>The metrics used by the controller, for example the &lt;code>shoots&lt;/code> metric above, could be evaluated in one of the following ways:&lt;/p>
&lt;ul>
&lt;li>Directly, by looking at the &lt;code>capacity&lt;/code> and &lt;code>allocatable&lt;/code> fields in the Seed status and comparing to the actual resource consumption calculated by simply counting all shoots that meet a certain criteria (e.g. shoots that are scheduled onto the seed), then taking an average over all seeds in the set.&lt;/li>
&lt;li>By sampling existing metrics exported for example by &lt;a href="https://github.com/gardener/gardener-metrics-exporter">&lt;code>gardener-metrics-exporter&lt;/code>&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>The second approach decouples the seed autoscaler controller from the actual metrics evaluation, and therefore allows plugging in new metrics more easily. It also has the advantage that the exported metrics could also be used for other purposes, e.g. for triggering Prometheus alerts or building Grafana dashboards. It has the disadvantage that the seed autoscaler controller would depend on the metrics exporter to do its job properly.&lt;/p></description></item><item><title>Docs: 17 Shoot Control Plane Migration Bad Case</title><link>https://gardener.cloud/docs/gardener/proposals/17-shoot-control-plane-migration-bad-case/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/17-shoot-control-plane-migration-bad-case/</guid><description>
&lt;h1 id="shoot-control-plane-migration-bad-case-scenario">Shoot Control Plane Migration &amp;ldquo;Bad Case&amp;rdquo; Scenario&lt;/h1>
&lt;p>The &lt;a href="https://gardener.cloud/docs/gardener/proposals/07-shoot-control-plane-migration/#migration-workflow">migration flow&lt;/a> described as part of &lt;a href="https://gardener.cloud/docs/gardener/proposals/07-shoot-control-plane-migration/">GEP-7&lt;/a> can only be executed if both the Garden cluster and source seed cluster are healthy, and &lt;code>gardenlet&lt;/code> in the source seed cluster can connect to the Garden cluster. In this case, &lt;code>gardenlet&lt;/code> can directly scale down the shoot&amp;rsquo;s control plane in the source seed, after checking the &lt;code>spec.seedName&lt;/code> field.&lt;/p>
&lt;p>However, there might be situations in which &lt;code>gardenlet&lt;/code> in the source seed cluster can&amp;rsquo;t connect to the Garden cluster and determine that &lt;code>spec.seedName&lt;/code> has changed. Similarly, the connection to the seed &lt;code>kube-apiserver&lt;/code> could also be broken. This might be caused by issues with the seed cluster itself. In other situations, the migration flow steps in the source seed might have started but might not be able to finish successfully. In all such cases, it should still be possible to migrate a shoot&amp;rsquo;s control plane to a different seed, even though executing the migration flow steps in the source seed might not be possible. The potential &amp;ldquo;split brain&amp;rdquo; situation caused by having the shoot&amp;rsquo;s control plane components attempting to reconcile the shoot resources in two different seeds must still be avoided, by ensuring that the shoot&amp;rsquo;s control plane in the source seed is deactivated before it is activated in the destination seed.&lt;/p>
&lt;p>The mechanisms and adaptations described below have been tested as part of a PoC prior to describing them here.&lt;/p>
&lt;h2 id="owner-election--copying-snapshots">Owner Election / Copying Snapshots&lt;/h2>
&lt;p>To achieve the goals outlined above, an &amp;ldquo;owner election&amp;rdquo; (or rather, &amp;ldquo;ownership passing&amp;rdquo;) mechanism is introduced to ensure that the source and destination seeds are able to successfully negotiate a single &amp;ldquo;owner&amp;rdquo; during the migration. This mechanism is based on special &lt;em>owner DNS records&lt;/em> that uniquely identify the seed that currently hosts the shoot&amp;rsquo;s control plane (&amp;ldquo;owns&amp;rdquo; the shoot).&lt;/p>
&lt;p>For example, for a shoot named &lt;code>i500152-gcp&lt;/code> in project &lt;code>dev&lt;/code> that uses an internal domain suffix &lt;code>internal.dev.k8s.ondemand.com&lt;/code> and is scheduled on a seed with an identity &lt;code>shoot--i500152--gcp2-0841c87f-8db9-4d04-a603-35570da6341f-sap-landscape-dev&lt;/code>, the owner DNS record is a TXT record with a domain name &lt;code>owner.i500152-gcp.dev.internal.dev.k8s.ondemand.com&lt;/code> and a single value &lt;code>shoot--i500152--gcp2-0841c87f-8db9-4d04-a603-35570da6341f-sap-landscape-dev&lt;/code>. The owner DNS record is created and maintained by reconciling an &lt;code>owner&lt;/code> DNSRecord resource.&lt;/p>
&lt;p>Unlike other extension resources, the &lt;code>owner&lt;/code> DNSRecord resource is not reconciled every time the shoot is reconciled, but only when the resource is created. Therefore, the owner DNS record value (the owner ID) is updated only when the shoot is migrated to a different seed. For more information, see &lt;a href="https://github.com/gardener/gardener/pull/4307">Add handling of owner DNSRecord resources&lt;/a>.&lt;/p>
&lt;p>The owner DNS record domain name and owner ID are passed to components that need to perform ownership checks, such as the &lt;code>backup-restore&lt;/code> container of the &lt;code>etcd-main&lt;/code> StatefulSet, and all extension controllers. These components then check regularly whether the actual owner ID (the value of the record) matches the passed ID. If they don&amp;rsquo;t, the ownership check is considered failed, which causes the special behavior described below.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> A previous revision of this document proposed using &amp;ldquo;sync objects&amp;rdquo; written to and read from the backup container of the source seed as JSON files by the &lt;code>etcd-backup-restore&lt;/code> processes in both seeds. With the introduction of owner DNS records such sync objects are no longer needed.&lt;/p>
&lt;p>For the destination seed to actually become the owner, it needs to acquire the shoot&amp;rsquo;s etcd data by copying the final full snapshot (and potentially also older snapshots) from the backup container of the source seed.&lt;/p>
&lt;p>The mechanism to copy the snapshots and pass the ownership from the source to the destination seed consists of the following steps:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>The reconciliation flow (&amp;ldquo;restore&amp;rdquo; phase) is triggered in the destination seed without first executing the migration flow in the source seed (or perhaps it was executed, but it failed, and its state is currently unknown).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;code>owner&lt;/code> DNSRecord resource is created in the destination seed. As a result, the actual owner DNS record is updated with the destination seed ID. From this point, ownership checks by the &lt;code>etcd-backup-restore&lt;/code> process and &lt;a href="#extension-controller-watchdogs">extension controller watchdogs&lt;/a> in the source seed will fail, which will cause the special behavior described below.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>An additional &amp;ldquo;source&amp;rdquo; backup entry referencing the source seed backup bucket is deployed to the Garden cluster and the destination seed and reconciled by the backup entry controller. As a result, a secret with the appropriate credentials for accessing the source seed backup container named &lt;code>source-etcd-backup&lt;/code> is created in the destination seed. The normal backup entry (referencing the destination seed backup container) is also deployed and reconciled, as usual, resulting in the usual &lt;code>etcd-backup&lt;/code> secret being created.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>A special &amp;ldquo;copy&amp;rdquo; version of the &lt;code>etcd-main&lt;/code> Etcd resource is deployed to the destination seed. In its &lt;code>backup&lt;/code> section, this resource contains a &lt;code>sourceStore&lt;/code> in addition to the usual &lt;code>store&lt;/code>, which contains the parameters needed to use the source seed backup container, such as its name and the secret created in the previous step.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backup:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> store:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> container: 408740b8-6491-415e-98e6-76e92e5956ac
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: etcd-backup
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sourceStore:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> container: d1435fea-cd5e-4d5b-a198-81f4025454ff
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: source-etcd-backup
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>The &lt;code>etcd-druid&lt;/code> in the destination seed reconciles the above resource by deploying a &lt;code>etcd-copy&lt;/code> Job that contains a single &lt;code>backup-restore&lt;/code> container. It executes the newly introduced &lt;code>copy&lt;/code> command of &lt;code>etcd-backup-restore&lt;/code> that copies the snapshots from the source to the destination backup container.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Before starting the copy itself, the &lt;code>etcd-backup-restore&lt;/code> process in the destination seed checks if a final full snapshot (a full snapshot marked as &lt;code>final=true&lt;/code>) exists in the backup container. If such a snapshot is not found, it waits for it to appear in order to proceed. This waiting is up to a certain timeout that should be sufficient for a full snapshot to be taken; after this timeout has elapsed, it proceeds anyway, and the reconciliation flow continues from step 9. As described in &lt;a href="#handling-inability-to-access-the-backup-container">Handling Inability to Access the Backup Container&lt;/a> below, this is safe to do.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;code>etcd-backup-restore&lt;/code> process in the source seed detects that the owner ID in the owner DNS record is different from the expected owner ID (because it was updated in step 2) and switches to a special &amp;ldquo;final snapshot&amp;rdquo; mode. In this mode the regular snapshotter is stopped, the readiness probe of the main &lt;code>etcd&lt;/code> container starts returning 503, and one final full snapshot is taken. This snapshot is marked as &lt;code>final=true&lt;/code> in order to ensure that it&amp;rsquo;s only taken once, and in order to enable the &lt;code>etcd-backup-restore&lt;/code> process in the destination seed to find it (see step 6).&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> While testing our PoC, we noticed that simply making the readiness probe of the main &lt;code>etcd&lt;/code> container fail doesn&amp;rsquo;t terminate the existing open connections from &lt;code>kube-apiserver&lt;/code> to &lt;code>etcd&lt;/code>. For this to happen, either the &lt;code>kube-apiserver&lt;/code> or the &lt;code>etcd&lt;/code> process has to be restarted at least once. Therefore, when the snapshotter is stopped because an ownership change has been detected, the main &lt;code>etcd&lt;/code> process is killed (using &lt;code>SIGTERM&lt;/code> to allow graceful termination) to ensure that any open connections from &lt;code>kube-apiserver&lt;/code> are terminated. For this to work, the 2 containers must &lt;a href="https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/">share the process namespace&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Since the &lt;code>kube-apiserver&lt;/code> process in the source seed is no longer able to connect to &lt;code>etcd&lt;/code>, all shoot control plane controllers (&lt;code>kube-controller-manager&lt;/code>, &lt;code>kube-scheduler&lt;/code>, &lt;code>machine-controller-manager&lt;/code>, etc.) and extension controllers reconciling shoot resources in the source seed that require a connection to the shoot in order to work start failing. All remaining extension controllers are prevented from reconciling shoot resources via the &lt;a href="#extension-controller-watchdogs">watchdogs&lt;/a> mechanism. At this point, the source seed has effectively lost its ownership of the shoot, and it is safe for the destination seed to assume the ownership.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>After the &lt;code>etcd-backup-restore&lt;/code> process in the destination seed detects that a final full snapshot exists, it copies all snapshots (or a subset of all snapshots) from the source to the destination backup container. When this is done, the Job finishes successfully which signals to the reconciliation flow that the snapshots have been copied.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> To save time, only the final full snapshot taken in step 6, or a subset defined by some criteria, could be copied, instead of all snapshots.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The special &amp;ldquo;copy&amp;rdquo; version of the &lt;code>etcd-main&lt;/code> Etcd resource is deleted from the source seed, and as a result the &lt;code>etcd-copy&lt;/code> Job is also deleted by &lt;code>etcd-druid&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The additional &amp;ldquo;source&amp;rdquo; backup entry referencing the source seed backup container is deleted from the Garden cluster and the destination seed. As a result, its corresponding &lt;code>source-etcd-backup&lt;/code> secret is also deleted from the destination seed.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>From this point, the reconciliation flow proceeds as already described in &lt;a href="https://gardener.cloud/docs/gardener/proposals/07-shoot-control-plane-migration/">GEP-7&lt;/a>. This is safe, since the source seed cluster is no longer able to interfere with the shoot.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="handling-inability-to-access-the-backup-container">Handling Inability to Access the Backup Container&lt;/h2>
&lt;p>The mechanism described above assumes that the &lt;code>etcd-backup-restore&lt;/code> process in the source seed is able to access its backup container in order to take snapshots. If this is not the case, but an ownership change was detected, the &lt;code>etcd-backup-restore&lt;/code> process still sets the readiness probe status of the main &lt;code>etcd&lt;/code> container to 503, and kills the main &lt;code>etcd&lt;/code> process as described above to ensure that any open connections from &lt;code>kube-apiserver&lt;/code> are terminated. This effectively deactivates the source seed control plane to ensure that the ownership of the shoot can be passed to a different seed.&lt;/p>
&lt;p>Because of this, &lt;code>etcd-backup-restore&lt;/code> process in the destination seed responsible for copying the snapshots can avoid waiting forever for a final full snapshot to appear. Instead, after a certain timeout has elapsed, it can proceed with the copying. In this situation, whatever latest snapshot is found in the source backup container will be restored in the destination seed. The shoot is still migrated to a healthy seed at the cost of losing the etcd data that accumulated between the point in time when the connection to the source backup container was lost, and the point in time when the source seed cluster was deactivated.&lt;/p>
&lt;p>When the connection to the backup container is restored in the source seed, a final full snapshot will be eventually taken. Depending on the stage of the restoration flow in the destination seed, this snapshot may be copied to the destination seed and restored, or it may simply be ignored since the snapshots have already been copied.&lt;/p>
&lt;h2 id="handling-inability-to-resolve-the-owner-dns-record">Handling Inability to Resolve the Owner DNS Record&lt;/h2>
&lt;p>The situation when the owner DNS record cannot be resolved is treated similarly to a failed ownership check: the &lt;code>etcd-backup-restore&lt;/code> process sets the readiness probe status of the main &lt;code>etcd&lt;/code> container to 503, and kills the main &lt;code>etcd&lt;/code> process as described above to ensure that any open connections from &lt;code>kube-apiserver&lt;/code> are terminated, effectively deactivating the source seed control plane. The final full snapshot is not taken in this case to ensure that the control plane can be re-activated if needed.&lt;/p>
&lt;p>When the owner DNS record can be resolved again, the following 2 situations are possible:&lt;/p>
&lt;ul>
&lt;li>If the source seed is still the owner of the shoot, the &lt;code>etcd-backup-restore&lt;/code> process will set the readiness probe status of the main &lt;code>etcd&lt;/code> container to 200, so &lt;code>kube-apiserver&lt;/code> will be able to connect to &lt;code>etcd&lt;/code> and the source seed control plane will be activated again.&lt;/li>
&lt;li>If the source seed is no longer the owner of the shoot, the etcd readiness probe will continue to fail, and the source seed control plane will remain inactive. In addition, the final full snapshot will be taken at this time, for the same reason as described in &lt;a href="#handling-inability-to-access-the-backup-container">Handling Inability to Access the Backup Container&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note:&lt;/strong> We expect that actual DNS outages are extremely unlikely. A more likely reason for an inability to resolve a DNS record could be network issues with the underlying infrastructure. In such cases, the shoot would usually not be usable / reachable anyway, so deactivating its control plane would not cause a worse outage.&lt;/p>
&lt;h2 id="migration-flow-adaptations">Migration Flow Adaptations&lt;/h2>
&lt;p>Certain changes to the migration flow are needed in order to ensure that it is compatible with the &lt;a href="#owner-election--copying-snapshots">owner election&lt;/a> mechanism described above. Instead of taking a full snapshot of the source seed etcd, the flow deletes the owner DNS record by deleting the &lt;code>owner&lt;/code> DNSRecord resource. This causes the ownership check by &lt;code>etcd-backup-restore&lt;/code> to fail, and the final full snapshot to be eventually taken, so the migration flow waits for a final full snapshot to appear as the last step before deleting the shoot namespace in the source seed. This ensures that the reconciliation flow described above will find a final full snapshot waiting to be copied at step 6.&lt;/p>
&lt;p>Checking for the final full snapshot is performed by calling the already existing &lt;code>etcd-backup-restore&lt;/code> endpoint &lt;code>snapshot/latest&lt;/code>. This is possible, since the &lt;code>backup-restore&lt;/code> container is always running at this point.&lt;/p>
&lt;p>After the final full snapshot has been taken, the readiness probe of the main &lt;code>etcd&lt;/code> container starts failing, which means that if the migration flow is retried due to an error it must skip the step that waits for &lt;code>etcd-main&lt;/code> to become ready. To determine if this is the case, a check whether the final full snapshot has been taken or not is performed by calling the same &lt;code>etcd-backup-restore&lt;/code> endpoint, e.g. &lt;code>snapshot/latest&lt;/code>. This is possible if the &lt;code>etcd-main&lt;/code> Etcd resource exists with non-zero replicas. Otherwise:&lt;/p>
&lt;ul>
&lt;li>If the resource doesn&amp;rsquo;t exist, it must have been already deleted, so the final full snapshot n must have been already taken.&lt;/li>
&lt;li>If it exists with zero replicas, the shoot must be hibernated, and the migration flow must have never been executed (since it scales up etcd as one of its first steps), so the final full snapshot must not have been taken yet.&lt;/li>
&lt;/ul>
&lt;h2 id="extension-controller-watchdogs">Extension Controller Watchdogs&lt;/h2>
&lt;p>Some extension controllers will stop reconciling shoot resources after the connection to the shoot&amp;rsquo;s &lt;code>kube-apiserver&lt;/code> is lost. Others, most notably the infrastructure controller, will not be affected. Even though new shoot reconciliations won&amp;rsquo;t be performed by &lt;code>gardenlet&lt;/code>, such extension controllers might be stuck in a retry loop triggered by a previous reconciliation, which may cause them to reconcile their resources after &lt;code>gardenlet&lt;/code> has already stopped reconciling the shoot. In addition, a reconciliation started when the seed still owned the shoot might take some time and therefore might still be running after the ownership has changed. To ensure that the source seed is completely deactivated, an additional safety mechanism is needed.&lt;/p>
&lt;p>This mechanism should handle the following interesting cases:&lt;/p>
&lt;ul>
&lt;li>&lt;code>gardenlet&lt;/code> cannot connect to the Garden &lt;code>kube-apiserver&lt;/code>. In this case it cannot fetch shoots and therefore does not know if control plane migration has been triggered. Even though &lt;code>gardenlet&lt;/code> will not trigger new reconciliations, extension controllers could still attempt to reconcile their resources if they are stuck a retry loop from a previous reconciliation, and already running reconciliations will not be stopped.&lt;/li>
&lt;li>&lt;code>gardenlet&lt;/code> cannot connect to the seed&amp;rsquo;s &lt;code>kube-apiserver&lt;/code>. In this case &lt;code>gardenlet&lt;/code> knows if migration has been triggered, but it will not start shoot migration or reconciliation as it will first check the seed conditions and try to update the &lt;code>Cluster&lt;/code> resource, both of which will fail. Extension controllers could still be able to connect to the seed&amp;rsquo;s &lt;code>kube-apiserver&lt;/code> (if they are not running where &lt;code>gardenlet&lt;/code> is running), and similarly to the previous case, they could still attempt to reconcile their resources.&lt;/li>
&lt;li>The seed components (&lt;code>etcd-druid&lt;/code>, extension controllers, etc) cannot connect to the seed&amp;rsquo;s &lt;code>kube-apiserver&lt;/code>. In this case extension controllers would not be able to reconcile their resources as they cannot fetch them from the seed&amp;rsquo;s &lt;code>kube-apiserver&lt;/code>. When the connection to the &lt;code>kube-apiserver&lt;/code> comes back, the controllers might be stuck in a retry loop from a previous reconciliation, or the resources could still be annotated with &lt;code>gardener.cloud/operation=reconcile&lt;/code>. This could lead to a race condition depending on who manages to &lt;code>update&lt;/code> or &lt;code>get&lt;/code> the resources first. If &lt;code>gardenlet&lt;/code> manages to update the resources before they are read by the extension controllers, they would be properly updated with &lt;code>gardener.cloud/operation=migrate&lt;/code>. Otherwise, they would be reconciled as usual.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Note:&lt;/strong> A previous revision of this document proposed using &amp;ldquo;cluster leases&amp;rdquo; as such an additional safety mechanism. With the introduction of owner DNS records cluster leases are no longer needed.&lt;/p>
&lt;p>The safety mechanism is based on &lt;em>extension controller watchdogs&lt;/em>. These are simply additional goroutines that are started when a reconciliation is started by an extension controller. These goroutines perform an ownership check on a regular basis using the owner DNS record, similar to the check performed by the &lt;code>etcd-backup-restore&lt;/code> process described above. If the check fails, the watchdog cancels the reconciliation context, which immediately aborts the reconciliation.&lt;/p>
&lt;p>&lt;strong>Note:&lt;/strong> The &lt;code>dns-external&lt;/code> extension controller is the only extension controller that neither needs the shoot&amp;rsquo;s &lt;code>kube-apiserver&lt;/code>, nor uses the watchdog mechanism described here. Therefore, this controller will continue reconciling &lt;code>DNSEntry&lt;/code> resources even after the source seed has lost the ownership of the shoot. With the PoC, we manually delete the &lt;code>DNSOwner&lt;/code> resources from the source seed cluster to prevent this from happening. Eventually, the &lt;code>dns-external&lt;/code> controller should be adapted to use the owner DNS records to ensure that it disables itself after the seed has lost the ownership of the shoot. Changes in this direction have already been agreed and relevant PRs proposed.&lt;/p></description></item><item><title>Docs: Access Restrictions</title><link>https://gardener.cloud/docs/dashboard/deployment/access-restrictions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/dashboard/deployment/access-restrictions/</guid><description>
&lt;h1 id="access-restrictions">Access Restrictions&lt;/h1>
&lt;p>The dashboard can be configured with access restrictions.&lt;/p>
&lt;img src="https://gardener.cloud/__resources/access-restrictions-1_071de9.png">
&lt;p>Access restrictions are shown for regions that have a matching label in the &lt;code>CloudProfile&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span> regions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: pangaea-north-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> zones:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: pangaea-north-1a
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: pangaea-north-1b
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: pangaea-north-1c
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seed.gardener.cloud/eu-access: &lt;span style="color:#a31515">&amp;#34;true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>If the user selects the access restriction, &lt;code>spec.seedSelector.matchLabels[key]&lt;/code> will be set.&lt;/li>
&lt;li>When selecting an option, &lt;code>metadata.annotations[optionKey]&lt;/code> will be set.&lt;/li>
&lt;/ul>
&lt;p>The value that is set depends on the configuration. See &lt;em>2.&lt;/em> under &lt;em>Configuration&lt;/em> section below.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: core.gardener.cloud/v1beta1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> annotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> support.gardener.cloud/eu-access-for-cluster-addons: &lt;span style="color:#a31515">&amp;#34;true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> support.gardener.cloud/eu-access-for-cluster-nodes: &lt;span style="color:#a31515">&amp;#34;true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seedSelector:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> matchLabels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seed.gardener.cloud/eu-access: &lt;span style="color:#a31515">&amp;#34;true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In order for the shoot (with enabled access restriction) to be scheduled on a seed, the seed needs to have the label set. E.g.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: core.gardener.cloud/v1beta1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Seed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seed.gardener.cloud/eu-access: &lt;span style="color:#a31515">&amp;#34;true&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;img src="https://gardener.cloud/__resources/access-restrictions-2_2e2c49.png">
&lt;p>&lt;strong>Configuration&lt;/strong>
As gardener administrator:&lt;/p>
&lt;ol>
&lt;li>you can control the visibility of the chips with the &lt;code>accessRestriction.items[].display.visibleIf&lt;/code> and &lt;code>accessRestriction.items[].options[].display.visibleIf&lt;/code> property. E.g. in this example the access restriction chip is shown if the value is true and the option is shown if the value is false.&lt;/li>
&lt;li>you can control the value of the input field (switch / checkbox) with the &lt;code>accessRestriction.items[].input.inverted&lt;/code> and &lt;code>accessRestriction.items[].options[].input.inverted&lt;/code> property. Setting the &lt;code>inverted&lt;/code> property to &lt;code>true&lt;/code> will invert the value. That means that when selecting the input field the value will be&lt;code>'false'&lt;/code> instead of &lt;code>'true'&lt;/code>.&lt;/li>
&lt;li>you can configure the text that is displayed when no access restriction options are available by setting &lt;code>accessRestriction.noItemsText&lt;/code>
example &lt;code>values.yaml&lt;/code>:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>accessRestriction:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> noItemsText: &lt;span style="color:#00f">No&lt;/span> access restriction options available for region {region} and cloud profile {cloudProfile}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> items:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - key: seed.gardener.cloud/eu-access
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> display:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> visibleIf: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># title: foo # optional title, if not defined key will be used&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># description: bar # optional description displayed in a tooltip&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> title: EU Access
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> description: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> &lt;/span> This service is offered to you with our regular SLAs and 24x7 support for the control plane of the cluster. 24x7 support for cluster add-ons and nodes is only available if you meet the following conditions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> options:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - key: support.gardener.cloud/eu-access-for-cluster-addons
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> display:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> visibleIf: &lt;span style="color:#00f">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># title: bar # optional title, if not defined key will be used&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># description: baz # optional description displayed in a tooltip&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> title: &lt;span style="color:#00f">No&lt;/span> personal data is used as name or in the content of Gardener or Kubernetes resources (e.g. Gardener project name or Kubernetes namespace, configMap or secret in Gardener or Kubernetes)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> description: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> &lt;/span> If you can&amp;#39;t comply, only third-level/dev support at usual 8x5 working hours in EEA will be available to you for all cluster add-ons such as DNS and certificates, Calico overlay network and network policies, kube-proxy and services, and everything else that would require direct inspection of your cluster through its API server
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inverted: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - key: support.gardener.cloud/eu-access-for-cluster-nodes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> display:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> visibleIf: &lt;span style="color:#00f">false&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> title: &lt;span style="color:#00f">No&lt;/span> personal data is stored in any Kubernetes volume except for container file system, emptyDirs, and persistentVolumes (in particular, not on hostPath volumes)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> description: |&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> &lt;/span> If you can&amp;#39;t comply, only third-level/dev support at usual 8x5 working hours in EEA will be available to you for all node-related components such as Docker and Kubelet, the operating system, and everything else that would require direct inspection of your nodes through a privileged pod or SSH
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> inverted: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Adding Support for a Cloud Provider</title><link>https://gardener.cloud/docs/other-components/machine-controller-manager/docs/development/cp_support_new/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/machine-controller-manager/docs/development/cp_support_new/</guid><description>
&lt;h1 id="adding-support-for-a-new-provider">Adding support for a new provider&lt;/h1>
&lt;p>Steps to be followed while implementing a new (hyperscale) provider are mentioned below. This is the easiest way to add new provider support using a blueprint code.&lt;/p>
&lt;p>However, you may also develop your machine controller from scratch, which would provide you with more flexibility. First, however, make sure that your custom machine controller adheres to the &lt;code>Machine.Status&lt;/code> struct defined in the &lt;a href="https://github.com/gardener/machine-controller-manager/blob/master/pkg/apis/machine/types.go">MachineAPIs&lt;/a>. This will make sure the MCM can act with higher-level controllers like MachineSet and MachineDeployment controller. The key is the &lt;code>Machine.Status.CurrentStatus.Phase&lt;/code> key that indicates the status of the machine object.&lt;/p>
&lt;p>Our strong recommendation would be to follow the steps below. This provides the most flexibility required to support machine management for adding new providers. And if you feel to extend the functionality, feel free to update our &lt;a href="https://github.com/gardener/machine-controller-manager/tree/master/pkg/util/provider">machine controller libraries&lt;/a>.&lt;/p>
&lt;h2 id="setting-up-your-repository">Setting up your repository&lt;/h2>
&lt;ol>
&lt;li>Create a new empty repository named &lt;code>machine-controller-manager-provider-{provider-name}&lt;/code> on GitHub username/project. Do not initialize this repository with a README.&lt;/li>
&lt;li>Copy the remote repository &lt;code>URL&lt;/code> (HTTPS/SSH) to this repository displayed once you create this repository.&lt;/li>
&lt;li>Now, on your local system, create directories as required. {your-github-username} given below could also be {github-project} depending on where you have created the new repository.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>mkdir -p $GOPATH/src/github.com/{your-github-username}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Navigate to this created directory.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cd $GOPATH/src/github.com/{your-github-username}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Clone &lt;a href="https://github.com/gardener/machine-controller-manager-provider-sampleprovider">this repository&lt;/a> on your local machine.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>git clone git@github.com:gardener/machine-controller-manager-provider-sampleprovider.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Rename the directory from &lt;code>machine-controller-manager-provider-sampleprovider&lt;/code> to &lt;code>machine-controller-manager-provider-{provider-name}&lt;/code>.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>mv machine-controller-manager-provider-sampleprovider machine-controller-manager-provider-{provider-name}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Navigate into the newly-created directory.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cd machine-controller-manager-provider-{provider-name}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Update the remote &lt;code>origin&lt;/code> URL to the newly created repository&amp;rsquo;s URL you had copied above.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>git remote set-url origin git@github.com:{your-github-username}/machine-controller-manager-provider-{provider-name}.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Rename GitHub project from &lt;code>gardener&lt;/code> to &lt;code>{github-org/your-github-username}&lt;/code> wherever you have cloned the repository above. Also, edit all occurrences of the word &lt;code>sampleprovider&lt;/code> to &lt;code>{provider-name}&lt;/code> in the code. Then, use the hack script given below to do the same.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make rename-project PROJECT_NAME={github-org/your-github-username} PROVIDER_NAME={provider-name}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>eg:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> make rename-project PROJECT_NAME=gardener PROVIDER_NAME=AmazonWebServices (or)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> make rename-project PROJECT_NAME=githubusername PROVIDER_NAME=AWS
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Now, commit your changes and push them upstream.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>git add -A
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>git commit -m &lt;span style="color:#a31515">&amp;#34;Renamed SampleProvide to {provider-name}&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>git push origin master
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ol>
&lt;h2 id="code-changes-required">Code changes required&lt;/h2>
&lt;p>The contract between the Machine Controller Manager (MCM) and the Machine Controller (MC) AKA driver has been &lt;a href="https://gardener.cloud/docs/other-components/machine-controller-manager/docs/development/machine_error_codes/">documented here&lt;/a> and the &lt;a href="https://github.com/gardener/machine-controller-manager/blob/master/pkg/util/provider/machinecodes/codes/codes.go">machine error codes can be found here&lt;/a>. You may refer to them for any queries.&lt;/p>
&lt;p>⚠️&lt;/p>
&lt;ul>
&lt;li>Keep in mind that &lt;strong>there should be a unique way to map between machine objects and VMs&lt;/strong>. This can be done by mapping machine object names with VM-Name/ tags/ other metadata.&lt;/li>
&lt;li>Optionally, there should also be a unique way to map a VM to its machine class object. This can be done by tagging VM objects with tags/resource groups associated with the machine class.&lt;/li>
&lt;/ul>
&lt;h4 id="steps-to-integrate">Steps to integrate&lt;/h4>
&lt;ol>
&lt;li>Update the &lt;code>pkg/provider/apis/provider_spec.go&lt;/code> specification file to reflect the structure of the &lt;code>ProviderSpec&lt;/code> blob. It typically contains the machine template details in the &lt;code>MachineClass&lt;/code> object. Follow the sample spec provided already in the file. A sample provider specification can be found &lt;a href="https://github.com/gardener/machine-controller-manager-provider-aws/blob/master/pkg/aws/apis/aws_provider_spec.go">here&lt;/a>.&lt;/li>
&lt;li>Fill in the methods described at &lt;code>pkg/provider/core.go&lt;/code> to manage VMs on your cloud provider. Comments are provided above each method to help you fill them up with desired &lt;code>REQUEST&lt;/code> and &lt;code>RESPONSE&lt;/code> parameters.
&lt;ul>
&lt;li>A sample provider implementation for these methods can be found &lt;a href="https://github.com/gardener/machine-controller-manager-provider-aws/blob/master/pkg/aws/core.go">here&lt;/a>.&lt;/li>
&lt;li>Fill in the required methods &lt;code>CreateMachine()&lt;/code>, and &lt;code>DeleteMachine()&lt;/code> methods.&lt;/li>
&lt;li>Optionally fill in methods like &lt;code>GetMachineStatus()&lt;/code>, &lt;code>ListMachines()&lt;/code>, and &lt;code>GetVolumeIDs()&lt;/code>. You may choose to fill these once the working of the required methods seems to be working.&lt;/li>
&lt;li>&lt;code>GetVolumeIDs()&lt;/code> expects VolumeIDs to be decoded from the volumeSpec based on the cloud provider.&lt;/li>
&lt;li>There is also an OPTIONAL method &lt;code>GenerateMachineClassForMigration()&lt;/code> that helps in migration of &lt;code>{ProviderSpecific}MachineClass&lt;/code> to &lt;code>MachineClass&lt;/code> CR (custom resource). This only makes sense if you have an existing implementation (in-tree) acting on different CRD types. You would like to migrate this. If not, you MUST return an error (machine error UNIMPLEMENTED) to avoid processing this step.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Perform validation of APIs that you have described and make it a part of your methods as required at each request.&lt;/li>
&lt;li>Write unit tests to make it work with your implementation by running &lt;code>make test&lt;/code>.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make test
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Re-generate the vendors to update any new vendors imported.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make revendor
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Update the sample YAML files on the &lt;code>kubernetes/&lt;/code> directory to provide sample files through which the working of the machine controller can be tested.&lt;/li>
&lt;li>Update &lt;code>README.md&lt;/code> to reflect any additional changes&lt;/li>
&lt;/ol>
&lt;h2 id="testing-your-code-changes">Testing your code changes&lt;/h2>
&lt;p>Make sure &lt;code>$TARGET_KUBECONFIG&lt;/code> points to the cluster where you wish to manage machines. Likewise, &lt;code>$CONTROL_NAMESPACE&lt;/code> represents the namespaces where MCM is looking for machine CR objects, and &lt;code>$CONTROL_KUBECONFIG&lt;/code> points to the cluster that holds these machine CRs.&lt;/p>
&lt;ol>
&lt;li>On the first terminal running at &lt;code>$GOPATH/src/github.com/{github-org/your-github-username}/machine-controller-manager-provider-{provider-name}&lt;/code>,
&lt;ul>
&lt;li>Run the machine controller (driver) using the command below.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make start
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>On the second terminal pointing to &lt;code>$GOPATH/src/github.com/gardener&lt;/code>,
&lt;ul>
&lt;li>Clone the &lt;a href="https://github.com/gardener/machine-controller-manager">latest MCM code&lt;/a>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>git clone git@github.com:gardener/machine-controller-manager.git
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Navigate to the newly-created directory.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>cd machine-controller-manager
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Deploy the required CRDs from the machine-controller-manager repo,
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kubectl apply -f kubernetes/crds
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Run the machine-controller-manager in the &lt;code>master&lt;/code> branch
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>make start
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>On the third terminal pointing to &lt;code>$GOPATH/src/github.com/{github-org/your-github-username}/machine-controller-manager-provider-{provider-name}&lt;/code>
&lt;ul>
&lt;li>Fill in the object files given below and deploy them as described below.&lt;/li>
&lt;li>Deploy the &lt;code>machine-class&lt;/code>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kubectl apply -f kubernetes/machine-class.yaml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Deploy the &lt;code>kubernetes secret&lt;/code> if required.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kubectl apply -f kubernetes/secret.yaml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Deploy the &lt;code>machine&lt;/code> object and make sure it joins the cluster successfully.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kubectl apply -f kubernetes/machine.yaml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Once the machine joins, you can test by deploying a machine-deployment.&lt;/li>
&lt;li>Deploy the &lt;code>machine-deployment&lt;/code> object and make sure it joins the cluster successfully.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kubectl apply -f kubernetes/machine-deployment.yaml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>Make sure to delete both the &lt;code>machine&lt;/code> and &lt;code>machine-deployment&lt;/code> objects after use.
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>kubectl delete -f kubernetes/machine.yaml
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kubectl delete -f kubernetes/machine-deployment.yaml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="releasing-your-docker-image">Releasing your docker image&lt;/h2>
&lt;ol>
&lt;li>Make sure you have logged into gcloud/docker using the CLI.&lt;/li>
&lt;li>To release your docker image, run the following.&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span> make release IMAGE_REPOSITORY=&amp;lt;link-to-image-repo&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;ol start="3">
&lt;li>A sample kubernetes deploy file can be found at &lt;code>kubernetes/deployment.yaml&lt;/code>. Update the same (with your desired MCM and MC images) to deploy your MCM pod.&lt;/li>
&lt;/ol></description></item><item><title>Docs: Adding Support for a Cloud Provider (Legacy)</title><link>https://gardener.cloud/docs/other-components/machine-controller-manager/docs/development/cp_support_old/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/machine-controller-manager/docs/development/cp_support_old/</guid><description>
&lt;h1 id="adding-support-for-a-new-cloud-provider">Adding support for a new cloud provider&lt;/h1>
&lt;p>For adding support for a new cloud provider in the Machine Controller Manager, follow the steps described below. Replace provider with your provider-name.&lt;/p>
&lt;ol>
&lt;li>Add a ProviderMachineClass CRD similar to existing AWSMachineClass into &lt;code>kubernetes/crds.yaml&lt;/code>.&lt;/li>
&lt;li>Add ProviderMachineClass structs similar to existing AWSMachineClass into the machine APIs into &lt;code>pkg/apis/machine/types.go&lt;/code> and &lt;code>pkg/apis/machine/v1alpha1/types.go&lt;/code>. This would be the machineClass template used to describe provider specific configurations.&lt;/li>
&lt;li>Add the Go structures of your machine class (list) to &lt;code>pkg/apis/machine/register.go&lt;/code> and &lt;code>pkg/apis/machine/v1alpha1/register.go&lt;/code> to allow reporting events on these objects.&lt;/li>
&lt;li>Regenerate the machine API clients by running &lt;code>./hack/generate-code&lt;/code>&lt;/li>
&lt;li>Add validation for the new provider machine class at &lt;code>pkg/apis/machine/validation/providermachineclass.go&lt;/code> similar to &lt;code>pkg/apis/machine/validation/awsmachineclass.go&lt;/code>&lt;/li>
&lt;li>Update &lt;code>pkg/controller/machine_util.go&lt;/code> to allow validation of the new provider.&lt;/li>
&lt;li>Add a new driver into &lt;code>pkg/driver/driver_provider.go&lt;/code> similar to &lt;code>pkg/driver/driver_aws.go&lt;/code> to implement the driver interface.&lt;/li>
&lt;li>Update &lt;code>pkg/driver/driver.go&lt;/code> to add a new switch case to support the new provider driver.&lt;/li>
&lt;li>Add a new method in &lt;code>pkg/controller/machine_safety.go&lt;/code> called checkProviderMachineClass similar to the existing method called checkAWSMachineClass present in the same file. Now invoke this method as a go-routine in the method checkVMObjects.&lt;/li>
&lt;li>Extend the &lt;code>StartControllers()&lt;/code> function in &lt;code>cmd/machine-controller-manager/app/controllermanager.go&lt;/code> to only start if your new machine class is under the available resources.&lt;/li>
&lt;li>Update &lt;code>pkg/controller/controller.go&lt;/code> to add new providerMachineClassLister, providerMachineClassQueue, awsMachineClassSynced into the controller struct. Also initialize them in NewController() method.&lt;/li>
&lt;li>Add a new file &lt;code>pkg/controller/providermachineclass.go&lt;/code> that allows re-queuing of machines which refer to an modified providerMachineClass.&lt;/li>
&lt;li>Update &lt;code>pkg/controller/controller.go&lt;/code> to extend &lt;code>WaitForCacheSync&lt;/code> and &lt;code>.Shutdown()&lt;/code> similar to other cloud providers.&lt;/li>
&lt;li>Update the example ClusterRole in &lt;code>kubernetes/deployment/in-tree/clusterrole.yaml&lt;/code> to allow operations on your new machine class.&lt;/li>
&lt;li>Update &lt;code>pkg/controller/controller.go&lt;/code>, &lt;code>pkg/controller/secret.go&lt;/code>, &lt;code>pkg/controller/secret_util.go&lt;/code> to add event handlers to add/remove finalizers referenced by your machine Class. Refer &lt;a href="https://github.com/gardener/machine-controller-manager/pull/104/commits/013f70726b1057aed1cf7fe0f0449922ab9a256a">this commit&lt;/a>.&lt;/li>
&lt;/ol></description></item><item><title>Docs: Admission</title><link>https://gardener.cloud/docs/gardener/extensions/admission/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/extensions/admission/</guid><description>
&lt;h1 id="extension-admission">Extension Admission&lt;/h1>
&lt;p>The extensions are expected to validate their respective resources for their extension specific configurations, when the resources are newly created or updated. For example, &lt;a href="https://github.com/gardener/gardener/blob/master/extensions/README.md#infrastructure-provider">provider extensions&lt;/a> would validate &lt;code>spec.provider.infrastructureConfig&lt;/code> and &lt;code>spec.provider.controlPlaneConfig&lt;/code> in the &lt;code>Shoot&lt;/code> resource and &lt;code>spec.providerConfig&lt;/code> in the &lt;code>CloudProfile&lt;/code> resource, &lt;a href="https://github.com/gardener/gardener/blob/master/extensions/README.md#network-plugin">networking extensions&lt;/a> would validate &lt;code>spec.networking.providerConfig&lt;/code> in the &lt;code>Shoot&lt;/code> resource. As best practice, the validation should be performed only if there is a change in the &lt;code>spec&lt;/code> of the resource. Please find an exemplary implementation &lt;a href="https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/admission/validator">here&lt;/a>.&lt;/p>
&lt;p>When a resource is newly created or updated, Gardener adds an extension label for all the extension types referenced in the &lt;code>spec&lt;/code> of the resource. This label is of the form &lt;code>&amp;lt;extension-type&amp;gt;.extensions.gardener.cloud/&amp;lt;extension-name&amp;gt; : &amp;quot;true&amp;quot;&lt;/code>. For example, an extension label for provider extension type &lt;code>aws&lt;/code>, looks like &lt;code>provider.extensions.gardener.cloud/aws : &amp;quot;true&amp;quot;&lt;/code>. The extensions should add object selectors in their admission webhooks for these labels, to filter out the objects they are responsible for. At present, these labels are added to &lt;code>BackupEntry&lt;/code>s, &lt;code>BackupBucket&lt;/code>s, &lt;code>CloudProfile&lt;/code>s, &lt;code>Seed&lt;/code>s, &lt;code>SecretBinding&lt;/code>s and &lt;code>Shoot&lt;/code>s. Please see &lt;a href="https://github.com/gardener/gardener/tree/master/pkg/apis/core/v1beta1/constants/types_constants.go">this&lt;/a> for the full list of extension labels.&lt;/p></description></item><item><title>Docs: Admission Controller</title><link>https://gardener.cloud/docs/gardener/concepts/admission-controller/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/concepts/admission-controller/</guid><description>
&lt;h1 id="gardener-admission-controller">Gardener Admission Controller&lt;/h1>
&lt;p>While the Gardener API server works with &lt;a href="https://gardener.cloud/docs/gardener/concepts/apiserver_admission_plugins/">admission plugins&lt;/a> to validate and mutate resources belonging to Gardener related API groups, e.g. &lt;code>core.gardener.cloud&lt;/code>, the same is needed for resources belonging to non-Gardener API groups as well, e.g. &lt;code>Secret&lt;/code>s in the &lt;code>core&lt;/code> API group.
Therefore, the Gardener Admission Controller runs a http(s) server with the following handlers which serve as validating/mutating endpoints for &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/">admission webhooks&lt;/a>.
It is also used to serve http(s) handlers for authorization webhooks.&lt;/p>
&lt;h2 id="admission-webhook-handlers">Admission Webhook Handlers&lt;/h2>
&lt;p>This section describes the admission webhook handlers that are currently served.&lt;/p>
&lt;h3 id="kubeconfig-secret-validator">Kubeconfig Secret Validator&lt;/h3>
&lt;p>&lt;a href="https://github.com/kubernetes/kubectl/issues/697">Malicious Kubeconfigs&lt;/a> applied by end users may cause a leakage of sensitive data.
This handler checks if the incoming request contains a Kubernetes secret with a &lt;code>.data.kubeconfig&lt;/code> field and denies the request if the Kubeconfig structure violates Gardener&amp;rsquo;s security standards.&lt;/p>
&lt;h3 id="namespace-validator">Namespace Validator&lt;/h3>
&lt;p>Namespaces are the backing entities of Gardener projects in which shoot clusters objects reside.
This validation handler protects active namespaces against premature deletion requests.
Therefore, it denies deletion requests if a namespace still contains shoot clusters or if it belongs to a non-deleting Gardener project (w/o &lt;code>.metadata.deletionTimestamp&lt;/code>).&lt;/p>
&lt;h3 id="resource-size-validator">Resource Size Validator&lt;/h3>
&lt;p>Since users directly apply Kubernetes native objects to the Garden cluster, it also involves the risk of being vulnerable to DoS attacks because these resources are read continuously watched and read by controllers.
One example is the creation of &lt;code>Shoot&lt;/code> resources with large annotation values (up to 256 kB per value) which can cause severe out-of-memory issues for the Gardenlet component.
&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler">Vertical autoscaling&lt;/a> can help to mitigate such situations, but we cannot expect to scale infinitely, and thus need means to block the attack itself.&lt;/p>
&lt;p>The Resource Size Validator checks arbitrary incoming admission requests against a configured maximum size for the resource&amp;rsquo;s group-version-kind combination and denies the request if the contained object exceeds the quota.&lt;/p>
&lt;p>Example for Gardener Admission Controller configuration:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>server:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resourceAdmissionConfiguration:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> limits:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - apiGroups: [&lt;span style="color:#a31515">&amp;#34;core.gardener.cloud&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersions: [&lt;span style="color:#a31515">&amp;#34;*&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resources: [&lt;span style="color:#a31515">&amp;#34;shoots&amp;#34;&lt;/span>, &lt;span style="color:#a31515">&amp;#34;plants&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> size: 100k
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - apiGroups: [&lt;span style="color:#a31515">&amp;#34;&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersions: [&lt;span style="color:#a31515">&amp;#34;v1&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> resources: [&lt;span style="color:#a31515">&amp;#34;secrets&amp;#34;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> size: 100k
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> unrestrictedSubjects:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - kind: Group
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: gardener.cloud:system:seeds
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiGroup: rbac.authorization.k8s.io
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># - kind: User&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># name: admin&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># apiGroup: rbac.authorization.k8s.io&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># - kind: ServiceAccount&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># name: &amp;#34;*&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># namespace: garden&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># apiGroup: &amp;#34;&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> operationMode: block &lt;span style="color:#008000">#log&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>With the configuration above, the Resource Size Validator denies requests for shoots and plants with Gardener&amp;rsquo;s core API group which exceed a size of 100 kB. The same is done for Kubernetes secrets.&lt;/p>
&lt;p>As this feature is meant to protect the system from malicious requests sent by users, it is recommended to exclude trusted groups, users or service accounts from the size restriction via &lt;code>resourceAdmissionConfiguration.unrestrictedSubjects&lt;/code>.
For example, the backing user for the Gardenlet should always be capable of changing the shoot resource instead of being blocked due to size restrictions.
This is because the Gardenlet itself occasionally changes the shoot specification, labels or annotations, and might violate the quota if the existing resource is already close to the quota boundary.
Also, operators are supposed to be trusted users and subjecting them to a size limitation can inhibit important operational tasks.
Wildcard (&amp;quot;*&amp;quot;) in subject &lt;code>name&lt;/code> is supported.&lt;/p>
&lt;p>Size limitations depend on the individual Gardener setup and choosing the wrong values can affect the availability of your Gardener service.
&lt;code>resourceAdmissionConfiguration.operationMode&lt;/code> allows to control if a violating request is actually denied (default) or only logged.
It&amp;rsquo;s recommended to start with &lt;code>log&lt;/code>, check the logs for exceeding requests, adjust the limits if necessary and finally switch to &lt;code>block&lt;/code>.&lt;/p>
&lt;h3 id="seedrestriction">SeedRestriction&lt;/h3>
&lt;p>Please refer to &lt;a href="https://gardener.cloud/docs/gardener/deployment/gardenlet_api_access/">this document&lt;/a> for more information.&lt;/p>
&lt;h2 id="authorization-webhook-handlers">Authorization Webhook Handlers&lt;/h2>
&lt;p>This section describes the authorization webhook handlers that are currently served.&lt;/p>
&lt;h3 id="seedauthorization">SeedAuthorization&lt;/h3>
&lt;p>Please refer to &lt;a href="https://gardener.cloud/docs/gardener/deployment/gardenlet_api_access/">this document&lt;/a> for more information.&lt;/p></description></item><item><title>Docs: Alerting</title><link>https://gardener.cloud/docs/gardener/monitoring/alerting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/monitoring/alerting/</guid><description>
&lt;h1 id="alerting">Alerting&lt;/h1>
&lt;p>Gardener uses &lt;a href="https://prometheus.io/">Prometheus&lt;/a> to gather metrics from each component. A Prometheus is deployed in each shoot control plane (on the seed) which is responsible for gathering control plane and cluster metrics. Prometheus can be configured to fire alerts based on these metrics and send them to an &lt;a href="https://prometheus.io/docs/alerting/alertmanager/">alertmanager&lt;/a>. The alertmanager is responsible for sending the alerts to users and operators. This document describes how to setup alerting for:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#Alerting-for-Users">end-users/stakeholders/customers&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Alerting-for-Operators">operators/administrators&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="alerting-for-users">Alerting for Users&lt;/h1>
&lt;p>To receive email alerts as a user set the following values in the shoot spec:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> monitoring:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> alerting:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> emailReceivers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - john.doe@example.com
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>emailReceivers&lt;/code> is a list of emails that will receive alerts if something is wrong with the shoot cluster. A list of alerts for users can be found &lt;a href="https://gardener.cloud/docs/gardener/monitoring/user_alerts/">here&lt;/a>.&lt;/p>
&lt;h1 id="alerting-for-operators">Alerting for Operators&lt;/h1>
&lt;p>Currently, Gardener supports two options for alerting:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#Email-Alerting">Email Alerting&lt;/a>&lt;/li>
&lt;li>&lt;a href="#External-Alertmanager">Sending Alerts to an external alertmanager&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>A list of operator alerts can be found &lt;a href="https://gardener.cloud/docs/gardener/monitoring/operator_alerts/">here&lt;/a>.&lt;/p>
&lt;h2 id="email-alerting">Email Alerting&lt;/h2>
&lt;p>Gardener provides the option to deploy an alertmanager into each seed. This alertmanager is responsible for sending out alerts to operators for each shoot cluster in the seed. Only email alerts are supported by the alertmanager managed by Gardener. This is configurable by setting the Gardener controller manager configuration values &lt;code>alerting&lt;/code>. See &lt;a href="https://gardener.cloud/docs/gardener/usage/configuration/">this&lt;/a> on how to configure the Gardener&amp;rsquo;s SMTP secret. If the values are set, a secret with the label &lt;code>gardener.cloud/role: alerting&lt;/code> will be created in the garden namespace of the garden cluster. This secret will be used by each alertmanager in each seed.&lt;/p>
&lt;h2 id="external-alertmanager">External Alertmanager&lt;/h2>
&lt;p>The alertmanager supports different kinds of &lt;a href="https://prometheus.io/docs/alerting/configuration/">alerting configurations&lt;/a>. The alertmanager provided by Gardener only supports email alerts. If email is not sufficient, then alerts can be sent to an external alertmanager. Prometheus will send alerts to a URL and then alerts will be handled by the external alertmanager. This external alertmanager is operated and configured by the operator (i.e. Gardener does not configure or deploy this alertmanager). To configure sending alerts to an external alertmanager, create a secret in the virtual garden cluster in the garden namespace with the label: &lt;code>gardener.cloud/role: alerting&lt;/code>. This secret needs to contain a URL to the external alertmanager and information regarding authentication. Supported authentication types are:&lt;/p>
&lt;ul>
&lt;li>No Authentication (none)&lt;/li>
&lt;li>Basic Authentication (basic)&lt;/li>
&lt;li>Mutual TLS (certificate)&lt;/li>
&lt;/ul>
&lt;h3 id="remote-alertmanager-examples">Remote Alertmanager Examples&lt;/h3>
&lt;p>Note: the &lt;code>url&lt;/code> value cannot be prepended with &lt;code>http&lt;/code> or &lt;code>https&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># No Authentication&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gardener.cloud/role: alerting
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: alerting-auth
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># No Authentication&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_type: base64(none)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> url: base64(external.alertmanager.foo)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Basic Auth&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_type: base64(basic)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> url: base64(extenal.alertmanager.foo)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> username: base64(admin)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> password: base64(password)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Mutual TLS&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_type: base64(certificate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> url: base64(external.alertmanager.foo)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ca.crt: base64(ca)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tls.crt: base64(certificate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tls.key: base64(key)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> insecure_skip_verify: base64(false)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Email Alerts (internal alertmanager)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_type: base64(smtp)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_identity: base64(internal.alertmanager.auth_identity)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_password: base64(internal.alertmanager.auth_password)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_username: base64(internal.alertmanager.auth_username)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> from: base64(internal.alertmanager.from)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> smarthost: base64(internal.alertmanager.smarthost)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> to: base64(internal.alertmanager.to)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>type: Opaque
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="configuring-your-external-alertmanager">Configuring your External Alertmanager&lt;/h3>
&lt;p>Please refer to the &lt;a href="https://prometheus.io/docs/alerting/alertmanager/">alertmanager&lt;/a> documentation on how to configure an alertmanager.&lt;/p>
&lt;p>We recommend you use at least the following inhibition rules in your alertmanager configuration to prevent excessive alerts:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>inhibit_rules:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Apply inhibition if the alert name is the same.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: critical
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: warning
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;alertname&amp;#39;&lt;/span>, &lt;span style="color:#a31515">&amp;#39;service&amp;#39;&lt;/span>, &lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Stop all alerts for type=shoot if there are VPN problems.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: vpn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;type&amp;#39;&lt;/span>, &lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Stop warning and critical alerts if there is a blocker&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: blocker
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: ^(critical|warning)$
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># If the API server is down inhibit no worker nodes alert. No worker nodes depends on kube-state-metrics which depends on the API server.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: kube-apiserver
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: nodes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># If API server is down inhibit kube-state-metrics alerts.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: kube-apiserver
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: info
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># No Worker nodes depends on kube-state-metrics. Inhibit no worker nodes if kube-state-metrics is down.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: kube-state-metrics-shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: nodes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Below is a graph visualizing the inhibition rules:&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/alertInhibitionGraph_ceaef0.png" alt="inhibitionGraph">&lt;/p></description></item><item><title>Docs: API Server</title><link>https://gardener.cloud/docs/gardener/concepts/apiserver/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/concepts/apiserver/</guid><description>
&lt;h1 id="gardener-api-server">Gardener API server&lt;/h1>
&lt;p>The Gardener API server is a Kubernetes-native extension based on its &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/">aggregation layer&lt;/a>.
It is registered via an &lt;code>APIService&lt;/code> object and designed to run inside a Kubernetes cluster whose API it wants to extend.&lt;/p>
&lt;p>After registration, it exposes the following resources:&lt;/p>
&lt;h2 id="cloudprofiles">&lt;code>CloudProfile&lt;/code>s&lt;/h2>
&lt;p>&lt;code>CloudProfile&lt;/code>s are resources that describe a specific environment of an underlying infrastructure provider, e.g. AWS, Azure, etc.
Each shoot has to reference a &lt;code>CloudProfile&lt;/code> to declare the environment it should be created in.
In a &lt;code>CloudProfile&lt;/code> the gardener operator specifies certain constraints like available machine types, regions, which Kubernetes versions they want to offer, etc.
End-users can read &lt;code>CloudProfile&lt;/code>s to see these values, but only operators can change the content or create/delete them.
When a shoot is created or updated then an admission plugin checks that only values are used that are allowed via the referenced &lt;code>CloudProfile&lt;/code>.&lt;/p>
&lt;p>Additionally, a &lt;code>CloudProfile&lt;/code> may contain a &lt;code>providerConfig&lt;/code> which is a special configuration dedicated for the infrastructure provider.
Gardener does not evaluate or understand this config, but extension controllers might need for declaration of provider-specific constraints, or global settings.&lt;/p>
&lt;p>Please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/30-cloudprofile.yaml">this&lt;/a> example manifest and consult the documentation of your provider extension controller to get information about its &lt;code>providerConfig&lt;/code>.&lt;/p>
&lt;h2 id="seeds">&lt;code>Seed&lt;/code>s&lt;/h2>
&lt;p>&lt;code>Seed&lt;/code>s are resources that represent seed clusters.
Gardener does not care about how a seed cluster got created - the only requirement is that it is of at least Kubernetes v1.17 and passes the Kubernetes conformance tests.
The Gardener operator has to either deploy the Gardenlet into the cluster they want to use as seed (recommended, then the Gardenlet will create the &lt;code>Seed&lt;/code> object itself after bootstrapping), or they provide the kubeconfig to the cluster inside a secret (that is referenced by the &lt;code>Seed&lt;/code> resource) and create the &lt;code>Seed&lt;/code> resource themselves.&lt;/p>
&lt;p>Please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/45-secret-seed-backup.yaml">this&lt;/a>, &lt;a href="https://github.com/gardener/gardener/blob/master/example/50-seed.yaml">this&lt;/a>(, and optionally &lt;a href="https://github.com/gardener/gardener/blob/master/example/40-secret-seed.yaml">this&lt;/a>) example manifests.&lt;/p>
&lt;h2 id="shootquotas">Shoot&lt;code>Quota&lt;/code>s&lt;/h2>
&lt;p>In order to allow end-users not having their own dedicated infrastructure account to try out Gardener the operator can register an account owned by them that they allow to be used for trial clusters.
Trial clusters can be put under quota such that they don&amp;rsquo;t consume too many resources (resulting in costs), and so that one user cannot consume all resources on their own.
These clusters are automatically terminated after a specified time, but end-users may extend the lifetime manually if needed.&lt;/p>
&lt;p>Please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/60-quota.yaml">this&lt;/a> example manifest.&lt;/p>
&lt;h2 id="projects">&lt;code>Project&lt;/code>s&lt;/h2>
&lt;p>The first thing before creating a shoot cluster is to create a &lt;code>Project&lt;/code>.
A project is used to group multiple shoot clusters together.
End-users can invite colleagues to the project to enable collaboration, and they can either make them &lt;code>admin&lt;/code> or &lt;code>viewer&lt;/code>.
After an end-user has created a project they will get a dedicated namespace in the garden cluster for all their shoots.&lt;/p>
&lt;p>Please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/05-project-dev.yaml">this&lt;/a> example manifest.&lt;/p>
&lt;h2 id="secretbindings">&lt;code>SecretBinding&lt;/code>s&lt;/h2>
&lt;p>Now that the end-user has a namespace the next step is registering their infrastructure provider account.&lt;/p>
&lt;p>Please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/70-secret-provider.yaml">this&lt;/a> example manifest and consult the documentation of the extension controller for the respective infrastructure provider to get information about which keys are required in this secret.&lt;/p>
&lt;p>After the secret has been created the end-user has to create a special &lt;code>SecretBinding&lt;/code> resource that binds this secret.
Later when creating shoot clusters they will reference such a binding.&lt;/p>
&lt;p>Please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/80-secretbinding.yaml">this&lt;/a> example manifest.&lt;/p>
&lt;h2 id="shoots">&lt;code>Shoot&lt;/code>s&lt;/h2>
&lt;p>Shoot cluster contain various settings that influence how end-user Kubernetes clusters will look like in the end.
As Gardener heavily relies on extension controllers for operating system configuration, networking, and infrastructure specifics, the end-user has the possibility (and responsibility) to provide these provider-specific configurations as well.
Such configurations are not evaluated by Gardener (because it doesn&amp;rsquo;t know/understand them), but they are only transported to the respective extension controller.&lt;/p>
&lt;p>⚠️ This means that any configuration issues/mistake on the end-user side that relates to a provider-specific flag or setting cannot be caught during the update request itself but only later during the reconciliation (unless a validator webhook has been registered in the garden cluster by an operator).&lt;/p>
&lt;p>Please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/90-shoot.yaml">this&lt;/a> example manifest and consult the documentation of the provider extension controller to get information about its &lt;code>spec.provider.controlPlaneConfig&lt;/code>, &lt;code>.spec.provider.infrastructureConfig&lt;/code>, and &lt;code>.spec.provider.workers[].providerConfig&lt;/code>.&lt;/p>
&lt;h2 id="clusteropenidconnectpresets">&lt;code>(Cluster)OpenIDConnectPreset&lt;/code>s&lt;/h2>
&lt;p>Please see &lt;a href="https://gardener.cloud/docs/gardener/usage/openidconnect-presets/">this&lt;/a> separate documentation file.&lt;/p>
&lt;h2 id="overview-data-model">Overview Data Model&lt;/h2>
&lt;p>&lt;img src="https://gardener.cloud/__resources/gardener-data-model-overview_c5b559.png" alt="Gardener Overview Data Model">&lt;/p></description></item><item><title>Docs: APIs</title><link>https://gardener.cloud/docs/other-components/machine-controller-manager/docs/documents/apis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/machine-controller-manager/docs/documents/apis/</guid><description>
&lt;h2 id="specification">Specification&lt;/h2>
&lt;h3 id="providerspec-schema">ProviderSpec Schema&lt;/h3>
&lt;br>
&lt;h3 id="AWSMachineClass">
&lt;b>AWSMachineClass&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>AWSMachineClass TODO&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>
machine.sapcloud.io.v1alpha1
&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>AWSMachineClass&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AWSMachineClassSpec">
AWSMachineClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>ami&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>region&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>blockDevices&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AWSBlockDeviceMappingSpec">
[]AWSBlockDeviceMappingSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>ebsOptimized&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>iam&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AWSIAMProfileSpec">
AWSIAMProfileSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>keyName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>monitoring&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>networkInterfaces&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AWSNetworkInterfaceSpec">
[]AWSNetworkInterfaceSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spotPrice&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AlicloudMachineClass">
&lt;b>AlicloudMachineClass&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>AlicloudMachineClass TODO&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>
machine.sapcloud.io.v1alpha1
&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>AlicloudMachineClass&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AlicloudMachineClassSpec">
AlicloudMachineClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>imageID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>instanceType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>region&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>zoneID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>securityGroupID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>vSwitchID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>privateIPAddress&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>systemDisk&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AlicloudSystemDisk">
AlicloudSystemDisk
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>dataDisks&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AlicloudDataDisk">
[]AlicloudDataDisk
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>instanceChargeType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>internetChargeType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>internetMaxBandwidthIn&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>internetMaxBandwidthOut&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spotStrategy&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>IoOptimized&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>keyPairName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureMachineClass">
&lt;b>AzureMachineClass&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>AzureMachineClass TODO&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>
machine.sapcloud.io.v1alpha1
&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>AzureMachineClass&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureMachineClassSpec">
AzureMachineClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>location&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>properties&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureVirtualMachineProperties">
AzureVirtualMachineProperties
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>resourceGroup&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>subnetInfo&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureSubnetInfo">
AzureSubnetInfo
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="GCPMachineClass">
&lt;b>GCPMachineClass&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>GCPMachineClass TODO&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>
machine.sapcloud.io.v1alpha1
&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>GCPMachineClass&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#GCPMachineClassSpec">
GCPMachineClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>canIpForward&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>deletionProtection&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>description&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>disks&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#%2agithub.com%2fgardener%2fmachine-controller-manager%2fpkg%2fapis%2fmachine%2fv1alpha1.GCPDisk">
[]*github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1.GCPDisk
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>labels&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#%2agithub.com%2fgardener%2fmachine-controller-manager%2fpkg%2fapis%2fmachine%2fv1alpha1.GCPMetadata">
[]*github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1.GCPMetadata
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>networkInterfaces&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#%2agithub.com%2fgardener%2fmachine-controller-manager%2fpkg%2fapis%2fmachine%2fv1alpha1.GCPNetworkInterface">
[]*github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1.GCPNetworkInterface
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>scheduling&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#GCPScheduling">
GCPScheduling
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>serviceAccounts&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#GCPServiceAccount">
[]GCPServiceAccount
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>region&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>zone&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="Machine">
&lt;b>Machine&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>Machine is the representation of a physical or virtual machine.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>
machine.sapcloud.io.v1alpha1
&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>Machine&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>ObjectMeta for machine object&lt;/p>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineSpec">
MachineSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Spec contains the specification of the machine&lt;/p>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>class&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#ClassSpec">
ClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Class contains the machineclass attributes of a machine&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>providerID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ProviderID represents the provider&amp;rsquo;s unique ID given to a machine&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>nodeTemplate&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#NodeTemplateSpec">
NodeTemplateSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>NodeTemplateSpec describes the data a node should have when created from a template&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>MachineConfiguration&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineConfiguration">
MachineConfiguration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>
(Members of &lt;code>MachineConfiguration&lt;/code> are embedded into this type.)
&lt;/p>
&lt;em>(Optional)&lt;/em>
&lt;p>Configuration for the machine-controller.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineStatus">
MachineStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Status contains fields depicting the status&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineClass">
&lt;b>MachineClass&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>MachineClass can be used to templatize and re-use provider configuration
across multiple Machines / MachineSets / MachineDeployments.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>
machine.sapcloud.io.v1alpha1
&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>MachineClass&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>nodeTemplate&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#NodeTemplate">
NodeTemplate
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>NodeTemplate contains subfields to track all node resources and other node info required to scale nodegroup from zero&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>CredentialsSecretRef can optionally store the credentials (in this case the SecretRef does not need to store them).
This might be useful if multiple machine classes with the same credentials but different user-datas are used.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>providerSpec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fgodoc.org%2fk8s.io%2fapimachinery%2fpkg%2fruntime%23RawExtension">
k8s.io/apimachinery/pkg/runtime.RawExtension
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Provider-specific configuration to use during node creation.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>provider&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Provider is the combination of name and location of cloud-specific drivers.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>SecretRef stores the necessary secrets such as credentials or userdata.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineSet">
&lt;b>MachineSet&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>MachineSet TODO&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>
machine.sapcloud.io.v1alpha1
&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>MachineSet&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineSetSpec">
MachineSetSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>replicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>selector&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23labelselector-v1-meta">
Kubernetes meta/v1.LabelSelector
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineClass&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#ClassSpec">
ClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>template&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineTemplateSpec">
MachineTemplateSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>minReadySeconds&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineSetStatus">
MachineSetStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="PacketMachineClass">
&lt;b>PacketMachineClass&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>PacketMachineClass TODO&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>
machine.sapcloud.io.v1alpha1
&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
string
&lt;/td>
&lt;td>
&lt;code>PacketMachineClass&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#PacketMachineClassSpec">
PacketMachineClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>facility&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>billingCycle&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>OS&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>projectID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>sshKeys&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>userdata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AWSBlockDeviceMappingSpec">
&lt;b>AWSBlockDeviceMappingSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AWSMachineClassSpec">AWSMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>deviceName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The device name exposed to the machine (for example, /dev/sdh or xvdh).&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>ebs&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AWSEbsBlockDeviceSpec">
AWSEbsBlockDeviceSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Parameters used to automatically set up EBS volumes when the machine is
launched.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>noDevice&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Suppresses the specified device included in the block device mapping of the
AMI.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>virtualName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The virtual device name (ephemeralN). Machine store volumes are numbered
starting from 0. An machine type with 2 available machine store volumes
can specify mappings for ephemeral0 and ephemeral1.The number of available
machine store volumes depends on the machine type. After you connect to
the machine, you must mount the volume.&lt;/p>
&lt;p>Constraints: For M3 machines, you must specify machine store volumes in
the block device mapping for the machine. When you launch an M3 machine,
we ignore any machine store volumes specified in the block device mapping
for the AMI.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AWSEbsBlockDeviceSpec">
&lt;b>AWSEbsBlockDeviceSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AWSBlockDeviceMappingSpec">AWSBlockDeviceMappingSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>Describes a block device for an EBS volume.
Please also see &lt;a href="https://docs.aws.amazon.com/goto/WebAPI/ec2-2016-11-15/EbsBlockDevice">https://docs.aws.amazon.com/goto/WebAPI/ec2-2016-11-15/EbsBlockDevice&lt;/a>&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>deleteOnTermination&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Indicates whether the EBS volume is deleted on machine termination.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>encrypted&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Indicates whether the EBS volume is encrypted. Encrypted Amazon EBS volumes
may only be attached to machines that support Amazon EBS encryption.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>iops&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The number of I/O operations per second (IOPS) that the volume supports.
For io1, this represents the number of IOPS that are provisioned for the
volume. For gp2, this represents the baseline performance of the volume and
the rate at which the volume accumulates I/O credits for bursting. For more
information about General Purpose SSD baseline performance, I/O credits,
and bursting, see Amazon EBS Volume Types (&lt;a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html">http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html&lt;/a>)
in the Amazon Elastic Compute Cloud User Guide.&lt;/p>
&lt;p>Constraint: Range is 100-20000 IOPS for io1 volumes and 100-10000 IOPS for
gp2 volumes.&lt;/p>
&lt;p>Condition: This parameter is required for requests to create io1 volumes;
it is not used in requests to create gp2, st1, sc1, or standard volumes.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kmsKeyID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Identifier (key ID, key alias, ID ARN, or alias ARN) for a customer managed
CMK under which the EBS volume is encrypted.&lt;/p>
&lt;p>This parameter is only supported on BlockDeviceMapping objects called by
RunInstances (&lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RunInstances.html">https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RunInstances.html&lt;/a>),
RequestSpotFleet (&lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RequestSpotFleet.html">https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RequestSpotFleet.html&lt;/a>),
and RequestSpotInstances (&lt;a href="https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RequestSpotInstances.html">https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RequestSpotInstances.html&lt;/a>).&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>snapshotID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The ID of the snapshot.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>volumeSize&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The size of the volume, in GiB.&lt;/p>
&lt;p>Constraints: 1-16384 for General Purpose SSD (gp2), 4-16384 for Provisioned
IOPS SSD (io1), 500-16384 for Throughput Optimized HDD (st1), 500-16384 for
Cold HDD (sc1), and 1-1024 for Magnetic (standard) volumes. If you specify
a snapshot, the volume size must be equal to or larger than the snapshot
size.&lt;/p>
&lt;p>Default: If you&amp;rsquo;re creating the volume from a snapshot and don&amp;rsquo;t specify
a volume size, the default is the snapshot size.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>volumeType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The volume type: gp2, io1, st1, sc1, or standard.&lt;/p>
&lt;p>Default: standard&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AWSIAMProfileSpec">
&lt;b>AWSIAMProfileSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AWSMachineClassSpec">AWSMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>Describes an IAM machine profile.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>arn&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The Amazon Resource Name (ARN) of the machine profile.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>name&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The name of the machine profile.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AWSMachineClassSpec">
&lt;b>AWSMachineClassSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AWSMachineClass">AWSMachineClass&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AWSMachineClassSpec is the specification of a AWSMachineClass.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>ami&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>region&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>blockDevices&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AWSBlockDeviceMappingSpec">
[]AWSBlockDeviceMappingSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>ebsOptimized&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>iam&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AWSIAMProfileSpec">
AWSIAMProfileSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>keyName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>monitoring&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>networkInterfaces&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AWSNetworkInterfaceSpec">
[]AWSNetworkInterfaceSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spotPrice&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AWSNetworkInterfaceSpec">
&lt;b>AWSNetworkInterfaceSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AWSMachineClassSpec">AWSMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>Describes a network interface.
Please also see &lt;a href="https://docs.aws.amazon.com/goto/WebAPI/ec2-2016-11-15/MachineAWSNetworkInterfaceSpecification">https://docs.aws.amazon.com/goto/WebAPI/ec2-2016-11-15/MachineAWSNetworkInterfaceSpecification&lt;/a>&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>associatePublicIPAddress&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Indicates whether to assign a public IPv4 address to an machine you launch
in a VPC. The public IP address can only be assigned to a network interface
for eth0, and can only be assigned to a new network interface, not an existing
one. You cannot specify more than one network interface in the request. If
launching into a default subnet, the default value is true.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>deleteOnTermination&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>If set to true, the interface is deleted when the machine is terminated.
You can specify true only if creating a new network interface when launching
an machine.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>description&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The description of the network interface. Applies only if creating a network
interface when launching an machine.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>securityGroupIDs&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The IDs of the security groups for the network interface. Applies only if
creating a network interface when launching an machine.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>subnetID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The ID of the subnet associated with the network string. Applies only if
creating a network interface when launching an machine.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AlicloudDataDisk">
&lt;b>AlicloudDataDisk&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AlicloudMachineClassSpec">AlicloudMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>name&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>category&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>description&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>encrypted&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>deleteWithInstance&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>size&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AlicloudMachineClassSpec">
&lt;b>AlicloudMachineClassSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AlicloudMachineClass">AlicloudMachineClass&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AlicloudMachineClassSpec is the specification of a AlicloudMachineClass.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>imageID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>instanceType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>region&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>zoneID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>securityGroupID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>vSwitchID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>privateIPAddress&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>systemDisk&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AlicloudSystemDisk">
AlicloudSystemDisk
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>dataDisks&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AlicloudDataDisk">
[]AlicloudDataDisk
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>instanceChargeType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>internetChargeType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>internetMaxBandwidthIn&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>internetMaxBandwidthOut&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spotStrategy&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>IoOptimized&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>keyPairName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AlicloudSystemDisk">
&lt;b>AlicloudSystemDisk&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AlicloudMachineClassSpec">AlicloudMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AlicloudSystemDisk describes SystemDisk for Alicloud.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>category&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>size&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureDataDisk">
&lt;b>AzureDataDisk&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureStorageProfile">AzureStorageProfile&lt;/a>)
&lt;/p>
&lt;p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>name&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lun&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>caching&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>storageAccountType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>diskSizeGB&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureHardwareProfile">
&lt;b>AzureHardwareProfile&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureVirtualMachineProperties">AzureVirtualMachineProperties&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureHardwareProfile is specifies the hardware settings for the virtual machine.
Refer github.com/Azure/azure-sdk-for-go/arm/compute/models.go for VMSizes&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>vmSize&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureImageReference">
&lt;b>AzureImageReference&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureStorageProfile">AzureStorageProfile&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureImageReference is specifies information about the image to use. You can specify information about platform images,
marketplace images, or virtual machine images. This element is required when you want to use a platform image,
marketplace image, or virtual machine image, but is not used in other creation operations.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>id&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>urn&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Uniform Resource Name of the OS image to be used , it has the format &amp;lsquo;publisher:offer:sku:version&amp;rsquo;&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureLinuxConfiguration">
&lt;b>AzureLinuxConfiguration&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureOSProfile">AzureOSProfile&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureLinuxConfiguration is specifies the Linux operating system settings on the virtual machine. &lt;br>&lt;br>For a list of
supported Linux distributions, see &lt;a href="https://docs.microsoft.com/en-us/azure/virtual-machines/linux/endorsed-distros">Endorsed Linux distributions on Azure
Distributions&lt;/a>
&lt;br>&lt;br> For running non-endorsed distributions, see &lt;a href="https://docs.microsoft.com/en-us/azure/virtual-machines/linux/create-upload-generic">Information for community supported and non-endorsed distributions&lt;/a>.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>disablePasswordAuthentication&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>ssh&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureSSHConfiguration">
AzureSSHConfiguration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureMachineClassSpec">
&lt;b>AzureMachineClassSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureMachineClass">AzureMachineClass&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureMachineClassSpec is the specification of a AzureMachineClass.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>location&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>properties&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureVirtualMachineProperties">
AzureVirtualMachineProperties
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>resourceGroup&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>subnetInfo&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureSubnetInfo">
AzureSubnetInfo
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureMachineSetConfig">
&lt;b>AzureMachineSetConfig&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureVirtualMachineProperties">AzureVirtualMachineProperties&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureMachineSetConfig contains the information about the machine set&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>id&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureManagedDiskParameters">
&lt;b>AzureManagedDiskParameters&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureOSDisk">AzureOSDisk&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureManagedDiskParameters is the parameters of a managed disk.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>id&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>storageAccountType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureNetworkInterfaceReference">
&lt;b>AzureNetworkInterfaceReference&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureNetworkProfile">AzureNetworkProfile&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureNetworkInterfaceReference is describes a network interface reference.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>id&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>properties&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureNetworkInterfaceReferenceProperties">
AzureNetworkInterfaceReferenceProperties
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureNetworkInterfaceReferenceProperties">
&lt;b>AzureNetworkInterfaceReferenceProperties&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureNetworkInterfaceReference">AzureNetworkInterfaceReference&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureNetworkInterfaceReferenceProperties is describes a network interface reference properties.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>primary&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureNetworkProfile">
&lt;b>AzureNetworkProfile&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureVirtualMachineProperties">AzureVirtualMachineProperties&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureNetworkProfile is specifies the network interfaces of the virtual machine.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>networkInterfaces&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureNetworkInterfaceReference">
AzureNetworkInterfaceReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>acceleratedNetworking&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureOSDisk">
&lt;b>AzureOSDisk&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureStorageProfile">AzureStorageProfile&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureOSDisk specifies information about the operating system disk used by the virtual machine. &lt;br>&lt;br> For more
information about disks, see &lt;a href="https://docs.microsoft.com/en-us/azure/virtual-machines/managed-disks-overview">Introduction to Azure managed disks&lt;/a>.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>name&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>caching&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>managedDisk&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureManagedDiskParameters">
AzureManagedDiskParameters
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>diskSizeGB&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>createOption&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureOSProfile">
&lt;b>AzureOSProfile&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureVirtualMachineProperties">AzureVirtualMachineProperties&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureOSProfile is specifies the operating system settings for the virtual machine.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>computerName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>adminUsername&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>adminPassword&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>customData&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>linuxConfiguration&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureLinuxConfiguration">
AzureLinuxConfiguration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureSSHConfiguration">
&lt;b>AzureSSHConfiguration&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureLinuxConfiguration">AzureLinuxConfiguration&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureSSHConfiguration is SSH configuration for Linux based VMs running on Azure&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>publicKeys&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureSSHPublicKey">
AzureSSHPublicKey
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureSSHPublicKey">
&lt;b>AzureSSHPublicKey&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureSSHConfiguration">AzureSSHConfiguration&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureSSHPublicKey is contains information about SSH certificate public key and the path on the Linux VM where the public
key is placed.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>path&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>keyData&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureStorageProfile">
&lt;b>AzureStorageProfile&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureVirtualMachineProperties">AzureVirtualMachineProperties&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureStorageProfile is specifies the storage settings for the virtual machine disks.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>imageReference&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureImageReference">
AzureImageReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>osDisk&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureOSDisk">
AzureOSDisk
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>dataDisks&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureDataDisk">
[]AzureDataDisk
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureSubResource">
&lt;b>AzureSubResource&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureVirtualMachineProperties">AzureVirtualMachineProperties&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureSubResource is the Sub Resource definition.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>id&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureSubnetInfo">
&lt;b>AzureSubnetInfo&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureMachineClassSpec">AzureMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureSubnetInfo is the information containing the subnet details&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>vnetName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>vnetResourceGroup&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>subnetName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="AzureVirtualMachineProperties">
&lt;b>AzureVirtualMachineProperties&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#AzureMachineClassSpec">AzureMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AzureVirtualMachineProperties is describes the properties of a Virtual Machine.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>hardwareProfile&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureHardwareProfile">
AzureHardwareProfile
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>storageProfile&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureStorageProfile">
AzureStorageProfile
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>osProfile&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureOSProfile">
AzureOSProfile
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>networkProfile&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureNetworkProfile">
AzureNetworkProfile
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>availabilitySet&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureSubResource">
AzureSubResource
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>identityID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>zone&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineSet&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#AzureMachineSetConfig">
AzureMachineSetConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="ClassSpec">
&lt;b>ClassSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineSetSpec">MachineSetSpec&lt;/a>,
&lt;a href="#MachineSpec">MachineSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>ClassSpec is the class specification of machine&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiGroup&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>API group to which it belongs&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Kind for machine class&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>name&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Name of machine class&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="ConditionStatus">
&lt;b>ConditionStatus&lt;/b>
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeploymentCondition">MachineDeploymentCondition&lt;/a>,
&lt;a href="#MachineSetCondition">MachineSetCondition&lt;/a>)
&lt;/p>
&lt;p>
&lt;/p>
&lt;br>
&lt;h3 id="CurrentStatus">
&lt;b>CurrentStatus&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineStatus">MachineStatus&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>CurrentStatus contains information about the current status of Machine.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>phase&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachinePhase">
MachinePhase
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>timeoutActive&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastUpdateTime&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23time-v1-meta">
Kubernetes meta/v1.Time
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Last update time of current status&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="GCPDisk">
&lt;b>GCPDisk&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>GCPDisk describes disks for GCP.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>autoDelete&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>boot&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>sizeGb&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>type&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>interface&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>image&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>labels&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="GCPMachineClassSpec">
&lt;b>GCPMachineClassSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#GCPMachineClass">GCPMachineClass&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>GCPMachineClassSpec is the specification of a GCPMachineClass.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>canIpForward&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>deletionProtection&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>description&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>disks&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#%2agithub.com%2fgardener%2fmachine-controller-manager%2fpkg%2fapis%2fmachine%2fv1alpha1.GCPDisk">
[]*github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1.GCPDisk
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>labels&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#%2agithub.com%2fgardener%2fmachine-controller-manager%2fpkg%2fapis%2fmachine%2fv1alpha1.GCPMetadata">
[]*github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1.GCPMetadata
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>networkInterfaces&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#%2agithub.com%2fgardener%2fmachine-controller-manager%2fpkg%2fapis%2fmachine%2fv1alpha1.GCPNetworkInterface">
[]*github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1.GCPNetworkInterface
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>scheduling&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#GCPScheduling">
GCPScheduling
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>serviceAccounts&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#GCPServiceAccount">
[]GCPServiceAccount
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>region&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>zone&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="GCPMetadata">
&lt;b>GCPMetadata&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>GCPMetadata describes metadata for GCP.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>key&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>value&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="GCPNetworkInterface">
&lt;b>GCPNetworkInterface&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>GCPNetworkInterface describes network interfaces for GCP&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>disableExternalIP&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>network&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>subnetwork&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="GCPScheduling">
&lt;b>GCPScheduling&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#GCPMachineClassSpec">GCPMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>GCPScheduling describes scheduling configuration for GCP.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>automaticRestart&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>onHostMaintenance&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>preemptible&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="GCPServiceAccount">
&lt;b>GCPServiceAccount&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#GCPMachineClassSpec">GCPMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>GCPServiceAccount describes service accounts for GCP.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>email&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>scopes&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="LastOperation">
&lt;b>LastOperation&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineSetStatus">MachineSetStatus&lt;/a>,
&lt;a href="#MachineStatus">MachineStatus&lt;/a>,
&lt;a href="#MachineSummary">MachineSummary&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>LastOperation suggests the last operation performed on the object&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>description&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Description of the current operation&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastUpdateTime&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23time-v1-meta">
Kubernetes meta/v1.Time
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Last update time of current operation&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>state&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineState">
MachineState
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>State of operation&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>type&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineOperationType">
MachineOperationType
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Type of operation&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineConfiguration">
&lt;b>MachineConfiguration&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineSpec">MachineSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineConfiguration describes the configurations useful for the machine-controller.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>drainTimeout&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fgodoc.org%2fk8s.io%2fapimachinery%2fpkg%2fapis%2fmeta%2fv1%23Duration">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>MachineDraintimeout is the timeout after which machine is forcefully deleted.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>healthTimeout&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fgodoc.org%2fk8s.io%2fapimachinery%2fpkg%2fapis%2fmeta%2fv1%23Duration">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>MachineHealthTimeout is the timeout after which machine is declared unhealhty/failed.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>creationTimeout&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fgodoc.org%2fk8s.io%2fapimachinery%2fpkg%2fapis%2fmeta%2fv1%23Duration">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>MachineCreationTimeout is the timeout after which machinie creation is declared failed.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>maxEvictRetries&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>MaxEvictRetries is the number of retries that will be attempted while draining the node.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>nodeConditions&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>NodeConditions are the set of conditions if set to true for MachineHealthTimeOut, machine will be declared failed.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineDeployment">
&lt;b>MachineDeployment&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>Deployment enables declarative updates for machines and MachineSets.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Standard object metadata.&lt;/p>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineDeploymentSpec">
MachineDeploymentSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Specification of the desired behavior of the MachineDeployment.&lt;/p>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>replicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Number of desired machines. This is a pointer to distinguish between explicit
zero and not specified. Defaults to 0.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>selector&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23labelselector-v1-meta">
Kubernetes meta/v1.LabelSelector
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Label selector for machines. Existing MachineSets whose machines are
selected by this will be the ones affected by this MachineDeployment.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>template&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineTemplateSpec">
MachineTemplateSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Template describes the machines that will be created.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>strategy&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineDeploymentStrategy">
MachineDeploymentStrategy
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The MachineDeployment strategy to use to replace existing machines with new ones.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>minReadySeconds&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Minimum number of seconds for which a newly created machine should be ready
without any of its container crashing, for it to be considered available.
Defaults to 0 (machine will be considered available as soon as it is ready)&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>revisionHistoryLimit&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The number of old MachineSets to retain to allow rollback.
This is a pointer to distinguish between explicit zero and not specified.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>paused&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Indicates that the MachineDeployment is paused and will not be processed by the
MachineDeployment controller.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>rollbackTo&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#RollbackConfig">
RollbackConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>DEPRECATED.
The config this MachineDeployment is rolling back to. Will be cleared after rollback is done.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>progressDeadlineSeconds&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The maximum time in seconds for a MachineDeployment to make progress before it
is considered to be failed. The MachineDeployment controller will continue to
process failed MachineDeployments and a condition with a ProgressDeadlineExceeded
reason will be surfaced in the MachineDeployment status. Note that progress will
not be estimated during the time a MachineDeployment is paused. This is not set
by default.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineDeploymentStatus">
MachineDeploymentStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Most recently observed status of the MachineDeployment.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineDeploymentCondition">
&lt;b>MachineDeploymentCondition&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeploymentStatus">MachineDeploymentStatus&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineDeploymentCondition describes the state of a MachineDeployment at a certain point.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>type&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineDeploymentConditionType">
MachineDeploymentConditionType
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Type of MachineDeployment condition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#ConditionStatus">
ConditionStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Status of the condition, one of True, False, Unknown.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastUpdateTime&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23time-v1-meta">
Kubernetes meta/v1.Time
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The last time this condition was updated.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastTransitionTime&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23time-v1-meta">
Kubernetes meta/v1.Time
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Last time the condition transitioned from one status to another.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>reason&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The reason for the condition&amp;rsquo;s last transition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>message&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>A human readable message indicating details about the transition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineDeploymentConditionType">
&lt;b>MachineDeploymentConditionType&lt;/b>
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeploymentCondition">MachineDeploymentCondition&lt;/a>)
&lt;/p>
&lt;p>
&lt;/p>
&lt;br>
&lt;h3 id="MachineDeploymentSpec">
&lt;b>MachineDeploymentSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeployment">MachineDeployment&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineDeploymentSpec is the specification of the desired behavior of the MachineDeployment.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>replicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Number of desired machines. This is a pointer to distinguish between explicit
zero and not specified. Defaults to 0.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>selector&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23labelselector-v1-meta">
Kubernetes meta/v1.LabelSelector
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Label selector for machines. Existing MachineSets whose machines are
selected by this will be the ones affected by this MachineDeployment.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>template&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineTemplateSpec">
MachineTemplateSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Template describes the machines that will be created.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>strategy&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineDeploymentStrategy">
MachineDeploymentStrategy
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The MachineDeployment strategy to use to replace existing machines with new ones.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>minReadySeconds&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Minimum number of seconds for which a newly created machine should be ready
without any of its container crashing, for it to be considered available.
Defaults to 0 (machine will be considered available as soon as it is ready)&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>revisionHistoryLimit&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The number of old MachineSets to retain to allow rollback.
This is a pointer to distinguish between explicit zero and not specified.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>paused&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Indicates that the MachineDeployment is paused and will not be processed by the
MachineDeployment controller.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>rollbackTo&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#RollbackConfig">
RollbackConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>DEPRECATED.
The config this MachineDeployment is rolling back to. Will be cleared after rollback is done.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>progressDeadlineSeconds&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The maximum time in seconds for a MachineDeployment to make progress before it
is considered to be failed. The MachineDeployment controller will continue to
process failed MachineDeployments and a condition with a ProgressDeadlineExceeded
reason will be surfaced in the MachineDeployment status. Note that progress will
not be estimated during the time a MachineDeployment is paused. This is not set
by default.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineDeploymentStatus">
&lt;b>MachineDeploymentStatus&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeployment">MachineDeployment&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineDeploymentStatus is the most recently observed status of the MachineDeployment.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>observedGeneration&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The generation observed by the MachineDeployment controller.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>replicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Total number of non-terminated machines targeted by this MachineDeployment (their labels match the selector).&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>updatedReplicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Total number of non-terminated machines targeted by this MachineDeployment that have the desired template spec.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>readyReplicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Total number of ready machines targeted by this MachineDeployment.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>availableReplicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Total number of available machines (ready for at least minReadySeconds) targeted by this MachineDeployment.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>unavailableReplicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Total number of unavailable machines targeted by this MachineDeployment. This is the total number of
machines that are still required for the MachineDeployment to have 100% available capacity. They may
either be machines that are running but not yet available or machines that still have not been created.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>conditions&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineDeploymentCondition">
[]MachineDeploymentCondition
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Represents the latest available observations of a MachineDeployment&amp;rsquo;s current state.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>collisionCount&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Count of hash collisions for the MachineDeployment. The MachineDeployment controller uses this
field as a collision avoidance mechanism when it needs to create the name for the
newest MachineSet.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>failedMachines&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#%2agithub.com%2fgardener%2fmachine-controller-manager%2fpkg%2fapis%2fmachine%2fv1alpha1.MachineSummary">
[]*github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1.MachineSummary
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>FailedMachines has summary of machines on which lastOperation Failed&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineDeploymentStrategy">
&lt;b>MachineDeploymentStrategy&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeploymentSpec">MachineDeploymentSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineDeploymentStrategy describes how to replace existing machines with new ones.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>type&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineDeploymentStrategyType">
MachineDeploymentStrategyType
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Type of MachineDeployment. Can be &amp;ldquo;Recreate&amp;rdquo; or &amp;ldquo;RollingUpdate&amp;rdquo;. Default is RollingUpdate.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>rollingUpdate&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#RollingUpdateMachineDeployment">
RollingUpdateMachineDeployment
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Rolling update config params. Present only if MachineDeploymentStrategyType =&lt;/p>
&lt;h2>RollingUpdate.&lt;/h2>
&lt;p>TODO: Update this to follow our convention for oneOf, whatever we decide it
to be.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineDeploymentStrategyType">
&lt;b>MachineDeploymentStrategyType&lt;/b>
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeploymentStrategy">MachineDeploymentStrategy&lt;/a>)
&lt;/p>
&lt;p>
&lt;/p>
&lt;br>
&lt;h3 id="MachineOperationType">
&lt;b>MachineOperationType&lt;/b>
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#LastOperation">LastOperation&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineOperationType is a label for the operation performed on a machine object.&lt;/p>
&lt;/p>
&lt;br>
&lt;h3 id="MachinePhase">
&lt;b>MachinePhase&lt;/b>
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#CurrentStatus">CurrentStatus&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachinePhase is a label for the condition of a machines at the current time.&lt;/p>
&lt;/p>
&lt;br>
&lt;h3 id="MachineSetCondition">
&lt;b>MachineSetCondition&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineSetStatus">MachineSetStatus&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineSetCondition describes the state of a machine set at a certain point.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>type&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineSetConditionType">
MachineSetConditionType
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Type of machine set condition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#ConditionStatus">
ConditionStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Status of the condition, one of True, False, Unknown.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastTransitionTime&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23time-v1-meta">
Kubernetes meta/v1.Time
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The last time the condition transitioned from one status to another.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>reason&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The reason for the condition&amp;rsquo;s last transition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>message&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>A human readable message indicating details about the transition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineSetConditionType">
&lt;b>MachineSetConditionType&lt;/b>
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineSetCondition">MachineSetCondition&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineSetConditionType is the condition on machineset object&lt;/p>
&lt;/p>
&lt;br>
&lt;h3 id="MachineSetSpec">
&lt;b>MachineSetSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineSet">MachineSet&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineSetSpec is the specification of a MachineSet.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>replicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>selector&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23labelselector-v1-meta">
Kubernetes meta/v1.LabelSelector
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineClass&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#ClassSpec">
ClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>template&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineTemplateSpec">
MachineTemplateSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>minReadySeconds&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineSetStatus">
&lt;b>MachineSetStatus&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineSet">MachineSet&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineSetStatus holds the most recently observed status of MachineSet.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>replicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Replicas is the number of actual replicas.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>fullyLabeledReplicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The number of pods that have labels matching the labels of the pod template of the replicaset.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>readyReplicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The number of ready replicas for this replica set.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>availableReplicas&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The number of available replicas (ready for at least minReadySeconds) for this replica set.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>observedGeneration&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ObservedGeneration is the most recent generation observed by the controller.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineSetCondition&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineSetCondition">
[]MachineSetCondition
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Represents the latest available observations of a replica set&amp;rsquo;s current state.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastOperation&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#LastOperation">
LastOperation
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>LastOperation performed&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>failedMachines&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#%5b%5dgithub.com%2fgardener%2fmachine-controller-manager%2fpkg%2fapis%2fmachine%2fv1alpha1.MachineSummary">
[]github.com/gardener/machine-controller-manager/pkg/apis/machine/v1alpha1.MachineSummary
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>FailedMachines has summary of machines on which lastOperation Failed&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineSpec">
&lt;b>MachineSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#Machine">Machine&lt;/a>,
&lt;a href="#MachineTemplateSpec">MachineTemplateSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineSpec is the specification of a Machine.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>class&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#ClassSpec">
ClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Class contains the machineclass attributes of a machine&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>providerID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ProviderID represents the provider&amp;rsquo;s unique ID given to a machine&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>nodeTemplate&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#NodeTemplateSpec">
NodeTemplateSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>NodeTemplateSpec describes the data a node should have when created from a template&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>MachineConfiguration&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineConfiguration">
MachineConfiguration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>
(Members of &lt;code>MachineConfiguration&lt;/code> are embedded into this type.)
&lt;/p>
&lt;em>(Optional)&lt;/em>
&lt;p>Configuration for the machine-controller.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineState">
&lt;b>MachineState&lt;/b>
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#LastOperation">LastOperation&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineState is a current state of the machine.&lt;/p>
&lt;/p>
&lt;br>
&lt;h3 id="MachineStatus">
&lt;b>MachineStatus&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#Machine">Machine&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineStatus holds the most recently observed status of Machine.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>node&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Node string&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>conditions&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23nodecondition-v1-core">
[]Kubernetes core/v1.NodeCondition
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Conditions of this machine, same as node&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastOperation&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#LastOperation">
LastOperation
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Last operation refers to the status of the last operation performed&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>currentStatus&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#CurrentStatus">
CurrentStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Current status of the machine object&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastKnownState&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>LastKnownState can store details of the last known state of the VM by the plugins.
It can be used by future operation calls to determine current infrastucture state&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineSummary">
&lt;b>MachineSummary&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>MachineSummary store the summary of machine.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>name&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Name of the machine object&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>providerID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>ProviderID represents the provider&amp;rsquo;s unique ID given to a machine&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastOperation&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#LastOperation">
LastOperation
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Last operation refers to the status of the last operation performed&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>ownerRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>OwnerRef&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="MachineTemplateSpec">
&lt;b>MachineTemplateSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeploymentSpec">MachineDeploymentSpec&lt;/a>,
&lt;a href="#MachineSetSpec">MachineSetSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MachineTemplateSpec describes the data a machine should have when created from a template&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Standard object&amp;rsquo;s metadata.
More info: &lt;a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata
">API Conventions - Metadata&lt;/a>&lt;/p>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineSpec">
MachineSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Specification of the desired behavior of the machine.
More info: &lt;a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#spec-and-status">API Conventions - Spec and Status&lt;/a>&lt;/p>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>class&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#ClassSpec">
ClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Class contains the machineclass attributes of a machine&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>providerID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ProviderID represents the provider&amp;rsquo;s unique ID given to a machine&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>nodeTemplate&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#NodeTemplateSpec">
NodeTemplateSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>NodeTemplateSpec describes the data a node should have when created from a template&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>MachineConfiguration&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#MachineConfiguration">
MachineConfiguration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>
(Members of &lt;code>MachineConfiguration&lt;/code> are embedded into this type.)
&lt;/p>
&lt;em>(Optional)&lt;/em>
&lt;p>Configuration for the machine-controller.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="NodeTemplate">
&lt;b>NodeTemplate&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineClass">MachineClass&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>NodeTemplate contains subfields to track all node resources and other node info required to scale nodegroup from zero&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>capacity&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23resourcelist-v1-core">
Kubernetes core/v1.ResourceList
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Capacity contains subfields to track all node resources required to scale nodegroup from zero&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>instanceType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Instance type of the node belonging to nodeGroup&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>region&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Region of the expected node belonging to nodeGroup&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>zone&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Zone of the expected node belonging to nodeGroup&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="NodeTemplateSpec">
&lt;b>NodeTemplateSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineSpec">MachineSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>NodeTemplateSpec describes the data a node should have when created from a template&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23nodespec-v1-core">
Kubernetes core/v1.NodeSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>NodeSpec describes the attributes that a node is created with.&lt;/p>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>podCIDR&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>PodCIDR represents the pod IP range assigned to the node.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>podCIDRs&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>podCIDRs represents the IP ranges assigned to the node for usage by Pods on that node. If this
field is specified, the 0th entry must match the podCIDR field. It may contain at most 1 value for
each of IPv4 and IPv6.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>providerID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ID of the node assigned by the cloud provider in the format: &lt;ProviderName>://&lt;ProviderSpecificNodeID>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>unschedulable&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Unschedulable controls node schedulability of new pods. By default, node is schedulable.
More info: &lt;a href="https://kubernetes.io/docs/concepts/nodes/node/#manual-node-administration">https://kubernetes.io/docs/concepts/nodes/node/#manual-node-administration&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>taints&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23taint-v1-core">
[]Kubernetes core/v1.Taint
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>If specified, the node&amp;rsquo;s taints.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>configSource&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23nodeconfigsource-v1-core">
Kubernetes core/v1.NodeConfigSource
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Deprecated. If specified, the source of the node&amp;rsquo;s configuration.
The DynamicKubeletConfig feature gate must be enabled for the Kubelet to use this field.
This field is deprecated as of 1.22: &lt;a href="https://git.k8s.io/enhancements/keps/sig-node/281-dynamic-kubelet-configuration">https://git.k8s.io/enhancements/keps/sig-node/281-dynamic-kubelet-configuration&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>externalID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Deprecated. Not all kubelets will set this field. Remove field after 1.13.
see: &lt;a href="https://issues.k8s.io/61966">https://issues.k8s.io/61966&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="OpenStackMachineClass">
&lt;b>OpenStackMachineClass&lt;/b>
&lt;/h3>
&lt;p>
&lt;p>OpenStackMachineClass TODO&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#OpenStackMachineClassSpec">
OpenStackMachineClassSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>imageID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>imageName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>region&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>availabilityZone&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>flavorName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>keyName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>securityGroups&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>networkID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>networks&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#OpenStackNetwork">
[]OpenStackNetwork
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>subnetID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>podNetworkCidr&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>rootDiskSize&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>useConfigDrive&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>in GB&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>serverGroupID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="OpenStackMachineClassSpec">
&lt;b>OpenStackMachineClassSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#OpenStackMachineClass">OpenStackMachineClass&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>OpenStackMachineClassSpec is the specification of a OpenStackMachineClass.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>imageID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>imageName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>region&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>availabilityZone&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>flavorName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>keyName&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>securityGroups&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>networkID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>networks&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#OpenStackNetwork">
[]OpenStackNetwork
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>subnetID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>podNetworkCidr&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>rootDiskSize&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>useConfigDrive&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>in GB&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>serverGroupID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
*string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="OpenStackNetwork">
&lt;b>OpenStackNetwork&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#OpenStackMachineClassSpec">OpenStackMachineClassSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>id&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>name&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>takes priority before name&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>podNetwork&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="PacketMachineClassSpec">
&lt;b>PacketMachineClassSpec&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#PacketMachineClass">PacketMachineClass&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>PacketMachineClassSpec is the specification of a PacketMachineClass.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>facility&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>machineType&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>billingCycle&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>OS&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>projectID&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tags&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>sshKeys&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
[]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>userdata&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>credentialsSecretRef&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fkubernetes.io%2fdocs%2freference%2fgenerated%2fkubernetes-api%2fv1.19%2f%23secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="RollbackConfig">
&lt;b>RollbackConfig&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeploymentSpec">MachineDeploymentSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>revision&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The revision to rollback to. If set to 0, rollback to the last revision.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;br>
&lt;h3 id="RollingUpdateMachineDeployment">
&lt;b>RollingUpdateMachineDeployment&lt;/b>
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#MachineDeploymentStrategy">MachineDeploymentStrategy&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>Spec to control the desired behavior of rolling update.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>maxUnavailable&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fgodoc.org%2fk8s.io%2fapimachinery%2fpkg%2futil%2fintstr%23IntOrString">
k8s.io/apimachinery/pkg/util/intstr.IntOrString
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The maximum number of machines that can be unavailable during the update.
Value can be an absolute number (ex: 5) or a percentage of desired machines (ex: 10%).
Absolute number is calculated from percentage by rounding down.
This can not be 0 if MaxSurge is 0.
By default, a fixed value of 1 is used.
Example: when this is set to 30%, the old MC can be scaled down to 70% of desired machines
immediately when the rolling update starts. Once new machines are ready, old MC
can be scaled down further, followed by scaling up the new MC, ensuring
that the total number of machines available at all times during the update is at
least 70% of desired machines.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>maxSurge&lt;/code>
&lt;/td>
&lt;td>
&lt;em>
&lt;a href="#https%3a%2f%2fgodoc.org%2fk8s.io%2fapimachinery%2fpkg%2futil%2fintstr%23IntOrString">
k8s.io/apimachinery/pkg/util/intstr.IntOrString
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>The maximum number of machines that can be scheduled above the desired number of
machines.
Value can be an absolute number (ex: 5) or a percentage of desired machines (ex: 10%).
This can not be 0 if MaxUnavailable is 0.
Absolute number is calculated from percentage by rounding up.
By default, a value of 1 is used.
Example: when this is set to 30%, the new MC can be scaled up immediately when
the rolling update starts, such that the total number of old and new machines do not exceed
130% of desired machines. Once old machines have been killed,
new MC can be scaled up further, ensuring that total number of machines running
at any time during the update is atmost 130% of desired machines.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr/>
&lt;p>&lt;em>
Generated with &lt;a href="https://github.com/ahmetb/gen-crd-api-reference-docs">gen-crd-api-reference-docs&lt;/a>
&lt;/em>&lt;/p></description></item><item><title>Docs: APIServer Admission Plugins</title><link>https://gardener.cloud/docs/gardener/concepts/apiserver_admission_plugins/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/concepts/apiserver_admission_plugins/</guid><description>
&lt;h1 id="admission-plugins">Admission Plugins&lt;/h1>
&lt;p>Similar to the kube-apiserver, the gardener-apiserver comes with a few in-tree managed admission plugins.
If you want to get an overview of the what and why of admission plugins then &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/">this document&lt;/a> might be a good start.&lt;/p>
&lt;p>This document lists all existing admission plugins with a short explanation of what it is responsible for.&lt;/p>
&lt;h2 id="clusteropenidconnectpreset-openidconnectpreset">&lt;code>ClusterOpenIDConnectPreset&lt;/code>, &lt;code>OpenIDConnectPreset&lt;/code>&lt;/h2>
&lt;p>&lt;em>(both enabled by default)&lt;/em>&lt;/p>
&lt;p>These admission controllers react on &lt;code>CREATE&lt;/code> operations for &lt;code>Shoot&lt;/code>s.
If the &lt;code>Shoot&lt;/code> does not specify any OIDC configuration (&lt;code>.spec.kubernetes.kubeAPIServer.oidcConfig=nil&lt;/code>) then it tries to find a matching &lt;code>ClusterOpenIDConnectPreset&lt;/code> or &lt;code>OpenIDConnectPreset&lt;/code>, respectively.
If there are multiples that match then the one with the highest weight &amp;ldquo;wins&amp;rdquo;.
In this case, the admission controller will default the OIDC configuration in the &lt;code>Shoot&lt;/code>.&lt;/p>
&lt;h2 id="controllerregistrationresources">&lt;code>ControllerRegistrationResources&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>ControllerRegistration&lt;/code>s.
It validates that there exists only one &lt;code>ControllerRegistration&lt;/code> in the system that is primarily responsible for a given kind/type resource combination.
This prevents misconfiguration by the Gardener administrator/operator.&lt;/p>
&lt;h2 id="customverbauthorizer">&lt;code>CustomVerbAuthorizer&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>Project&lt;/code>s.
It validates whether the user is bound to a RBAC role with the &lt;code>modify-spec-tolerations-whitelist&lt;/code> verb in case the user tries to change the &lt;code>.spec.tolerations.whitelist&lt;/code> field of the respective &lt;code>Project&lt;/code> resource.
Usually, regular project members are not bound to this custom verb, allowing the Gardener administrator to manage certain toleration whitelists on &lt;code>Project&lt;/code> basis.&lt;/p>
&lt;h2 id="deletionconfirmation">&lt;code>DeletionConfirmation&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>DELETE&lt;/code> operations for &lt;code>Project&lt;/code>s and &lt;code>Shoot&lt;/code>s and &lt;code>ShootState&lt;/code>s.
It validates that the respective resource is annotated with a deletion confirmation annotation, namely &lt;code>confirmation.gardener.cloud/deletion=true&lt;/code>.
Only if this annotation is present it allows the &lt;code>DELETE&lt;/code> operation to pass.
This prevents users from accidental/undesired deletions.&lt;/p>
&lt;h2 id="exposureclass">&lt;code>ExposureClass&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>Create&lt;/code> operations for &lt;code>Shoots&lt;/code>s.
It mutates &lt;code>Shoot&lt;/code> resources which has an &lt;code>ExposureClass&lt;/code> referenced by merging their both &lt;code>shootSelectors&lt;/code> and/or &lt;code>tolerations&lt;/code> into the &lt;code>Shoot&lt;/code> resource.&lt;/p>
&lt;h2 id="extensionvalidator">&lt;code>ExtensionValidator&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>BackupEntry&lt;/code>s, &lt;code>BackupBucket&lt;/code>s, &lt;code>Seed&lt;/code>s, and &lt;code>Shoot&lt;/code>s.
For all the various extension types in the specifications of these objects, it validates whether there exists a &lt;code>ControllerRegistration&lt;/code> in the system that is primarily responsible for the stated extension type(s).
This prevents misconfigurations that would otherwise allow users to create such resources with extension types that don&amp;rsquo;t exist in the cluster, effectively leading to failing reconciliation loops.&lt;/p>
&lt;h2 id="extensionlabels">&lt;code>ExtensionLabels&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>BackupBucket&lt;/code>s, &lt;code>BackupEntry&lt;/code>s, &lt;code>CloudProfile&lt;/code>s, &lt;code>Seed&lt;/code>s, &lt;code>SecretBinding&lt;/code>s and &lt;code>Shoot&lt;/code>s. For all the various extension types in the specifications of these objects, it adds a corresponding label in the resource. This would allow extension admission webhooks to filter out the resources they are responsible for and ignore all others. This label is of the form &lt;code>&amp;lt;extension-type&amp;gt;.extensions.gardener.cloud/&amp;lt;extension-name&amp;gt; : &amp;quot;true&amp;quot;&lt;/code>. For example, an extension label for provider extension type &lt;code>aws&lt;/code>, looks like &lt;code>provider.extensions.gardener.cloud/aws : &amp;quot;true&amp;quot;&lt;/code>.&lt;/p>
&lt;h2 id="plantvalidator">&lt;code>PlantValidator&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>Plant&lt;/code>s.
It sets the &lt;code>gardener.cloud/created-by&lt;/code> annotation for newly created &lt;code>Plant&lt;/code> resources.
Also, it prevents creating new &lt;code>Plant&lt;/code> resources in &lt;code>Project&lt;/code>s that are already have a deletion timestamp.&lt;/p>
&lt;h2 id="projectvalidator">&lt;code>ProjectValidator&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> operations for &lt;code>Project&lt;/code>s.
It prevents creating &lt;code>Project&lt;/code>s with a non-empty &lt;code>.spec.namespace&lt;/code> if the value in &lt;code>.spec.namespace&lt;/code> does not start with &lt;code>garden-&lt;/code>.&lt;/p>
&lt;p>⚠️ This admission plugin will be removed in a future release and its business logic will be incorporated into the static validation of the &lt;code>gardener-apiserver&lt;/code>.&lt;/p>
&lt;h2 id="resourcequota">&lt;code>ResourceQuota&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller enables &lt;a href="https://kubernetes.io/docs/concepts/policy/resource-quotas/#object-count-quota">object count ResourceQuotas&lt;/a> for Gardener resources, e.g. &lt;code>Shoots&lt;/code>, &lt;code>SecretBindings&lt;/code>, &lt;code>Projects&lt;/code>, etc..&lt;/p>
&lt;blockquote>
&lt;p>⚠️ In addition to this admission plugin, the &lt;a href="https://github.com/kubernetes/kubernetes/blob/release-1.2/docs/design/admission_control_resource_quota.md#resource-quota-controller">ResourceQuota controller&lt;/a> must be enabled for the Kube-Controller-Manager of your Garden cluster.&lt;/p>
&lt;/blockquote>
&lt;h2 id="resourcereferencemanager">&lt;code>ResourceReferenceManager&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>CloudProfile&lt;/code>s, &lt;code>Project&lt;/code>s, &lt;code>SecretBinding&lt;/code>s, &lt;code>Seed&lt;/code>s, and &lt;code>Shoot&lt;/code>s.
Generally, it checks whether referred resources stated in the specifications of these objects exist in the system (e.g., if a referenced &lt;code>Secret&lt;/code> exists).
However, it also has some special behaviours for certain resources:&lt;/p>
&lt;ul>
&lt;li>&lt;code>CloudProfile&lt;/code>s: It rejects removing Kubernetes or machine image versions if there is at least one &lt;code>Shoot&lt;/code> that refers to them.&lt;/li>
&lt;li>&lt;code>Project&lt;/code>s: It sets the &lt;code>.spec.createdBy&lt;/code> field for newly created &lt;code>Project&lt;/code> resources, and defaults the &lt;code>.spec.owner&lt;/code> field in case it is empty (to the same value of &lt;code>.spec.createdBy&lt;/code>).&lt;/li>
&lt;li>&lt;code>Seed&lt;/code>s: It rejects changing the &lt;code>.spec.settings.shootDNS.enabled&lt;/code> value if there is at least one &lt;code>Shoot&lt;/code> that refers to this seed.&lt;/li>
&lt;li>&lt;code>Shoot&lt;/code>s: It sets the &lt;code>gardener.cloud/created-by=&amp;lt;username&amp;gt;&lt;/code> annotation for newly created &lt;code>Shoot&lt;/code> resources.&lt;/li>
&lt;/ul>
&lt;h2 id="seedvalidator">&lt;code>SeedValidator&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>DELETE&lt;/code> operations for &lt;code>Seed&lt;/code>s.
Rejects the deletion if &lt;code>Shoot&lt;/code>(s) reference the seed cluster.&lt;/p>
&lt;h2 id="shootbinding">&lt;code>ShootBinding&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>UPDATE&lt;/code> operation for &lt;code>Binding&lt;/code> subresource of &lt;code>Shoot&lt;/code>s.
It checks for various scheduling constraints for the &lt;code>Seed&lt;/code> in the &lt;code>spec.seedName&lt;/code>.
It rejects the update if &lt;code>SeedChange&lt;/code> feature gate is disabled and the &lt;code>Shoot&lt;/code> is already assigned to a &lt;code>Seed&lt;/code>.&lt;/p>
&lt;h2 id="shootdns">&lt;code>ShootDNS&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>Shoot&lt;/code>s.
It tries to assign a default domain to the &lt;code>Shoot&lt;/code> if it gets scheduled to a seed that enables DNS for shoots (&lt;code>.spec.settings.shootDNS.enabled=true&lt;/code>).
It also validates that the DNS configuration (&lt;code>.spec.dns&lt;/code>) is not set if the seed disables DNS for shoots.&lt;/p>
&lt;h2 id="shootnodelocaldnsenabledbydefault">&lt;code>ShootNodeLocalDNSEnabledByDefault&lt;/code>&lt;/h2>
&lt;p>&lt;em>(disabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> operations for &lt;code>Shoot&lt;/code>s.
If enabled, it will enable node local dns within the shoot cluster (see &lt;a href="https://gardener.cloud/docs/gardener/usage/node-local-dns/">this doc&lt;/a>)
by setting &lt;code>spec.systemComponents.nodeLocalDNS.enabled=true&lt;/code> for newly created Shoots.
Already existing Shoots and new Shoots that explicitly disable node local dns (&lt;code>spec.systemComponents.nodeLocalDNS.enabled=false&lt;/code>)
will not be affected by this admission plugin.&lt;/p>
&lt;h2 id="shootquotavalidator">&lt;code>ShootQuotaValidator&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>Shoot&lt;/code>s.
It validates the resource consumption declared in the specification against applicable &lt;code>Quota&lt;/code> resources.
Only if the applicable &lt;code>Quota&lt;/code> resources admit the configured resources in the &lt;code>Shoot&lt;/code> then it allows the request.
Applicable &lt;code>Quota&lt;/code>s are referred in the &lt;code>SecretBinding&lt;/code> that is used by the &lt;code>Shoot&lt;/code>.&lt;/p>
&lt;h2 id="shootvpaenabledbydefault">&lt;code>ShootVPAEnabledByDefault&lt;/code>&lt;/h2>
&lt;p>&lt;em>(disabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> operations for &lt;code>Shoot&lt;/code>s.
If enabled, it will enable the managed &lt;code>VerticalPodAutoscaler&lt;/code> components (see &lt;a href="https://gardener.cloud/docs/gardener/usage/shoot_autoscaling/#vertical-pod-auto-scaling">this doc&lt;/a>)
by setting &lt;code>spec.kubernetes.verticalPodAutoscaler.enabled=true&lt;/code> for newly created Shoots.
Already existing Shoots and new Shoots that explicitly disable VPA (&lt;code>spec.kubernetes.verticalPodAutoscaler.enabled=false&lt;/code>)
will not be affected by this admission plugin.&lt;/p>
&lt;h2 id="shoottolerationrestriction">&lt;code>ShootTolerationRestriction&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>Shoot&lt;/code>s.
It validates the &lt;code>.spec.tolerations&lt;/code> used in &lt;code>Shoot&lt;/code>s against the whitelist of its &lt;code>Project&lt;/code>, or against the whitelist configured in the admission controller&amp;rsquo;s configuration, respectively.
Additionally, it defaults the &lt;code>.spec.tolerations&lt;/code> in &lt;code>Shoot&lt;/code>s with those configured in its &lt;code>Project&lt;/code>, and those configured in the admission controller&amp;rsquo;s configuration, respectively.&lt;/p>
&lt;h2 id="shootvalidator">&lt;code>ShootValidator&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code>, &lt;code>UPDATE&lt;/code> and &lt;code>DELETE&lt;/code> operations for &lt;code>Shoot&lt;/code>s.
It validates certain configurations in the specification against the referred &lt;code>CloudProfile&lt;/code> (e.g., machine images, machine types, used Kubernetes version, &amp;hellip;).
Generally, it performs validations that cannot be handled by the static API validation due to their dynamic nature (e.g., when something needs to be checked against referred resources).
Additionally, it takes over certain defaulting tasks (e.g., default machine image for worker pools).&lt;/p>
&lt;h2 id="shootmanagedseed">&lt;code>ShootManagedSeed&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>UPDATE&lt;/code> and &lt;code>DELETE&lt;/code> operations for &lt;code>Shoot&lt;/code>s.
It validates certain configuration values in the specification that are specific to &lt;code>ManagedSeed&lt;/code>s (e.g. the nginx-addon of the Shoot has to be disabled, the Shoot VPA has to be enabled).
It rejects the deletion if the &lt;code>Shoot&lt;/code> is referred to by a &lt;code>ManagedSeed&lt;/code>.&lt;/p>
&lt;h2 id="managedseedvalidator">&lt;code>ManagedSeedValidator&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>CREATE&lt;/code> and &lt;code>UPDATE&lt;/code> operations for &lt;code>ManagedSeeds&lt;/code>s.
It validates certain configuration values in the specification against the referred &lt;code>Shoot&lt;/code>, for example Seed provider, network ranges, DNS domain, etc.
Similarly to &lt;code>ShootValidator&lt;/code>, it performs validations that cannot be handled by the static API validation due to their dynamic nature.
Additionally, it performs certain defaulting tasks, making sure that configuration values that are not specified are defaulted to the values of the referred &lt;code>Shoot&lt;/code>, for example Seed provider, network ranges, DNS domain, etc.&lt;/p>
&lt;h2 id="managedseedshoot">&lt;code>ManagedSeedShoot&lt;/code>&lt;/h2>
&lt;p>&lt;em>(enabled by default)&lt;/em>&lt;/p>
&lt;p>This admission controller reacts on &lt;code>DELETE&lt;/code> operations for &lt;code>ManagedSeed&lt;/code>s.
It rejects the deletion if there are &lt;code>Shoot&lt;/code>s that are scheduled onto the &lt;code>Seed&lt;/code> that is registered by the &lt;code>ManagedSeed&lt;/code>.&lt;/p></description></item><item><title>Docs: APIServer SNI Injection</title><link>https://gardener.cloud/docs/gardener/usage/apiserver-sni-injection/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/usage/apiserver-sni-injection/</guid><description>
&lt;h1 id="apiserversni-environment-variable-injection">APIServerSNI environment variable injection&lt;/h1>
&lt;p>If the Gardener administrator has enabled &lt;code>APIServerSNI&lt;/code> feature gate for a particular Seed cluster, then in each Shoot cluster&amp;rsquo;s &lt;code>kube-system&lt;/code> namespace a &lt;code>DaemonSet&lt;/code> called &lt;code>apiserver-proxy&lt;/code> is deployed. It routes traffic to the upstream Shoot Kube APIServer. See the &lt;a href="https://gardener.cloud/docs/gardener/proposals/08-shoot-apiserver-via-sni/">APIServer SNI GEP&lt;/a> for more details.&lt;/p>
&lt;p>To skip this extra network hop, a &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#mutatingadmissionwebhook">mutating webhook&lt;/a> called &lt;code>apiserver-proxy.networking.gardener.cloud&lt;/code> is deployed next to the API server in the Seed. It adds &lt;code>KUBERNETES_SERVICE_HOST&lt;/code> environment variable to each container and init container that do not specify it. See the webhook &lt;a href="https://github.com/gardener/apiserver-proxy/">repository&lt;/a> for more information.&lt;/p>
&lt;h2 id="opt-out-of-pod-injection">Opt-out of pod injection&lt;/h2>
&lt;p>In some cases it&amp;rsquo;s desirable to opt-out of Pod injection:&lt;/p>
&lt;ul>
&lt;li>DNS is disabled on that individual Pod, but it still needs to talk to the kube-apiserver.&lt;/li>
&lt;li>Want to test the &lt;code>kube-proxy&lt;/code> and &lt;code>kubelet&lt;/code> in-cluster discovery.&lt;/li>
&lt;/ul>
&lt;h3 id="opt-out-of-pod-injection-for-specific-pods">Opt-out of pod injection for specific pods&lt;/h3>
&lt;p>To opt out of the injection, the Pod should be labeled with &lt;code>apiserver-proxy.networking.gardener.cloud/inject: disable&lt;/code> e.g.:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: apps/v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Deployment
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> app: nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> replicas: 1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> selector:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> matchLabels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> app: nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> template:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> app: nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiserver-proxy.networking.gardener.cloud/inject: disable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> containers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - name: nginx
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> image: nginx:1.14.2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ports:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - containerPort: 80
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="opt-out-of-pod-injection-on-namespace-level">Opt-out of pod injection on namespace level&lt;/h3>
&lt;p>To opt out of the injection of &lt;strong>all&lt;/strong> Pods in a namespace, you should label your namespace with &lt;code>apiserver-proxy.networking.gardener.cloud/inject: disable&lt;/code> e.g.:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Namespace
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiserver-proxy.networking.gardener.cloud/inject: disable
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-namespace
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>or via &lt;code>kubectl&lt;/code> for existing namespace:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-console" data-lang="console">&lt;span style="display:flex;">&lt;span>kubectl label namespace my-namespace apiserver-proxy.networking.gardener.cloud/inject=disable
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>NOTE: Please be aware that it&amp;rsquo;s not possible to disable injection on namespace level and enable it for individual pods in it.&lt;/p>
&lt;/blockquote>
&lt;h3 id="opt-out-of-pod-injection-for-the-entire-cluster">Opt-out of pod injection for the entire cluster&lt;/h3>
&lt;p>If the injection is causing problems for different workloads and ignoring individual pods or namespaces is not possible, then the feature could be disabled for the entire cluster with the &lt;code>alpha.featuregates.shoot.gardener.cloud/apiserver-sni-pod-injector&lt;/code> annotation with value &lt;code>disable&lt;/code> on the &lt;code>Shoot&lt;/code> resource itself:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: core.gardener.cloud/v1beta1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> annotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> alpha.featuregates.shoot.gardener.cloud/apiserver-sni-pod-injector: &lt;span style="color:#a31515">&amp;#39;disable&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-cluster
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>or via &lt;code>kubectl&lt;/code> for existing shoot cluster:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-console" data-lang="console">&lt;span style="display:flex;">&lt;span>kubectl label shoot my-cluster alpha.featuregates.shoot.gardener.cloud/apiserver-sni-pod-injector=disable
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>NOTE: Please be aware that it&amp;rsquo;s not possible to disable injection on cluster level and enable it for individual pods in it.&lt;/p>
&lt;/blockquote></description></item><item><title>Docs: Architecture</title><link>https://gardener.cloud/docs/gardener/concepts/architecture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/concepts/architecture/</guid><description>
&lt;h4 id="official-definition---what-is-kubernetes">Official Definition - What is Kubernetes?&lt;/h4>
&lt;blockquote>
&lt;p>&amp;ldquo;Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.&amp;rdquo;&lt;/p>
&lt;/blockquote>
&lt;h4 id="introduction---basic-principle">Introduction - Basic Principle&lt;/h4>
&lt;p>The foundation of the Gardener (providing &lt;em>&lt;strong>Kubernetes Clusters as a Service&lt;/strong>&lt;/em>) is Kubernetes itself, because Kubernetes is the go-to solution to manage software in the Cloud, even when it&amp;rsquo;s Kubernetes itself (see also OpenStack which is provisioned more and more on top of Kubernetes as well).&lt;/p>
&lt;p>While self-hosting, meaning to run Kubernetes components inside Kubernetes, is a popular topic in the community, we apply a special pattern catering to the needs of our cloud platform to provision hundreds or even thousands of clusters. We take a so-called &amp;ldquo;seed&amp;rdquo; cluster and seed the control plane (such as the API server, scheduler, controllers, etcd persistence and others) of an end-user cluster, which we call &amp;ldquo;shoot&amp;rdquo; cluster, as pods into the &amp;ldquo;seed&amp;rdquo; cluster. That means one &amp;ldquo;seed&amp;rdquo; cluster, of which we will have one per IaaS and region, hosts the control planes of multiple &amp;ldquo;shoot&amp;rdquo; clusters. That allows us to avoid dedicated hardware/virtual machines for the &amp;ldquo;shoot&amp;rdquo; cluster control planes. We simply put the control plane into pods/containers and since the &amp;ldquo;seed&amp;rdquo; cluster watches them, they can be deployed with a replica count of 1 and only need to be scaled out when the control plane gets under pressure, but no longer for HA reasons. At the same time, the deployments get simpler (standard Kubernetes deployment) and easier to update (standard Kubernetes rolling update). The actual &amp;ldquo;shoot&amp;rdquo; cluster consists only out of the worker nodes (no control plane) and therefore the users may get full administrative access to their clusters.&lt;/p>
&lt;h4 id="setting-the-scene---components-and-procedure">Setting The Scene - Components and Procedure&lt;/h4>
&lt;p>We provide a central operator UI, which we call the &amp;ldquo;Gardener Dashboard&amp;rdquo;. It talks to a dedicated cluster, which we call the &amp;ldquo;Garden&amp;rdquo; cluster and uses custom resources managed by an &lt;a href="https://kubernetes.io/docs/concepts/api-extension/custom-resources/#api-server-aggregation">aggregated API server&lt;/a>, one of the general extension concepts of Kubernetes) to represent &amp;ldquo;shoot&amp;rdquo; clusters. In this &amp;ldquo;Garden&amp;rdquo; cluster runs the &amp;ldquo;Gardener&amp;rdquo;, which is basically a Kubernetes controller that watches the custom resources and acts upon them, i.e. creates, updates/modifies, or deletes &amp;ldquo;shoot&amp;rdquo; clusters. The creation follows basically these steps:&lt;/p>
&lt;ul>
&lt;li>Create a namespace in the &amp;ldquo;seed&amp;rdquo; cluster for the &amp;ldquo;shoot&amp;rdquo; cluster which will host the &amp;ldquo;shoot&amp;rdquo; cluster control plane&lt;/li>
&lt;li>Generate secrets and credentials which the worker nodes will need to talk to the control plane&lt;/li>
&lt;li>Create the infrastructure (using &lt;a href="https://www.terraform.io/">Terraform&lt;/a>), which basically consists out of the network setup)&lt;/li>
&lt;li>Deploy the &amp;ldquo;shoot&amp;rdquo; cluster control plane into the &amp;ldquo;shoot&amp;rdquo; namespace in the &amp;ldquo;seed&amp;rdquo; cluster, containing the &amp;ldquo;machine-controller-manager&amp;rdquo; pod&lt;/li>
&lt;li>Create machine CRDs in the &amp;ldquo;seed&amp;rdquo; cluster, describing the configuration and the number of worker machines for the &amp;ldquo;shoot&amp;rdquo; (the machine-controller-manager watches the CRDs and creates virtual machines out of it)&lt;/li>
&lt;li>Wait for the &amp;ldquo;shoot&amp;rdquo; cluster API server to become responsive (pods will be scheduled, persistent volumes and load balancers are created by Kubernetes via the respective cloud provider)&lt;/li>
&lt;li>Finally we deploy &lt;code>kube-system&lt;/code> daemons like &lt;code>kube-proxy&lt;/code> and further add-ons like the &lt;code>dashboard&lt;/code> into the &amp;ldquo;shoot&amp;rdquo; cluster and the cluster becomes active&lt;/li>
&lt;/ul>
&lt;h4 id="overview-architecture-diagram">Overview Architecture Diagram&lt;/h4>
&lt;p>&lt;img src="https://gardener.cloud/__resources/gardener-architecture-overview_2bd462.png" alt="Gardener Overview Architecture Diagram">&lt;/p>
&lt;h4 id="detailed-architecture-diagram">Detailed Architecture Diagram&lt;/h4>
&lt;p>&lt;img src="https://gardener.cloud/__resources/gardener-architecture-detailed_945c90.png" alt="Gardener Detailed Architecture Diagram">&lt;/p>
&lt;p>Note: The &lt;code>kubelet&lt;/code> as well as the pods inside the &amp;ldquo;shoot&amp;rdquo; cluster talk through the front-door (load balancer IP; public Internet) to its &amp;ldquo;shoot&amp;rdquo; cluster API server running in the &amp;ldquo;seed&amp;rdquo; cluster. The reverse communication from the API server to the pod, service, and node networks happens through a VPN connection that we deploy into &amp;ldquo;seed&amp;rdquo; and &amp;ldquo;shoot&amp;rdquo; clusters.&lt;/p></description></item><item><title>Docs: Authentication</title><link>https://gardener.cloud/docs/gardener/api-reference/authentication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/api-reference/authentication/</guid><description>
&lt;p>Packages:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="#authentication.gardener.cloud%2fv1alpha1">authentication.gardener.cloud/v1alpha1&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h2 id="authentication.gardener.cloud/v1alpha1">authentication.gardener.cloud/v1alpha1&lt;/h2>
&lt;p>
&lt;p>Package v1alpha1 is a version of the API.&lt;/p>
&lt;/p>
Resource Types:
&lt;ul>&lt;li>
&lt;a href="#authentication.gardener.cloud/v1alpha1.AdminKubeconfigRequest">AdminKubeconfigRequest&lt;/a>
&lt;/li>&lt;/ul>
&lt;h3 id="authentication.gardener.cloud/v1alpha1.AdminKubeconfigRequest">AdminKubeconfigRequest
&lt;/h3>
&lt;p>
&lt;p>AdminKubeconfigRequest can be used to request a kubeconfig with admin credentials
for a Shoot cluster.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>&lt;/br>
string&lt;/td>
&lt;td>
&lt;code>
authentication.gardener.cloud/v1alpha1
&lt;/code>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>&lt;/br>
string
&lt;/td>
&lt;td>&lt;code>AdminKubeconfigRequest&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Standard object metadata.&lt;/p>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#authentication.gardener.cloud/v1alpha1.AdminKubeconfigRequestSpec">
AdminKubeconfigRequestSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Spec is the specification of the AdminKubeconfigRequest.&lt;/p>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>expirationSeconds&lt;/code>&lt;/br>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ExpirationSeconds is the requested validity duration of the credential. The
credential issuer may return a credential with a different validity duration so a
client needs to check the &amp;lsquo;expirationTimestamp&amp;rsquo; field in a response.
Defaults to 1 hour.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#authentication.gardener.cloud/v1alpha1.AdminKubeconfigRequestStatus">
AdminKubeconfigRequestStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Status is the status of the AdminKubeconfigRequest.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="authentication.gardener.cloud/v1alpha1.AdminKubeconfigRequestSpec">AdminKubeconfigRequestSpec
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#authentication.gardener.cloud/v1alpha1.AdminKubeconfigRequest">AdminKubeconfigRequest&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AdminKubeconfigRequestSpec contains the expiration time of the kubeconfig.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>expirationSeconds&lt;/code>&lt;/br>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ExpirationSeconds is the requested validity duration of the credential. The
credential issuer may return a credential with a different validity duration so a
client needs to check the &amp;lsquo;expirationTimestamp&amp;rsquo; field in a response.
Defaults to 1 hour.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="authentication.gardener.cloud/v1alpha1.AdminKubeconfigRequestStatus">AdminKubeconfigRequestStatus
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#authentication.gardener.cloud/v1alpha1.AdminKubeconfigRequest">AdminKubeconfigRequest&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>AdminKubeconfigRequestStatus is the status of the AdminKubeconfigRequest containing
the kubeconfig and expiration of the credential.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>kubeconfig&lt;/code>&lt;/br>
&lt;em>
[]byte
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Kubeconfig contains the kubeconfig with cluster-admin privileges for the shoot cluster.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>expirationTimestamp&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#time-v1-meta">
Kubernetes meta/v1.Time
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>ExpirationTimestamp is the expiration timestamp of the returned credential.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr/>
&lt;p>&lt;em>
Generated with &lt;a href="https://github.com/ahmetb/gen-crd-api-reference-docs">gen-crd-api-reference-docs&lt;/a>
&lt;/em>&lt;/p></description></item><item><title>Docs: Authentication Gardener Control Plane</title><link>https://gardener.cloud/docs/gardener/deployment/authentication_gardener_control_plane/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/deployment/authentication_gardener_control_plane/</guid><description>
&lt;h1 id="authentication-of-gardener-control-plane-components-against-the-garden-cluster">Authentication of Gardener control plane components against the Garden cluster&lt;/h1>
&lt;p>&lt;strong>Note:&lt;/strong> This document refers to Gardener&amp;rsquo;s API server, admission controller, controller manager and scheduler components. Any reference to the term &lt;strong>Gardener control plane component&lt;/strong> can be replaced with any of the mentioned above.&lt;/p>
&lt;p>There are several authentication possibilities depending on whether or not &lt;a href="https://github.com/gardener/garden-setup#concept-the-virtual-cluster">the concept of Virtual Garden&lt;/a> is used.&lt;/p>
&lt;h2 id="virtual-garden-is-not-used-ie-the-runtime-garden-cluster-is-also-the-target-garden-cluster">Virtual Garden is not used, i.e., the &lt;code>runtime&lt;/code> Garden cluster is also the &lt;code>target&lt;/code> Garden cluster.&lt;/h2>
&lt;h4 id="automounted-service-account-token">Automounted Service Account Token&lt;/h4>
&lt;p>The easiest way to deploy a &lt;strong>Gardener control plane component&lt;/strong> will be to not provide &lt;code>kubeconfig&lt;/code> at all. This way in-cluster configuration and an automounted service account token will be used. The drawback of this approach is that the automounted token will not be automatically rotated.&lt;/p>
&lt;h4 id="service-account-token-volume-projection">Service Account Token Volume Projection&lt;/h4>
&lt;p>Another solution will be to use &lt;a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#service-account-token-volume-projection">Service Account Token Volume Projection&lt;/a> combined with a &lt;code>kubeconfig&lt;/code> referencing a token file (see example below).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Config
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>clusters:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- cluster:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> certificate-authority-data: &amp;lt;CA-DATA&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> server: https://default.kubernetes.svc.cluster.local
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>contexts:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- context:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> user: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>current-context: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>users:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- name: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> user:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tokenFile: /var/run/secrets/projected/serviceaccount/token
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>This will allow for automatic rotation of the service account token by the &lt;code>kubelet&lt;/code>. The configuration can be achieved by setting both &lt;code>.Values.global.&amp;lt;GardenerControlPlaneComponent&amp;gt;.serviceAccountTokenVolumeProjection.enabled: true&lt;/code> and &lt;code>.Values.global.&amp;lt;GardenerControlPlaneComponent&amp;gt;.kubeconfig&lt;/code> in the respective chart&amp;rsquo;s &lt;code>values.yaml&lt;/code> file.&lt;/p>
&lt;h2 id="virtual-garden-is-used-ie-the-runtime-garden-cluster-is-different-from-the-target-garden-cluster">Virtual Garden is used, i.e., the &lt;code>runtime&lt;/code> Garden cluster is different from the &lt;code>target&lt;/code> Garden cluster.&lt;/h2>
&lt;h4 id="service-account">Service Account&lt;/h4>
&lt;p>The easiest way to setup the authentication will be to create a service account and the respective roles will be bound to this service account in the &lt;code>target&lt;/code> cluster. Then use the generated service account token and craft a &lt;code>kubeconfig&lt;/code> which will be used by the workload in the &lt;code>runtime&lt;/code> cluster. This approach does not provide a solution for the rotation of the service account token. However, this setup can be achieved by setting &lt;code>.Values.global.deployment.virtualGarden.enabled: true&lt;/code> and following these steps:&lt;/p>
&lt;ol>
&lt;li>Deploy the &lt;code>application&lt;/code> part of the charts in the &lt;code>target&lt;/code> cluster.&lt;/li>
&lt;li>Get the service account token and craft the &lt;code>kubeconfig&lt;/code>.&lt;/li>
&lt;li>Set the crafted &lt;code>kubeconfig&lt;/code> and deploy the &lt;code>runtime&lt;/code> part of the charts in the &lt;code>runtime&lt;/code> cluster.&lt;/li>
&lt;/ol>
&lt;h4 id="client-certificate">Client Certificate&lt;/h4>
&lt;p>Another solution will be to bind the roles in the &lt;code>target&lt;/code> cluster to a &lt;code>User&lt;/code> subject instead of a service account and use a client certificate for authentication. This approach does not provide a solution for the client certificate rotation. However, this setup can be achieved by setting both &lt;code>.Values.global.deployment.virtualGarden.enabled: true&lt;/code> and &lt;code>.Values.global.deployment.virtualGarden.&amp;lt;GardenerControlPlaneComponent&amp;gt;.user.name&lt;/code>, then following these steps:&lt;/p>
&lt;ol>
&lt;li>Generate a client certificate for the &lt;code>target&lt;/code> cluster for the respective user.&lt;/li>
&lt;li>Deploy the &lt;code>application&lt;/code> part of the charts in the &lt;code>target&lt;/code> cluster.&lt;/li>
&lt;li>Craft a &lt;code>kubeconfig&lt;/code> using the already generated client certificate.&lt;/li>
&lt;li>Set the crafted &lt;code>kubeconfig&lt;/code> and deploy the &lt;code>runtime&lt;/code> part of the charts in the &lt;code>runtime&lt;/code> cluster.&lt;/li>
&lt;/ol>
&lt;h4 id="projected-service-account-token">Projected Service Account Token&lt;/h4>
&lt;p>This approach requires an already deployed and configured &lt;a href="https://github.com/gardener/oidc-webhook-authenticator">oidc-webhook-authenticator&lt;/a> for the &lt;code>target&lt;/code> cluster. Also the &lt;code>runtime&lt;/code> cluster should be registered as a trusted identity provider in the &lt;code>target&lt;/code> cluster. Then projected service accounts tokens from the &lt;code>runtime&lt;/code> cluster can be used to authenticate against the &lt;code>target&lt;/code> cluster. The needed steps are as follows:&lt;/p>
&lt;ol>
&lt;li>Deploy &lt;a href="https://github.com/gardener/oidc-webhook-authenticator">OWA&lt;/a> and establish the needed trust.&lt;/li>
&lt;li>Set &lt;code>.Values.global.deployment.virtualGarden.enabled: true&lt;/code> and &lt;code>.Values.global.deployment.virtualGarden.&amp;lt;GardenerControlPlaneComponent&amp;gt;.user.name&lt;/code>. &lt;strong>Note:&lt;/strong> username value will depend on the trust configuration, e.g., &lt;code>&amp;lt;prefix&amp;gt;:system:serviceaccount:&amp;lt;namespace&amp;gt;:&amp;lt;serviceaccount&amp;gt;&lt;/code>&lt;/li>
&lt;li>Set &lt;code>.Values.global.&amp;lt;GardenerControlPlaneComponent&amp;gt;.serviceAccountTokenVolumeProjection.enabled: true&lt;/code> and &lt;code>.Values.global.&amp;lt;GardenerControlPlaneComponent&amp;gt;.serviceAccountTokenVolumeProjection.audience&lt;/code>. &lt;strong>Note:&lt;/strong> audience value will depend on the trust configuration, e.g., &lt;code>&amp;lt;cliend-id-from-trust-config&amp;gt;&lt;/code>.&lt;/li>
&lt;li>Craft a kubeconfig (see example below).&lt;/li>
&lt;li>Deploy the &lt;code>application&lt;/code> part of the charts in the &lt;code>target&lt;/code> cluster.&lt;/li>
&lt;li>Deploy the &lt;code>runtime&lt;/code> part of the charts in the &lt;code>runtime&lt;/code> cluster.&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Config
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>clusters:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- cluster:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> certificate-authority-data: &amp;lt;CA-DATA&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> server: https://virtual-garden.api
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: virtual-garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>contexts:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- context:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster: virtual-garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> user: virtual-garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: virtual-garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>current-context: virtual-garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>users:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- name: virtual-garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> user:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tokenFile: /var/run/secrets/projected/serviceaccount/token
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Azure Permissions</title><link>https://gardener.cloud/docs/extensions/infrastructure-extensions/gardener-extension-provider-azure/docs/azure-permissions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/extensions/infrastructure-extensions/gardener-extension-provider-azure/docs/azure-permissions/</guid><description>
&lt;h1 id="azure-permissions">Azure Permissions&lt;/h1>
&lt;p>The following document describes the required Azure actions manage a Shoot cluster on Azure split by the different Azure provider/services.&lt;/p>
&lt;p>Be aware some actions are just required if particilar deployment sceanrios or features e.g. bring your own vNet, use Azure-file, let the Shoot act as Seed etc. should be used.&lt;/p>
&lt;h2 id="microsoftcompute">&lt;code>Microsoft.Compute&lt;/code>&lt;/h2>
&lt;pre tabindex="0">&lt;code># Required if a non zonal cluster based on Availability Set should be used.
Microsoft.Compute/availabilitySets/delete
Microsoft.Compute/availabilitySets/read
Microsoft.Compute/availabilitySets/write
# Required to let Kubernetes manage Azure disks.
Microsoft.Compute/disks/delete
Microsoft.Compute/disks/read
Microsoft.Compute/disks/write
# Required for to fetch meta information about disk and virtual machines sizes.
Microsoft.Compute/locations/diskOperations/read
Microsoft.Compute/locations/operations/read
Microsoft.Compute/locations/vmSizes/read
# Required if csi snapshot capabilities should be used and/or the Shoot should act as a Seed.
Microsoft.Compute/snapshots/delete
Microsoft.Compute/snapshots/read
Microsoft.Compute/snapshots/write
# Required to let Gardener/Machine-Controller-Manager manage the cluster nodes/machines.
Microsoft.Compute/virtualMachines/delete
Microsoft.Compute/virtualMachines/read
Microsoft.Compute/virtualMachines/start/action
Microsoft.Compute/virtualMachines/write
# Required if a non zonal cluster based on VMSS Flex (VMO) should be used.
Microsoft.Compute/virtualMachineScaleSets/delete
Microsoft.Compute/virtualMachineScaleSets/read
Microsoft.Compute/virtualMachineScaleSets/write
&lt;/code>&lt;/pre>&lt;h2 id="microsoftmanagedidentity">&lt;code>Microsoft.ManagedIdentity&lt;/code>&lt;/h2>
&lt;pre tabindex="0">&lt;code># Required if a user provided Azure managed identity should attached to the cluster nodes.
Microsoft.ManagedIdentity/userAssignedIdentities/assign/action
Microsoft.ManagedIdentity/userAssignedIdentities/read
&lt;/code>&lt;/pre>&lt;h2 id="microsoftmarketplaceordering">&lt;code>Microsoft.MarketplaceOrdering&lt;/code>&lt;/h2>
&lt;pre tabindex="0">&lt;code># Required if nodes/machines should be created with images hosted on the Azure Marketplace.
Microsoft.MarketplaceOrdering/offertypes/publishers/offers/plans/agreements/read
Microsoft.MarketplaceOrdering/offertypes/publishers/offers/plans/agreements/write
&lt;/code>&lt;/pre>&lt;h2 id="microsoftnetwork">&lt;code>Microsoft.Network&lt;/code>&lt;/h2>
&lt;pre tabindex="0">&lt;code># Required to let Kubernetes manage services of type &amp;#39;LoadBalancer&amp;#39;.
Microsoft.Network/loadBalancers/backendAddressPools/join/action
Microsoft.Network/loadBalancers/delete
Microsoft.Network/loadBalancers/read
Microsoft.Network/loadBalancers/write
# Required in case the Shoot should use NatGateway(s).
Microsoft.Network/natGateways/delete
Microsoft.Network/natGateways/join/action
Microsoft.Network/natGateways/read
Microsoft.Network/natGateways/write
# Required to let Gardener/Machine-Controller-Manager manage the cluster nodes/machines.
Microsoft.Network/networkInterfaces/delete
Microsoft.Network/networkInterfaces/ipconfigurations/join/action
Microsoft.Network/networkInterfaces/ipconfigurations/read
Microsoft.Network/networkInterfaces/join/action
Microsoft.Network/networkInterfaces/read
Microsoft.Network/networkInterfaces/write
# Required to let Gardener maintain the basic infrastructure of the Shoot cluster and maintaing LoadBalancer services.
Microsoft.Network/networkSecurityGroups/delete
Microsoft.Network/networkSecurityGroups/join/action
Microsoft.Network/networkSecurityGroups/read
Microsoft.Network/networkSecurityGroups/write
# Required for managing LoadBalancers and NatGateways.
Microsoft.Network/publicIPAddresses/delete
Microsoft.Network/publicIPAddresses/join/action
Microsoft.Network/publicIPAddresses/read
Microsoft.Network/publicIPAddresses/write
# Required for managing the basic infrastructure of a cluster and maintaing LoadBalancer services.
Microsoft.Network/routeTables/delete
Microsoft.Network/routeTables/join/action
Microsoft.Network/routeTables/read
Microsoft.Network/routeTables/routes/delete
Microsoft.Network/routeTables/routes/read
Microsoft.Network/routeTables/routes/write
Microsoft.Network/routeTables/write
# Required to let Gardener maintain the basic infrastructure of the Shoot cluster.
# Only a subset is required for the bring your own vNet scenario.
Microsoft.Network/virtualNetworks/delete # not required for bring your own vnet
Microsoft.Network/virtualNetworks/read
Microsoft.Network/virtualNetworks/subnets/delete
Microsoft.Network/virtualNetworks/subnets/join/action
Microsoft.Network/virtualNetworks/subnets/read
Microsoft.Network/virtualNetworks/subnets/write
Microsoft.Network/virtualNetworks/write # not required for bring your own vnet
&lt;/code>&lt;/pre>&lt;h2 id="microsoftresources">&lt;code>Microsoft.Resources&lt;/code>&lt;/h2>
&lt;pre tabindex="0">&lt;code># Required to let Gardener maintain the basic infrastructure of the Shoot cluster.
Microsoft.Resources/subscriptions/resourceGroups/delete
Microsoft.Resources/subscriptions/resourceGroups/read
Microsoft.Resources/subscriptions/resourceGroups/write
&lt;/code>&lt;/pre>&lt;h2 id="microsoftstorage">&lt;code>Microsoft.Storage&lt;/code>&lt;/h2>
&lt;pre tabindex="0">&lt;code># Required if Azure File should be used and/or if the Shoot should act as Seed.
Microsoft.Storage/operations/read
Microsoft.Storage/storageAccounts/blobServices/containers/delete
Microsoft.Storage/storageAccounts/blobServices/containers/read
Microsoft.Storage/storageAccounts/blobServices/containers/write
Microsoft.Storage/storageAccounts/blobServices/read
Microsoft.Storage/storageAccounts/delete
Microsoft.Storage/storageAccounts/listkeys/action
Microsoft.Storage/storageAccounts/read
Microsoft.Storage/storageAccounts/write
&lt;/code>&lt;/pre></description></item><item><title>Docs: Backup Restore</title><link>https://gardener.cloud/docs/gardener/concepts/backup-restore/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/concepts/backup-restore/</guid><description>
&lt;h1 id="backup-and-restore">Backup and restore&lt;/h1>
&lt;p>Kubernetes uses Etcd as the key-value store for its resource definitions. Gardener supports the backup and restore of etcd. It is the responsibility of the shoot owners to backup the workload data.&lt;/p>
&lt;p>Gardener uses &lt;a href="https://github.com/gardener/etcd-backup-restore">etcd-backup-restore&lt;/a> component to backup the etcd backing the Shoot cluster regularly and restore in case of disaster. It is deployed as sidecar via &lt;a href="https://github.com/gardener/etcd-druid">etcd-druid&lt;/a>. This doc mainly focuses on the backup and restore configuration used by Gardener when deploying these components. For more details on the design and internal implementation details, please refer &lt;a href="https://gardener.cloud/docs/gardener/proposals/06-etcd-druid/">GEP-06&lt;/a> and documentation on individual repository.&lt;/p>
&lt;h2 id="bucket-provisioning">Bucket provisioning&lt;/h2>
&lt;p>Refer the &lt;a href="https://gardener.cloud/docs/gardener/extensions/backupbucket/">backup bucket extension document&lt;/a> to know details about configuring backup bucket.&lt;/p>
&lt;h2 id="backup-policy">Backup Policy&lt;/h2>
&lt;p>etcd-backup-restore supports full snapshot and delta snapshots over full snapshot. In Gardener, this configuration is currently hard-coded to following parameters:&lt;/p>
&lt;ul>
&lt;li>Full Snapshot Schedule:
&lt;ul>
&lt;li>Daily, &lt;code>24hr&lt;/code> interval.&lt;/li>
&lt;li>For each Shoot, the schedule time in a day is randomized based on the configured Shoot maintenance window.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Delta Snapshot schedule:
&lt;ul>
&lt;li>At &lt;code>5min&lt;/code> interval.&lt;/li>
&lt;li>If aggregated events size since last snapshot goes beyond &lt;code>100Mib&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Backup History / Garbage backup deletion policy:
&lt;ul>
&lt;li>Gardener configure backup restore to have &lt;code>Exponential&lt;/code> garbage collection policy.&lt;/li>
&lt;li>As per policy, following backups are retained.&lt;/li>
&lt;li>All full backups and delta backups for the previous hour.&lt;/li>
&lt;li>Latest full snapshot of each previous hour for the day.&lt;/li>
&lt;li>Latest full snapshot of each previous day for 7 days.&lt;/li>
&lt;li>Latest full snapshot of the previous 4 weeks.&lt;/li>
&lt;li>Garbage Collection is configured at &lt;code>12hr&lt;/code> interval.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Listing:
&lt;ul>
&lt;li>Gardener don&amp;rsquo;t have any API to list out the backups.&lt;/li>
&lt;li>To find the backup list, admin can checkout the &lt;code>BackupEntry&lt;/code> resource associated with Shoot which holds the bucket and prefix details on object store.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="restoration">Restoration&lt;/h2>
&lt;p>Restoration process of etcd is automated through the etcd-backup-restore component from latest snapshot. Gardener dosen&amp;rsquo;t support Point-In-Time-Recovery (PITR) of etcd. In case of etcd disaster, the etcd is recovered from latest backup automatically. For further details, please refer the &lt;a href="https://github.com/gardener/etcd-backup-restore/blob/master/doc/proposals/restoration.md">doc&lt;/a>. Post restoration of etcd, the Shoot reconciliation loop brings back the cluster to same state.&lt;/p>
&lt;p>Again, Shoot owner is responsible for maintaining the backup/restore of his workload. Gardener does only take care of the cluster&amp;rsquo;s etcd.&lt;/p></description></item><item><title>Docs: BackupBucket</title><link>https://gardener.cloud/docs/gardener/extensions/backupbucket/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/extensions/backupbucket/</guid><description>
&lt;h1 id="contract-backupbucket-resource">Contract: &lt;code>BackupBucket&lt;/code> Resource&lt;/h1>
&lt;p>The Gardener project features a sub-project called &lt;a href="https://github.com/gardener/etcd-backup-restore">etcd-backup-restore&lt;/a> to take periodic backups of etcd backing Shoot clusters. It demands the bucket (or its equivalent in different object store providers) to be created and configured externally with appropriate credentials. The &lt;code>BackupBucket&lt;/code> resource takes this responsibility in Gardener.&lt;/p>
&lt;p>Before introducing the &lt;code>BackupBucket&lt;/code> extension resource, Gardener was using Terraform in order to create and manage these provider-specific resources (e.g., see &lt;a href="https://github.com/gardener/gardener/tree/0.27.0/charts/seed-terraformer/charts/aws-backup">AWS Backup&lt;/a>).
Now, Gardener commissions an external, provider-specific controller to take over this task. You can also refer to &lt;a href="https://gardener.cloud/docs/gardener/proposals/02-backupinfra/">backupInfra proposal documentation&lt;/a> to get idea about how the transition was done and understand the resource in broader scope.&lt;/p>
&lt;h2 id="what-is-the-scope-of-bucket">What is the Scope of Bucket?&lt;/h2>
&lt;p>A bucket will be provisioned per &lt;code>Seed&lt;/code>. So, a backup of every &lt;code>Shoot&lt;/code> created on that &lt;code>Seed&lt;/code> will be stored under a different shoot specific prefix under the bucket.
For the backup of the &lt;code>Shoot&lt;/code> rescheduled on different &lt;code>Seed&lt;/code>, it will continue to use the same bucket.&lt;/p>
&lt;h2 id="what-is-the-lifespan-of-backupbucket">What is the Lifespan of &lt;code>BackupBucket&lt;/code>?&lt;/h2>
&lt;p>The bucket associated with &lt;code>BackupBucket&lt;/code> will be created at the creation of the &lt;code>Seed&lt;/code>. And as per current implementation, it will also be deleted on deletion of the &lt;code>Seed&lt;/code>, if there isn&amp;rsquo;t any &lt;code>BackupEntry&lt;/code> resource associated with it.&lt;/p>
&lt;p>In the future, we plan to introduce a schedule for &lt;code>BackupBucket&lt;/code> - the deletion logic for the &lt;code>BackupBucket&lt;/code> resource, which will reschedule it on different available &lt;code>Seed&lt;/code>s on deletion or failure of a health check for the currently associated &lt;code>seed&lt;/code>. In that case, the &lt;code>BackupBucket&lt;/code> will be deleted only if there isn&amp;rsquo;t any schedulable &lt;code>Seed&lt;/code> available and there isn&amp;rsquo;t any associated &lt;code>BackupEntry&lt;/code> resource.&lt;/p>
&lt;h2 id="what-needs-to-be-implemented-to-support-a-new-infrastructure-provider">What Needs to be Implemented to Support a New Infrastructure Provider?&lt;/h2>
&lt;p>As part of the seed flow, Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: BackupBucket
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: azure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;some-optional-provider-specific-backupbucket-configuration&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: backupprovider
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--foo--bar
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>.spec.secretRef&lt;/code> contains a reference to the provider secret pointing to the account that shall be used to create the needed resources. This provider secret will be configured by the Gardener operator in the &lt;code>Seed&lt;/code> resource and propagated over there by the seed controller.&lt;/p>
&lt;p>After your controller has created the required bucket, if required, it generates the secret to access the objects in the bucket and put a reference to it in &lt;code>status&lt;/code>. This secret is supposed to be used by Gardener or eventually a &lt;code>BackupEntry&lt;/code> resource and etcd-backup-restore component to backup the etcd.&lt;/p>
&lt;p>In order to support a new infrastructure provider, you need to write a controller that watches all &lt;code>BackupBucket&lt;/code>s with &lt;code>.spec.type=&amp;lt;my-provider-name&amp;gt;&lt;/code>. You can take a look at the below referenced example implementation for the Azure provider.&lt;/p>
&lt;h2 id="references-and-additional-resources">References and Additional Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://gardener.cloud/docs/gardener/api-reference/extensions/#backupbucket">&lt;code>BackupBucket&lt;/code> API Reference&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/gardener/gardener-extension-provider-azure/tree/master/pkg/controller/backupbucket">Exemplary implementation for the Azure provider&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gardener.cloud/docs/gardener/extensions/backupentry/">&lt;code>BackupEntry&lt;/code> resource documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gardener.cloud/docs/gardener/proposals/02-backupinfra/">Shared bucket proposal&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: BackupEntry</title><link>https://gardener.cloud/docs/gardener/extensions/backupentry/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/extensions/backupentry/</guid><description>
&lt;h1 id="contract-backupentry-resource">Contract: &lt;code>BackupEntry&lt;/code> Resource&lt;/h1>
&lt;p>The Gardener project features a sub-project called &lt;a href="https://github.com/gardener/etcd-backup-restore">etcd-backup-restore&lt;/a> to take periodic backups of etcd backing Shoot clusters. It demands the bucket (or its equivalent in different object store providers) access credentials to be created and configured externally with appropriate credentials. The &lt;code>BackupEntry&lt;/code> resource takes this responsibility in Gardener to provide this information by creating a secret specific to the component.&lt;/p>
&lt;p>That being said, the core motivation for introducing this resource was to support retention of backups post deletion of &lt;code>Shoot&lt;/code>. The etcd-backup-restore components take responsibility of garbage collecting old backups out of the defined period. Once a shoot is deleted, we need to persist the backups for few days. Hence, Gardener uses the &lt;code>BackupEntry&lt;/code> resource for this housekeeping work post deletion of a &lt;code>Shoot&lt;/code>. The &lt;code>BackupEntry&lt;/code> resource is responsible for shoot specific prefix under referred bucket.&lt;/p>
&lt;p>Before introducing the &lt;code>BackupEntry&lt;/code> extension resource, Gardener was using Terraform in order to create and manage these provider-specific resources (e.g., see &lt;a href="https://github.com/gardener/gardener/tree/0.27.0/charts/seed-terraformer/charts/aws-backup">AWS Backup&lt;/a>).
Now, Gardener commissions an external, provider-specific controller to take over this task. You can also refer to &lt;a href="https://gardener.cloud/docs/gardener/proposals/02-backupinfra/">backupInfra proposal documentation&lt;/a> to get idea about how the transition was done and understand the resource in broader scope.&lt;/p>
&lt;h2 id="what-is-the-lifespan-of-backupentry">What is the Lifespan of &lt;code>BackupEntry&lt;/code>?&lt;/h2>
&lt;p>The bucket associated with &lt;code>BackupEntry&lt;/code> will be created by using a &lt;code>BackupBucket&lt;/code> resource. The &lt;code>BackupEntry&lt;/code> resource will be created as a part of the &lt;code>Shoot&lt;/code> creation. But resources might continue to exist post deletion of a &lt;code>Shoot&lt;/code> (see &lt;a href="https://gardener.cloud/docs/gardener/concepts/gardenlet/#backupentry-controller">Gardenlet&lt;/a> for more details).&lt;/p>
&lt;h2 id="what-needs-to-be-implemented-to-support-a-new-infrastructure-provider">What Needs to be Implemented to Support a New Infrastructure Provider?&lt;/h2>
&lt;p>As part of the shoot flow, Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: BackupEntry
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: shoot--foo--bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: azure
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerConfig:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;some-optional-provider-specific-backup-bucket-configuration&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> backupBucketProviderStatus:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &amp;lt;some-optional-provider-specific-backup-bucket-status&amp;gt;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> region: eu-west-1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> bucketName: foo
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> secretRef:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: backupprovider
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--foo--bar
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The &lt;code>.spec.secretRef&lt;/code> contains a reference to the provider secret pointing to the account that shall be used to create the needed resources. This provider secret will be propagated from the &lt;code>BackupBucket&lt;/code> resource by the shoot controller.&lt;/p>
&lt;p>Your controller is supposed to create the &lt;code>etcd-backup&lt;/code> secret in the control plane namespace of a shoot. This secret is supposed to be used by Gardener or eventually by the etcd-backup-restore component to backup the etcd. The controller implementation should clean up the objects created under the shoot specific prefix in the bucket equivalent to the name of the &lt;code>BackupEntry&lt;/code> resource.&lt;/p>
&lt;p>In order to support a new infrastructure provider, you need to write a controller that watches all the &lt;code>BackupBucket&lt;/code>s with &lt;code>.spec.type=&amp;lt;my-provider-name&amp;gt;&lt;/code>. You can take a look at the below referenced example implementation for the Azure provider.&lt;/p>
&lt;h2 id="references-and-additional-resources">References and Additional Resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://gardener.cloud/docs/gardener/api-reference/extensions/#backupbucket">&lt;code>BackupEntry&lt;/code> API Reference&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/gardener/gardener-extension-provider-azure/tree/master/pkg/controller/backupentry">Exemplary implementation for the Azure provider&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gardener.cloud/docs/gardener/extensions/backupbucket/">&lt;code>BackupBucket&lt;/code> resource documentation&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gardener.cloud/docs/gardener/proposals/02-backupinfra/">Shared bucket proposal&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/gardener/gardener/blob/master/pkg/controllermanager/apis/config/types.go#L101-%23L107">Gardener-controller-manager-component-config API specification&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: Bastion</title><link>https://gardener.cloud/docs/gardener/extensions/bastion/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/extensions/bastion/</guid><description>
&lt;h1 id="contract-bastion-resource">Contract: &lt;code>Bastion&lt;/code> resource&lt;/h1>
&lt;p>The Gardener project allows users to connect to Shoot worker nodes via SSH. As nodes are usually firewalled and not directly accessible from the public internet, &lt;a href="https://gardener.cloud/docs/gardener/proposals/15-manage-bastions-and-ssh-key-pair-rotation/">GEP-15&lt;/a> introduced the concept of &amp;ldquo;Bastions&amp;rdquo;. A bastion is a dedicated server that only serves to allow SSH ingress to the worker nodes.&lt;/p>
&lt;p>&lt;code>Bastion&lt;/code> resources contain the user&amp;rsquo;s public SSH key and IP address, in order to provision the server accordingly: The public key is put onto the Bastion and SSH ingress is only authorized for the given IP address (in fact, it&amp;rsquo;s not a single IP address, but a set of IP ranges, however for most purposes a single IP is be used).&lt;/p>
&lt;h2 id="what-is-the-lifespan-of-bastion">What is the lifespan of &lt;code>Bastion&lt;/code>?&lt;/h2>
&lt;p>Once a &lt;code>Bastion&lt;/code> has been created in the garden, it will be replicated to the appropriate seed cluster, where a controller then reconciles a server and firewall rules etc. on the cloud provider used by the target Shoot. When the Bastion is ready (i.e. has a public IP), that IP is stored in the &lt;code>Bastion&lt;/code>&amp;rsquo;s status and from there is picked up by the garden cluster and &lt;code>gardenctl&lt;/code> eventually.&lt;/p>
&lt;p>To make multiple SSH sessions possible, the existence of the &lt;code>Bastion&lt;/code> is not directly tied to the execution of &lt;code>gardenctl&lt;/code>: users can exit out of &lt;code>gardenctl&lt;/code> and use &lt;code>ssh&lt;/code> manually to connect to the bastion and worker nodes.&lt;/p>
&lt;p>However, &lt;code>Bastion&lt;/code>s have an expiry date, after which they will be garbage collected.&lt;/p>
&lt;h2 id="what-needs-to-be-implemented-to-support-a-new-infrastructure-provider">What needs to be implemented to support a new infrastructure provider?&lt;/h2>
&lt;p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Bastion
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: mybastion
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--foo--bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># userData is base64-encoded cloud provider user data; this contains the&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># user&amp;#39;s SSH key&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> userData: IyEvYmluL2Jhc2ggL....Nlcgo=
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ingress:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - ipBlock:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cidr: 192.88.99.0/32 &lt;span style="color:#008000"># this is most likely the user&amp;#39;s IP address&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Your controller is supposed to create a new instance at the given cloud provider, firewall it to only allow SSH (TCP port 22) from the given IP blocks, and then to configure the firewall for the worker nodes to allow SSH from the bastion instance. When a &lt;code>Bastion&lt;/code> is deleted, all these changes need to be reverted.&lt;/p>
&lt;h2 id="implementation-details">Implementation details&lt;/h2>
&lt;h3 id="configvalidator-interface">&lt;code>ConfigValidator&lt;/code> interface&lt;/h3>
&lt;p>For bastion controllers, the generic &lt;code>Reconciler&lt;/code> also delegates to &lt;a href="https://github.com/gardener/gardener/blob/master/extensions/pkg/controller/bastion/configvalidator.go">a &lt;code>ConfigValidator&lt;/code> interface&lt;/a> that contains a single &lt;code>Validate&lt;/code> method. This method is called by the generic &lt;code>Reconciler&lt;/code> at the beginning of every reconciliation, and can be implemented by the extension to validate the &lt;code>.spec.providerConfig&lt;/code> part of the &lt;code>Bastion&lt;/code> resource with the respective cloud provider, typically the existence and validity of cloud provider resources such as VPCs, Images.&lt;/p>
&lt;p>The &lt;code>Validate&lt;/code> method returns a list of errors. If this list is non-empty, the generic &lt;code>Reconciler&lt;/code> will fail with an error. This error will have the error code &lt;code>ERR_CONFIGURATION_PROBLEM&lt;/code>, unless there is at least one error in the list that has its &lt;code>ErrorType&lt;/code> field set to &lt;code>field.ErrorTypeInternal&lt;/code>.&lt;/p>
&lt;h2 id="references-and-additional-resources">References and additional resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://gardener.cloud/docs/gardener/api-reference/extensions/#bastion">&lt;code>Bastion&lt;/code> API Reference&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/bastion">Exemplary implementation for the AWS provider&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gardener.cloud/docs/gardener/proposals/15-manage-bastions-and-ssh-key-pair-rotation/">GEP-15&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: Bastion Management and SSH Key Pair Rotation</title><link>https://gardener.cloud/docs/gardener/proposals/15-manage-bastions-and-ssh-key-pair-rotation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/proposals/15-manage-bastions-and-ssh-key-pair-rotation/</guid><description>
&lt;h1 id="gep-15-bastion-management-and-ssh-key-pair-rotation">GEP-15: Bastion Management and SSH Key Pair Rotation&lt;/h1>
&lt;h2 id="table-of-contents">Table of Contents&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#motivation">Motivation&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#goals">Goals&lt;/a>&lt;/li>
&lt;li>&lt;a href="#non-goals">Non-Goals&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#proposal">Proposal&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#involved-components">Involved Components&lt;/a>&lt;/li>
&lt;li>&lt;a href="#ssh-flow">SSH Flow&lt;/a>&lt;/li>
&lt;li>&lt;a href="#resource-example">Resource Example&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#ssh-key-pair-rotation">SSH Key Pair Rotation&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#rotation-proposal">Rotation Proposal&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>&lt;code>gardenctl&lt;/code> (v1) has the functionality to setup &lt;code>ssh&lt;/code> sessions to the targeted shoot cluster (nodes). To this end, infrastructure resources like VMs, public IPs, firewall rules, etc. have to be created. &lt;code>gardenctl&lt;/code> will clean up the resources after termination of the &lt;code>ssh&lt;/code> session (or rather when the operator is done with her work). However, there were issues in the past where these infrastructure resources were not properly cleaned up afterwards, e.g. due to some error (no retries either). Hence, the proposal is to have a dedicated controller (for each infrastructure) that manages the infrastructure resources and their cleanup. The current &lt;code>gardenctl&lt;/code> also re-used the &lt;code>ssh&lt;/code> node credentials for the bastion host. While that&amp;rsquo;s possible, it would be safer to rather use personal or generated &lt;code>ssh&lt;/code> key pairs to access the bastion host.
The static shoot-specific &lt;code>ssh&lt;/code> key pair should be rotated regularly, e.g. once in the maintenance time window. This also means that we cannot create the node VMs anymore with infrastructure public keys as these cannot be revoked or rotated (e.g. in AWS) without terminating the VM itself.&lt;/p>
&lt;p>Changes to the &lt;code>Bastion&lt;/code> resource should only be allowed for controllers on seeds that are responsible for it. This cannot be restricted when using custom resources.
The proposal, as outlined below, suggests to implement the necessary changes in the gardener core components and to adapt the &lt;a href="https://github.com/gardener/gardener/issues/1723">SeedAuthorizer&lt;/a> to consider &lt;code>Bastion&lt;/code> resources that the Gardener API Server serves.&lt;/p>
&lt;h3 id="goals">Goals&lt;/h3>
&lt;ul>
&lt;li>Operators can request and will be granted time-limited &lt;code>ssh&lt;/code> access to shoot cluster nodes via bastion hosts.&lt;/li>
&lt;li>To that end, requestors must present their public &lt;code>ssh&lt;/code> key and only this will be installed into &lt;code>sshd&lt;/code> on the bastion hosts.&lt;/li>
&lt;li>The bastion hosts will be firewalled and ingress traffic will be permitted only from the client IP of the requestor. Except for traffic on port 22 to the cluster worker nodes, no egress from the bastion is allowed.&lt;/li>
&lt;li>The actual node &lt;code>ssh&lt;/code> private key (resp. key pair) will be rotated by Gardener and access to the nodes is only possible with this constantly rotated key pair and not with the personal one that is used only for the bastion host.&lt;/li>
&lt;li>Bastion host and access is granted only for the extent of this operator request (of course multiple &lt;code>ssh&lt;/code> sessions are possible, in parallel or repeatedly, but after &amp;ldquo;the time is up&amp;rdquo;, access is no longer possible).&lt;/li>
&lt;li>By these means (personal public key and allow-listed client IP) nobody else can use (a.k.a. impersonate) the requestor (not even other operators).&lt;/li>
&lt;li>Necessary infrastructure resources for &lt;code>ssh&lt;/code> access (such as VMs, public IPs, firewall rules, etc.) are automatically created and also terminated after usage, but at the latest after the above mentioned time span is up.&lt;/li>
&lt;/ul>
&lt;h3 id="non-goals">Non-Goals&lt;/h3>
&lt;ul>
&lt;li>Node-specific access&lt;/li>
&lt;li>Auditability on operating system level (not only auditing the &lt;code>ssh&lt;/code> login, but everything that is done on a node and other respective resources, e.g. by using dedicated operating system users)&lt;/li>
&lt;li>Reuse of temporarily created necessary infrastructure resources by different users&lt;/li>
&lt;/ul>
&lt;h2 id="proposal">Proposal&lt;/h2>
&lt;h3 id="involved-components">Involved Components&lt;/h3>
&lt;p>The following is a list of involved components, that either need to be newly introduced or extended if already existing&lt;/p>
&lt;ul>
&lt;li>Gardener API Server (&lt;code>GAPI&lt;/code>)
&lt;ul>
&lt;li>New &lt;code>operations.gardener.cloud&lt;/code> API Group&lt;/li>
&lt;li>New resource type &lt;code>Bastion&lt;/code>, see &lt;a href="#resource-example">resource example&lt;/a> below&lt;/li>
&lt;li>New Admission Webhooks for &lt;code>Bastion&lt;/code> resource&lt;/li>
&lt;li>&lt;code>SeedAuthorizer&lt;/code>: The &lt;code>SeedAuthorizer&lt;/code> and dependency graph needs to be extended to consider the &lt;code>Bastion&lt;/code> resource &lt;a href="https://github.com/gardener/gardener/tree/master/pkg/admissioncontroller/webhooks/auth/seed/graph">https://github.com/gardener/gardener/tree/master/pkg/admissioncontroller/webhooks/auth/seed/graph&lt;/a>&lt;/li>
&lt;li>Is configured with &lt;code>timeToLive&lt;/code>, the time to add to the current time on each heartbeat&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>gardenlet&lt;/code>
&lt;ul>
&lt;li>Deploys &lt;code>Bastion&lt;/code> CRD under the &lt;code>extensions.gardener.cloud&lt;/code> API Group to the Seed, see &lt;a href="#resource-example">resource example&lt;/a> below&lt;/li>
&lt;li>Similar to &lt;code>BackupBucket&lt;/code>s or &lt;code>BackupEntry&lt;/code>, the &lt;code>gardenlet&lt;/code> watches the &lt;code>Bastion&lt;/code> resource in the garden cluster and creates a seed-local &lt;code>Bastion&lt;/code> resource, on which the provider specific bastion controller acts upon&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>gardenctlv2&lt;/code> (or any other client)
&lt;ul>
&lt;li>Creates &lt;code>Bastion&lt;/code> resource in the garden cluster&lt;/li>
&lt;li>Establishes an &lt;code>ssh&lt;/code> connection to a shoot node, using a bastion host as proxy&lt;/li>
&lt;li>Heartbeats / keeps alive the &lt;code>Bastion&lt;/code> resource during &lt;code>ssh&lt;/code> connection&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Gardener extension provider &lt;infra>
&lt;ul>
&lt;li>Provider specific bastion controller&lt;/li>
&lt;li>Should be added to gardener-extension-provider-&lt;infra> repos, e.g. &lt;a href="https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller">https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller&lt;/a>&lt;/li>
&lt;li>Has the permission to update the &lt;code>Bastion/status&lt;/code> subresource on the seed cluster&lt;/li>
&lt;li>Runs on seed (of course)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Gardener Controller Manager (&lt;code>GCM&lt;/code>)
&lt;ul>
&lt;li>&lt;code>Bastion&lt;/code> heartbeat controller
&lt;ul>
&lt;li>Cleans up &lt;code>Bastion&lt;/code> resource on missing heartbeat.&lt;/li>
&lt;li>Is configured with a &lt;code>maxLifetime&lt;/code> for the &lt;code>Bastion&lt;/code> resource&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Gardener (RBAC)
&lt;ul>
&lt;li>The project &lt;code>admin&lt;/code> role should be extended to allow CRUD operations on the &lt;code>Bastion&lt;/code> resource. The &lt;code>gardener.cloud:system:project-member-aggregation&lt;/code> &lt;code>ClusterRole&lt;/code> needs to be updated accordingly (&lt;a href="https://github.com/gardener/gardener/blob/master/charts/gardener/controlplane/charts/application/templates/rbac-user.yaml">https://github.com/gardener/gardener/blob/master/charts/gardener/controlplane/charts/application/templates/rbac-user.yaml&lt;/a>)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="ssh-flow">SSH Flow&lt;/h3>
&lt;ol start="0">
&lt;li>Users should only get the RBAC permission to &lt;code>create&lt;/code> / &lt;code>update&lt;/code> &lt;code>Bastion&lt;/code> resources for a namespace, if they should be allowed to &lt;code>ssh&lt;/code> onto the shoot nodes in this namespace. A project member with &lt;code>admin&lt;/code> role will have these permissions.&lt;/li>
&lt;li>User/&lt;code>gardenctlv2&lt;/code> creates &lt;code>Bastion&lt;/code> resource in garden cluster (see &lt;a href="#resource-example">resource example&lt;/a> below)
&lt;ul>
&lt;li>First, gardenctl would figure out the own public IP of the user&amp;rsquo;s machine. Either by calling an external service (gardenctl (v1) uses &lt;a href="https://github.com/gardener/gardenctl/blob/master/pkg/cmd/miscellaneous.go#L226">https://github.com/gardener/gardenctl/blob/master/pkg/cmd/miscellaneous.go#L226&lt;/a>) or by calling a binary that prints the public IP(s) to stdout. The binary should be configurable. The result is set under &lt;code>spec.ingress[].ipBlock.cidr&lt;/code>&lt;/li>
&lt;li>Creates new &lt;code>ssh&lt;/code> key pair. The newly created key pair is used only once for each bastion host, so it has a 1:1 relationship to it. It is cleaned up after it is not used anymore, e.g. if the &lt;code>Bastion&lt;/code> resource was deleted.&lt;/li>
&lt;li>The public &lt;code>ssh&lt;/code> key is set under &lt;code>spec.sshPublicKey&lt;/code>&lt;/li>
&lt;li>The targeted shoot is set under &lt;code>spec.shootRef&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>GAPI Admission Plugin for the &lt;code>Bastion&lt;/code> resource in the garden cluster
&lt;ul>
&lt;li>on creation, sets &lt;code>metadata.annotations[&amp;quot;gardener.cloud/created-by&amp;quot;]&lt;/code> according to the user that created the resource&lt;/li>
&lt;li>when &lt;code>gardener.cloud/operation: keepalive&lt;/code> is set it will be removed by GAPI from the annotations and &lt;code>status.lastHeartbeatTimestamp&lt;/code> will be set with the current timestamp. The &lt;code>status.expirationTimestamp&lt;/code> will be calculated by taking the last heartbeat timestamp and adding &lt;code>x&lt;/code> minutes (configurable, default &lt;code>60&lt;/code> Minutes).&lt;/li>
&lt;li>validates that only the creator of the bastion (see &lt;code>gardener.cloud/created-by&lt;/code> annotation) can update &lt;code>spec.ingress&lt;/code>&lt;/li>
&lt;li>validates that a Bastion can only be created for a Shoot if that Shoot is already assigned to a Seed&lt;/li>
&lt;li>sets &lt;code>spec.seedName&lt;/code> and &lt;code>spec.providerType&lt;/code> based on the &lt;code>spec.shootRef&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>gardenlet&lt;/code>
&lt;ul>
&lt;li>Watches &lt;code>Bastion&lt;/code> resource for own seed under api group &lt;code>operations.gardener.cloud&lt;/code> in the garden cluster&lt;/li>
&lt;li>Creates &lt;code>Bastion&lt;/code> custom resource under api group &lt;code>extensions.gardener.cloud/v1alpha1&lt;/code> in the seed cluster
&lt;ul>
&lt;li>Populates bastion user data under field under &lt;code>spec.userData&lt;/code> similar to &lt;a href="https://github.com/gardener/gardenctl/blob/1e3e5fa1d5603e2161f45046ba7c6b5b4107369e/pkg/cmd/ssh.go#L160-L171">https://github.com/gardener/gardenctl/blob/1e3e5fa1d5603e2161f45046ba7c6b5b4107369e/pkg/cmd/ssh.go#L160-L171&lt;/a>. By this means the &lt;code>spec.sshPublicKey&lt;/code> from the &lt;code>Bastion&lt;/code> resource in the garden cluster will end up in the &lt;code>authorized_keys&lt;/code> file on the bastion host.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Gardener extension provider &lt;infra> / Bastion Controller on Seed:
&lt;ul>
&lt;li>With own &lt;code>Bastion&lt;/code> Custom Resource Definition in the seed under the api group &lt;code>extensions.gardener.cloud/v1alpha1&lt;/code>&lt;/li>
&lt;li>Watches &lt;code>Bastion&lt;/code> custom resources that are created by the &lt;code>gardenlet&lt;/code> in the seed&lt;/li>
&lt;li>Controller reads &lt;code>cloudprovider&lt;/code> credentials from seed-shoot namespace&lt;/li>
&lt;li>Deploy infrastructure resources
&lt;ul>
&lt;li>Bastion VM. Uses user data from &lt;code>spec.userData&lt;/code>&lt;/li>
&lt;li>attaches public IP, creates security group, firewall rules, etc.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Updates status of &lt;code>Bastion&lt;/code> resource:
&lt;ul>
&lt;li>With bastion IP under &lt;code>status.ingress.ip&lt;/code> or hostname under &lt;code>status.ingress.hostname&lt;/code>&lt;/li>
&lt;li>Updates the &lt;code>status.lastOperation&lt;/code> with the status of the last reconcile operation&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>gardenlet&lt;/code>
&lt;ul>
&lt;li>Syncs back the &lt;code>status.ingress&lt;/code> and &lt;code>status.conditions&lt;/code> of the &lt;code>Bastion&lt;/code> resource in the seed to the garden cluster in case it changed&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>gardenctl&lt;/code>
&lt;ul>
&lt;li>initiates &lt;code>ssh&lt;/code> session once &lt;code>status.conditions['BastionReady']&lt;/code> is true of the &lt;code>Bastion&lt;/code> resource in the garden cluster
&lt;ul>
&lt;li>locates private &lt;code>ssh&lt;/code> key matching &lt;code>spec[&amp;quot;sshPublicKey&amp;quot;]&lt;/code> which was configured beforehand by the user&lt;/li>
&lt;li>reads bastion IP (&lt;code>status.ingress.ip&lt;/code>) or hostname (&lt;code>status.ingress.hostname&lt;/code>)&lt;/li>
&lt;li>reads the private key from the &lt;code>ssh&lt;/code> key pair for the shoot node&lt;/li>
&lt;li>opens &lt;code>ssh&lt;/code> connection to the bastion and from there to the respective shoot node&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>runs heartbeat in parallel as long as the &lt;code>ssh&lt;/code> session is open by annotating the &lt;code>Bastion&lt;/code> resource with &lt;code>gardener.cloud/operation: keepalive&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>GCM&lt;/code>:
&lt;ul>
&lt;li>Once &lt;code>status.expirationTimestamp&lt;/code> is reached, the &lt;code>Bastion&lt;/code> will be marked for deletion&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>gardenlet&lt;/code>:
&lt;ul>
&lt;li>Once the &lt;code>Bastion&lt;/code> resource in the garden cluster is marked for deletion, it marks the &lt;code>Bastion&lt;/code> resource in the seed for deletion&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Gardener extension provider &lt;infra> / Bastion Controller on Seed:
&lt;ul>
&lt;li>all created resources will be cleaned up&lt;/li>
&lt;li>On succes, removes finalizer on &lt;code>Bastion&lt;/code> resource in seed&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;code>gardenlet&lt;/code>:
&lt;ul>
&lt;li>removes finalizer on &lt;code>Bastion&lt;/code> resource in garden cluster&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h3 id="resource-example">Resource Example&lt;/h3>
&lt;p>&lt;code>Bastion&lt;/code> resource in the garden cluster&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: operations.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Bastion
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> generateName: cli-
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: cli-abcdef
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden-myproject
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> annotations:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gardener.cloud/created-by: foo &lt;span style="color:#008000"># immutable, set by the GAPI Admission Plugin&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># gardener.cloud/operation: keepalive # this annotation is removed by the GAPI and the status.lastHeartbeatTimestamp and status.expirationTimestamp will be updated accordingly&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootRef: &lt;span style="color:#008000"># namespace cannot be set / it&amp;#39;s the same as .metadata.namespace&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-cluster &lt;span style="color:#008000"># immutable&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># the following fields are set by the GAPI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seedName: aws-eu2
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> providerType: aws
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sshPublicKey: c3NoLXJzYSAuLi4K &lt;span style="color:#008000"># immutable, public `ssh` key of the user&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ingress: &lt;span style="color:#008000"># can only be updated by the creator of the bastion&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - ipBlock:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cidr: 1.2.3.4/32 &lt;span style="color:#008000"># public IP of the user. CIDR is a string representing the IP Block. Valid examples are &amp;#34;192.168.1.1/24&amp;#34; or &amp;#34;2001:db9::/64&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: 1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># the following fields are managed by the controller in the seed and synced by gardenlet&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ingress: &lt;span style="color:#008000"># IP or hostname of the bastion&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ip: 1.2.3.5
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># hostname: foo.bar&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> conditions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: BastionReady &lt;span style="color:#008000"># when the `status` is true of condition type `BastionReady`, the client can initiate the `ssh` connection&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> status: &lt;span style="color:#a31515">&amp;#39;True&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastTransitionTime: &lt;span style="color:#a31515">&amp;#34;2021-03-19T11:59:00Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastUpdateTime: &lt;span style="color:#a31515">&amp;#34;2021-03-19T11:59:00Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reason: BastionReady
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> message: Bastion for the cluster is ready.
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># the following fields are only set by the GAPI&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastHeartbeatTimestamp: &lt;span style="color:#a31515">&amp;#34;2021-03-19T11:58:00Z&amp;#34;&lt;/span> &lt;span style="color:#008000"># will be set when setting the annotation gardener.cloud/operation: keepalive&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> expirationTimestamp: &lt;span style="color:#a31515">&amp;#34;2021-03-19T12:58:00Z&amp;#34;&lt;/span> &lt;span style="color:#008000"># extended on each keepalive&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>Bastion&lt;/code> custom resource in the seed cluster&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Bastion
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: cli-abcdef
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: shoot--myproject--mycluster
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> userData: |- &lt;span style="color:#008000"># this is normally base64-encoded, but decoded for the example. Contains spec.sshPublicKey from Bastion resource in garden cluster&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">#!/bin/bash&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># create user&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># add ssh public key to authorized_keys&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ingress:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - ipBlock:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cidr: 1.2.3.4/32
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: aws &lt;span style="color:#008000"># from extensionsv1alpha1.DefaultSpec&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>status:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> observedGeneration: 1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ingress:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ip: 1.2.3.5
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># hostname: foo.bar&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> conditions:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - type: BastionReady
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> status: &lt;span style="color:#a31515">&amp;#39;True&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastTransitionTime: &lt;span style="color:#a31515">&amp;#34;2021-03-19T11:59:00Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> lastUpdateTime: &lt;span style="color:#a31515">&amp;#34;2021-03-19T11:59:00Z&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> reason: BastionReady
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> message: Bastion for the cluster is ready.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="ssh-key-pair-rotation">SSH Key Pair Rotation&lt;/h2>
&lt;p>Currently, the &lt;code>ssh&lt;/code> key pair for the shoot nodes are created once during shoot cluster creation. These key pairs should be rotated on a regular basis.&lt;/p>
&lt;h3 id="rotation-proposal">Rotation Proposal&lt;/h3>
&lt;ul>
&lt;li>&lt;code>gardeneruser&lt;/code> original user data &lt;a href="https://github.com/gardener/gardener/tree/master/pkg/operation/botanist/component/extensions/operatingsystemconfig/original/components/gardeneruser">component&lt;/a>:
&lt;ul>
&lt;li>The &lt;code>gardeneruser&lt;/code> create script should be changed into a reconcile script script, and renamed accordingly. It needs to be adapted so that the &lt;code>authorized_keys&lt;/code> file will be updated / overwritten with the current and old &lt;code>ssh&lt;/code> public key from the cloud-config user data.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Rotation trigger:
&lt;ul>
&lt;li>Once in the maintenance time window&lt;/li>
&lt;li>On demand, by annotating the shoot with &lt;code>gardener.cloud/operation: rotate-ssh-keypair&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>On rotation trigger:
&lt;ul>
&lt;li>&lt;code>gardenlet&lt;/code>
&lt;ul>
&lt;li>Prerequisite of &lt;code>ssh&lt;/code> key pair rotation: all nodes of all the worker pools have successfully applied the desired version of their cloud-config user data&lt;/li>
&lt;li>Creates or updates the secret &lt;code>ssh-keypair.old&lt;/code> with the content of &lt;code>ssh-keypair&lt;/code> in the seed-shoot namespace. The old private key can be used by clients as fallback, in case the new &lt;code>ssh&lt;/code> public key is not yet applied on the node&lt;/li>
&lt;li>Generates new &lt;code>ssh-keypair&lt;/code> secret&lt;/li>
&lt;li>The &lt;code>OperatingSystemConfig&lt;/code> needs to be re-generated and deployed with the new and old &lt;code>ssh&lt;/code> public key&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>As usual (for more details, see &lt;a href="https://gardener.cloud/docs/gardener/extensions/operatingsystemconfig/">here&lt;/a>):
&lt;ul>
&lt;li>Once the &lt;code>cloud-config-&amp;lt;X&amp;gt;&lt;/code> secret in the &lt;code>kube-system&lt;/code> namespace of the shoot cluster is updated, it will be picked up by the &lt;a href="https://github.com/gardener/gardener/blob/master/pkg/operation/botanist/component/extensions/operatingsystemconfig/downloader/templates/scripts/download-cloud-config.tpl.sh">&lt;code>downloader&lt;/code> script&lt;/a> (checks every 30s for updates)&lt;/li>
&lt;li>The &lt;code>downloader&lt;/code> runs the &lt;a href="https://github.com/gardener/gardener/blob/master/pkg/operation/botanist/component/extensions/operatingsystemconfig/executor/templates/scripts/execute-cloud-config.tpl.sh">&amp;ldquo;execution&amp;rdquo; script&lt;/a> from the &lt;code>cloud-config-&amp;lt;X&amp;gt;&lt;/code> secret&lt;/li>
&lt;li>The &amp;ldquo;execution&amp;rdquo; script includes also the original user data script, which it writes to &lt;code>PATH_CLOUDCONFIG&lt;/code>, compares it against the previous cloud config and runs the script in case it has changed&lt;/li>
&lt;li>Running the &lt;a href="https://github.com/gardener/gardener/tree/master/pkg/operation/botanist/component/extensions/operatingsystemconfig/original">original user data&lt;/a> script will also run the &lt;code>gardeneruser&lt;/code> component, where the &lt;code>authorized_keys&lt;/code> file will be updated&lt;/li>
&lt;li>After the most recent cloud-config user data was applied, the &amp;ldquo;execution&amp;rdquo; script annotates the node with &lt;code>checksum/cloud-config-data: &amp;lt;cloud-config-checksum&amp;gt;&lt;/code> to indicate the success&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="limitations">Limitations&lt;/h3>
&lt;p>Each operating system has its own default user (e.g. &lt;code>core&lt;/code>, &lt;code>admin&lt;/code>, &lt;code>ec2-user&lt;/code> etc). These users get their SSH keys during VM creation (however there is a different handling on Google Cloud Platform as stated below). These keys currently do not get rotated respectively are not removed from the &lt;code>authorized_keys&lt;/code> file. This means that the initial &lt;code>ssh&lt;/code> key will still be valid for the default operating system user.&lt;/p>
&lt;p>On Google Cloud Platform, the VMs do not have any static users (i.e. no &lt;code>gardener&lt;/code> user) and there is an agent on the nodes that syncs the users with their SSH keypairs from the GCP IAM service.&lt;/p></description></item><item><title>Docs: CA Rotation</title><link>https://gardener.cloud/docs/gardener/extensions/ca-rotation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/extensions/ca-rotation/</guid><description>
&lt;h1 id="ca-rotation-in-extensions">CA Rotation in Extensions&lt;/h1>
&lt;p>&lt;a href="https://gardener.cloud/docs/gardener/proposals/18-shoot-ca-rotation/">GEP-18&lt;/a> proposes adding support for automated rotation of Shoot cluster certificate authorities (CAs).
This document outlines all requirements that Gardener extensions need to fulfill in order to support the CA rotation feature.&lt;/p>
&lt;h2 id="requirements-for-shoot-cluster-ca-rotation">Requirements for Shoot Cluster CA Rotation&lt;/h2>
&lt;ul>
&lt;li>Extensions must not rely on static CA &lt;code>Secret&lt;/code> names managed by gardenlet, because their names are changing during CA rotation.&lt;/li>
&lt;li>Extensions cannot issue or use client certificates for authenticating against shoot API servers. Instead, they should use short-lived auto-rotated &lt;code>ServiceAccount&lt;/code> tokens via gardener-resource-manager&amp;rsquo;s &lt;code>TokenRequestor&lt;/code>. Also see &lt;a href="https://gardener.cloud/docs/gardener/extensions/conventions/">Conventions&lt;/a> and &lt;a href="https://gardener.cloud/docs/gardener/concepts/resource-manager/#tokenrequestor">&lt;code>TokenRequestor&lt;/code>&lt;/a> documents.&lt;/li>
&lt;li>Extensions need to generate dedicated CAs for signing server certificates (e.g. &lt;code>cloud-controller-manager&lt;/code>). There should be one CA per controller and purpose in order to bind the lifecycle to the reconciliation cycle of the respective object for which it is created.&lt;/li>
&lt;li>CAs managed by extensions should be rotated in lock-step with the shoot cluster CA.
When the user triggers a rotation, gardenlet writes phase and initiation time to &lt;code>Shoot.status.credentials.rotation.certificateAuthorities.{phase,lastInitiationTime}&lt;/code>. See &lt;a href="https://gardener.cloud/docs/gardener/proposals/18-shoot-ca-rotation/#rotation-sequence-for-cluster-and-client-ca">GEP-18&lt;/a> for a detailed description on what needs to happen in each phase.
Extensions can retrieve this information from &lt;a href="https://gardener.cloud/docs/gardener/extensions/cluster/">&lt;code>Cluster.shoot.status&lt;/code>&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h2 id="utilities-for-secrets-management">Utilities for Secrets Management&lt;/h2>
&lt;p>In order to fulfill the requirements listed above, extension controllers can reuse the &lt;a href="https://gardener.cloud/docs/gardener/development/secrets_management/">&lt;code>SecretsManager&lt;/code>&lt;/a> that gardenlet uses to manage all shoot cluster CAs, certificates, and other secrets as well.
It implements the core logic for managing secrets that need to be rotated, auto-renewed etc.&lt;/p>
&lt;p>Additionally, there are utilities for reusing &lt;code>SecretsManager&lt;/code> in extension controllers.
They already implement above requirements based on the &lt;code>Cluster&lt;/code> resource and allow focusing on the extension controllers&amp;rsquo; business logic.&lt;/p>
&lt;p>For example, a simple &lt;code>SecretsManager&lt;/code> usage in an extension controller could look like this:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-go" data-lang="go">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00f">const&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// identity for SecretsManager instance in ControlPlane controller
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> identity = &lt;span style="color:#a31515">&amp;#34;provider-foo-controlplane&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// secret config name of the dedicated CA
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> caControlPlaneName = &lt;span style="color:#a31515">&amp;#34;ca-provider-foo-controlplane&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00f">func&lt;/span> Reconcile() {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#00f">var&lt;/span> (
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cluster *extensionscontroller.Cluster
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> client client.Client
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// define wanted secrets with options
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> secretConfigs = []extensionssecretsmanager.SecretConfigWithOptions{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// dedicated CA for ControlPlane controller
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> Config: &amp;amp;secretutils.CertificateSecretConfig{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Name: caControlPlaneName,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CommonName: &lt;span style="color:#a31515">&amp;#34;ca-provider-foo-controlplane&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CertType: secretutils.CACert,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// persist CA so that it gets restored on control plane migration
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> Options: []secretsmanager.GenerateOption{secretsmanager.Persist()},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// server cert for control plane component
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> Config: &amp;amp;secretutils.CertificateSecretConfig{
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> Name: &lt;span style="color:#a31515">&amp;#34;cloud-controller-manager&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CommonName: &lt;span style="color:#a31515">&amp;#34;cloud-controller-manager&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> DNSNames: kutil.DNSNamesForService(&lt;span style="color:#a31515">&amp;#34;cloud-controller-manager&amp;#34;&lt;/span>, namespace),
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> CertType: secretutils.ServerCert,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// sign with our dedicated CA
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> Options: []secretsmanager.GenerateOption{secretsmanager.SignedByCA(caControlPlaneName)},
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> },
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> }
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> )
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// initialize SecretsManager based on Cluster object
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> sm, err := extensionssecretsmanager.SecretsManagerForCluster(ctx, logger.WithName(&lt;span style="color:#a31515">&amp;#34;secretsmanager&amp;#34;&lt;/span>), clock.RealClock{}, client, cluster, identity, secretConfigs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// generate all wanted secrets (first CAs, then the rest)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> secrets, err := extensionssecretsmanager.GenerateAllSecrets(ctx, sm, secretConfigs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000">// cleanup any secrets that are not needed any more (e.g. after rotation)
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000">&lt;/span> err = sm.Cleanup(ctx)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Please pay attention to the following points:&lt;/p>
&lt;ul>
&lt;li>There should be one &lt;code>SecretsManager&lt;/code> identity per controller (and purpose if applicable) in order to prevent conflicts between different instances.
E.g., there should be different identities for &lt;code>Infrastructrue&lt;/code>, &lt;code>Worker&lt;/code> controller etc. and the &lt;code>ControlPlane&lt;/code> controller should use dedicated &lt;code>SecretsManager&lt;/code> identities per purpose (e.g. &lt;code>provider-foo-controlplane&lt;/code> and &lt;code>provider-foo-controlplane-exposure&lt;/code>).&lt;/li>
&lt;li>All other points in &lt;a href="https://gardener.cloud/docs/gardener/development/secrets_management/#reusing-the-secretsmanager-in-other-components">Reusing the SecretsManager in Other Components&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: Can I run privileged containers?</title><link>https://gardener.cloud/docs/faq/privileged-containers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/faq/privileged-containers/</guid><description>
&lt;p>While it is possible, we highly recommend not to use privileged containers in your productive environment.&lt;/p></description></item><item><title>Docs: Can Kubernetes upgrade automatically?</title><link>https://gardener.cloud/docs/faq/automatic-upgrade/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/faq/automatic-upgrade/</guid><description>
&lt;p>There is no automatic migration of major/minor versions of Kubernetes. You need to update your clusters manually or press the &lt;em>Upgrade&lt;/em> button in the Dashboard.&lt;/p>
&lt;p>Before updating a cluster you should be aware of the potential errors this might cause. The following video will dive into a Kubernetes outage in production that Monzo experienced, its causes and effects, and the architectural and operational lessons learned.&lt;/p>
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/OUYTNywPk-s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>&lt;/iframe>
&lt;p>It is therefore recommended to first update your test cluster and validate it before performing changes on a productive environment.&lt;/p></description></item><item><title>Docs: Can you backup your Kubernetes cluster resources?</title><link>https://gardener.cloud/docs/faq/backup/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/faq/backup/</guid><description>
&lt;p>Backing up your Kubernetes cluster is possible through the use of specialized software like &lt;a href="https://velero.io/">Velero&lt;/a>. Velero consists of a server side component and a client tool that allow you to backup or restore all objects in your cluster, as well as the cluster resources and persistent volumes.&lt;/p></description></item><item><title>Docs: Can you migrate the content of one cluster to another cluster?</title><link>https://gardener.cloud/docs/faq/automatic-migrate/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/faq/automatic-migrate/</guid><description>
&lt;p>The migration of clusters or content from one cluster to another is out of scope for the Gardener project. For such scenarios you may consider using tools like &lt;a href="https://velero.io/">Velero&lt;/a>.&lt;/p></description></item><item><title>Docs: Changing the APIs</title><link>https://gardener.cloud/docs/gardener/development/changing-the-api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/development/changing-the-api/</guid><description>
&lt;h1 id="extending-the-api">Extending the API&lt;/h1>
&lt;p>This document describes the steps that need to be performed when changing the API.
It provides guidance for API changes to both (Gardener system in general or component configurations).&lt;/p>
&lt;p>Generally, as Gardener is a Kubernetes-native extension, it follows the same API conventions and guidelines like Kubernetes itself.
&lt;a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md">This document&lt;/a> as well as &lt;a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api_changes.md">this document&lt;/a> already provide a good overview and general explanation of the basic concepts behind it.
We are following the same approaches.&lt;/p>
&lt;h2 id="gardener-api">Gardener API&lt;/h2>
&lt;p>The Gardener API is defined in &lt;code>pkg/apis/{core,extensions,settings}&lt;/code> directories and is the main point of interaction with the system.
It must be ensured that the API is always backwards-compatible.
If fields shall be removed permanently from the API then a proper deprecation period must be adhered to so that end-users have enough time adapt their clients.&lt;/p>
&lt;p>&lt;strong>Checklist&lt;/strong> when changing the API:&lt;/p>
&lt;ol>
&lt;li>Modify the field(s) in the respective Golang files of all external and the internal version.
&lt;ol>
&lt;li>Make sure new fields are being added as &amp;ldquo;optional&amp;rdquo; fields, i.e., they are of pointer types, they have the &lt;code>// +optional&lt;/code> comment, and they have the &lt;code>omitempty&lt;/code> JSON tag.&lt;/li>
&lt;li>Make sure that the existing field numbers in the protobuf tags are not changed.&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>If necessary then implement/adapt the conversion logic defined in the versioned APIs (e.g., &lt;code>pkg/apis/core/v1beta1/conversions*.go&lt;/code>).&lt;/li>
&lt;li>If necessary then implement/adapt defaulting logic defined in the versioned APIs (e.g., &lt;code>pkg/apis/core/v1beta1/defaults*.go&lt;/code>).&lt;/li>
&lt;li>Run the code generation: &lt;code>make generate&lt;/code>&lt;/li>
&lt;li>If necessary then implement/adapt validation logic defined in the internal API (e.g., &lt;code>pkg/apis/core/validation/validation*.go&lt;/code>).&lt;/li>
&lt;li>If necessary then adapt the exemplary YAML manifests of the Gardener resources defined in &lt;code>example/*.yaml&lt;/code>.&lt;/li>
&lt;li>In most cases it makes sense to add/adapt the documentation for administrators/operators and/or end-users in the &lt;code>docs&lt;/code> folder to provide information on purpose and usage of the added/changed fields.&lt;/li>
&lt;li>When opening the pull request then always add a release note so that end-users are becoming aware of the changes.&lt;/li>
&lt;/ol>
&lt;h2 id="component-configuration-apis">Component configuration APIs&lt;/h2>
&lt;p>Most Gardener components have a component configuration that follows similar principles to the Gardener API.
Those component configurations are defined in &lt;code>pkg/{controllermanager,gardenlet,scheduler},pkg/apis/config&lt;/code>.
Hence, the above checklist also applies for changes to those APIs.
However, since these APIs are only used internally and only during the deployment of Gardener the guidelines with respect to changes and backwards-compatibility are slightly relaxed.
If necessary then it is allowed to remove fields without a proper deprecation period if the release note uses the &lt;code>breaking operator&lt;/code> keywords.&lt;/p>
&lt;p>In addition to the above checklist:&lt;/p>
&lt;ol>
&lt;li>If necessary then adapt the Helm chart of Gardener defined in &lt;code>charts/gardener&lt;/code>. Adapt the &lt;code>values.yaml&lt;/code> file as well as the manifest templates.&lt;/li>
&lt;/ol></description></item><item><title>Docs: Cluster</title><link>https://gardener.cloud/docs/gardener/extensions/cluster/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/extensions/cluster/</guid><description>
&lt;h1 id="cluster-resource">&lt;code>Cluster&lt;/code> resource&lt;/h1>
&lt;p>As part of the extensibility epic a lot of responsibility that was previously taken over by Gardener directly has now been shifted to extension controllers running in the seed clusters.
These extensions often serve a well-defined purpose, e.g. the management of &lt;a href="https://github.com/gardener/gardener/blob/master/docs/extensions/dns.md">DNS records&lt;/a>, &lt;a href="https://gardener.cloud/docs/gardener/extensions/infrastructure/">infrastructure&lt;/a>, etc.
We have introduced a couple of extension CRDs in the seeds whose specification is written by Gardener, and which are acted up by the extensions.&lt;/p>
&lt;p>However, the extensions sometimes require more information that is not directly part of the specification.
One example of that is the GCP infrastructure controller which needs to know the shoot&amp;rsquo;s pod and service network.
Another example is the Azure infrastructure controller which requires some information out of the &lt;code>CloudProfile&lt;/code> resource.
The problem is that Gardener does not know which extension requires which information so that it can write it into their specific CRDs.&lt;/p>
&lt;p>In order to deal with this problem we have introduced the &lt;code>Cluster&lt;/code> extension resource.
This CRD is written into the seeds, however, it does not contain a &lt;code>status&lt;/code>, so it is not expected that something acts upon it.
Instead, you can treat it like a &lt;code>ConfigMap&lt;/code> which contains data that might be interesting for you.
In the context of Gardener, seeds and shoots, and extensibility the &lt;code>Cluster&lt;/code> resource contains the &lt;code>CloudProfile&lt;/code>, &lt;code>Seed&lt;/code>, and &lt;code>Shoot&lt;/code> manifest.
Extension controllers can take whatever information they want out of it that might help completing their individual tasks.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Cluster
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: shoot--foo--bar
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> cloudProfile:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: core.gardener.cloud/v1beta1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: CloudProfile
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> seed:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: core.gardener.cloud/v1beta1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: Seed
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shoot:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> apiVersion: core.gardener.cloud/v1beta1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kind: Shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ...
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The resource is written by Gardener before it starts the reconciliation flow of the shoot.&lt;/p>
&lt;p>⚠️ All Gardener components use the &lt;code>core.gardener.cloud/v1beta1&lt;/code> version, i.e., the &lt;code>Cluster&lt;/code> resource will contain the objects in this version.&lt;/p>
&lt;h2 id="important-information-that-should-be-taken-into-account">Important information that should be taken into account&lt;/h2>
&lt;p>There are some fields in the &lt;code>Shoot&lt;/code> specification that might be interesting to take into account.&lt;/p>
&lt;ul>
&lt;li>&lt;code>.spec.hibernation.enabled={true,false}&lt;/code>: Extension controllers might want to behave differently if the shoot is hibernated or not (probably they might want to scale down their control plane components, for example).&lt;/li>
&lt;li>&lt;code>.status.lastOperation.state=Failed&lt;/code>: If Gardener sets the shoot&amp;rsquo;s last operation state to &lt;code>Failed&lt;/code> it means that Gardener won&amp;rsquo;t automatically retry to finish the reconciliation/deletion flow because an error occurred that could not be resolved within the last &lt;code>24h&lt;/code> (default). In this case end-users are expected to manually re-trigger the reconciliation flow in case they want Gardener to try again. Extension controllers are expected to follow the same principle. This means they have to read the shoot state out of the &lt;code>Cluster&lt;/code> resource.&lt;/li>
&lt;/ul>
&lt;h2 id="extension-resources-not-associated-with-a-shoot">Extension resources not associated with a shoot&lt;/h2>
&lt;p>In some cases, Gardener may create extension resources that are not associated with a shoot, but are needed to support some functionality internal to Gardener. Such resources will be created in the &lt;code>garden&lt;/code> namespace of a seed cluster.&lt;/p>
&lt;p>For example, if the &lt;a href="https://gardener.cloud/docs/gardener/deployment/deploy_gardenlet_manually/">managed ingress controller&lt;/a> is active on the seed, Gardener will create a &lt;a href="https://gardener.cloud/docs/gardener/extensions/dnsrecord/">DNSRecord&lt;/a> resource(s) in the &lt;code>garden&lt;/code> namespace of the seed cluster for the ingress DNS record.&lt;/p>
&lt;p>Extension controllers that may be expected to reconcile extension resources in the &lt;code>garden&lt;/code> namespace should make sure that they can tolerate the absence of a cluster resource. This means that they should not attempt to read the cluster resource in such cases, or if they do they should ignore the &amp;ldquo;not found&amp;rdquo; error.&lt;/p>
&lt;h2 id="references-and-additional-resources">References and additional resources&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_cluster.go">&lt;code>Cluster&lt;/code> API (Golang specification)&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: Cluster API</title><link>https://gardener.cloud/docs/gardener/concepts/cluster-api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/concepts/cluster-api/</guid><description>
&lt;h1 id="relation-between-gardener-api-and-cluster-api-sig-cluster-lifecycle">Relation between Gardener API and Cluster API (SIG Cluster Lifecycle)&lt;/h1>
&lt;p>In essence, the Cluster API harmonizes how to get to clusters, while Gardener goes one step further and also harmonizes the clusters themselves. The Cluster API delegates the specifics to so-called providers for infrastructures or control planes via specific CR(D)s while Gardener only has one cluster CR(D). Different Cluster API providers, e.g. for AWS, Azure, GCP, etc. give you vastly different Kubernetes clusters. In contrast, Gardener gives you the exact same clusters with the exact same K8s version, operating system, control plane configuration like for API server or kubelet, add-ons like overlay network, HPA/VPA, DNS and certificate controllers, ingress and network policy controllers, control plane monitoring and logging stacks, down to the behavior of update procedures, auto-scaling, self-healing, etc. on all supported infrastructures. These homogeneous clusters are an essential goal for Gardener as its main purpose is to simplify operations for teams that need to develop and ship software on Kubernetes clusters on a plethora of infrastructures (a.k.a. multi-cloud).&lt;/p>
&lt;p>Incidentally, Gardener influenced the Machine API in the Cluster API with its &lt;a href="https://github.com/gardener/machine-controller-manager">Machine Controller Manager&lt;/a> and was the &lt;a href="https://github.com/kubernetes-sigs/cluster-api/commit/00b1ead264aea6f88585559056c180771cce3815">first to adopt it&lt;/a>, see also &lt;a href="https://www.youtube.com/watch?v=Mtg8jygK3Hs">joint SIG Cluster Lifecycle KubeCon talk&lt;/a> where @hardikdr from our Gardener team in India spoke.&lt;/p>
&lt;p>That means, we follow the &lt;a href="https://github.com/kubernetes-sigs/cluster-api#cluster-api">Cluster API&lt;/a> with great interest and are active members. It was completely overhauled from &lt;code>v1alpha1&lt;/code> to &lt;code>v1alpha2&lt;/code>. But because &lt;code>v1alpha2&lt;/code> made too many assumptions about the bring-up of masters and was enforcing master machine operations (see &lt;a href="https://cluster-api.sigs.k8s.io/user/concepts.html#control-plane">here&lt;/a>: “As of &lt;code>v1alpha2&lt;/code>, Machine-Based is the only control plane type that Cluster API supports”), services that managed their control planes differently like GKE or Gardener couldn&amp;rsquo;t adopt it (e.g. &lt;a href="https://cloud.google.com/anthos/gke/docs/on-prem/concepts/cluster-api">Google only supports &lt;code>v1alpha1&lt;/code>&lt;/a>). In 2020 &lt;a href="https://kubernetes.io/blog/2020/04/21/cluster-api-v1alpha3-delivers-new-features-and-an-improved-user-experience/">&lt;code>v1alpha3&lt;/code>&lt;/a> was introduced and made it possible (again) to integrate managed services like GKE or Gardener. The mapping from the Gardener API to the Cluster API is mostly syntactic.&lt;/p>
&lt;p>To wrap it up, while the Cluster API knows about clusters, it doesn&amp;rsquo;t know about their make-up. With Gardener, we wanted to go beyond that and harmonize the make-up of the clusters themselves and make them homogeneous across all supported infrastructures. Gardener can therefore deliver homogeneous clusters with exactly the same configuration and behavior on all infrastructures (see also &lt;a href="https://k8s-testgrid.appspot.com/conformance-all">Gardener&amp;rsquo;s coverage in the official conformance test grid&lt;/a>).&lt;/p>
&lt;p>With &lt;a href="https://kubernetes.io/blog/2020/04/21/cluster-api-v1alpha3-delivers-new-features-and-an-improved-user-experience">Cluster API &lt;code>v1alpha3&lt;/code>&lt;/a> and the support for declarative control plane management, it became now possible (again) to enable Kubernetes managed services like GKE or Gardener. We would be more than happy, if the community would be interested, to contribute a Gardener control plane provider.&lt;/p></description></item><item><title>Docs: Concept Topic Structure</title><link>https://gardener.cloud/docs/contribute/20_documentation/40_style_guide/concept_template/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/contribute/20_documentation/40_style_guide/concept_template/</guid><description>
&lt;h1 id="concept-title">Concept Title&lt;/h1>
&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>This section provides an overview of the topic and the information provided in it.&lt;/p>
&lt;h2 id="relevant-heading-1">Relevant heading 1&lt;/h2>
&lt;p>This section gives the user all the information needed in order to understand the topic.&lt;/p>
&lt;h3 id="relevant-subheading">Relevant subheading&lt;/h3>
&lt;p>This adds information that belongs to the topic discussed in the parent heading&lt;/p>
&lt;h2 id="relevant-heading-2">Relevant heading 2&lt;/h2>
&lt;p>This section gives the user all the information needed in order to understand the topic.&lt;/p>
&lt;h2 id="related-links">Related Links&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://gardener.cloud/docs/contribute/20_documentation/40_style_guide/concept_template/">Link 1&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gardener.cloud/docs/contribute/20_documentation/40_style_guide/concept_template/">Link 2&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: Configuration</title><link>https://gardener.cloud/docs/gardener/usage/configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/usage/configuration/</guid><description>
&lt;h1 id="gardener-configuration-and-usage">Gardener Configuration and Usage&lt;/h1>
&lt;p>Gardener automates the full lifecycle of Kubernetes clusters as a service.
Additionally, it has several extension points allowing external controllers to plug-in to the lifecycle.
As a consequence, there are several configuration options for the various custom resources that are partially required.&lt;/p>
&lt;p>This document describes the&lt;/p>
&lt;ol>
&lt;li>&lt;a href="#configuration-and-usage-of-gardener-as-operatoradministrator">configuration and usage of Gardener as operator/administrator&lt;/a>.&lt;/li>
&lt;li>&lt;a href="#configuration-and-usage-of-gardener-as-end-userstakeholdercustomer">configuration and usage of Gardener as end-user/stakeholder/customer&lt;/a>.&lt;/li>
&lt;/ol>
&lt;h2 id="configuration-and-usage-of-gardener-as-operatoradministrator">Configuration and Usage of Gardener as Operator/Administrator&lt;/h2>
&lt;p>When we use the terms &amp;ldquo;operator/administrator&amp;rdquo; we refer to both the people deploying and operating Gardener.
Gardener consists of the following components:&lt;/p>
&lt;ol>
&lt;li>&lt;code>gardener-apiserver&lt;/code>, a Kubernetes-native API extension that serves custom resources in the Kubernetes-style (like &lt;code>Seed&lt;/code>s and &lt;code>Shoot&lt;/code>s), and a component that contains multiple admission plugins.&lt;/li>
&lt;li>&lt;code>gardener-admission-controller&lt;/code>, an HTTP(S) server with several handlers to be used in a &lt;a href="https://github.com/gardener/gardener/blob/master/charts/gardener/controlplane/charts/application/templates/validatingwebhook-admission-controller.yaml">ValidatingWebhookConfiguration&lt;/a>.&lt;/li>
&lt;li>&lt;code>gardener-controller-manager&lt;/code>, a component consisting out of multiple controllers that implement reconciliation and deletion flows for some of the custom resources (e.g., it contains the logic for maintaining &lt;code>Shoot&lt;/code>s, reconciling &lt;code>Plant&lt;/code>s, etc.).&lt;/li>
&lt;li>&lt;code>gardener-scheduler&lt;/code>, a component that assigns newly created &lt;code>Shoot&lt;/code> clusters to appropriate &lt;code>Seed&lt;/code> clusters.&lt;/li>
&lt;li>&lt;code>gardenlet&lt;/code>, a component running in seed clusters and consisting out of multiple controllers that implement reconciliation and deletion flows for some of the custom resources (e.g., it contains the logic for reconciliation and deletion of &lt;code>Shoot&lt;/code>s).&lt;/li>
&lt;/ol>
&lt;p>Each of these components have various configuration options.
The &lt;code>gardener-apiserver&lt;/code> uses the standard API server library maintained by the Kubernetes community, and as such it mainly supports command line flags.
Other components use so-called componentconfig files that describe their configuration in a Kubernetes-style versioned object.&lt;/p>
&lt;h3 id="configuration-file-for-gardener-admission-controller">Configuration file for Gardener admission controller&lt;/h3>
&lt;p>The Gardener admission controller does only support one command line flag which should be a path to a valid admission-controller configuration file.
Please take a look at &lt;a href="https://github.com/gardener/gardener/blob/master/example/20-componentconfig-gardener-admission-controller.yaml">this&lt;/a> example configuration.&lt;/p>
&lt;h3 id="configuration-file-for-gardener-controller-manager">Configuration file for Gardener controller manager&lt;/h3>
&lt;p>The Gardener controller manager does only support one command line flag which should be a path to a valid controller-manager configuration file.
Please take a look at &lt;a href="https://github.com/gardener/gardener/blob/master/example/20-componentconfig-gardener-controller-manager.yaml">this&lt;/a> example configuration.&lt;/p>
&lt;h3 id="configuration-file-for-gardener-scheduler">Configuration file for Gardener scheduler&lt;/h3>
&lt;p>The Gardener scheduler also only supports one command line flag which should be a path to a valid scheduler configuration file.
Please take a look at &lt;a href="https://github.com/gardener/gardener/blob/master/example/20-componentconfig-gardener-scheduler.yaml">this&lt;/a> example configuration.
Information about the concepts of the Gardener scheduler can be found &lt;a href="https://gardener.cloud/docs/gardener/concepts/scheduler/">here&lt;/a>&lt;/p>
&lt;h3 id="configuration-file-for-gardenlet">Configuration file for Gardenlet&lt;/h3>
&lt;p>The Gardenlet also only supports one command line flag which should be a path to a valid gardenlet configuration file.
Please take a look at &lt;a href="https://github.com/gardener/gardener/blob/master/example/20-componentconfig-gardenlet.yaml">this&lt;/a> example configuration.
Information about the concepts of the Gardenlet can be found &lt;a href="https://gardener.cloud/docs/gardener/concepts/gardenlet/">here&lt;/a>&lt;/p>
&lt;h3 id="system-configuration">System configuration&lt;/h3>
&lt;p>After successful deployment of the four components you need to setup the system.
Let&amp;rsquo;s first focus on some &amp;ldquo;static&amp;rdquo; configuration.
When the &lt;code>gardenlet&lt;/code> starts it scans the &lt;code>garden&lt;/code> namespace of the garden cluster for &lt;code>Secret&lt;/code>s that have influence on its reconciliation loops, mainly the &lt;code>Shoot&lt;/code> reconciliation:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Internal domain secret&lt;/strong>, contains the DNS provider credentials (having appropriate privileges) which will be used to create/delete so-called &amp;ldquo;internal&amp;rdquo; DNS records for the Shoot clusters, please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/10-secret-internal-domain.yaml">this&lt;/a> for an example.&lt;/p>
&lt;ul>
&lt;li>This secret is used in order to establish a stable endpoint for shoot clusters which is used internally by all control plane components.&lt;/li>
&lt;li>The DNS records are normal DNS records but called &amp;ldquo;internal&amp;rdquo; in our scenario because only the kubeconfigs for the control plane components use this endpoint when talking to the shoot clusters.&lt;/li>
&lt;li>It is forbidden to change the internal domain secret if there are existing shoot clusters.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Default domain secrets&lt;/strong> (optional), contain the DNS provider credentials (having appropriate privileges) which will be used to create/delete DNS records for a default domain for shoots (e.g., &lt;code>example.com&lt;/code>), please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/10-secret-default-domain.yaml">this&lt;/a> for an example.&lt;/p>
&lt;ul>
&lt;li>Not every end-user/stakeholder/customer has its own domain, however, Gardener needs to create a DNS record for every shoot cluster.&lt;/li>
&lt;li>As landscape operator you might want to define a default domain owned and controlled by you that is used for all shoot clusters that don&amp;rsquo;t specify their own domain.&lt;/li>
&lt;li>If you have multiple default domain secrets defined you can add a priority as an annotation (&lt;code>dns.gardener.cloud/domain-default-priority&lt;/code>) to select which domain should be used for new shoots while creation. The domain with the highest priority is selected while shoot creation. If there is no annotation defined the default priority is &lt;code>0&lt;/code>, also all non integer values are considered as priority &lt;code>0&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>⚠️ Please note that the mentioned domain secrets are only needed if you have at least one seed cluster that is not specifing &lt;code>.spec.settings.shootDNS.enabled=false&lt;/code>.
Seeds with this taint don&amp;rsquo;t create any DNS records for shoots scheduled on it, hence, if you only have such seeds, you don&amp;rsquo;t need to create the domain secrets.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Alerting secrets&lt;/strong> (optional), contain the alerting configuration and credentials for the &lt;a href="https://prometheus.io/docs/alerting/alertmanager/">AlertManager&lt;/a> to send email alerts. It is also possible to configure the monitoring stack to send alerts to an AlertManager not deployed by Gardener to handle alerting. Please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/10-secret-alerting.yaml">this&lt;/a> for an example.&lt;/p>
&lt;ul>
&lt;li>If email alerting is configured:
&lt;ul>
&lt;li>An AlertManager is deployed into each seed cluster that handles the alerting for all shoots on the seed cluster.&lt;/li>
&lt;li>Gardener will inject the SMTP credentials into the configuration of the AlertManager.&lt;/li>
&lt;li>The AlertManager will send emails to the configured email address in case any alerts are firing.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>If an external AlertManager is configured:
&lt;ul>
&lt;li>Each shoot has a &lt;a href="https://prometheus.io/docs/introduction/overview/">Prometheus&lt;/a> responsible for monitoring components and sending out alerts. The alerts will be sent to a URL configured in the alerting secret.&lt;/li>
&lt;li>This external AlertManager is not managed by Gardener and can be configured however the operator sees fit.&lt;/li>
&lt;li>Supported authentication types are no authentication, basic, or mutual TLS.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>OpenVPN Diffie-Hellmann Key secret&lt;/strong> (optional), contains the self-generated Diffie-Hellmann key used by OpenVPN in your landscape, please see &lt;a href="https://github.com/gardener/gardener/blob/master/example/10-secret-openvpn-diffie-hellman.yaml">this&lt;/a> for an example.&lt;/p>
&lt;ul>
&lt;li>If you don&amp;rsquo;t specify a custom key then a default key is used, but for productive landscapes it&amp;rsquo;s recommend to create a landscape-specific key and define it.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Global monitoring secrets&lt;/strong> (optional), contains basic authentication credentials for the Prometheus aggregating metrics for all clusters.&lt;/p>
&lt;ul>
&lt;li>These secrets are synced to each seed cluster and used to gain access to the aggregate monitoring components.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Apart from this &amp;ldquo;static&amp;rdquo; configuration there are several custom resources extending the Kubernetes API and used by Gardener.
As an operator/administrator you have to configure some of them to make the system work.&lt;/p>
&lt;h3 id="configuration-and-usage-of-gardener-as-end-userstakeholdercustomer">Configuration and Usage of Gardener as End-User/Stakeholder/Customer&lt;/h3>
&lt;p>As an end-user/stakeholder/customer you are using a Gardener landscape that has been setup for you by another team.
You don&amp;rsquo;t need to care about how Gardener itself has to be configured or how it has to be deployed.
Take a look at &lt;a href="https://gardener.cloud/docs/gardener/concepts/apiserver/">this document&lt;/a> - it describes which resources are offered by Gardener.
You may want to have a more detailed look for &lt;code>Project&lt;/code>s, &lt;code>SecretBinding&lt;/code>s, &lt;code>Shoot&lt;/code>s, &lt;code>Plant&lt;/code>s, and &lt;code>(Cluster)OpenIDConnectPreset&lt;/code>s.&lt;/p></description></item><item><title>Docs: Configuring Logging</title><link>https://gardener.cloud/docs/gardener/deployment/configuring_logging/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/deployment/configuring_logging/</guid><description>
&lt;h1 id="configuring-the-logging-stack-via-gardenlet-configurations">Configuring the Logging stack via Gardenlet configurations&lt;/h1>
&lt;h1 id="enable-the-logging">Enable the Logging&lt;/h1>
&lt;p>In order to install the Gardener logging stack the &lt;code>logging.enabled&lt;/code> configuration option has to be enabled in the Gardenlet configuration:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>logging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>From now on each Seed is going to have a logging stack which will collect logs from all pods and some systemd services. Logs related to Shoots with &lt;code>testing&lt;/code> purpose are dropped in the &lt;code>fluent-bit&lt;/code> output plugin. Shoots with a purpose different than &lt;code>testing&lt;/code> have the same type of log aggregator (but different instance) as the Seed. The logs can be viewed in the Grafana in the &lt;code>garden&lt;/code> namespace for the Seed components and in the respective shoot control plane namespaces.&lt;/p>
&lt;h1 id="enable-logs-from-the-shoots-node-systemd-services">Enable logs from the Shoot&amp;rsquo;s node systemd services.&lt;/h1>
&lt;p>The logs from the systemd services on each node can be retrieved by enabling the &lt;code>logging.shootNodeLogging&lt;/code> option in the Gardenlet configuration:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>logging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootNodeLogging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> shootPurposes:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#a31515">&amp;#34;evaluation&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - &lt;span style="color:#a31515">&amp;#34;deployment&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Under the &lt;code>shootPurpose&lt;/code> section just list all the shoot purposes for which the Shoot node logging feature will be enabled. Specifying the &lt;code>testing&lt;/code> purpose has no effect because this purpose prevents the logging stack installation.
Logs can be viewed in the operator Grafana!
The dedicated labels are &lt;code>unit&lt;/code>, &lt;code>syslog_identifier&lt;/code> and &lt;code>nodename&lt;/code> in the &lt;code>Explore&lt;/code> menu.&lt;/p>
&lt;h1 id="configuring-the-log-processor">Configuring the log processor&lt;/h1>
&lt;p>Under &lt;code>logging.fluentBit&lt;/code> there is three optional sections.&lt;/p>
&lt;ul>
&lt;li>&lt;code>input&lt;/code>: This overwrite the input configuration of the fluent-bit log processor.&lt;/li>
&lt;li>&lt;code>output&lt;/code>: This overwrite the output configuration of the fluent-bit log processor.&lt;/li>
&lt;li>&lt;code>service&lt;/code>: This overwrite the service configuration of the fluent-bit log processor.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>logging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fluentBit:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> output: |-&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Output]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> input: |-&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Input]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: |-&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Service]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ...&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="additional-egress-ipblock-for-allow-fluentbit-networkpolicy">additional egress IPBlock for allow-fluentbit NetworkPolicy&lt;/h1>
&lt;p>The optional setting under &lt;code>logging.fluentBit.networkPolicy.additionalEgressIPBlocks&lt;/code> add additional egress IPBlock to &lt;code>allow-fluentbit&lt;/code> NetworkPolicy to forward logs to a central system.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>logging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fluentBit:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> additionalEgressIpBlock:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - 123.123.123.123/32
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="configuring-the-loki-priorityclass">Configuring the Loki PriorityClass&lt;/h1>
&lt;p>The central Loki, which is in the &lt;code>garden&lt;/code> namespace, contains all the logs from the most important seed components. When the central Loki &lt;code>PriorityClass&lt;/code> is with low value then its pods can be preempted and often moved from one node to another while Kubernetes tries to free space for more important pods. The persistent volume will be detached/attached again as well. Based on the performance of the underlying infrastructure, this leads to great central Loki downtime. To give greater priority of the seed Loki you can use the &lt;code>logging.loki.garden.priority&lt;/code> option.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>logging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loki:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> garden:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> priority: 100
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="configure-central-logging">Configure central logging&lt;/h1>
&lt;p>For central logging, the output configuration of the fluent-bit log processor can be overwritten (&lt;code>logging.fluentBit.output&lt;/code>) and the Loki instances deployments in Garden and Shoot namespace can be enabled/disabled (&lt;code>logging.loki.enabled&lt;/code>), by default Loki is enabled.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>logging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fluentBit:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> output: |-&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Output]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loki:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">false&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="configuring-central-loki-storage-capacity">Configuring central Loki storage capacity&lt;/h1>
&lt;p>By default, the central Loki has &lt;code>100Gi&lt;/code> of storage capacity.
To overwrite the current central Loki storage capacity, the &lt;code>logging.loki.garden.storage&lt;/code> setting in the gardenlet&amp;rsquo;s component configuration should be altered.
If you need to increase it you can do so without losing the current data by specifying higher capacity. Doing so, the Loki&amp;rsquo;s &lt;code>PersistentVolume&lt;/code> capacity will be increased instead of deleting the current PV.
However, if you specify less capacity then the &lt;code>PersistentVolume&lt;/code> will be deleted and with it the logs, too.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>logging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enabled: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fluentBit:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> output: |-&lt;span style="color:#a31515">
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> [Output]
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515"> ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> loki:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> garden:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> storage: &lt;span style="color:#a31515">&amp;#34;200Gi&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Connect Kubectl</title><link>https://gardener.cloud/docs/dashboard/usage/connect-kubectl/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/dashboard/usage/connect-kubectl/</guid><description>
&lt;h1 id="connect-kubectl">Connect kubectl&lt;/h1>
&lt;p>In Kubernetes, the configuration for access to your cluster is a format known as &lt;code>kubeconfig&lt;/code> that is normally stored as a file. It contains details such as cluster API server addresses and user access credentials. Treat it as sensitive data. Tools like &lt;code>kubectl&lt;/code> use &lt;code>kubeconfig&lt;/code> to connect and authenticate to a cluster and perform operations on it.
Learn more about &lt;a href="https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/">kubeconfig&lt;/a> and &lt;a href="https://kubernetes.io/docs/reference/kubectl/overview/">kubectl&lt;/a> on &lt;a href="https://kubernetes.io">kubernetes.io&lt;/a>.&lt;/p>
&lt;h3 id="prerequisites">Prerequisites&lt;/h3>
&lt;ul>
&lt;li>You are logged on to the Gardener Dashboard.&lt;/li>
&lt;li>You have created a cluster and its status is operational.&lt;/li>
&lt;/ul>
&lt;p>On this page:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#downloading-kubeconfig-for-a-cluster">Downloading kubeconfig for a cluster&lt;/a>&lt;/li>
&lt;li>&lt;a href="#connecting-to-the-cluster">Connecting to the cluster&lt;/a>&lt;/li>
&lt;li>&lt;a href="#exporting-kubeconfig-environment-variable">Exporting KUBECONFIG environment variable&lt;/a>&lt;/li>
&lt;/ul>
&lt;br/>
&lt;h3 id="downloading-kubeconfig-for-a-cluster">Downloading kubeconfig for a cluster&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>Select your project from the dropdown on the left, then choose &lt;strong>CLUSTERS&lt;/strong> and locate your cluster in the list. Choose the &lt;em>key&lt;/em> icon to bring up a dialog with the access options.&lt;/p>
&lt;img src="https://gardener.cloud/__resources/01-select-cluster_524ec7.png">
&lt;p>In the &lt;strong>Kubeconfig&lt;/strong> section the options are to &lt;em>download&lt;/em>, &lt;em>copy&lt;/em> or &lt;em>view&lt;/em> the &lt;code>kubeconfig&lt;/code> for the cluster.
The same options are available also in the &lt;strong>Access&lt;/strong> section in the cluster details screen. To find it, choose a cluster from the list.&lt;/p>
&lt;img src="https://gardener.cloud/__resources/01-access-1_742623.png">
&lt;/li>
&lt;li>
&lt;p>Choose the download icon to download &lt;code>kubeconfig&lt;/code> as file on your local system.&lt;/p>
&lt;img style="max-width: 40%" src="https://gardener.cloud/__resources/02-download_48ab9b.png">
&lt;/li>
&lt;/ol>
&lt;h3 id="connecting-to-the-cluster">Connecting to the cluster&lt;/h3>
&lt;p>In the following command, change &lt;code>&amp;lt;path-to-kubeconfig&amp;gt;&lt;/code> with the actual path to the file where you stored the &lt;code>kubeconfig&lt;/code> downloaded in the previous steps.&lt;/p>
&lt;pre tabindex="0">&lt;code>$ kubectl --kubeconfig=&amp;lt;path-to-kubeconfig&amp;gt; get namespaces
&lt;/code>&lt;/pre>&lt;p>The command connects to the cluster and list its namespaces.&lt;/p>
&lt;h3 id="exporting-kubeconfig-environment-variable">Exporting KUBECONFIG environment variable&lt;/h3>
&lt;p>Since many &lt;code>kubectl&lt;/code> commands will be used, it’s a good idea to take advantage of every opportunity to shorten the expressions. The &lt;code>kubectl&lt;/code> tool has a fallback strategy for looking up a kubeconfig to work with. For example, it looks for the &lt;code>KUBECONFIG&lt;/code> environment variable with value that is the path to the &lt;code>kubeconfig&lt;/code> file meant to be used. Export the variable:&lt;/p>
&lt;pre tabindex="0">&lt;code>$ export KUBECONFIG=&amp;lt;path-to-file&amp;gt;
&lt;/code>&lt;/pre>&lt;p>In the previous snippet make sure to change the &lt;code>&amp;lt;path-to-file&amp;gt;&lt;/code> with the path to the kubeconfig for the cluster that you want to connect to on your system.&lt;/p>
&lt;br>
&lt;h2 id="whats-next">What&amp;rsquo;s next?&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://gardener.cloud/docs/dashboard/usage/using-terminal/">Using Dashboard Terminal&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Docs: Connectivity</title><link>https://gardener.cloud/docs/gardener/monitoring/connectivity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/monitoring/connectivity/</guid><description>
&lt;h1 id="connectivity">Connectivity&lt;/h1>
&lt;h2 id="shoot-connectivity">Shoot Connectivity&lt;/h2>
&lt;p>We measure the connectivity from the shoot to the API Server. This is done via the &lt;code>blackbox exporter&lt;/code> which is deployed in the shoot&amp;rsquo;s &lt;code>kube-system&lt;/code> namespace. Prometheus will scrape the &lt;code>blackbox exporter&lt;/code> and then the exporter will try to access the API Server. Metrics are exposed if the connection was successful or not. This can be seen in the dashboard &lt;code>Kubernetes Control Plane Status&lt;/code> dashboard under the &lt;code>API Server Connectivity&lt;/code> panel. The &lt;code>shoot&lt;/code> line represents the connectivity from the shoot.&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/panel_393a41.png" alt="image">&lt;/p>
&lt;h2 id="seed-connectivity">Seed Connectivity&lt;/h2>
&lt;p>In addition to the shoot connectivity, we also measure the seed connectivity. This means trying to reach the API Server from the seed via the external fully qualified domain name of the API server. The connectivity is also displayed in the above panel as the &lt;code>seed&lt;/code> line. Both &lt;code>seed&lt;/code> and &lt;code>shoot&lt;/code> connectivity are shown below.&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/connectivity_b79584.png" alt="image">&lt;/p></description></item><item><title>Docs: ContainerRuntime</title><link>https://gardener.cloud/docs/gardener/extensions/containerruntime/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/extensions/containerruntime/</guid><description>
&lt;h1 id="gardener-container-runtime-extension">Gardener Container Runtime Extension&lt;/h1>
&lt;p>At the lowest layers of a Kubernetes node is the software that, among other things, starts and stops containers. It is called “Container Runtime”.
The most widely known container runtime is Docker, but it is not alone in this space. In fact, the container runtime space has been rapidly evolving.&lt;/p>
&lt;p>Kubernetes supports different container runtimes using Container Runtime Interface (CRI) – a plugin interface which enables kubelet to use a wide variety of container runtimes.&lt;/p>
&lt;p>Gardener supports creation of Worker machines using CRI, more information can be found here: &lt;a href="https://gardener.cloud/docs/gardener/extensions/operatingsystemconfig/#cri-support">CRI Support&lt;/a>.&lt;/p>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>Prior to the &lt;code>Container Runtime Extensibility&lt;/code> concept, Gardener used Docker as the only
container runtime to use in shoot worker machines. Because of the wide variety of different container runtimes
offers multiple important features (for example enhanced security concepts) it is important to enable end users to use other container runtimes as well.&lt;/p>
&lt;h2 id="the-containerruntime-extension-resource">The &lt;code>ContainerRuntime&lt;/code> Extension Resource&lt;/h2>
&lt;p>Here is what a typical &lt;code>ContainerRuntime&lt;/code> resource would look-like:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>---
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: extensions.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: ContainerRuntime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: my-container-runtime
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> binaryPath: /var/bin/containerruntimes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: gvisor
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> workerPool:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: worker-ubuntu
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> selector:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> matchLabels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> worker.gardener.cloud/pool: worker-ubuntu
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Gardener deploys one &lt;code>ContainerRuntime&lt;/code> resource per worker pool per CRI.
To exemplify this, consider a Shoot having two worker pools (&lt;code>worker-one&lt;/code>, &lt;code>worker-two&lt;/code>) using &lt;code>containerd&lt;/code> as the CRI as well as &lt;code>gvisor&lt;/code> and &lt;code>kata&lt;/code> as enabled container runtimes.
Gardener would deploy four &lt;code>ContainerRuntime&lt;/code> resources. For &lt;code>worker-one&lt;/code>: one &lt;code>ContainerRuntime&lt;/code> for type &lt;code>gvisor&lt;/code> and one for type &lt;code>kata&lt;/code>. The same resource are being deployed for &lt;code>worker-two&lt;/code>.&lt;/p>
&lt;h2 id="supporting-a-new-container-runtime-provider">Supporting a new Container Runtime Provider&lt;/h2>
&lt;p>To add support for another container runtime (e.g., gvisor, kata-containers, etc.) a container runtime extension controller needs to be implemented. It should support Gardener&amp;rsquo;s supported CRI plugins.&lt;/p>
&lt;p>The container runtime extension should install the necessary resources into the shoot cluster (e.g., &lt;code>RuntimeClass&lt;/code>es), and it should copy the runtime binaries to the relevant worker machines in path: &lt;code>spec.binaryPath&lt;/code>.
Gardener labels the shoot nodes according to the CRI configured: &lt;code>worker.gardener.cloud/cri-name=&amp;lt;value&amp;gt;&lt;/code> (e.g &lt;code>worker.gardener.cloud/cri-name=containerd&lt;/code>) and multiple labels for each of the container runtimes configured for the shoot Worker machine:
&lt;code>containerruntime.worker.gardener.cloud/&amp;lt;container-runtime-type-value&amp;gt;=true&lt;/code> (e.g &lt;code>containerruntime.worker.gardener.cloud/gvisor=true&lt;/code>).
The way to install the binaries is by creating a daemon set which copies the binaries from an image in a docker registry to the relevant labeled Worker&amp;rsquo;s nodes (avoid downloading binaries from internet to also cater with isolated environments).&lt;/p>
&lt;p>For additional reference, please have a look at the &lt;a href="https://github.com/gardener/gardener-extension-runtime-gvisor">runtime-gvsior&lt;/a> provider extension, which provides more information on how to configure the necessary charts as well as the actuators required to reconcile container runtime inside the &lt;code>Shoot&lt;/code> cluster to the desired state.&lt;/p></description></item><item><title>Docs: Control Plane Migration</title><link>https://gardener.cloud/docs/gardener/usage/control_plane_migration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/usage/control_plane_migration/</guid><description>
&lt;h1 id="control-plane-migration">Control Plane Migration&lt;/h1>
&lt;h2 id="preconditions">Preconditions&lt;/h2>
&lt;p>To be able to use this feature, the &lt;code>SeedChange&lt;/code> feature gate has to be enabled on your &lt;code>gardener-apiserver&lt;/code>.&lt;/p>
&lt;p>Also, the involved Seeds need to have enabled BackupBuckets.&lt;/p>
&lt;h2 id="shootstate">ShootState&lt;/h2>
&lt;p>&lt;code>ShootState&lt;/code> is an API resource which stores non-reconstructible state and data required to completely recreate a &lt;code>Shoot&lt;/code>&amp;rsquo;s control plane on a new &lt;code>Seed&lt;/code>. The &lt;code>ShootState&lt;/code> resource is created on &lt;code>Shoot&lt;/code> creation in its &lt;code>Project&lt;/code> namespace and the required state/data is persisted during &lt;code>Shoot&lt;/code> creation or reconciliation.&lt;/p>
&lt;h2 id="shoot-control-plane-migration">Shoot Control Plane Migration&lt;/h2>
&lt;p>Triggering the migration is done by changing the &lt;code>Shoot&lt;/code>&amp;rsquo;s &lt;code>.spec.seedName&lt;/code> to a &lt;code>Seed&lt;/code> that differs from the &lt;code>.status.seedName&lt;/code>, we call this &lt;code>Seed&lt;/code> &lt;code>&amp;quot;Destination Seed&amp;quot;&lt;/code>. This action can only be performed by an operator with necessary RBAC. If the Destination &lt;code>Seed&lt;/code> does not have a backup and restore configuration, the change to &lt;code>spec.seedName&lt;/code> is rejected. Additionally, this Seed must not be set for deletion and must be healthy.&lt;/p>
&lt;p>If the &lt;code>Shoot&lt;/code> has different &lt;code>.spec.seedName&lt;/code> and &lt;code>.status.seedName&lt;/code> a process is started to prepare the Control Plane for migration:&lt;/p>
&lt;ol>
&lt;li>&lt;code>.status.lastOperation&lt;/code> is changed to &lt;code>Migrate&lt;/code>.&lt;/li>
&lt;li>Kubernetes API Server is stopped and the extension resources are annotated with &lt;code>gardener.cloud/operation=migrate&lt;/code>.&lt;/li>
&lt;li>Full snapshot of the ETCD is created and terminating of the Control Plane in the &lt;code>Source Seed&lt;/code> is initiated.&lt;/li>
&lt;/ol>
&lt;p>If the process is successful, we update the status of the &lt;code>Shoot&lt;/code> by setting the &lt;code>.status.seedName&lt;/code> to the null value. That way, a restoration is triggered in the &lt;code>Destination Seed&lt;/code> and &lt;code>.status.lastOperation&lt;/code> is changed to &lt;code>Restore&lt;/code>. The control plane migration is completed when the &lt;code>Restore&lt;/code> operation has completed successfully.&lt;/p>
&lt;p>When the &lt;code>CopyEtcdBackupsDuringControlPlaneMigration&lt;/code> feature gate is enabled on the &lt;code>gardenlet&lt;/code>, the etcd backups will be copied over to the &lt;code>BackupBucket&lt;/code> of the &lt;code>Destination Seed&lt;/code> during control plane migration and any future backups will be uploaded there. Otherwise, backups will continue to be uploaded to the &lt;code>BackupBucket&lt;/code> of the &lt;code>Source Seed&lt;/code>,&lt;/p>
&lt;h2 id="triggering-the-migration">Triggering the migration&lt;/h2>
&lt;p>For controlplane migration, operators with necessary RBAC can use the &lt;a href="https://gardener.cloud/docs/gardener/concepts/scheduler/#shootsbinding-subresource">&lt;code>shoots/binding&lt;/code>&lt;/a> subresource to change the &lt;code>.spec.seedName&lt;/code>, with the following commands:&lt;/p>
&lt;pre tabindex="0">&lt;code>export NAMESPACE=my-namespace
export SHOOT_NAME=my-shoot
kubectl -n ${NAMESPACE} get shoot ${SHOOT_NAME} -o json | jq &amp;#39;.spec.seedName = &amp;#34;&amp;lt;destination-seed&amp;gt;&amp;#34;&amp;#39; | kubectl replace --raw /apis/core.gardener.cloud/v1beta1/namespaces/${NAMESPACE}/shoots/${SHOOT_NAME}/binding -f - | jq -r &amp;#39;.spec.seedName&amp;#39;
&lt;/code>&lt;/pre></description></item></channel></rss>