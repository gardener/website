<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.95.0"><link rel=canonical type=text/html href=https://gardener.cloud/docs/other-components/etcd-druid/><link rel=alternate type=application/rss+xml href=https://gardener.cloud/docs/other-components/etcd-druid/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>etcd Druid | Gardener</title><meta name=description content="A druid for etcd management in Gardener"><meta property="og:title" content="etcd Druid"><meta property="og:description" content="A druid for etcd management in Gardener"><meta property="og:type" content="website"><meta property="og:url" content="https://gardener.cloud/docs/other-components/etcd-druid/"><meta property="og:image" content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta itemprop=name content="etcd Druid"><meta itemprop=description content="A druid for etcd management in Gardener"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta name=twitter:title content="etcd Druid"><meta name=twitter:description content="A druid for etcd management in Gardener"><link rel=preload href=/scss/main.min.b5b806bb2cd9fe9ed809539377398aa9df0eb8ca0c983a6eae0b413d528d8f0e.css as=style><link href=/scss/main.min.b5b806bb2cd9fe9ed809539377398aa9df0eb8ca0c983a6eae0b413d528d8f0e.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7N3XF5XLGV"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7N3XF5XLGV",{anonymize_ip:!1})}</script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg width="90" height="90" viewBox="0 0 90 90" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>logo</title><desc>Created with Sketch.</desc><defs><path d="M41.8864954.994901575c.996545099999999-.479910833 2.6164002-.477918931 3.6088091.0L76.8159138 16.0781121C77.8124589 16.5580229 78.8208647 17.8257185 79.0659694 18.8995926l7.7355517 33.8916663C87.0476474 53.8696088 86.6852538 55.4484075 85.9984855 56.3095876L64.3239514 83.4885938C63.6343208 84.3533632 62.1740175 85.0543973 61.0725268 85.0543973H26.3092731c-1.1060816.0-2.5646564-.704623400000003-3.2514246-1.5658035L1.38331434 56.3095876C.693683723 55.4448182.335174016 53.865133.580278769 52.7912589L8.31583044 18.8995926C8.56195675 17.8212428 9.57347722 16.556031 10.5658861 16.0781121L41.8864954.994901575z" id="path-1"/><linearGradient x1="12.7542673%" y1="-18.6617048%" x2="88.2666158%" y2="84.6075483%" id="linearGradient-3"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="50%" y1="4.93673768%" x2="148.756007%" y2="175.514523%" id="linearGradient-4"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="19.1574381%" y1="-9.04800713%" x2="82.2203149%" y2="77.9084293%" id="linearGradient-5"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="57.4403751%" y1="26.3148481%" x2="137.966711%" y2="158.080556%" id="linearGradient-6"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="logo"><g id="Rectangle-2" transform="translate(1.000000, 0.000000)"><mask id="mask-2" fill="#fff"><use xlink:href="#path-1"/></mask><use id="Mask" fill="#009f76" xlink:href="#path-1"/><polygon fill="#000" opacity=".289628623" mask="url(#mask-2)" points="-17.6484375 54.5224609 30.8242188 25.0791016 63.4726562 58.5 24.7324219 92.6689453"/></g><path d="M56.8508631 39.260019C56.4193519 40.443987 55.6088085 41.581593 54.6736295 42.1938694l-8.0738997 5.2861089c-1.3854671.907087099999998-3.6247515.9116711-5.0172201.0L33.50861 42.1938694C32.123143 41.2867823 31 39.206345 31 37.545932V26.4150304c0-.725313.2131118-1.5301454.569268099999999-2.2825772L56.8508631 39.260019z" id="Combined-Shape" fill="url(#linearGradient-3)" transform="translate(43.925432, 36.147233) scale(-1, 1) translate(-43.925432, -36.147233)"/><path d="M56.0774672 25.1412464C56.4306829 25.8903325 56.6425556 26.6907345 56.6425556 27.4119019V38.5428034c0 1.6598979-1.1161415 3.73626640000001-2.50861 4.6479374l-8.0738997 5.286109c-1.3854671.907087000000004-3.6247516.911671000000005-5.0172201.0L32.9689261 43.1907408C32.2918101 42.7474223 31.6773514 42.0238435 31.2260376 41.206007L56.0774672 25.1412464z" id="Combined-Shape" fill="url(#linearGradient-4)" transform="translate(43.821278, 37.246598) scale(-1, 1) translate(-43.821278, -37.246598)"/><path d="M65.0702134 57.1846889C64.5985426 58.2007851 63.8367404 59.1236871 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.1597438 58.7930183 24 56.7816693 24 55.1323495V37.1145303C24 36.3487436 24.249712 35.5060005 24.6599102 34.7400631L65.0702134 57.1846889z" id="Combined-Shape" fill="url(#linearGradient-5)"/><path d="M65.0189476 34.954538C65.3636909 35.6617313 65.5692194 36.42021 65.5692194 37.1145303V55.1323495C65.5692194 56.7842831 64.4072119 58.7943252 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.9237304 59.2341061 25.3159155 58.5918431 24.8568495 57.8487596L65.0189476 34.954538z" id="Combined-Shape" fill="url(#linearGradient-6)"/></g></g></svg></span><span class=text-capitalize>Gardener</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/adopter><span>Adopters</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs><span>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog><span>Blogs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community><span>Community</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.55d1d64674e5a9d3d0b5e01d07f4538a.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/other-components/etcd-druid/>Return to the regular view of this page</a>.</p></div><h1 class=title>etcd Druid</h1><div class=lead>A druid for etcd management in Gardener</div><div class=content><h1 id=etcd-druid>ETCD Druid</h1><p><a href=https://concourse.ci.gardener.cloud/teams/gardener/pipelines/etcd-druid-master/jobs/master-head-update-job><img src=https://concourse.ci.gardener.cloud/api/v1/teams/gardener/pipelines/etcd-druid-master/jobs/master-head-update-job/badge alt="CI Build status"></a>
<a href=https://goreportcard.com/report/github.com/gardener/etcd-druid><img src=https://goreportcard.com/badge/github.com/gardener/gardener alt="Go Report Card"></a></p><h2 id=background>Background</h2><p><a href=https://github.com/etcd-io/etcd>Etcd</a> in the control plane of Kubernetes clusters which are managed by Gardener is deployed as a StatefulSet. The statefulset has replica of a pod containing two containers namely, etcd and <a href=https://github.com/gardener/etcd-backup-restore>backup-restore</a>. The etcd container calls components in etcd-backup-restore via REST api to perform data validation before etcd is started. If this validation fails etcd data is restored from the latest snapshot stored in the cloud-provider&rsquo;s object store. Once etcd has started, the etcd-backup-restore periodically creates full and delta snapshots. It also performs defragmentation of etcd data periodically.</p><p>The etcd-backup-restore needs as input the cloud-provider information comprising of security credentials to access the object store, the object store bucket name and prefix for the directory used to store snapshots. Currently, for operations like migration and validation, the bash script has to be updated to initiate the operation.</p><h2 id=goals>Goals</h2><ul><li>Deploy etcd and etcd-backup-restore using an etcd CRD.</li><li>Support more than one etcd replica.</li><li>Perform scheduled snapshots.</li><li>Support operations such as restores, defragmentation and scaling with zero-downtime.</li><li>Handle cloud-provider specific operation logic.</li><li>Trigger a full backup on request before volume deletion.</li><li>Offline compaction of full and delta snapshots stored in object store.</li></ul><h2 id=proposal>Proposal</h2><p>The existing method of deploying etcd and backup-sidecar as a StatefulSet alleviates the pain of ensuring the pods are live and ready after node crashes. However, deploying etcd as a Statefulset introduces a plethora of challenges. The etcd controller should be smart enough to handle etcd statefulsets taking into account limitations imposed by statefulsets. The controller shall update the status regarding how to target the K8s objects it has created. This field in the status can be leveraged by <code>HVPA</code> to scale etcd resources eventually.</p><h2 id=crd-specification>CRD specification</h2><p>The etcd CRD should contain the information required to create the etcd and backup-restore sidecar in a pod/statefulset.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>apiVersion: druid.gardener.cloud/v1alpha1
</span></span><span style=display:flex><span>kind: Etcd
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  finalizers:
</span></span><span style=display:flex><span>  - druid.gardener.cloud/etcd
</span></span><span style=display:flex><span>  name: test
</span></span><span style=display:flex><span>  namespace: demo
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  annotations:
</span></span><span style=display:flex><span>    app: etcd-statefulset
</span></span><span style=display:flex><span>    gardener.cloud/role: controlplane
</span></span><span style=display:flex><span>    networking.gardener.cloud/to-dns: allowed
</span></span><span style=display:flex><span>    networking.gardener.cloud/to-private-networks: allowed
</span></span><span style=display:flex><span>    networking.gardener.cloud/to-public-networks: allowed
</span></span><span style=display:flex><span>    role: test
</span></span><span style=display:flex><span>  backup:
</span></span><span style=display:flex><span>    deltaSnapshotMemoryLimit: 1Gi
</span></span><span style=display:flex><span>    deltaSnapshotPeriod: 300s
</span></span><span style=display:flex><span>    fullSnapshotSchedule: 0 <span style=color:#00f>*/24</span> * * *
</span></span><span style=display:flex><span>    garbageCollectionPeriod: 43200s
</span></span><span style=display:flex><span>    garbageCollectionPolicy: Exponential
</span></span><span style=display:flex><span>    imageRepository: eu.gcr.io/gardener-project/gardener/etcdbrctl
</span></span><span style=display:flex><span>    imageVersion: v0.12.0
</span></span><span style=display:flex><span>    port: 8080
</span></span><span style=display:flex><span>    resources:
</span></span><span style=display:flex><span>      limits:
</span></span><span style=display:flex><span>        cpu: 500m
</span></span><span style=display:flex><span>        memory: 2Gi
</span></span><span style=display:flex><span>      requests:
</span></span><span style=display:flex><span>        cpu: 23m
</span></span><span style=display:flex><span>        memory: 128Mi
</span></span><span style=display:flex><span>    snapstoreTempDir: /var/etcd/data/temp
</span></span><span style=display:flex><span>  etcd:
</span></span><span style=display:flex><span>    Quota: 8Gi
</span></span><span style=display:flex><span>    clientPort: 2379
</span></span><span style=display:flex><span>    defragmentationSchedule: 0 <span style=color:#00f>*/24</span> * * *
</span></span><span style=display:flex><span>    enableTLS: <span style=color:#00f>false</span>
</span></span><span style=display:flex><span>    imageRepository: eu.gcr.io/gardener-project/gardener/etcd
</span></span><span style=display:flex><span>    imageVersion: v3.4.13-bootstrap
</span></span><span style=display:flex><span>    initialClusterState: new
</span></span><span style=display:flex><span>    initialClusterToken: new
</span></span><span style=display:flex><span>    metrics: basic
</span></span><span style=display:flex><span>    pullPolicy: IfNotPresent
</span></span><span style=display:flex><span>    resources:
</span></span><span style=display:flex><span>      limits:
</span></span><span style=display:flex><span>        cpu: 2500m
</span></span><span style=display:flex><span>        memory: 4Gi
</span></span><span style=display:flex><span>      requests:
</span></span><span style=display:flex><span>        cpu: 500m
</span></span><span style=display:flex><span>        memory: 1000Mi
</span></span><span style=display:flex><span>    serverPort: 2380
</span></span><span style=display:flex><span>    storageCapacity: 80Gi
</span></span><span style=display:flex><span>    storageClass: gardener.cloud-fast
</span></span><span style=display:flex><span>  sharedConfig:
</span></span><span style=display:flex><span>    autoCompactionMode: periodic
</span></span><span style=display:flex><span>    autoCompactionRetention: 30m
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    app: etcd-statefulset
</span></span><span style=display:flex><span>    gardener.cloud/role: controlplane
</span></span><span style=display:flex><span>    networking.gardener.cloud/to-dns: allowed
</span></span><span style=display:flex><span>    networking.gardener.cloud/to-private-networks: allowed
</span></span><span style=display:flex><span>    networking.gardener.cloud/to-public-networks: allowed
</span></span><span style=display:flex><span>    role: test
</span></span><span style=display:flex><span>  pvcRetentionPolicy: DeleteAll
</span></span><span style=display:flex><span>  replicas: 1
</span></span><span style=display:flex><span>  storageCapacity: 80Gi
</span></span><span style=display:flex><span>  storageClass: gardener.cloud-fast
</span></span><span style=display:flex><span>  store:
</span></span><span style=display:flex><span>    storageContainer: test
</span></span><span style=display:flex><span>    storageProvider: S3
</span></span><span style=display:flex><span>    storePrefix: etcd-test
</span></span><span style=display:flex><span>    storeSecret: etcd-backup
</span></span><span style=display:flex><span>  tlsClientSecret: etcd-client-tls
</span></span><span style=display:flex><span>  tlsServerSecret: etcd-server-tls
</span></span><span style=display:flex><span>status:
</span></span><span style=display:flex><span>  etcd:
</span></span><span style=display:flex><span>    apiVersion: apps/v1
</span></span><span style=display:flex><span>    kind: StatefulSet
</span></span><span style=display:flex><span>    name: etcd-test
</span></span></code></pre></div><h2 id=implementation-agenda>Implementation Agenda</h2><p>As first step implement defragmentation during maintenance windows. Subsequently, we will add zero-downtime upgrades and defragmentation.</p><h2 id=workflow>Workflow</h2><h3 id=deployment-workflow>Deployment workflow</h3><p><img src=/__resources/controller_6d5b8f.png alt=controller-diagram></p><h3 id=defragmentation-workflow>Defragmentation workflow</h3><p><img src=/__resources/defrag_da50bf.png alt=defrag-diagram></p></div></div><div class=td-content style=page-break-before:always><h1 id=pg-d3e3c086757c3ad4577b7dfcc863f5b7>1 - API Reference</h1><p>Packages:</p><ul><li><a href=#druid.gardener.cloud%2fv1alpha1>druid.gardener.cloud/v1alpha1</a></li></ul><h2 id=druid.gardener.cloud/v1alpha1>druid.gardener.cloud/v1alpha1</h2><p><p>Package v1alpha1 is the v1alpha1 version of the etcd-druid API.</p></p>Resource Types:<ul></ul><h3 id=druid.gardener.cloud/v1alpha1.BackupSpec>BackupSpec</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdSpec>EtcdSpec</a>)</p><p><p>BackupSpec defines parameters associated with the full and delta snapshots of etcd.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>port</code></br><em>int32</em></td><td><em>(Optional)</em><p>Port define the port on which etcd-backup-restore server will be exposed.</p></td></tr><tr><td><code>tls</code></br><em><a href=#druid.gardener.cloud/v1alpha1.TLSConfig>TLSConfig</a></em></td><td><em>(Optional)</em></td></tr><tr><td><code>image</code></br><em>string</em></td><td><em>(Optional)</em><p>Image defines the etcd container image and tag</p></td></tr><tr><td><code>store</code></br><em><a href=#druid.gardener.cloud/v1alpha1.StoreSpec>StoreSpec</a></em></td><td><em>(Optional)</em><p>Store defines the specification of object store provider for storing backups.</p></td></tr><tr><td><code>resources</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#resourcerequirements-v1-core>Kubernetes core/v1.ResourceRequirements</a></em></td><td><em>(Optional)</em><p>Resources defines compute Resources required by backup-restore container.
More info: <a href=https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/>https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/</a></p></td></tr><tr><td><code>compactionResources</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#resourcerequirements-v1-core>Kubernetes core/v1.ResourceRequirements</a></em></td><td><em>(Optional)</em><p>CompactionResources defines compute Resources required by compaction job.
More info: <a href=https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/>https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/</a></p></td></tr><tr><td><code>fullSnapshotSchedule</code></br><em>string</em></td><td><em>(Optional)</em><p>FullSnapshotSchedule defines the cron standard schedule for full snapshots.</p></td></tr><tr><td><code>garbageCollectionPolicy</code></br><em><a href=#druid.gardener.cloud/v1alpha1.GarbageCollectionPolicy>GarbageCollectionPolicy</a></em></td><td><em>(Optional)</em><p>GarbageCollectionPolicy defines the policy for garbage collecting old backups</p></td></tr><tr><td><code>garbageCollectionPeriod</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta>Kubernetes meta/v1.Duration</a></em></td><td><em>(Optional)</em><p>GarbageCollectionPeriod defines the period for garbage collecting old backups</p></td></tr><tr><td><code>deltaSnapshotPeriod</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta>Kubernetes meta/v1.Duration</a></em></td><td><em>(Optional)</em><p>DeltaSnapshotPeriod defines the period after which delta snapshots will be taken</p></td></tr><tr><td><code>deltaSnapshotMemoryLimit</code></br><em>k8s.io/apimachinery/pkg/api/resource.Quantity</em></td><td><em>(Optional)</em><p>DeltaSnapshotMemoryLimit defines the memory limit after which delta snapshots will be taken</p></td></tr><tr><td><code>compression</code></br><em><a href=#druid.gardener.cloud/v1alpha1.CompressionSpec>CompressionSpec</a></em></td><td><em>(Optional)</em><p>SnapshotCompression defines the specification for compression of Snapshots.</p></td></tr><tr><td><code>enableProfiling</code></br><em>bool</em></td><td><em>(Optional)</em><p>EnableProfiling defines if profiling should be enabled for the etcd-backup-restore-sidecar</p></td></tr><tr><td><code>etcdSnapshotTimeout</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta>Kubernetes meta/v1.Duration</a></em></td><td><em>(Optional)</em><p>EtcdSnapshotTimeout defines the timeout duration for etcd FullSnapshot operation</p></td></tr><tr><td><code>leaderElection</code></br><em><a href=#druid.gardener.cloud/v1alpha1.LeaderElectionSpec>LeaderElectionSpec</a></em></td><td><em>(Optional)</em><p>LeaderElection defines parameters related to the LeaderElection configuration.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.ClientService>ClientService</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdConfig>EtcdConfig</a>)</p><p><p>ClientService defines the parameters of the client service that a user can specify</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>annotations</code></br><em>map[string]string</em></td><td><em>(Optional)</em><p>Annotations specify the annotations that should be added to the client service</p></td></tr><tr><td><code>labels</code></br><em>map[string]string</em></td><td><em>(Optional)</em><p>Labels specify the labels that should be added to the client service</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.CompactionMode>CompactionMode
(<code>string</code> alias)</p></h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.SharedConfig>SharedConfig</a>)</p><p><p>CompactionMode defines the auto-compaction-mode: &lsquo;periodic&rsquo; or &lsquo;revision&rsquo;.
&lsquo;periodic&rsquo; for duration based retention and &lsquo;revision&rsquo; for revision number based retention.</p></p><h3 id=druid.gardener.cloud/v1alpha1.CompressionPolicy>CompressionPolicy
(<code>string</code> alias)</p></h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.CompressionSpec>CompressionSpec</a>)</p><p><p>CompressionPolicy defines the type of policy for compression of snapshots.</p></p><h3 id=druid.gardener.cloud/v1alpha1.CompressionSpec>CompressionSpec</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.BackupSpec>BackupSpec</a>)</p><p><p>CompressionSpec defines parameters related to compression of Snapshots(full as well as delta).</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>enabled</code></br><em>bool</em></td><td><em>(Optional)</em></td></tr><tr><td><code>policy</code></br><em><a href=#druid.gardener.cloud/v1alpha1.CompressionPolicy>CompressionPolicy</a></em></td><td><em>(Optional)</em></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.Condition>Condition</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskStatus>EtcdCopyBackupsTaskStatus</a>,
<a href=#druid.gardener.cloud/v1alpha1.EtcdStatus>EtcdStatus</a>)</p><p><p>Condition holds the information about the state of a resource.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>type</code></br><em><a href=#druid.gardener.cloud/v1alpha1.ConditionType>ConditionType</a></em></td><td><p>Type of the Etcd condition.</p></td></tr><tr><td><code>status</code></br><em><a href=#druid.gardener.cloud/v1alpha1.ConditionStatus>ConditionStatus</a></em></td><td><p>Status of the condition, one of True, False, Unknown.</p></td></tr><tr><td><code>lastTransitionTime</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#time-v1-meta>Kubernetes meta/v1.Time</a></em></td><td><p>Last time the condition transitioned from one status to another.</p></td></tr><tr><td><code>lastUpdateTime</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#time-v1-meta>Kubernetes meta/v1.Time</a></em></td><td><p>Last time the condition was updated.</p></td></tr><tr><td><code>reason</code></br><em>string</em></td><td><p>The reason for the condition&rsquo;s last transition.</p></td></tr><tr><td><code>message</code></br><em>string</em></td><td><p>A human-readable message indicating details about the transition.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.ConditionStatus>ConditionStatus
(<code>string</code> alias)</p></h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.Condition>Condition</a>)</p><p><p>ConditionStatus is the status of a condition.</p></p><h3 id=druid.gardener.cloud/v1alpha1.ConditionType>ConditionType
(<code>string</code> alias)</p></h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.Condition>Condition</a>)</p><p><p>ConditionType is the type of condition.</p></p><h3 id=druid.gardener.cloud/v1alpha1.CrossVersionObjectReference>CrossVersionObjectReference</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdStatus>EtcdStatus</a>)</p><p><p>CrossVersionObjectReference contains enough information to let you identify the referred resource.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>kind</code></br><em>string</em></td><td><p>Kind of the referent</p></td></tr><tr><td><code>name</code></br><em>string</em></td><td><p>Name of the referent</p></td></tr><tr><td><code>apiVersion</code></br><em>string</em></td><td><em>(Optional)</em><p>API version of the referent</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.Etcd>Etcd</h3><p><p>Etcd is the Schema for the etcds API</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>metadata</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#objectmeta-v1-meta>Kubernetes meta/v1.ObjectMeta</a></em></td><td>Refer to the Kubernetes API documentation for the fields of the
<code>metadata</code> field.</td></tr><tr><td><code>spec</code></br><em><a href=#druid.gardener.cloud/v1alpha1.EtcdSpec>EtcdSpec</a></em></td><td><br><br><table><tr><td><code>selector</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#labelselector-v1-meta>Kubernetes meta/v1.LabelSelector</a></em></td><td><p>selector is a label query over pods that should match the replica count.
It must match the pod template&rsquo;s labels.
More info: <a href=https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors>https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors</a></p></td></tr><tr><td><code>labels</code></br><em>map[string]string</em></td><td></td></tr><tr><td><code>annotations</code></br><em>map[string]string</em></td><td><em>(Optional)</em></td></tr><tr><td><code>etcd</code></br><em><a href=#druid.gardener.cloud/v1alpha1.EtcdConfig>EtcdConfig</a></em></td><td></td></tr><tr><td><code>backup</code></br><em><a href=#druid.gardener.cloud/v1alpha1.BackupSpec>BackupSpec</a></em></td><td></td></tr><tr><td><code>sharedConfig</code></br><em><a href=#druid.gardener.cloud/v1alpha1.SharedConfig>SharedConfig</a></em></td><td><em>(Optional)</em></td></tr><tr><td><code>schedulingConstraints</code></br><em><a href=#druid.gardener.cloud/v1alpha1.SchedulingConstraints>SchedulingConstraints</a></em></td><td><em>(Optional)</em></td></tr><tr><td><code>replicas</code></br><em>int32</em></td><td></td></tr><tr><td><code>priorityClassName</code></br><em>string</em></td><td><em>(Optional)</em><p>PriorityClassName is the name of a priority class that shall be used for the etcd pods.</p></td></tr><tr><td><code>storageClass</code></br><em>string</em></td><td><em>(Optional)</em><p>StorageClass defines the name of the StorageClass required by the claim.
More info: <a href=https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1>https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1</a></p></td></tr><tr><td><code>storageCapacity</code></br><em>k8s.io/apimachinery/pkg/api/resource.Quantity</em></td><td><em>(Optional)</em><p>StorageCapacity defines the size of persistent volume.</p></td></tr><tr><td><code>volumeClaimTemplate</code></br><em>string</em></td><td><em>(Optional)</em><p>VolumeClaimTemplate defines the volume claim template to be created</p></td></tr></table></td></tr><tr><td><code>status</code></br><em><a href=#druid.gardener.cloud/v1alpha1.EtcdStatus>EtcdStatus</a></em></td><td></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.EtcdConfig>EtcdConfig</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdSpec>EtcdSpec</a>)</p><p><p>EtcdConfig defines parameters associated etcd deployed</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>quota</code></br><em>k8s.io/apimachinery/pkg/api/resource.Quantity</em></td><td><em>(Optional)</em><p>Quota defines the etcd DB quota.</p></td></tr><tr><td><code>defragmentationSchedule</code></br><em>string</em></td><td><em>(Optional)</em><p>DefragmentationSchedule defines the cron standard schedule for defragmentation of etcd.</p></td></tr><tr><td><code>serverPort</code></br><em>int32</em></td><td><em>(Optional)</em></td></tr><tr><td><code>clientPort</code></br><em>int32</em></td><td><em>(Optional)</em></td></tr><tr><td><code>image</code></br><em>string</em></td><td><em>(Optional)</em><p>Image defines the etcd container image and tag</p></td></tr><tr><td><code>authSecretRef</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core>Kubernetes core/v1.SecretReference</a></em></td><td><em>(Optional)</em></td></tr><tr><td><code>metrics</code></br><em><a href=#druid.gardener.cloud/v1alpha1.MetricsLevel>MetricsLevel</a></em></td><td><em>(Optional)</em><p>Metrics defines the level of detail for exported metrics of etcd, specify &lsquo;extensive&rsquo; to include histogram metrics.</p></td></tr><tr><td><code>resources</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#resourcerequirements-v1-core>Kubernetes core/v1.ResourceRequirements</a></em></td><td><em>(Optional)</em><p>Resources defines the compute Resources required by etcd container.
More info: <a href=https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/>https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/</a></p></td></tr><tr><td><code>clientUrlTls</code></br><em><a href=#druid.gardener.cloud/v1alpha1.TLSConfig>TLSConfig</a></em></td><td><em>(Optional)</em><p>ClientUrlTLS contains the ca, server TLS and client TLS secrets for client communication to ETCD cluster</p></td></tr><tr><td><code>peerUrlTls</code></br><em><a href=#druid.gardener.cloud/v1alpha1.TLSConfig>TLSConfig</a></em></td><td><em>(Optional)</em><p>PeerUrlTLS contains the ca and server TLS secrets for peer communication within ETCD cluster
Currently, PeerUrlTLS does not require client TLS secrets for gardener implementation of ETCD cluster.</p></td></tr><tr><td><code>etcdDefragTimeout</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta>Kubernetes meta/v1.Duration</a></em></td><td><em>(Optional)</em><p>EtcdDefragTimeout defines the timeout duration for etcd defrag call</p></td></tr><tr><td><code>heartbeatDuration</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta>Kubernetes meta/v1.Duration</a></em></td><td><em>(Optional)</em><p>HeartbeatDuration defines the duration for members to send heartbeats. The default value is 10s.</p></td></tr><tr><td><code>clientService</code></br><em><a href=#druid.gardener.cloud/v1alpha1.ClientService>ClientService</a></em></td><td><em>(Optional)</em><p>ClientService defines the parameters of the client service that a user can specify</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTask>EtcdCopyBackupsTask</h3><p><p>EtcdCopyBackupsTask is a task for copying etcd backups from a source to a target store.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>metadata</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#objectmeta-v1-meta>Kubernetes meta/v1.ObjectMeta</a></em></td><td>Refer to the Kubernetes API documentation for the fields of the
<code>metadata</code> field.</td></tr><tr><td><code>spec</code></br><em><a href=#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskSpec>EtcdCopyBackupsTaskSpec</a></em></td><td><br><br><table><tr><td><code>sourceStore</code></br><em><a href=#druid.gardener.cloud/v1alpha1.StoreSpec>StoreSpec</a></em></td><td><p>SourceStore defines the specification of the source object store provider for storing backups.</p></td></tr><tr><td><code>targetStore</code></br><em><a href=#druid.gardener.cloud/v1alpha1.StoreSpec>StoreSpec</a></em></td><td><p>TargetStore defines the specification of the target object store provider for storing backups.</p></td></tr><tr><td><code>maxBackupAge</code></br><em>uint32</em></td><td><em>(Optional)</em><p>MaxBackupAge is the maximum age in days that a backup must have in order to be copied.
By default all backups will be copied.</p></td></tr><tr><td><code>maxBackups</code></br><em>uint32</em></td><td><em>(Optional)</em><p>MaxBackups is the maximum number of backups that will be copied starting with the most recent ones.</p></td></tr><tr><td><code>waitForFinalSnapshot</code></br><em><a href=#druid.gardener.cloud/v1alpha1.WaitForFinalSnapshotSpec>WaitForFinalSnapshotSpec</a></em></td><td><em>(Optional)</em><p>WaitForFinalSnapshot defines the parameters for waiting for a final full snapshot before copying backups.</p></td></tr></table></td></tr><tr><td><code>status</code></br><em><a href=#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskStatus>EtcdCopyBackupsTaskStatus</a></em></td><td></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskSpec>EtcdCopyBackupsTaskSpec</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTask>EtcdCopyBackupsTask</a>)</p><p><p>EtcdCopyBackupsTaskSpec defines the parameters for the copy backups task.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>sourceStore</code></br><em><a href=#druid.gardener.cloud/v1alpha1.StoreSpec>StoreSpec</a></em></td><td><p>SourceStore defines the specification of the source object store provider for storing backups.</p></td></tr><tr><td><code>targetStore</code></br><em><a href=#druid.gardener.cloud/v1alpha1.StoreSpec>StoreSpec</a></em></td><td><p>TargetStore defines the specification of the target object store provider for storing backups.</p></td></tr><tr><td><code>maxBackupAge</code></br><em>uint32</em></td><td><em>(Optional)</em><p>MaxBackupAge is the maximum age in days that a backup must have in order to be copied.
By default all backups will be copied.</p></td></tr><tr><td><code>maxBackups</code></br><em>uint32</em></td><td><em>(Optional)</em><p>MaxBackups is the maximum number of backups that will be copied starting with the most recent ones.</p></td></tr><tr><td><code>waitForFinalSnapshot</code></br><em><a href=#druid.gardener.cloud/v1alpha1.WaitForFinalSnapshotSpec>WaitForFinalSnapshotSpec</a></em></td><td><em>(Optional)</em><p>WaitForFinalSnapshot defines the parameters for waiting for a final full snapshot before copying backups.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskStatus>EtcdCopyBackupsTaskStatus</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTask>EtcdCopyBackupsTask</a>)</p><p><p>EtcdCopyBackupsTaskStatus defines the observed state of the copy backups task.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>conditions</code></br><em><a href=#druid.gardener.cloud/v1alpha1.Condition>[]Condition</a></em></td><td><em>(Optional)</em><p>Conditions represents the latest available observations of an object&rsquo;s current state.</p></td></tr><tr><td><code>observedGeneration</code></br><em>int64</em></td><td><em>(Optional)</em><p>ObservedGeneration is the most recent generation observed for this resource.</p></td></tr><tr><td><code>lastError</code></br><em>string</em></td><td><em>(Optional)</em><p>LastError represents the last occurred error.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.EtcdMemberConditionStatus>EtcdMemberConditionStatus
(<code>string</code> alias)</p></h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdMemberStatus>EtcdMemberStatus</a>)</p><p><p>EtcdMemberConditionStatus is the status of an etcd cluster member.</p></p><h3 id=druid.gardener.cloud/v1alpha1.EtcdMemberStatus>EtcdMemberStatus</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdStatus>EtcdStatus</a>)</p><p><p>EtcdMemberStatus holds information about a etcd cluster membership.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>name</code></br><em>string</em></td><td><p>Name is the name of the etcd member. It is the name of the backing <code>Pod</code>.</p></td></tr><tr><td><code>id</code></br><em>string</em></td><td><em>(Optional)</em><p>ID is the ID of the etcd member.</p></td></tr><tr><td><code>role</code></br><em><a href=#druid.gardener.cloud/v1alpha1.EtcdRole>EtcdRole</a></em></td><td><em>(Optional)</em><p>Role is the role in the etcd cluster, either <code>Leader</code> or <code>Member</code>.</p></td></tr><tr><td><code>status</code></br><em><a href=#druid.gardener.cloud/v1alpha1.EtcdMemberConditionStatus>EtcdMemberConditionStatus</a></em></td><td><p>Status of the condition, one of True, False, Unknown.</p></td></tr><tr><td><code>reason</code></br><em>string</em></td><td><p>The reason for the condition&rsquo;s last transition.</p></td></tr><tr><td><code>lastTransitionTime</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#time-v1-meta>Kubernetes meta/v1.Time</a></em></td><td><p>LastTransitionTime is the last time the condition&rsquo;s status changed.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.EtcdRole>EtcdRole
(<code>string</code> alias)</p></h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdMemberStatus>EtcdMemberStatus</a>)</p><p><p>EtcdRole is the role of an etcd cluster member.</p></p><h3 id=druid.gardener.cloud/v1alpha1.EtcdSpec>EtcdSpec</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.Etcd>Etcd</a>)</p><p><p>EtcdSpec defines the desired state of Etcd</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>selector</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#labelselector-v1-meta>Kubernetes meta/v1.LabelSelector</a></em></td><td><p>selector is a label query over pods that should match the replica count.
It must match the pod template&rsquo;s labels.
More info: <a href=https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors>https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors</a></p></td></tr><tr><td><code>labels</code></br><em>map[string]string</em></td><td></td></tr><tr><td><code>annotations</code></br><em>map[string]string</em></td><td><em>(Optional)</em></td></tr><tr><td><code>etcd</code></br><em><a href=#druid.gardener.cloud/v1alpha1.EtcdConfig>EtcdConfig</a></em></td><td></td></tr><tr><td><code>backup</code></br><em><a href=#druid.gardener.cloud/v1alpha1.BackupSpec>BackupSpec</a></em></td><td></td></tr><tr><td><code>sharedConfig</code></br><em><a href=#druid.gardener.cloud/v1alpha1.SharedConfig>SharedConfig</a></em></td><td><em>(Optional)</em></td></tr><tr><td><code>schedulingConstraints</code></br><em><a href=#druid.gardener.cloud/v1alpha1.SchedulingConstraints>SchedulingConstraints</a></em></td><td><em>(Optional)</em></td></tr><tr><td><code>replicas</code></br><em>int32</em></td><td></td></tr><tr><td><code>priorityClassName</code></br><em>string</em></td><td><em>(Optional)</em><p>PriorityClassName is the name of a priority class that shall be used for the etcd pods.</p></td></tr><tr><td><code>storageClass</code></br><em>string</em></td><td><em>(Optional)</em><p>StorageClass defines the name of the StorageClass required by the claim.
More info: <a href=https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1>https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1</a></p></td></tr><tr><td><code>storageCapacity</code></br><em>k8s.io/apimachinery/pkg/api/resource.Quantity</em></td><td><em>(Optional)</em><p>StorageCapacity defines the size of persistent volume.</p></td></tr><tr><td><code>volumeClaimTemplate</code></br><em>string</em></td><td><em>(Optional)</em><p>VolumeClaimTemplate defines the volume claim template to be created</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.EtcdStatus>EtcdStatus</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.Etcd>Etcd</a>)</p><p><p>EtcdStatus defines the observed state of Etcd.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>observedGeneration</code></br><em>int64</em></td><td><em>(Optional)</em><p>ObservedGeneration is the most recent generation observed for this resource.</p></td></tr><tr><td><code>etcd</code></br><em><a href=#druid.gardener.cloud/v1alpha1.CrossVersionObjectReference>CrossVersionObjectReference</a></em></td><td><em>(Optional)</em></td></tr><tr><td><code>conditions</code></br><em><a href=#druid.gardener.cloud/v1alpha1.Condition>[]Condition</a></em></td><td><em>(Optional)</em><p>Conditions represents the latest available observations of an etcd&rsquo;s current state.</p></td></tr><tr><td><code>serviceName</code></br><em>string</em></td><td><em>(Optional)</em><p>ServiceName is the name of the etcd service.</p></td></tr><tr><td><code>lastError</code></br><em>string</em></td><td><em>(Optional)</em><p>LastError represents the last occurred error.</p></td></tr><tr><td><code>clusterSize</code></br><em>int32</em></td><td><em>(Optional)</em><p>Cluster size is the size of the etcd cluster.</p></td></tr><tr><td><code>currentReplicas</code></br><em>int32</em></td><td><em>(Optional)</em><p>CurrentReplicas is the current replica count for the etcd cluster.</p></td></tr><tr><td><code>replicas</code></br><em>int32</em></td><td><em>(Optional)</em><p>Replicas is the replica count of the etcd resource.</p></td></tr><tr><td><code>readyReplicas</code></br><em>int32</em></td><td><em>(Optional)</em><p>ReadyReplicas is the count of replicas being ready in the etcd cluster.</p></td></tr><tr><td><code>ready</code></br><em>bool</em></td><td><em>(Optional)</em><p>Ready is <code>true</code> if all etcd replicas are ready.</p></td></tr><tr><td><code>updatedReplicas</code></br><em>int32</em></td><td><em>(Optional)</em><p>UpdatedReplicas is the count of updated replicas in the etcd cluster.</p></td></tr><tr><td><code>labelSelector</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#labelselector-v1-meta>Kubernetes meta/v1.LabelSelector</a></em></td><td><em>(Optional)</em><p>LabelSelector is a label query over pods that should match the replica count.
It must match the pod template&rsquo;s labels.</p></td></tr><tr><td><code>members</code></br><em><a href=#druid.gardener.cloud/v1alpha1.EtcdMemberStatus>[]EtcdMemberStatus</a></em></td><td><em>(Optional)</em><p>Members represents the members of the etcd cluster</p></td></tr><tr><td><code>peerUrlTLSEnabled</code></br><em>bool</em></td><td><em>(Optional)</em><p>PeerUrlTLSEnabled captures the state of peer url TLS being enabled for the etcd member(s)</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.GarbageCollectionPolicy>GarbageCollectionPolicy
(<code>string</code> alias)</p></h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.BackupSpec>BackupSpec</a>)</p><p><p>GarbageCollectionPolicy defines the type of policy for snapshot garbage collection.</p></p><h3 id=druid.gardener.cloud/v1alpha1.LeaderElectionSpec>LeaderElectionSpec</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.BackupSpec>BackupSpec</a>)</p><p><p>LeaderElectionSpec defines parameters related to the LeaderElection configuration.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>reelectionPeriod</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta>Kubernetes meta/v1.Duration</a></em></td><td><em>(Optional)</em><p>ReelectionPeriod defines the Period after which leadership status of corresponding etcd is checked.</p></td></tr><tr><td><code>etcdConnectionTimeout</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta>Kubernetes meta/v1.Duration</a></em></td><td><em>(Optional)</em><p>EtcdConnectionTimeout defines the timeout duration for etcd client connection during leader election.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.MetricsLevel>MetricsLevel
(<code>string</code> alias)</p></h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdConfig>EtcdConfig</a>)</p><p><p>MetricsLevel defines the level &lsquo;basic&rsquo; or &lsquo;extensive&rsquo;.</p></p><h3 id=druid.gardener.cloud/v1alpha1.SchedulingConstraints>SchedulingConstraints</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdSpec>EtcdSpec</a>)</p><p><p>SchedulingConstraints defines the different scheduling constraints that must be applied to the
pod spec in the etcd statefulset.
Currently supported constraints are Affinity and TopologySpreadConstraints.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>affinity</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#affinity-v1-core>Kubernetes core/v1.Affinity</a></em></td><td><em>(Optional)</em><p>Affinity defines the various affinity and anti-affinity rules for a pod
that are honoured by the kube-scheduler.</p></td></tr><tr><td><code>topologySpreadConstraints</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#topologyspreadconstraint-v1-core>[]Kubernetes core/v1.TopologySpreadConstraint</a></em></td><td><em>(Optional)</em><p>TopologySpreadConstraints describes how a group of pods ought to spread across topology domains,
that are honoured by the kube-scheduler.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.SecretReference>SecretReference</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.TLSConfig>TLSConfig</a>)</p><p><p>SecretReference defines a reference to a secret.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>SecretReference</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core>Kubernetes core/v1.SecretReference</a></em></td><td><p>(Members of <code>SecretReference</code> are embedded into this type.)</p></td></tr><tr><td><code>dataKey</code></br><em>string</em></td><td><em>(Optional)</em><p>DataKey is the name of the key in the data map containing the credentials.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.SharedConfig>SharedConfig</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdSpec>EtcdSpec</a>)</p><p><p>SharedConfig defines parameters shared and used by Etcd as well as backup-restore sidecar.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>autoCompactionMode</code></br><em><a href=#druid.gardener.cloud/v1alpha1.CompactionMode>CompactionMode</a></em></td><td><em>(Optional)</em><p>AutoCompactionMode defines the auto-compaction-mode:&lsquo;periodic&rsquo; mode or &lsquo;revision&rsquo; mode for etcd and embedded-Etcd of backup-restore sidecar.</p></td></tr><tr><td><code>autoCompactionRetention</code></br><em>string</em></td><td><em>(Optional)</em><p>AutoCompactionRetention defines the auto-compaction-retention length for etcd as well as for embedded-Etcd of backup-restore sidecar.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.StorageProvider>StorageProvider
(<code>string</code> alias)</p></h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.StoreSpec>StoreSpec</a>)</p><p><p>StorageProvider defines the type of object store provider for storing backups.</p></p><h3 id=druid.gardener.cloud/v1alpha1.StoreSpec>StoreSpec</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.BackupSpec>BackupSpec</a>,
<a href=#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskSpec>EtcdCopyBackupsTaskSpec</a>)</p><p><p>StoreSpec defines parameters related to ObjectStore persisting backups</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>container</code></br><em>string</em></td><td><em>(Optional)</em><p>Container is the name of the container the backup is stored at.</p></td></tr><tr><td><code>prefix</code></br><em>string</em></td><td><p>Prefix is the prefix used for the store.</p></td></tr><tr><td><code>provider</code></br><em><a href=#druid.gardener.cloud/v1alpha1.StorageProvider>StorageProvider</a></em></td><td><em>(Optional)</em><p>Provider is the name of the backup provider.</p></td></tr><tr><td><code>secretRef</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core>Kubernetes core/v1.SecretReference</a></em></td><td><em>(Optional)</em><p>SecretRef is the reference to the secret which used to connect to the backup store.</p></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.TLSConfig>TLSConfig</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.BackupSpec>BackupSpec</a>,
<a href=#druid.gardener.cloud/v1alpha1.EtcdConfig>EtcdConfig</a>)</p><p><p>TLSConfig hold the TLS configuration details.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>tlsCASecretRef</code></br><em><a href=#druid.gardener.cloud/v1alpha1.SecretReference>SecretReference</a></em></td><td></td></tr><tr><td><code>serverTLSSecretRef</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core>Kubernetes core/v1.SecretReference</a></em></td><td></td></tr><tr><td><code>clientTLSSecretRef</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core>Kubernetes core/v1.SecretReference</a></em></td><td><em>(Optional)</em></td></tr></tbody></table><h3 id=druid.gardener.cloud/v1alpha1.WaitForFinalSnapshotSpec>WaitForFinalSnapshotSpec</h3><p>(<em>Appears on:</em>
<a href=#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskSpec>EtcdCopyBackupsTaskSpec</a>)</p><p><p>WaitForFinalSnapshotSpec defines the parameters for waiting for a final full snapshot before copying backups.</p></p><table><thead><tr><th>Field</th><th>Description</th></tr></thead><tbody><tr><td><code>enabled</code></br><em>bool</em></td><td><p>Enabled specifies whether to wait for a final full snapshot before copying backups.</p></td></tr><tr><td><code>timeout</code></br><em><a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta>Kubernetes meta/v1.Duration</a></em></td><td><em>(Optional)</em><p>Timeout is the timeout for waiting for a final full snapshot. When this timeout expires, the copying of backups
will be performed anyway. No timeout or 0 means wait forever.</p></td></tr></tbody></table><hr><p><em>Generated with <a href=https://github.com/ahmetb/gen-crd-api-reference-docs>gen-crd-api-reference-docs</a></em></p></div><div class=td-content style=page-break-before:always><h1 id=pg-8dbd3fe2209d2acc19af1a74b97eb846>2 - Compactor</h1><h1 id=backup-compaction-for-etcd>Backup Compaction for ETCD</h1><h2 id=current-problem>Current Problem</h2><p>To ensure recoverability of ETCD, backups of the database are taken at regular interval.
Backups are of two types: Full Snapshots and Incremental Snapshots.</p><h3 id=full-snapshots>Full Snapshots</h3><p>Full snapshot is a snapshot of the complete database at given point in time.The size of the database keeps changing with time and typically the size is relatively large (measured in 100s of megabytes or even in gigabytes. For this reason, full snapshots are taken after some large intervals.</p><h3 id=incremental-snapshots>Incremental Snapshots</h3><p>Incremental Snapshots are collection of events on ETCD database, obtained through running WATCH API Call on ETCD. After some short intervals, all the events that are accumulated through WATCH API Call are saved in a file and named as Incremental Snapshots at relatively short time intervals.</p><h3 id=recovery-from-the-snapshots>Recovery from the Snapshots</h3><h4 id=recovery-from-full-snapshots>Recovery from Full Snapshots</h4><p>As the full snapshots are snapshots of the complete database, the whole database can be recovered from a full snapshot in one go. ETCD provides API Call to restore the database from a full snapshot file.</p><h4 id=recovery-from-incremental-snapshots>Recovery from Incremental Snapshots</h4><p>Delta snapshots are collection of retrospective ETCD events. So, to restore from Incremental snapshot file, the events from the file are needed to be applied sequentially on ETCD database through ETCD Put/Delete API calls. As it is heavily dependent on ETCD calls sequentially, restoring from Incremental Snapshot files can take long if there are numerous commands captured in Incremental Snapshot files.</p><p>Delta snapshots are applied on top of running ETCD database. So, if there is inconsistency between the state of database at the point of applying and the state of the database when the delta snapshot commands were captured, restoration will fail.</p><p>Currently, in Gardener setup, ETCD is restored from the last full snapshot and then the delta snapshots, which were captured after the last full snapshot.</p><p>The main problem with this is that the complete restoration time can be unacceptably large if the rate of change coming into the etcd database is quite high because there are large number of events in the delta snapshots to be applied sequentially.
A secondary problem is that, though auto-compaction is enabled for etcd, it is not quick enough to compact all the changes from the incremental snapshots being re-applied during the relatively short period of time of restoration (as compared to the actual period of time when the incremental snapshots were accumulated). This may lead to the etcd pod (the backup-restore sidecar container, to be precise) to run out of memory and/or storage space even if it is sufficient for normal operations.</p><h2 id=solution>Solution</h2><h3 id=compaction-command>Compaction command</h3><p>To help with the problem mentioned earlier, our proposal is to introduce <code>compact</code> subcommand with <code>etcdbrctl</code>. On execution of <code>compact</code> command, A separate embedded ETCD process will be started where the ETCD data will be restored from the snapstore (exactly as in the restoration scenario today). Then the new ETCD database will be compacted and defragmented using ETCD API calls. The compaction will strip off the ETCD database of old revisions as per the ETCD auto-compaction configuration. The defragmentation will free up the unused fragment memory space released after compaction. Then a full snapshot of the compacted database will be saved in snapstore which then can be used as the base snapshot during any subsequent restoration (or backup compaction).</p><h3 id=how-the-solution-works>How the solution works</h3><p>The newly introduced compact command does not disturb the running ETCD while compacting the backup snapshots. The command is designed to run potentially separately (from the main ETCD process/container/pod). ETCD Druid can be configured to run the newly introduced compact command as a separate job (scheduled periodically) based on total number of ETCD events accumulated after the most recent full snapshot.</p><h3 id=druid-flags>Druid flags:</h3><p>ETCD druid introduced following flags to configure the compaction job:</p><ul><li><code>--enable-backup-compaction</code> (default <code>false</code>): Set this flag to <code>true</code> to enable the automatic compaction of etcd backups when <code>etcd-events-threshold</code> is exceeded.</li><li><code>--compaction-workers</code> (default <code>3</code>): If this flag is set to zero, no compaction job will be running. If it&rsquo;s set to any value greater than zero, druid controller will have that many threads to kickstart the compaction job.</li><li><code>--etcd-events-threshold</code> (default <code>1000000</code>): Set this flag with the value which will signify the number of ETCD events allowed after the most recent full snapshot. Once the number of ETCD events crosses the value mentioned in this flag, compaction job will be kickstarted.</li><li><code>--active-deadline-duration</code> (default <code>3h</code>): This flag signifies the maximum duration till which a compaction job won&rsquo;t be garbage-collected.</li></ul><h3 id=points-to-take-care-while-saving-the-compacted-snapshot><strong>Points to take care while saving the compacted snapshot:</strong></h3><p>As compacted snapshot and the existing periodic full snapshots are taken by different processes running in different pods but accessing same store to save the snapshots, some problems may arise:</p><ol><li>When uploading the compacted snapshot to the snapstore, there is the problem of how does the restorer know when to start using the newly compacted snapshot. This communication needs to be atomic.</li><li>With a regular schedule for compaction that happens potentially separately from the main etcd pod, is there a need for regular scheduled full snapshots anymore?</li><li>We are planning to introduce new directory structure, under v2 prefix, for saving the snapshots (compacted and full), as mentioned in details below. But for backward compatibility, we also need to consider the older directory, which is currently under v1 prefix, during accessing snapshots.</li></ol><h4 id=how-to-swap-full-snapshot-with-compacted-snapshot-atomically><strong>How to swap full snapshot with compacted snapshot atomically</strong></h4><p>Currently, full snapshots and the subsequent delta snapshots are grouped under same prefix path in the snapstore. When a full snapshot is created, it is placed under a prefix/directory with the name comprising of timestamp. Then subsequent delta snapshots are also pushed into the same directory. Thus each prefix/directory contains a single full snapshot and the subsequent delta snapshots. So far, it is the job of ETCDBR to start main ETCD process and snapshotter process which takes full snapshot and delta snapshot periodically. But as per our proposal, compaction will be running as parallel process to main ETCD process and snapshotter process. So we can&rsquo;t reliably co-ordinate between the processes to achieve switching to the compacted snapshot as the base snapshot atomically.</p><h5 id=current-directory-structure><strong>Current Directory Structure</strong></h5><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>- Backup-192345
</span></span><span style=display:flex><span>    - Full-Snapshot-0-1-192345
</span></span><span style=display:flex><span>    - Incremental-Snapshot-1-100-192355
</span></span><span style=display:flex><span>    - Incremental-Snapshot-100-200-192365
</span></span><span style=display:flex><span>    - Incremental-Snapshot-200-300-192375
</span></span><span style=display:flex><span>- Backup-192789
</span></span><span style=display:flex><span>    - Full-Snapshot-0-300-192789
</span></span><span style=display:flex><span>    - Incremental-Snapshot-300-400-192799
</span></span><span style=display:flex><span>    - Incremental-Snapshot-400-500-192809
</span></span><span style=display:flex><span>    - Incremental-Snapshot-500-600-192819
</span></span></code></pre></div><p>To solve the problem, proposal is:</p><ol><li>ETCDBR will take the first full snapshot after it starts main ETCD Process and snapshotter process. After taking the first full snapshot, snapshotter will continue taking full snapshots. On the other hand, ETCDBR compactor command will be run as periodic job in a separate pod and use the existing full or compacted snapshots to produce further compacted snapshots. Full snapshots and compacted snapshots will be named after same fashion. So, there is no need of any mechanism to choose which snapshots(among full and compacted snapshot) to consider as base snapshots.</li><li>Flatten the directory structure of backup folder. Save all the full snapshots, delta snapshots and compacted snapshots under same directory/prefix. Restorer will restore from full/compacted snapshots and delta snapshots sorted based on the revision numbers in name (or timestamp if the revision numbers are equal).</li></ol><h5 id=proposed-directory-structure><strong>Proposed Directory Structure</strong></h5><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>Backup :
</span></span><span style=display:flex><span>    - Full-Snapshot-0-1-192355 (Taken by snapshotter)
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-1-100-192365
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-100-200-192375
</span></span><span style=display:flex><span>    - Full-Snapshot-revision-0-200-192379 (Taken by snapshotter)
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-200-300-192385
</span></span><span style=display:flex><span>    - Full-Snapshot-revision-0-300-192386 (Taken by compaction job)
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-300-400-192396
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-400-500-192406
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-500-600-192416
</span></span><span style=display:flex><span>    - Full-Snapshot-revision-0-600-192419 (Taken by snapshotter)
</span></span><span style=display:flex><span>    - Full-Snapshot-revision-0-600-192420 (Taken by compaction job)
</span></span></code></pre></div><h5 id=what-happens-to-the-delta-snapshots-that-were-compacted>What happens to the delta snapshots that were compacted?</h5><p>The proposed <code>compaction</code> sub-command in <code>etcdbrctl</code> (and hence, the <code>CronJob</code> provisioned by <code>etcd-druid</code> that will schedule it at a regular interval) would only upload the compacted full snapshot.
It will not delete the snapshots (delta or full snapshots) that were compacted.
These snapshots which were superseded by a freshly uploaded compacted snapshot would follow the same life-cycle as other older snapshots.
I.e. they will be garbage collected according to the configured backup snapshot retention policy.
For example, if an <code>exponential</code> retention policy is configured and if compaction is done every <code>30m</code> then there might be at most <code>48</code> additional (compacted) full snapshots (<code>24h * 2</code>) in the backup for the latest day. As time rolls forward to the next day, these additional compacted snapshots (along with the delta snapshots that were compacted into them) will get garbage collected retaining only one full snapshot for the day before according to the retention policy.</p><h5 id=future-work><strong>Future work</strong></h5><p>In future, we have plan to stop the snapshotter just after taking the first full snapshot. Then, the compaction job will be solely responsible for taking subsequent full snapshots. The directory structure would be looking like following:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>Backup :
</span></span><span style=display:flex><span>    - Full-Snapshot-0-1-192355 (Taken by snapshotter)
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-1-100-192365
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-100-200-192375
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-200-300-192385
</span></span><span style=display:flex><span>    - Full-Snapshot-revision-0-300-192386 (Taken by compaction job)
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-300-400-192396
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-400-500-192406
</span></span><span style=display:flex><span>    - Incremental-Snapshot-revision-500-600-192416
</span></span><span style=display:flex><span>    - Full-Snapshot-revision-0-600-192420 (Taken by compaction job)
</span></span></code></pre></div><h4 id=backward-compatibility>Backward Compatibility</h4><ol><li><strong>Restoration</strong> : The changes to handle the newly proposed backup directory structure must be backward compatible with older structures at least for restoration because we need have to restore from backups in the older structure. This includes the support for restoring from a backup without a metadata file if that is used in the actual implementation.</li><li><strong>Backup</strong> : For new snapshots (even on a backup containing the older structure), the new structure may be used. The new structure must be setup automatically including creating the base full snapshot.</li><li><strong>Garbage collection</strong> : The existing functionality of garbage collection of snapshots (full and incremental) according to the backup retention policy must be compatible with both old and new backup folder structure. I.e. the snapshots in the older backup structure must be retained in their own structure and the snapshots in the proposed backup structure should be retained in the proposed structure. Once all the snapshots in the older backup structure go out of the retention policy and are garbage collected, we can think of removing the support for older backup folder structure.</li></ol><p><strong>Note:</strong> Compactor will run parallel to current snapshotter process and work only if there is any full snapshot already present in the store. By current design, a full snapshot will be taken if there is already no full snapshot or the existing full snapshot is older than 24 hours. It is not limitation but a design choice. As per proposed design, the backup storage will contain both periodic full snapshots as well as periodic compacted snapshot. Restorer will pickup the base snapshot whichever is latest one.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-1aacce489c5899db03f8fe65b293efb7>3 - etcd Network Latency</h1><h1 id=network-latency-analysis-sn-etcd-sz-vs--mn-etcd-sz-vs-mn-etcd-mz>Network Latency analysis: <code>sn-etcd-sz</code> vs <code>mn-etcd-sz</code> vs <code>mn-etcd-mz</code></h1><p>This page captures the ETCD cluster latency analysis for below scenarios using the benchmark tool (build from <a href=https://github.com/seshachalam-yv/etcd>ETCD benchmark tool</a>).</p><p><code>sn-etcd-sz</code> -> single-node ETCD single zone (Only single replica of etcd will be running)</p><p><code>mn-etcd-sz</code> -> multi-node ETCD single zone (Multiple replicas of etcd pods will be running across nodes in a single zone)</p><p><code>mn-etcd-mz</code> -> multi-node ETCD multi zone (Multiple replicas of etcd pods will be running across nodes in multiple zones)</p><h2 id=put-analysis>PUT Analysis</h2><h3 id=summary>Summary</h3><ul><li><code>sn-etcd-sz</code> latency is <strong>~20% less than</strong> <code>mn-etcd-sz</code> when benchmark tool with single client.</li><li><code>mn-etcd-sz</code> latency is less than <code>mn-etcd-mz</code> but the difference is <code>~+/-5%</code>.</li><li>Compared to <code>mn-etcd-sz</code>, <code>sn-etcd-sz</code> latency is higher and gradually grows with more clients and larger value size.</li><li>Compared to <code>mn-etcd-mz</code>, <code>mn-etcd-sz</code> latency is higher and gradually grows with more clients and larger value size.</li><li><em>Compared to <code>follower</code>, <code>leader</code> latency is less</em>, when benchmark tool with single client for all cases.</li><li><em>Compared to <code>follower</code>, <code>leader</code> latency is high</em>, when benchmark tool with multiple clients for all cases.</li></ul><p>Sample commands:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:green># write to leader</span>
</span></span><span style=display:flex><span>benchmark put --target-leader --conns=1 --clients=1 --precise <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --sequential-keys --key-starts 0 --val-size=256 --total=10000 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --endpoints=$ETCD_HOST 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># write to follower</span>
</span></span><span style=display:flex><span>benchmark put  --conns=1 --clients=1 --precise <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --sequential-keys --key-starts 0 --val-size=256 --total=10000 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --endpoints=$ETCD_FOLLOWER_HOST
</span></span></code></pre></div><h3 id=latency-analysis-during-put-requests-to-etcd>Latency analysis during PUT requests to ETCD</h3><ul><li><details><summary>In this case benchmark tool tries to put key with random 256 bytes value.</summary><ul><li><p>Benchmark tool loads key/value to <code>leader</code> with single client .</p><ul><li><code>sn-etcd-sz</code> latency (~0.815ms) is <strong>~50% lesser than</strong> <code>mn-etcd-sz</code> (~1.74ms ).</li><li><ul><li><code>mn-etcd-sz</code> latency (~1.74ms ) is slightly lesser than <code>mn-etcd-mz</code> (~1.8ms) but the difference is negligible (within same ms).</li></ul></li><li><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>leader</td><td style=text-align:center>1220.0520</td><td style=text-align:center>0.815ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>leader</td><td style=text-align:center>586.545</td><td style=text-align:center>1.74ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>leader</td><td style=text-align:center>554.0155654442634</td><td style=text-align:center>1.8ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool loads key/value to <code>follower</code> with single client.</p><ul><li><code>mn-etcd-sz</code> latency(<code>~2.2ms</code>) is <strong>20% to 30% lesser than</strong> <code>mn-etcd-mz</code>(<code>~2.7ms</code>).</li><li><em>Compare to <code>follower</code>, <code>leader</code> has lower latency.</em></li><li><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-1</td><td style=text-align:center>445.743</td><td style=text-align:center>2.23ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-1</td><td style=text-align:center>378.9366747610789</td><td style=text-align:center>2.63ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-2</td><td style=text-align:center>457.967</td><td style=text-align:center>2.17ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-2</td><td style=text-align:center>345.6586129825796</td><td style=text-align:center>2.89ms</td><td style=text-align:center>eu-west-1b</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool loads key/value to <code>leader</code> with multiple clients.</p><ul><li><code>sn-etcd-sz</code> latency(<code>~78.3ms</code>) is <strong>~10% greater than</strong> <code>mn-etcd-sz</code>(<code>~71.81ms</code>).</li><li><code>mn-etcd-sz</code> latency(<code>~71.81ms</code>) is less than <code>mn-etcd-mz</code>(<code>~72.5ms</code>) but the difference is negligible.</li><li><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>leader</td><td style=text-align:center>12638.905</td><td style=text-align:center>78.32ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>leader</td><td style=text-align:center>13789.248</td><td style=text-align:center>71.81ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>leader</td><td style=text-align:center>13728.446436395223</td><td style=text-align:center>72.5ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool loads key/value to <code>follower</code> with multiple clients.</p><ul><li><code>mn-etcd-sz</code> latency(<code>~69.8ms</code>) is <strong>~5% greater than</strong> <code>mn-etcd-mz</code>(<code>~72.6ms</code>).</li><li><em>Compare to <code>leader</code>, <code>follower</code> has lower latency</em>.</li><li><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>follower-1</td><td style=text-align:center>14271.983</td><td style=text-align:center>69.80ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>follower-1</td><td style=text-align:center>13695.98</td><td style=text-align:center>72.62ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>follower-2</td><td style=text-align:center>14325.436</td><td style=text-align:center>69.47ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>follower-2</td><td style=text-align:center>15750.409490407475</td><td style=text-align:center>63.3ms</td><td style=text-align:center>eu-west-1b</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li></ul></details></li><li><details><summary>In this case benchmark tool tries to put key with random 1 MB value.</summary><ul><li><p>Benchmark tool loads key/value to <code>leader</code> with single client.</p><ul><li><code>sn-etcd-sz</code> latency(<code>~16.35ms</code>) is <strong>~20% lesser than</strong> <code>mn-etcd-sz</code>(<code>~20.64ms</code>).</li><li><code>mn-etcd-sz</code> latency(<code>~20.64ms</code>) is less than <code>mn-etcd-mz</code>(<code>~21.08ms</code>) but the difference is negligible..</li><li><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>leader</td><td style=text-align:center>61.117</td><td style=text-align:center>16.35ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>leader</td><td style=text-align:center>48.416</td><td style=text-align:center>20.64ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>leader</td><td style=text-align:center>45.7517341664802</td><td style=text-align:center>21.08ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool loads key/value withto <code>follower</code> single client.</p><ul><li><code>mn-etcd-sz</code> latency(<code>~23.10ms</code>) is <strong>~10% greater than</strong> <code>mn-etcd-mz</code>(<code>~21.8ms</code>).</li><li><em>Compare to <code>follower</code>, <code>leader</code> has lower latency</em>.</li><li><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-1</td><td style=text-align:center>43.261</td><td style=text-align:center>23.10ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-1</td><td style=text-align:center>45.7517341664802</td><td style=text-align:center>21.8ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-1</td><td style=text-align:center>45.33</td><td style=text-align:center>22.05ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-2</td><td style=text-align:center>40.0518</td><td style=text-align:center>24.95ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-2</td><td style=text-align:center>43.28573155709838</td><td style=text-align:center>23.09ms</td><td style=text-align:center>eu-west-1b</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-mz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-2</td><td style=text-align:center>45.92</td><td style=text-align:center>21.76ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>follower-2</td><td style=text-align:center>35.5705</td><td style=text-align:center>28.1ms</td><td style=text-align:center>eu-west-1b</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool loads key/value to <code>leader</code> with multiple clients.</p><ul><li><code>sn-etcd-sz</code> latency(<code>~6.0375secs</code>) is <strong>~30% greater than</strong> <code>mn-etcd-sz``~4.000secs</code>).</li><li><code>mn-etcd-sz</code> latency(<code>~4.000secs</code>) is less than <code>mn-etcd-mz</code>(<code>~ 4.09secs</code>) but the difference is negligible.</li><li><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>300</td><td style=text-align:center>leader</td><td style=text-align:center>55.373</td><td style=text-align:center>6.0375secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>300</td><td style=text-align:center>leader</td><td style=text-align:center>67.319</td><td style=text-align:center>4.000secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>300</td><td style=text-align:center>leader</td><td style=text-align:center>65.91914167957594</td><td style=text-align:center>4.09secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool loads key/value to <code>follower</code> with multiple clients.</p><ul><li><em><code>mn-etcd-sz</code> latency(<code>~4.04secs</code>) is <strong>~5% greater than</strong> <code>mn-etcd-mz</code>(<code>~ 3.90secs</code>).</em></li><li><em>Compare to <code>leader</code>, <code>follower</code> has lower latency</em>.</li><li><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>300</td><td style=text-align:center>follower-1</td><td style=text-align:center>66.528</td><td style=text-align:center>4.0417secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>300</td><td style=text-align:center>follower-1</td><td style=text-align:center>70.6493461856332</td><td style=text-align:center>3.90secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>300</td><td style=text-align:center>follower-1</td><td style=text-align:center>71.95</td><td style=text-align:center>3.84secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table><table><thead><tr><th style=text-align:center>Number of keys</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>300</td><td style=text-align:center>follower-2</td><td style=text-align:center>66.447</td><td style=text-align:center>4.0164secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>300</td><td style=text-align:center>follower-2</td><td style=text-align:center>67.53038086369484</td><td style=text-align:center>3.87secs</td><td style=text-align:center>eu-west-1b</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-mz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>300</td><td style=text-align:center>follower-2</td><td style=text-align:center>68.46</td><td style=text-align:center>3.92secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li></ul></details></li></ul><hr><br><h2 id=range-analysis>Range Analysis</h2><p>Sample commands are:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:green># Single connection read request with sequential keys</span>
</span></span><span style=display:flex><span>benchmark range 0 --target-leader --conns=1 --clients=1 --precise <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --sequential-keys --key-starts 0  --total=10000 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --consistency=l <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --endpoints=$ETCD_HOST 
</span></span><span style=display:flex><span><span style=color:green># --consistency=s [Serializable]</span>
</span></span><span style=display:flex><span>benchmark range 0 --target-leader --conns=1 --clients=1 --precise <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --sequential-keys --key-starts 0  --total=10000 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --consistency=s <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --endpoints=$ETCD_HOST 
</span></span><span style=display:flex><span><span style=color:green># Each read request with range query matches key 0 9999 and repeats for total number of requests.  </span>
</span></span><span style=display:flex><span>benchmark range 0 9999 --target-leader --conns=1 --clients=1 --precise <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --total=10 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --consistency=s <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --endpoints=https://etcd-main-client:2379
</span></span><span style=display:flex><span><span style=color:green># Read requests with multiple connections</span>
</span></span><span style=display:flex><span>benchmark range 0 --target-leader --conns=100 --clients=1000 --precise <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --sequential-keys --key-starts 0  --total=100000 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --consistency=l <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --endpoints=$ETCD_HOST 
</span></span><span style=display:flex><span>benchmark range 0 --target-leader --conns=100 --clients=1000 --precise <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --sequential-keys --key-starts 0  --total=100000 <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --consistency=s <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>    --endpoints=$ETCD_HOST 
</span></span></code></pre></div><h3 id=latency-analysis-during-range-requests-to-etcd>Latency analysis during Range requests to ETCD</h3><ul><li><details><summary>In this case benchmark tool tries to get specific key with random 256 bytes value.</summary><ul><li><p>Benchmark tool range requests to <code>leader</code> with single client.</p><ul><li><p><code>sn-etcd-sz</code> latency(<code>~1.24ms</code>) is <strong>~40% greater than</strong> <code>mn-etcd-sz</code>(<code>~0.67ms</code>).</p></li><li><p><code>mn-etcd-sz</code> latency(<code>~0.67ms</code>) is <strong>~20% lesser than</strong> <code>mn-etcd-mz</code>(<code>~0.85ms</code>).</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>800.272</td><td style=text-align:center>1.24ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>1173.9081</td><td style=text-align:center>0.67ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>999.3020189178693</td><td style=text-align:center>0.85ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p>Compare to consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>~40% less</strong> for all cases</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>1411.229</td><td style=text-align:center>0.70ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>2033.131</td><td style=text-align:center>0.35ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>2100.2426362012025</td><td style=text-align:center>0.47ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool range requests to <code>follower</code> with single client .</p><ul><li><code>mn-etcd-sz</code> latency(<code>~1.3ms</code>) is <strong>~20% lesser than</strong> <code>mn-etcd-mz</code>(<code>~1.6ms</code>).</li><li><em>Compare to <code>follower</code>, <code>leader</code> read request latency is <strong>~50% less</strong> for both <code>mn-etcd-sz</code>, <code>mn-etcd-mz</code></em></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>765.325</td><td style=text-align:center>1.3ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>596.1</td><td style=text-align:center>1.6ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li>Compare to consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>~50% less</strong> for all cases</li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>1823.631</td><td style=text-align:center>0.54ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>1442.6</td><td style=text-align:center>0.69ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>1416.39</td><td style=text-align:center>0.70ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr><tr><td style=text-align:center>10000</td><td style=text-align:center>256</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>2077.449</td><td style=text-align:center>0.47ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool range requests to <code>leader</code> with multiple client.</p><ul><li><p><code>sn-etcd-sz</code> latency(<code>~84.66ms</code>) is <strong>~20% greater than</strong> <code>mn-etcd-sz</code>(<code>~73.95ms</code>).</p></li><li><p><code>mn-etcd-sz</code> latency(<code>~73.95ms</code>) is <strong>more or less equal to</strong> <code>mn-etcd-mz</code>(<code>~ 73.8ms</code>).</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>11775.721</td><td style=text-align:center>84.66ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>13446.9598</td><td style=text-align:center>73.95ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>13527.19810605353</td><td style=text-align:center>73.8ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p>Compare to consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>~20% lesser</strong> for all cases</p></li><li><p><code>sn-etcd-sz</code> latency(<code>~69.37ms</code>) is <strong>more or less equal to</strong> <code>mn-etcd-sz</code>(<code>~69.89ms</code>).</p></li><li><p><code>mn-etcd-sz</code> latency(<code>~69.89ms</code>) is <strong>slightly higher than</strong> <code>mn-etcd-mz</code>(<code>~67.63ms</code>).</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>14334.9027</td><td style=text-align:center>69.37ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>14270.008</td><td style=text-align:center>69.89ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>14715.287354023869</td><td style=text-align:center>67.63ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool range requests to <code>follower</code> with multiple client.</p><ul><li><p><code>mn-etcd-sz</code> latency(<code>~60.69ms</code>) is <strong>~20% lesser than</strong> <code>mn-etcd-mz</code>(<code>~70.76ms</code>).</p></li><li><p>Compare to <code>leader</code>, <code>follower</code> has lower read request latency.</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>11586.032</td><td style=text-align:center>60.69ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>14050.5</td><td style=text-align:center>70.76ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p><code>mn-etcd-sz</code> latency(<code>~86.09ms</code>) is <strong>~20 higher than</strong> <code>mn-etcd-mz</code>(<code>~64.6ms</code>).</p></li><li><ul><li>Compare to <code>mn-etcd-sz</code> consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>~20% higher</strong>.*</li></ul></li><li><p>Compare to <code>mn-etcd-mz</code> consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>~slightly less</strong>.</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>11582.438</td><td style=text-align:center>86.09ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>100000</td><td style=text-align:center>256</td><td style=text-align:center>100</td><td style=text-align:center>1000</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>15422.2</td><td style=text-align:center>64.6ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool range requests to <code>leader</code> all keys.</p><ul><li><p><code>sn-etcd-sz</code> latency(<code>~678.77ms</code>) is <strong>~5% slightly lesser than</strong> <code>mn-etcd-sz</code>(<code>~697.29ms</code>).</p></li><li><p><code>mn-etcd-sz</code> latency(<code>~697.29ms</code>) is less than <code>mn-etcd-mz</code>(<code>~701ms</code>) but the difference is negligible.</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>6.8875</td><td style=text-align:center>678.77ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>6.720</td><td style=text-align:center>697.29ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>6.7</td><td style=text-align:center>701ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><ul><li>Compare to consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>~5% slightly higher</strong> for all cases</li></ul></li><li><p><code>sn-etcd-sz</code> latency(<code>~687.36ms</code>) is less than <code>mn-etcd-sz</code>(<code>~692.68ms</code>) but the difference is negligible.</p></li><li><p><code>mn-etcd-sz</code> latency(<code>~692.68ms</code>) is <strong>~5% slightly lesser than</strong> <code>mn-etcd-mz</code>(<code>~735.7ms</code>).</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>6.76</td><td style=text-align:center>687.36ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>6.635</td><td style=text-align:center>692.68ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>6.3</td><td style=text-align:center>735.7ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool range requests to <code>follower</code> all keys</p><ul><li><p><code>mn-etcd-sz</code>(<code>~737.68ms</code>) latency is <strong>~5% slightly higher than</strong> <code>mn-etcd-mz</code>(<code>~713.7ms</code>).</p></li><li><p>Compare to <code>leader</code> consistency <code>Linearizable</code>read request, <code>follower</code> is <em>~5% slightly higher</em>.</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>6.163</td><td style=text-align:center>737.68ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>6.52</td><td style=text-align:center>713.7ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p><code>mn-etcd-sz</code> latency(<code>~757.73ms</code>) is <strong>~10% higher than</strong> <code>mn-etcd-mz</code>(<code>~690.4ms</code>).</p></li><li><p>Compare to <code>follower</code> consistency <code>Linearizable</code>read request, <code>follower</code> consistency <code>Serializable</code> is <em>~3% slightly higher</em> for <code>mn-etcd-sz</code>.</p></li><li><p><em>Compare to <code>follower</code> consistency <code>Linearizable</code>read request, <code>follower</code> consistency <code>Serializable</code> is <em>~5% less</em> for <code>mn-etcd-mz</code>.</em></p></li><li><p>*Compare to <code>leader</code> consistency <code>Serializable</code>read request, <code>follower</code> consistency <code>Serializable</code> is <em>~5% less</em> for <code>mn-etcd-mz</code>. *</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>6.0295</td><td style=text-align:center>757.73ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>256</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>6.87</td><td style=text-align:center>690.4ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li></ul><hr><br></details></li><li><details><summary>In this case benchmark tool tries to get specific key with random `1MB` value.</summary><ul><li><p>Benchmark tool range requests to <code>leader</code> with single client.</p><ul><li><p><code>sn-etcd-sz</code> latency(<code>~5.96ms</code>) is <strong>~5% lesser than</strong> <code>mn-etcd-sz</code>(<code>~6.28ms</code>).</p></li><li><p><code>mn-etcd-sz</code> latency(<code>~6.28ms</code>) is <strong>~10% higher than</strong> <code>mn-etcd-mz</code>(<code>~5.3ms</code>).</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>167.381</td><td style=text-align:center>5.96ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>158.822</td><td style=text-align:center>6.28ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>187.94</td><td style=text-align:center>5.3ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p>Compare to consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>~15% less</strong> for <code>sn-etcd-sz</code>, <code>mn-etcd-sz</code>, <code>mn-etcd-mz</code></p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>184.95</td><td style=text-align:center>5.398ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>176.901</td><td style=text-align:center>5.64ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>209.99</td><td style=text-align:center>4.7ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool range requests to <code>follower</code> with single client.</p><ul><li><p><code>mn-etcd-sz</code> latency(<code>~6.66ms</code>) is <strong>~10% higher than</strong> <code>mn-etcd-mz</code>(<code>~6.16ms</code>).</p></li><li><p><em>Compare to <code>leader</code>, <code>follower</code> read request latency is <strong>~10% high</strong> for <code>mn-etcd-sz</code></em></p></li><li><p><em>Compare to <code>leader</code>, <code>follower</code> read request latency is <strong>~20% high</strong> for <code>mn-etcd-mz</code></em></p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>150.680</td><td style=text-align:center>6.66ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>162.072</td><td style=text-align:center>6.16ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p>Compare to consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>~15% less</strong> for <code>mn-etcd-sz</code>(<code>~5.84ms</code>), <code>mn-etcd-mz</code>(<code>~5.01ms</code>).</p></li><li><p><em>Compare to <code>leader</code>, <code>follower</code> read request latency is <strong>~5% slightly high</strong> for <code>mn-etcd-sz</code>, <code>mn-etcd-mz</code></em></p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>170.918</td><td style=text-align:center>5.84ms</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>1</td><td style=text-align:center>1</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>199.01</td><td style=text-align:center>5.01ms</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool range requests to <code>leader</code> with multiple clients.</p><ul><li><code>sn-etcd-sz</code> latency(<code>~1.593secs</code>) is <strong>~20% lesser than</strong> <code>mn-etcd-sz</code>(<code>~1.974secs</code>).</li><li><code>mn-etcd-sz</code> latency(<code>~1.974secs</code>) is <strong>~5% greater than</strong> <code>mn-etcd-mz</code>(<code>~1.81secs</code>).</li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>252.149</td><td style=text-align:center>1.593secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>205.589</td><td style=text-align:center>1.974secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>230.42</td><td style=text-align:center>1.81secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p><em>Compare to consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>more or less same</strong> for <code>sn-etcd-sz</code>(<code>~1.57961secs</code>), <code>mn-etcd-mz</code>(<code>~1.8secs</code>) not a big difference</em></p></li><li><p>Compare to consistency <code>Linearizable</code>, <code>Serializable</code> is <strong>~10% high</strong> for <code>mn-etcd-sz</code>(<code>~ 2.277secs</code>).</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>252.406</td><td style=text-align:center>1.57961secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>181.905</td><td style=text-align:center>2.277secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>227.64</td><td style=text-align:center>1.8secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p>Benchmark tool range requests to <code>follower</code> with multiple client.</p><ul><li><code>mn-etcd-sz</code> latency is <strong>~20% less than</strong> <code>mn-etcd-mz</code>.</li><li>Compare to <code>leader</code> consistency <code>Linearizable</code>, <code>follower</code> read request latency is ~15 less for <code>mn-etcd-sz</code>(<code>~1.694secs</code>).</li><li>Compare to <code>leader</code> consistency <code>Linearizable</code>, <code>follower</code> read request latency is ~10% higher for <code>mn-etcd-sz</code>(<code>~1.977secs</code>).</li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>248.489</td><td style=text-align:center>1.694secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>210.22</td><td style=text-align:center>1.977secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-2</td><td style=text-align:center>205.765</td><td style=text-align:center>1.967secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>l</td><td style=text-align:center>follower-2</td><td style=text-align:center>195.2</td><td style=text-align:center>2.159secs</td><td style=text-align:center>eu-west-1b</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table><ul><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>231.458</td><td style=text-align:center>1.7413secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>214.80</td><td style=text-align:center>1.907secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-2</td><td style=text-align:center>183.320</td><td style=text-align:center>2.2810secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>1000</td><td style=text-align:center>1000000</td><td style=text-align:center>100</td><td style=text-align:center>500</td><td style=text-align:center>true</td><td style=text-align:center>s</td><td style=text-align:center>follower-2</td><td style=text-align:center>195.40</td><td style=text-align:center>2.164secs</td><td style=text-align:center>eu-west-1b</td><td style=text-align:center>etcd-main-2</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p>Benchmark tool range requests to <code>leader</code> all keys.</p><ul><li><p><code>sn-etcd-sz</code> latency(<code>~8.993secs</code>) is <strong>~3% slightly lower than</strong> <code>mn-etcd-sz</code>(<code>~9.236secs</code>).</p></li><li><p><code>mn-etcd-sz</code> latency(<code>~9.236secs</code>) is <strong>~2% slightly lower than</strong> <code>mn-etcd-mz</code>(<code>~9.100secs</code>).</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>0.5139</td><td style=text-align:center>8.993secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>0.506</td><td style=text-align:center>9.236secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>leader</td><td style=text-align:center>0.508</td><td style=text-align:center>9.100secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p>Compare to consistency <code>Linearizable</code>read request, <code>follower</code> for <code>sn-etcd-sz</code>(<code>~9.secs</code>) is <strong>a slight difference <code>10ms</code></strong>.</p></li><li><p>Compare to consistency <code>Linearizable</code>read request, <code>follower</code> for <code>mn-etcd-sz</code>(<code>~9.113secs</code>) is <strong>~1% less</strong>, not a big difference.</p></li><li><p>Compare to consistency <code>Linearizable</code>read request, <code>follower</code> for <code>mn-etcd-mz</code>(<code>~8.799secs</code>) is <strong>~3% less</strong>, not a big difference.</p></li><li><p><code>sn-etcd-sz</code> latency(<code>~9.secs</code>) is <strong>~1% slightly less than</strong> <code>mn-etcd-sz</code>(<code>~9.113secs</code>).</p></li><li><p><em><code>mn-etcd-sz</code> latency(<code>~9.113secs</code>) is <strong>~3% slightly higher than</strong> <code>mn-etcd-mz</code>(<code>~8.799secs</code>)</em>.</p><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>0.51125</td><td style=text-align:center>9.0003secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>sn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>0.4993</td><td style=text-align:center>9.113secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>leader</td><td style=text-align:center>0.522</td><td style=text-align:center>8.799secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-1</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li><li><p>Benchmark tool range requests to <code>follower</code> all keys</p><ul><li><p><code>mn-etcd-sz</code> latency(<code>~9.065secs</code>) is <strong>~1% slightly higher than</strong> <code>mn-etcd-mz</code>(<code>~9.007secs</code>).</p></li><li><p>Compare to <code>leader</code> consistency <code>Linearizable</code>read request, <code>follower</code> is <em>~1% slightly higher</em> for both cases <code>mn-etcd-sz</code>, <code>mn-etcd-mz</code> .</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>0.512</td><td style=text-align:center>9.065secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>l</td><td style=text-align:center>follower-1</td><td style=text-align:center>0.533</td><td style=text-align:center>9.007secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li><li><p>Compare to consistency <code>Linearizable</code>read request, <code>follower</code> for <code>mn-etcd-sz</code>(<code>~9.553secs</code>) is <strong>~5% high</strong>.</p></li><li><p><em>Compare to consistency <code>Linearizable</code>read request, <code>follower</code> for <code>mn-etcd-mz</code>(<code>~7.7433secs</code>) is <strong>~15% less</strong></em>.</p></li><li><p><em><code>mn-etcd-sz</code>(<code>~9.553secs</code>) latency is <strong>~20% higher than</strong> <code>mn-etcd-mz</code>(<code>~7.7433secs</code>)</em>.</p></li><li><table><thead><tr><th style=text-align:center>Number of requests</th><th style=text-align:center>Value size</th><th style=text-align:center>Number of connections</th><th style=text-align:center>Number of clients</th><th style=text-align:center>sequential-keys</th><th style=text-align:center>Consistency</th><th style=text-align:center>Target etcd server</th><th style=text-align:center>Average write QPS</th><th style=text-align:center>Average latency per request</th><th style=text-align:center>zone</th><th style=text-align:center>server name</th><th style=text-align:center>Test name</th></tr></thead><tbody><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>0.4743</td><td style=text-align:center>9.553secs</td><td style=text-align:center>eu-west-1a</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-sz</td></tr><tr><td style=text-align:center>20</td><td style=text-align:center>1000000</td><td style=text-align:center>2</td><td style=text-align:center>5</td><td style=text-align:center>false</td><td style=text-align:center>s</td><td style=text-align:center>follower-1</td><td style=text-align:center>0.5500</td><td style=text-align:center>7.7433secs</td><td style=text-align:center>eu-west-1c</td><td style=text-align:center>etcd-main-0</td><td style=text-align:center>mn-etcd-mz</td></tr></tbody></table></li></ul></li></ul><hr><br></details></li></ul><hr><br><br><blockquote><p>NOTE: This Network latency analysis is inspired by <a href=https://etcd.io/docs/v3.5/op-guide/performance/>ETCD performance</a>.</p></blockquote></div><div class=td-content style=page-break-before:always><h1 id=pg-0c08258ff2592af89695aa27767310a3>4 - Local e2e Tests</h1><h1 id=e2e-test-suite>e2e Test Suite</h1><p>Developers can run extended e2e tests, in addition to unit tests, for Etcd-Druid in or from
their local environments. This is recommended to verify the desired behavior of several features
and to avoid regressions in future releases.</p><p>The very same tests typically run as part of the component&rsquo;s release job as well as on demand, e.g.,
when triggered by Etcd-Druid maintainers for open pull requests.</p><p>Testing Etcd-Druid automatically involves a certain test coverage for <a href=https://github.com/gardener/etcd-backup-restore/>gardener/etcd-backup-restore</a>
which is deployed as a side-car to the actual <code>etcd</code> container.</p><h2 id=prerequisites>Prerequisites</h2><p>The e2e test lifecycle is managed with the help of <a href=https://skaffold.dev/>skaffold</a>. Every involved step like <code>setup</code>,
<code>deploy</code>, <code>undeploy</code> or <code>cleanup</code> is executed against a <strong>Kubernetes</strong> cluster which makes it a mandatory prerequisite at the same time.
Only <a href=https://skaffold.dev/>skaffold</a> itself with involved <code>docker</code>, <code>helm</code> and <code>kubectl</code> executions as well as
the e2e-tests are executed locally. Required binaries are automatically downloaded if you use the corresponding <code>make</code> target,
as described in this document.</p><p>It&rsquo;s expected that especially the <code>deploy</code> step is run against a Kubernetes cluster which doesn&rsquo;t contain an Druid deployment or any left-overs like <code>druid.gardener.cloud</code> CRDs.
The <code>deploy</code> step will likely fail in such scenarios.</p><blockquote><p>Tip: Create a fresh <a href=https://kind.sigs.k8s.io/>KinD</a> cluster or a similar one with a small footprint before executing the tests.</p></blockquote><h2 id=providers>Providers</h2><p>The following providers are supported for e2e tests:</p><ul><li>AWS</li><li>Azure</li><li>GCP</li></ul><blockquote><p>Valid credentials need to be provided when tests happen with mentioned cloud providers.</p></blockquote><h2 id=flow>Flow</h2><p>An e2e test execution involves the following steps:</p><table><thead><tr><th>Step</th><th>Description</th></tr></thead><tbody><tr><td><code>setup</code></td><td>Create a storage bucket which is used for etcd backups (only with cloud providers).</td></tr><tr><td><code>deploy</code></td><td>Build Docker image, upload it to registry (if remote cluster - see <a href=https://skaffold.dev/docs/pipeline-stages/builders/docker/>Docker build</a>), deploy Helm chart (<code>charts/druid</code>) to Kubernetes cluster.</td></tr><tr><td><code>test</code></td><td>Execute e2e tests as defined in <code>test/e2e</code>.</td></tr><tr><td><code>undeploy</code></td><td>Remove the deployed artifacts from Kubernetes cluster.</td></tr><tr><td><code>cleanup</code></td><td>Delete storage bucket and Druid deployment from test cluster.</td></tr></tbody></table><h3 id=make-target>Make target</h3><p>Executing e2e-tests is as easy as executing the following command <strong>with defined Env-Vars as desribed in the following
section and as needed for your test scenario</strong>.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>make test-e2e
</span></span></code></pre></div><h3 id=common-env-variables>Common Env Variables</h3><p>The following environment variables influence how the flow described above is executed:</p><ul><li><code>PROVIDERS</code>: Providers used for testing (<code>all</code>, <code>aws</code>, <code>azure</code>, <code>gcp</code>). Multiple entries must be comma separated.<blockquote><p><strong>Note</strong>: Some tests will use very first entry from env <code>PROVIDERS</code> for e2e testing (ex: multi-node tests). So for multi-node tests to use specific provider, specify that provider as first entry in env <code>PROVIDERS</code>.</p></blockquote></li><li><code>KUBECONFIG</code>: Kubeconfig pointing to cluster where Etcd-Druid will be deployed (preferably <a href=https://kind.sigs.k8s.io>KinD</a>).</li><li><code>TEST_ID</code>: Some ID which is used to create assets for and during testing.</li><li><code>STEPS</code>: Steps executed by <code>make</code> target (<code>setup</code>, <code>deploy</code>, <code>test</code>, <code>undeploy</code>, <code>cleanup</code> - default: all steps).</li></ul><h3 id=aws-env-variables>AWS Env Variables</h3><ul><li><code>AWS_ACCESS_KEY_ID</code>: Key ID of the user.</li><li><code>AWS_SECRET_ACCESS_KEY</code>: Access key of the user.</li><li><code>AWS_REGION</code>: Region in which the test bucket is created.</li></ul><p>Example:</p><pre tabindex=0><code>make \
  AWS_ACCESS_KEY_ID=&#34;abc&#34; \
  AWS_SECRET_ACCESS_KEY=&#34;xyz&#34; \
  AWS_REGION=&#34;eu-central-1&#34; \
  KUBECONFIG=&#34;$HOME/.kube/config&#34; \
  PROVIDERS=&#34;aws&#34; \
  TEST_ID=&#34;some-test-id&#34; \
  STEPS=&#34;setup,deploy,test,undeploy,cleanup&#34; \
test-e2e
</code></pre><h3 id=azure-env-variables>Azure Env Variables</h3><ul><li><code>STORAGE_ACCOUNT</code>: Storage account used for managing the storage container.</li><li><code>STORAGE_KEY</code>: Key of storage account.</li></ul><p>Example:</p><pre tabindex=0><code>make \
  STORAGE_ACCOUNT=&#34;abc&#34; \
  STORAGE_KEY=&#34;eHl6Cg==&#34; \
  KUBECONFIG=&#34;$HOME/.kube/config&#34; \
  PROVIDERS=&#34;azure&#34; \
  TEST_ID=&#34;some-test-id&#34; \
  STEPS=&#34;setup,deploy,test,undeploy,cleanup&#34; \
test-e2e
</code></pre><h3 id=gcp-env-variables>GCP Env Variables</h3><ul><li><code>GCP_SERVICEACCOUNT_JSON_PATH</code>: Path to the service account json file used for this test.</li><li><code>GCP_PROJECT_ID</code>: ID of the GCP project.</li></ul><p>Example:</p><pre tabindex=0><code>make \
  GCP_SERVICEACCOUNT_JSON_PATH=&#34;/var/lib/secrets/serviceaccount.json&#34; \
  GCP_PROJECT_ID=&#34;xyz-project&#34; \
  KUBECONFIG=&#34;$HOME/.kube/config&#34; \
  PROVIDERS=&#34;gcp&#34; \
  TEST_ID=&#34;some-test-id&#34; \
  STEPS=&#34;setup,deploy,test,undeploy,cleanup&#34; \
test-e2e
</code></pre><h2 id=e2e-test-with-localstack>e2e test with localstack</h2><p>Above mentioned e2e tests need actual storage from cloud provider to be setup. But there is a tool named <a href=https://docs.localstack.cloud/user-guide/aws/s3/>localstack</a> that enables to run e2e test with mock AWS storage. We can also provision KIND cluster for e2e tests. So, together with localstack and KIND cluster, we don&rsquo;t need to depend on any actual cloud provider infrastructure to be setup to run e2e tests.</p><h3 id=how-are-the-kind-cluster-and-localstack-set-up>How are the KIND cluster and localstack set up</h3><p>KIND or Kubernetes-In-Docker is a kubernetes cluster that is set up inside a docker container. This cluster is with limited capability as it does not have much compute power. But this cluster can easily be setup inside a container and can be tear down easily just by removing a container. That&rsquo;s why KIND cluster is very easy to use for e2e tests. <code>Makefile</code> command helps to spin up a KIND cluster and use the cluster to run e2e tests.</p><p>There is a docker image for localstack. The image is deployed as pod inside the KIND cluster through <code>hack/e2e-test/infrastructure/localstack/localstack.yaml</code>. <code>Makefile</code> takes care of deploying the yaml file in a KIND cluster.</p><p>The developer needs to run <code>make ci-e2e-kind</code> command. This command in turn runs <code>hack/ci-e2e-kind.sh</code> which spin up the KIND cluster and deploy localstack in it and then run the e2e tests using localstack as mock AWS storage provider. e2e tests are actually run on host machine but deploy the druid controller inside KIND cluster. Druid controller spawns multinode ETCD clusters inside KIND cluster. e2e tests verify whether the druid controller performs its jobs correctly or not. Mock localstack storage is cleaned up after every e2e tests. That&rsquo;s why the e2e tests need to access the localstack pod running inside KIND cluster. The network traffic between host machine and localstack pod is resolved via mapping localstack pod port to host port while setting up the KIND cluster via <code>hack/e2e-test/infrastructure/kind/cluster.yaml</code></p><h3 id=how-to-execute-e2e-tests-with-localstack-and-kind-cluster>How to execute e2e tests with localstack and KIND cluster</h3><p>The developer just needs to install KIND following <a href=https://kind.sigs.k8s.io/docs/user/quick-start/>https://kind.sigs.k8s.io/docs/user/quick-start/</a> and start docker daemon. Additionaly, KIND cluster can be enabled via docker desktop.</p><p>Check if KIND is working on your machine by running the following command:
<code>kind create cluster --name kind-2</code></p><p>If successful, delete the cluster by:
<code>kind delete cluster --name kind-2</code></p><p>Run the following <code>make</code> command to perform e2e tests that will automatically take care of spinning up KIND clsuter and deploying localstack pod:
<code>make ci-e2e-kind</code></p></div><div class=td-content style=page-break-before:always><h1 id=pg-13d7c740d2c1114db53a87610c20dae1>5 - Metrics</h1><h1 id=monitoring>Monitoring</h1><p>etcd-druid uses <a href=http://prometheus.io/>Prometheus</a> for metrics reporting. The metrics can be used for real-time monitoring and debugging of compaction jobs.</p><p>The simplest way to see the available metrics is to cURL the metrics endpoint <code>/metrics</code>. The format is described <a href=http://prometheus.io/docs/instrumenting/exposition_formats/>here</a>.</p><p>Follow the <a href=http://prometheus.io/docs/introduction/getting_started/>Prometheus getting started doc</a> to spin up a Prometheus server to collect etcd metrics.</p><p>The naming of metrics follows the suggested <a href=http://prometheus.io/docs/practices/naming/>Prometheus best practices</a>. All compaction related metrics are put under namespace <code>etcddruid</code> and subsystem <code>compaction</code>.</p><h3 id=compaction>Compaction</h3><p>These metrics give an idea about the compaction jobs that run after some interval in shoot control planes. Studying the metrices, we can deduce how many compaction job ran successfully, how many failed, how many delta events compacted etc.</p><table><thead><tr><th>Name</th><th>Description</th><th>Type</th></tr></thead><tbody><tr><td>etcddruid_compaction_jobs_total</td><td>Total number of compaction jobs initiated by compaction controller.</td><td>Counter</td></tr><tr><td>etcddruid_compaction_jobs_current</td><td>Number of currently running compaction job.</td><td>Gauge</td></tr><tr><td>etcddruid_compaction_job_duration_seconds</td><td>Total time taken in seconds to finish a running compaction job.</td><td>Histogram</td></tr><tr><td>etcddruid_compaction_num_delta_events</td><td>Total number of etcd events to be compacted by a compaction job.</td><td>Gauge</td></tr></tbody></table><p>There are two labels for <code>etcddruid_compaction_jobs_total</code> metrics. The label <code>succeeded</code> shows how many of the compaction jobs are succeeded and label <code>failed</code> shows how many of compaction jobs are failed.</p><p>There are two labels for <code>etcddruid_compaction_job_duration_seconds</code> metrics. The label <code>succeeded</code> shows how much time taken by a successful job to complete and label <code>failed</code> shows how much time taken by a failed compaction job.</p><p><code>etcddruid_compaction_jobs_current</code> metric comes with label <code>etcd_namespace</code> that indicates the namespace of the ETCD running in the control plane of a shoot cluster..</p><h2 id=prometheus-supplied-metrics>Prometheus supplied metrics</h2><p>The Prometheus client library provides a number of metrics under the <code>go</code> and <code>process</code> namespaces.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c9cb561d7c47dcbfd331f67e25c06add>6 - Multinode Metrics</h1><h2 id=metrics-multi-node-etcd>Metrics: Multi-node etcd</h2><h4 id=etcd>Etcd</h4><table><thead><tr><th>No.</th><th>Metrics Name</th><th>Description</th><th>Comments</th></tr></thead><tbody><tr><td>1</td><td>etcd_disk_wal_fsync_duration_seconds</td><td>latency distributions of fsync called by WAL.</td><td>High disk operation latencies indicate disk issues.</td></tr><tr><td>2</td><td>etcd_disk_backend_commit_duration_seconds</td><td>latency distributions of commit called by backend.</td><td>High disk operation latencies indicate disk issues.</td></tr><tr><td>3</td><td>etcd_server_has_leader</td><td>whether or not a leader exists. 1: leader exists, 0: leader not exists.</td><td>To capture quorum loss or to check the availability of etcd cluster.</td></tr><tr><td>4</td><td>etcd_server_is_leader</td><td>whether or not this member is a leader. 1 if it is, 0 otherwise.</td><td></td></tr><tr><td>5</td><td>etcd_server_leader_changes_seen_total</td><td>number of leader changes seen.</td><td>Helpful in fine tuning the zonal cluster like etcd-heartbeat time etc, it can also indicates the etcd load and network issues.</td></tr><tr><td>6</td><td>etcd_server_is_learner</td><td>whether or not this member is a learner. 1 if it is, 0 otherwise.</td><td></td></tr><tr><td>7</td><td>etcd_server_learner_promote_successes</td><td>total number of successful learner promotions while this member is leader.</td><td>Might be helpful in checking the success of API calls called by backup-restore.</td></tr><tr><td>8</td><td>etcd_network_client_grpc_received_bytes_total</td><td>total number of bytes received from grpc clients.</td><td>Client Traffic In.</td></tr><tr><td>9</td><td>etcd_network_client_grpc_sent_bytes_total</td><td>total number of bytes sent to grpc clients.</td><td>Client Traffic Out.</td></tr><tr><td>10</td><td>etcd_network_peer_sent_bytes_total</td><td>total number of bytes sent to peers.</td><td>Useful for network usage.</td></tr><tr><td>11</td><td>etcd_network_peer_received_bytes_total</td><td>total number of bytes received from peers.</td><td>Useful for network usage.</td></tr><tr><td>12</td><td>etcd_network_active_peers</td><td>current number of active peer connections.</td><td>Might be useful in detecting issues like network partition.</td></tr><tr><td>13</td><td>etcd_server_proposals_committed_total</td><td>total number of consensus proposals committed.</td><td>A consistently large lag between a single member and its leader indicates that member is slow or unhealthy.</td></tr><tr><td>14</td><td>etcd_server_proposals_pending</td><td>current number of pending proposals to commit.</td><td>Pending proposals suggests there is a high client load or the member cannot commit proposals.</td></tr><tr><td>15</td><td>etcd_server_proposals_failed_total</td><td>total number of failed proposals seen.</td><td>Might indicates downtime caused by a loss of quorum.</td></tr><tr><td>16</td><td>etcd_server_proposals_applied_total</td><td>total number of consensus proposals applied.</td><td>Difference between etcd_server_proposals_committed_total and etcd_server_proposals_applied_total should usually be small.</td></tr><tr><td>17</td><td>etcd_mvcc_db_total_size_in_bytes</td><td>total size of the underlying database physically allocated in bytes.</td><td></td></tr><tr><td>18</td><td>etcd_server_heartbeat_send_failures_total</td><td>total number of leader heartbeat send failures.</td><td>Might be helpful in fine-tuning the cluster or detecting slow disk or any network issues.</td></tr><tr><td>19</td><td>etcd_network_peer_round_trip_time_seconds</td><td>round-trip-time histogram between peers.</td><td>Might be helpful in fine-tuning network usage specially for zonal etcd cluster.</td></tr><tr><td>20</td><td>etcd_server_slow_apply_total</td><td>total number of slow apply requests.</td><td>Might indicate overloaded from slow disk.</td></tr><tr><td>21</td><td>etcd_server_slow_read_indexes_total</td><td>total number of pending read indexes not in sync with leader&rsquo;s or timed out read index requests.</td><td></td></tr></tbody></table><h4 id=backup-restore>Backup-restore</h4><table><thead><tr><th>No.</th><th>Metrics Name</th><th>Description</th></tr></thead><tbody><tr><td>1.</td><td>etcdbr_cluster_size</td><td>to capture the scale-up/scale-down scenarios.</td></tr><tr><td>2.</td><td>etcdbr_is_learner</td><td>whether or not this member is a learner. 1 if it is, 0 otherwise.</td></tr><tr><td>3.</td><td>etcdbr_is_learner_count_total</td><td>total number times member added as the learner.</td></tr><tr><td>4.</td><td>etcdbr_restoration_duration_seconds</td><td>total latency distribution required to restore the etcd member.</td></tr><tr><td>5.</td><td>etcdbr_add_learner_duration_seconds</td><td>total latency distribution of adding the etcd member as a learner to the cluster.</td></tr><tr><td>6.</td><td>etcdbr_member_remove_duration_seconds</td><td>total latency distribution removing the etcd member from the cluster.</td></tr><tr><td>7.</td><td>etcdbr_member_promote_duration_seconds</td><td>total latency distribution of promoting the learner to the voting member.</td></tr><tr><td>8.</td><td>etcdbr_defragmentation_duration_seconds</td><td>total latency distribution of defragmentation of each etcd cluster member.</td></tr></tbody></table></div><div class=td-content style=page-break-before:always><h1 id=pg-9a32aa2865b6d66481c92282e17a7abd>7 - Recover from etcd Permanent Quorum Loss</h1><h2 id=quorum-loss-in-etcd-cluster>Quorum loss in ETCD Cluster</h2><p><a href=https://etcd.io/docs/v3.4/op-guide/recovery/>Quorum loss</a> means when majority of ETCD pods(greater than or equal to n/2 + 1) are down simultaneously for some reason.</p><p>There are two types of quorum loss that can happen to <a href=/docs/other-components/etcd-druid/etcd-druid/proposals/multi-node/>ETCD multinode cluster</a> :</p><ol><li><p><strong>Transient quorum loss</strong> - A quorum loss is called transient when majority of ETCD pods are down simultaneously for some time. The pods may be down due to network unavailability, high resource usages etc. When the pods come back after some time, they can re-join to the cluster and the quorum is recovered automatically without any manual intervention. There should not be a permanent failure for majority of etcd pods due to hardware failure or disk corruption.</p></li><li><p><strong>Permanent quorum loss</strong> - A quorum loss is called permanent when majority of ETCD cluster members experience permanent failure, whether due to hardware failure or disk corruption etc. then the etcd cluster is not going to recover automatically from the quorum loss. A human operator will now need to intervene and execute the following steps to recover the multi-node ETCD cluster.</p></li></ol><p>If permanent quorum loss occurs to a multinode ETCD cluster, the operator needs to note down the PVCs, configmaps, statefulsets, CRs etc related to that ETCD cluster and work on those resources only. Following steps guide a human operator to recover from permanent quorum loss of a ETCD cluster. We assume the name of the ETCD CR for the ETCD cluster is <code>etcd-main</code>.</p><p><strong>ETCD cluster in shoot control plane of gardener deployment:</strong>
There are two <a href=/docs/other-components/etcd-druid/etcd-druid/proposals/multi-node/>ETCD clusters</a> running in shoot control plane. One is named as <code>etcd-events</code> and another is named <code>etcd-main</code>. The operator needs to take care of permanent quorum loss to a specific cluster. If permanent quorum loss occurs to <code>etcd-events</code> cluster, the operator needs to note down the PVCs, configmaps, statefulsets, CRs etc related to <code>etcd-events</code> cluster and work on those resources only.</p><p>⚠️ <strong>Note:</strong> Please note that manually restoring etcd can result in data loss. This guide is the last resort to bring an ETCD cluster up and running again.</p><p>If etcd-druid and etcd-backup-restore is being used with gardener, then</p><p>Target the control plane of affected shoot cluster via <code>kubectl</code>. Alternatively, you can use <a href=https://github.com/gardener/gardenctl-v2>gardenctl</a> to target the control plane of the affected shoot cluster. You can get the details to target the control plane from the Access tile in the shoot cluster details page on the Gardener dashboard. Ensure that you are targeting the correct namespace.</p><ol><li>Add the following annotation to the <code>Etcd</code> resource <code>kubectl annotate etcd etcd-main druid.gardener.cloud/ignore-reconciliation="true"</code></li><li>Note down the configmap name that is attached to the <code>etcd-main</code> statefulset. If you describe the statefulset with <code>kubectl describe sts etcd-main</code>, look for the lines similar to following lines to identify attached configmap name. It will be needed at later stages:</li></ol><pre tabindex=0><code>  Volumes:
   etcd-config-file:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      etcd-bootstrap-4785b0
    Optional:  false
</code></pre><pre tabindex=0><code>  Alternatively, the related configmap name can be obtained by executing following command as well:
</code></pre><p><code>kubectl get sts etcd-main -o jsonpath='{.spec.template.spec.volumes[?(@.name=="etcd-config-file")].configMap.name}'</code></p><ol start=3><li><p>Scale down the <code>etcd-main</code> statefulset replicas to <code>0</code></p><p><code>kubectl scale sts etcd-main --replicas=0</code></p></li><li><p>The PVCs will look like the following on listing them with the command <code>kubectl get pvc</code> :</p><pre tabindex=0><code>main-etcd-etcd-main-0        Bound    pv-shoot--garden--aws-ha-dcb51848-49fa-4501-b2f2-f8d8f1fad111   80Gi       RWO            gardener.cloud-fast   13d
main-etcd-etcd-main-1        Bound    pv-shoot--garden--aws-ha-b4751b28-c06e-41b7-b08c-6486e03090dd   80Gi       RWO            gardener.cloud-fast   13d
main-etcd-etcd-main-2        Bound    pv-shoot--garden--aws-ha-ff17323b-d62e-4d5e-a742-9de823621490   80Gi       RWO            gardener.cloud-fast   13d
</code></pre><p>Delete all PVCs that are attached to <code>etcd-main</code> cluster.</p><p><code>kubectl delete pvc -l instance=etcd-main</code></p></li><li><p>Edit the <code>etcd-main</code> cluster&rsquo;s configmap (ex: <code>etcd-bootstrap-4785b0</code>) as follows:</p><p>Find the <code>initial-cluster</code> field in the configmap. It will look like the following:</p><pre tabindex=0><code># Initial cluster
  initial-cluster: etcd-main-0=https://etcd-main-0.etcd-main-peer.default.svc:2380,etcd-main-1=https://etcd-main-1.etcd-main-peer.default.svc:2380,etcd-main-2=https://etcd-main-2.etcd-main-peer.default.svc:2380
</code></pre><p>Change the <code>initial-cluster</code> field to have only one member (<code>etcd-main-0</code>) in the string. It should now look like this:</p><pre tabindex=0><code># Initial cluster
  initial-cluster: etcd-main-0=https://etcd-main-0.etcd-main-peer.default.svc:2380
</code></pre></li><li><p>Scale up the <code>etcd-main</code> statefulset replicas to <code>1</code></p><p><code>kubectl scale sts etcd-main --replicas=1</code></p></li><li><p>Wait for the single-member etcd cluster to be completely ready.</p><p><code>kubectl get pods etcd-main-0</code> will give the following output when ready:</p><pre tabindex=0><code>NAME          READY   STATUS    RESTARTS   AGE
etcd-main-0   2/2     Running   0          1m
</code></pre></li><li><p>Remove the following annotation from the <code>Etcd</code> resource <code>etcd-main</code>: <code>kubectl annotate etcd etcd-main druid.gardener.cloud/ignore-reconciliation-</code></p></li><li><p>Finally add the following annotation to the <code>Etcd</code> resource <code>etcd-main</code>: <code>kubectl annotate etcd etcd-main gardener.cloud/operation="reconcile"</code></p></li><li><p>Verify that the etcd cluster is formed correctly.</p><p>All the <code>etcd-main</code> pods will have outputs similar to following:</p><pre tabindex=0><code>NAME          READY   STATUS    RESTARTS   AGE
etcd-main-0   2/2     Running   0          5m
etcd-main-1   2/2     Running   0          1m
etcd-main-2   2/2     Running   0          1m
</code></pre><p>Additionally, check if the ETCD CR is ready with <code>kubectl get etcd etcd-main</code> :</p><pre tabindex=0><code class=language-✹ data-lang=✹>NAME        READY   AGE
etcd-main   true    13d
</code></pre><p>Additionally, check the leases for 30 seconds at least. There should be leases starting with <code>etcd-main</code> as many as <code>etcd-main</code> replicas. One of those leases will have holder identity as <code>&lt;etcd-member-id>:Leader</code> and rest of those leases have holder identities as <code>&lt;etcd-member-id>:Member</code>. The <code>AGE</code> of those leases can also be inspected to identify if those leases were updated in conjunction with the restart of the ETCD cluster: Example:</p><pre tabindex=0><code>NAME        HOLDER                  AGE
etcd-main-0 4c37667312a3912b:Member 1m
etcd-main-1 75a9b74cfd3077cc:Member 1m
etcd-main-2 c62ee6af755e890d:Leader 1m
</code></pre></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-192f2fff3a7a52d0f8d8385ccab8ad84>8 - Single Member Restoration</h1><h1 id=restoration-of-a-single-member-in-multi-node-etcd-deployed-by-etcd-druid>Restoration of a single member in multi-node etcd deployed by etcd-druid.</h1><p><strong>Note</strong>:</p><ul><li>For a cluster with n members, we are proposing the solution to only single member restoration within a etcd cluster not the quorum loss scenario (when majority of members within a cluster fail).</li><li>In this proposal we are not targetting the recovery of single member which got separated from cluster due to <a href=https://etcd.io/docs/v3.3/op-guide/failures/#network-partition>network partition</a>.</li></ul><h2 id=motivation>Motivation</h2><p>If a single etcd member within a multi-node etcd cluster goes down due to DB corruption/PVC corruption/Invalid data-dir then it needs to be brought back. Unlike in the single-node case, a minority member of a multi-node cluster can&rsquo;t be restored from the snapshots present in storage container as you can&rsquo;t restore from the old snapshots as it contains the metadata information of cluster which leads to <strong>memberID mismatch</strong> that prevents the new member from coming up as new member is getting its metadata information from db which got restore from old snapshots.</p><h2 id=solution>Solution</h2><ul><li>If a corresponding backup-restore sidecar detects that its corresponding etcd is down due to <a href=https://github.com/gardener/etcd-backup-restore/blob/7d27a47f5793b0949492d225ada5fd8344b6b6a2/pkg/initializer/validator/datavalidator.go#L177>data-dir corruption</a> or <a href=https://github.com/gardener/etcd-backup-restore/blob/7d27a47f5793b0949492d225ada5fd8344b6b6a2/pkg/initializer/validator/datavalidator.go#L204>Invalid data-dir</a></li><li>Then backup-restore will first remove the failing etcd member from the cluster using the <a href=https://github.com/etcd-io/etcd/blob/ae9734ed278b7a1a7dfc82e800471ebbf9fce56f/clientv3/cluster.go#L45-L46>MemberRemove API</a> call and clean the data-dir of failed etcd member.</li><li>It won&rsquo;t affect the etcd cluster as quorum is still maintained.</li><li>After successfully removing failed etcd member from the cluster, backup-restore sidecar will try to add a new etcd member to a cluster to get the same cluster size as before.</li><li>Backup-restore firstly adds new member as a <a href=https://etcd.io/docs/v3.3/learning/learner/>Learner</a> using the <a href=https://github.com/etcd-io/etcd/blob/ae9734ed278b7a1a7dfc82e800471ebbf9fce56f/clientv3/cluster.go#L42-L43>MemberAddAsLearner API</a> call, once learner is added to the cluster and it&rsquo;s get in sync with leader and becomes up-to-date then promote the learner(non-voting member) to a voting member using <a href=https://github.com/etcd-io/etcd/blob/ae9734ed278b7a1a7dfc82e800471ebbf9fce56f/clientv3/cluster.go#L51-L52>MemberPromote API</a> call.</li><li>So, the failed member first needs to be removed from the cluster and then added as a new member.</li></ul><h3 id=example>Example:</h3><ol><li>If a <code>3</code> member etcd cluster has 1 downed member(due to invalid data-dir), the cluster can still make forward progress because the quorum is <code>2</code>.</li><li>Etcd downed member get restarted and it&rsquo;s corresponding backup-restore sidecar receives an <a href=https://github.com/gardener/etcd-backup-restore/blob/master/doc/proposals/design.md#workflow>initialization</a> request.</li><li>Then, backup-restore sidecar checks for data corruption/invalid data-dir.</li><li>Backup-restore sidecar detects that data-dir is invalid and its a multi-node etcd cluster.</li><li>Then, backup-restore sidecar removed the downed etcd member from cluster.</li><li>The number of members in a cluster becomes <code>2</code> and the quorum remains at <code>2</code>, so it won&rsquo;t affect the etcd cluster.</li><li>Clean the data-dir and add a member as a learner(non-voting member).</li><li>As soon as learner gets in sync with leader, promote the learner to a voting member, hence increasing number of members in a cluster back to <code>3</code>.</li></ol></div></main></div></div><footer class="footer row d-print-none"><div class="container-fluid footer-wrapper"><ul class=nav><li><a href=https://gardener.cloud/blog/>Blogs</a></li><li><a href=https://gardener.cloud/community/>Community</a></li><li><a href=https://gardener.cloud/adopter/>Adopters</a></li><li><a href=/docs/>Documentation</a></li></ul><img src=/images/lp/gardener-logo.svg alt="Logo Gardener" class=logo><ul class=media-wr><li><a target=_blank href=https://kubernetes.slack.com/archives/CB57N0BFG><img src=/images/branding/slack-logo-white.svg class=media-icon><div class=media-text>Slack</div></a></li><li><a target=_blank href=https://github.com/gardener><img src=/images/branding/github-mark-logo.png class=media-icon><div class=media-text>GitHub</div></a></li><li><a target=_blank href=https://www.youtube.com/channel/UCwUhwKFREV8Su0gwAJQX7tw><img src=/images/branding/youtube-logo-dark.svg class=media-icon><div class=media-text>YouTube</div></a></li><li><a target=_blank href=https://twitter.com/GardenerProject><img src=/images/branding/twitter-logo-white.svg class=media-icon><div class=media-text>Twitter</div></a></li></ul><span class=copyright>Copyright 2019-2023 Gardener project authors. <a href=https://www.sap.com/corporate/en/legal/privacy.html>Privacy policy
<i class="fa fa-external-link" aria-hidden=true></i></a></span></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/mermaid@8.13.4/dist/mermaid.min.js integrity="sha512-JERecFUBbsm75UpkVheAuDOE8NdHjQBrPACfEQYPwvPG+fjgCpHAz1Jw2ci9EXmd3DdfiWth3O3CQvcfEg8gsA==" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.7b24c0fb082ffb2de6cb14d6c95e9f8053053709ffcf8c761ef8e9ad2f8021e4.js integrity="sha256-eyTA+wgv+y3myxTWyV6fgFMFNwn/z4x2HvjprS+AIeQ=" crossorigin=anonymous></script></body></html>