<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=https://gardener.cloud/docs/other-components/network-problem-detector/><link rel=alternate type=application/rss+xml href=https://gardener.cloud/docs/other-components/network-problem-detector/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Network Problem Detector | Gardener</title>
<meta name=description content="A tool which diagnoses network issues in Kubernetes clusters by performing various connectivity checks"><meta property="og:url" content="https://gardener.cloud/docs/other-components/network-problem-detector/"><meta property="og:site_name" content="Gardener"><meta property="og:title" content="Network Problem Detector"><meta property="og:description" content="A tool which diagnoses network issues in Kubernetes clusters by performing various connectivity checks"><meta property="og:locale" content="en_US"><meta property="og:type" content="website"><meta property="og:image" content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta itemprop=name content="Network Problem Detector"><meta itemprop=description content="A tool which diagnoses network issues in Kubernetes clusters by performing various connectivity checks"><meta itemprop=wordCount content="1598"><meta itemprop=image content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta name=twitter:title content="Network Problem Detector"><meta name=twitter:description content="A tool which diagnoses network issues in Kubernetes clusters by performing various connectivity checks"><link rel=preload href=/scss/main.min.49c1324f1f1dba4c9ef68ad97115fa0ab62113d3bc7c5137b64b13a0cfb423c4.css as=style integrity="sha256-ScEyTx8dukye9orZcRX6CrYhE9O8fFE3tksToM+0I8Q=" crossorigin=anonymous><link href=/scss/main.min.49c1324f1f1dba4c9ef68ad97115fa0ab62113d3bc7c5137b64b13a0cfb423c4.css rel=stylesheet integrity="sha256-ScEyTx8dukye9orZcRX6CrYhE9O8fFE3tksToM+0I8Q=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg width="90" height="90" viewBox="0 0 90 90" xmlns:xlink="http://www.w3.org/1999/xlink"><title>logo</title><desc>Created with Sketch.</desc><defs><path d="M41.8864954.994901575c.996545099999999-.479910833 2.6164002-.477918931 3.6088091.0L76.8159138 16.0781121C77.8124589 16.5580229 78.8208647 17.8257185 79.0659694 18.8995926l7.7355517 33.8916663C87.0476474 53.8696088 86.6852538 55.4484075 85.9984855 56.3095876L64.3239514 83.4885938C63.6343208 84.3533632 62.1740175 85.0543973 61.0725268 85.0543973H26.3092731c-1.1060816.0-2.5646564-.704623400000003-3.2514246-1.5658035L1.38331434 56.3095876C.693683723 55.4448182.335174016 53.865133.580278769 52.7912589L8.31583044 18.8995926C8.56195675 17.8212428 9.57347722 16.556031 10.5658861 16.0781121L41.8864954.994901575z" id="path-1"/><linearGradient x1="12.7542673%" y1="-18.6617048%" x2="88.2666158%" y2="84.6075483%" id="linearGradient-3"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="50%" y1="4.93673768%" x2="148.756007%" y2="175.514523%" id="linearGradient-4"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="19.1574381%" y1="-9.04800713%" x2="82.2203149%" y2="77.9084293%" id="linearGradient-5"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="57.4403751%" y1="26.3148481%" x2="137.966711%" y2="158.080556%" id="linearGradient-6"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="logo"><g id="Rectangle-2" transform="translate(1.000000, 0.000000)"><mask id="mask-2" fill="#fff"><use xlink:href="#path-1"/></mask><use id="Mask" fill="#009f76" xlink:href="#path-1"/><polygon fill="#000" opacity=".289628623" mask="url(#mask-2)" points="-17.6484375 54.5224609 30.8242188 25.0791016 63.4726562 58.5 24.7324219 92.6689453"/></g><path d="M56.8508631 39.260019C56.4193519 40.443987 55.6088085 41.581593 54.6736295 42.1938694l-8.0738997 5.2861089c-1.3854671.907087099999998-3.6247515.9116711-5.0172201.0L33.50861 42.1938694C32.123143 41.2867823 31 39.206345 31 37.545932V26.4150304c0-.725313.2131118-1.5301454.569268099999999-2.2825772L56.8508631 39.260019z" id="Combined-Shape" fill="url(#linearGradient-3)" transform="translate(43.925432, 36.147233) scale(-1, 1) translate(-43.925432, -36.147233)"/><path d="M56.0774672 25.1412464C56.4306829 25.8903325 56.6425556 26.6907345 56.6425556 27.4119019V38.5428034c0 1.6598979-1.1161415 3.73626640000001-2.50861 4.6479374l-8.0738997 5.286109c-1.3854671.907087000000004-3.6247516.911671000000005-5.0172201.0L32.9689261 43.1907408C32.2918101 42.7474223 31.6773514 42.0238435 31.2260376 41.206007L56.0774672 25.1412464z" id="Combined-Shape" fill="url(#linearGradient-4)" transform="translate(43.821278, 37.246598) scale(-1, 1) translate(-43.821278, -37.246598)"/><path d="M65.0702134 57.1846889C64.5985426 58.2007851 63.8367404 59.1236871 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.1597438 58.7930183 24 56.7816693 24 55.1323495V37.1145303C24 36.3487436 24.249712 35.5060005 24.6599102 34.7400631L65.0702134 57.1846889z" id="Combined-Shape" fill="url(#linearGradient-5)"/><path d="M65.0189476 34.954538C65.3636909 35.6617313 65.5692194 36.42021 65.5692194 37.1145303V55.1323495C65.5692194 56.7842831 64.4072119 58.7943252 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.9237304 59.2341061 25.3159155 58.5918431 24.8568495 57.8487596L65.0189476 34.954538z" id="Combined-Shape" fill="url(#linearGradient-6)"/></g></g></svg></span><span class=text-capitalize>Gardener</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://demo.gardener.cloud target=_blank><span>Demo</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/adopter><span>Adopters</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><div class=dropdown><a href=/docs class=nav-link>Documentation</a><div class=dropdown-content><a class=taxonomy-term href=/docs>Users</a>
<a class=taxonomy-term href=/docs>Operators</a>
<a class=taxonomy-term href=/docs>Developers</a>
<a class=taxonomy-term href=/docs>All</a></div></div></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog><span>Blogs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community><span>Community</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.57066556943560c185eb65a29be52a03.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/other-components/network-problem-detector/>Return to the regular view of this page</a>.</p></div><h1 class=title>Network Problem Detector</h1><div class=lead>A tool which diagnoses network issues in Kubernetes clusters by performing various connectivity checks</div><div class=content><h1 id=network-problem-detector>Network Problem Detector<a class=td-heading-self-link href=#network-problem-detector aria-label="Heading self-link"></a></h1><p><a href=https://api.reuse.software/info/github.com/gardener/network-problem-detector><img src=https://api.reuse.software/badge/github.com/gardener/network-problem-detector alt="REUSE status"></a></p><p>The Network Problem Detector performs network-related periodic checks between all nodes of a Kubernetes cluster,
to its Kube API server and/or external endpoints. Checks are performed using TCP connections, HTTPS GET requests, DNS lookups (UDP), or
Ping (ICMP).</p><h2 id=architecture>Architecture<a class=td-heading-self-link href=#architecture aria-label="Heading self-link"></a></h2><p>The Network Problem Detector (NWPD) consists of two daemon sets and a separate controller.</p><ul><li>one daemon set on the cluster network running a first set of agents on all worker nodes</li><li>another daemon set on the host network running a second set of agents on all worker node</li><li>the controller watches for changes on nodes and agent pods and updates the <strong>cluster config</strong> consumed by the agents.</li></ul><p>A agent pod performs checks periodically as defined by the configuration in <strong>agent config</strong> <code>ConfigMap</code>.
The agents need to know about all nodes and agent pods on the cluster network for checking node-to-node communication.
But they don&rsquo;t communicate with the kube apiserver to watch for resources.
Instead they rely on the information provided by the <strong>cluster config</strong> <code>ConfigMap</code>
which is mounted as a volume in the pod. This <code>ConfigMap</code> is updated by the NWPD controller, which watches for changes on
nodes and pods in the kube-system namespace. As soon as a kubelet discovers these changes, the agents see them as a file change.</p><p>The results of the checks are stored locally on the node filesystem for later inspection with the <code>nwpdcli</code> command line tool.
Additionally they are also exposed as metrics for scrapping by Prometheus.
By enabling the <code>K8s exporter</code>, the agents periodically patch the node conditions <code>ClusterNetworkProblem</code> and <code>HostNetworkProblem</code> in
the status of the node resources. If checks are failing, a summarising event is created too.
The <code>K8s exporter</code> is the only part of the agent which talks to the kube-apiserver.</p><p><img src=/__resources/architecture-standalone_39319a.svg alt="Architecture Standalone Deployment"></p><p><em>Note:</em> When the NWPD is deployed by the <a href=https://github.com/gardener/gardener-extension-shoot-networking-problemdetector>gardener-extension-shoot-networking-problemdetector</a>,
the NWPD controller is deployed in the shoot control plane.</p><h2 id=deployment>Deployment<a class=td-heading-self-link href=#deployment aria-label="Heading self-link"></a></h2><h3 id=get-started-adhoc-stand-alone-deployment>Get Started: Adhoc stand-alone deployment<a class=td-heading-self-link href=#get-started-adhoc-stand-alone-deployment aria-label="Heading self-link"></a></h3><p>To get started, the Network Problem Detector is deployed without integration with other tools.</p><p><em>Side remark:</em></p><p>This is the fatest way to get started with NWPD. In a productive environment, you may prefer to scrap the check results
using <a href=https://prometheus.io/>Prometheus</a> from metrics HTTP endpoints
exposed by the agent pods. You may still follow this stand-alone installation, but
you will need additional configuration on the Prometheus side which is not covered here.
For more details see <a href=/docs/other-components/network-problem-detector/#access-check-results-by-prometheus-metrics>Access check results by Prometheus metrics</a> below.</p><p>Here we rely on the local collection created by each agent on the node file system. This collection keeps the check
results for the last several hours before they are garbage collected.</p><p>Follow these steps to deploy NWPD to a Kubernetes cluster:</p><ol><li><p>Checkout the latest release and build the <code>nwpdcli</code> with</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>make build-local
</span></span></code></pre></div></li><li><p>Set the <code>KUBECONFIG</code> environment variable to the kubeconfig of the cluster</p></li><li><p>Apply the two daemon sets (one for the host network, one for the pod network) with</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./nwpdcli deploy agent
</span></span></code></pre></div><p>This step will also provide a default configuration with jobs for the daemon sets on node and pod networks. See below for more details.</p><p><em>Note:</em> Run <code>./nwpdcli deploy agent --help</code> to see more options.</p></li><li><p>Optional: In a second shell run the controller to update the configuration on changes of nodes and pod endpoints of the pod network daemon set with</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./nwpdcli run-controller
</span></span></code></pre></div><p>Alternatively install the agent controller with</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./nwpdcli deploy controller
</span></span></code></pre></div></li><li><p>Collect the observations from all nodes with</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./nwpdcli collect
</span></span></code></pre></div></li><li><p>Aggregate the observations in text or SVG form</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./nwpdcli aggr --minutes 10 --svg-output aggr.html
</span></span><span style=display:flex><span>open aggr.html <span style=color:green># to open the html on Mac OS</span>
</span></span></code></pre></div><p>Your may apply filters on time window, source, destination or job ID to restrict the aggregation. See <code>./nwpdcli aggr --help</code> for more details.</p></li><li><p>Optional: Repeat steps 5. and 6. anytime</p></li><li><p>Drill down with query for specific observations</p><p>If you need to drill down to specific observations, you may use</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./nwpdcli query --help
</span></span></code></pre></div></li><li><p>Remove daemon sets with</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./nwpdcli deploy agent --delete
</span></span></code></pre></div></li><li><p>Optional: Remove controller deployment with</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./nwpdcli deploy controller --delete
</span></span></code></pre></div></li></ol><h3 id=deployment-in-a-gardener-landscape>Deployment in a Gardener landscape<a class=td-heading-self-link href=#deployment-in-a-gardener-landscape aria-label="Heading self-link"></a></h3><p>The Network Problem Detector can be deployed automatically in a <a href=https://github.com/gardener/gardener>Gardener</a> landscape.
Please see project <a href=https://github.com/gardener/gardener-extension-shoot-networking-problemdetector>gardener-extension-shoot-networking-problemdetector</a>
for more details.</p><p>In this case, the check results are available as Prometheus metrics and can be accessed by a predefined Grafana dashboard.</p><h4 id=access-check-results-by-prometheus-metrics>Access check results by Prometheus metrics<a class=td-heading-self-link href=#access-check-results-by-prometheus-metrics aria-label="Heading self-link"></a></h4><p>Two metrics are exposed.</p><ul><li><p><code>nwpd_aggregated_observations</code>
This is a counter vector with the total count of an observation (result of a check) and has these labels:</p><ul><li><code>src</code>: name of node the checking agent is running</li><li><code>dest</code>: name of the destination node or endpoint</li><li><code>jobid</code>: job id of the job definition</li><li><code>status</code>: result of the check, either <code>ok</code> or <code>failed</code></li></ul></li><li><p><code>nwpd_aggregated_observations_latency_secs</code>
This is a gauge vector with the duration of the last successful observation in seconds and has these labels:</p><ul><li><code>src</code>: name of node the checking agent is running</li><li><code>dest</code>: name of the destination node or endpoint</li><li><code>jobid</code>: job id of the job definition</li></ul></li></ul><h2 id=default-configuration-of-check-jobs>Default Configuration of Check Jobs<a class=td-heading-self-link href=#default-configuration-of-check-jobs aria-label="Heading self-link"></a></h2><p>Checks are defined as jobs using virtual command lines. These command lines are just Go routines executed periodically from the agent running in the pods of the two daemon sets.
There are two daemon sets. One running in the host network (i.e. using the host network in the pod), the other one running in the cluster (=pod) network.</p><h3 id=default-configuration>Default configuration<a class=td-heading-self-link href=#default-configuration aria-label="Heading self-link"></a></h3><p>To examine the current default configuration, run the command</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./nwpdcli deploy print-default-config
</span></span></code></pre></div><h3 id=job-types>Job types<a class=td-heading-self-link href=#job-types aria-label="Heading self-link"></a></h3><ol><li><p><code>checkTCPPort [--period &lt;duration>] [--scale-period] [--endpoints &lt;host1:ip1:port1>,&lt;host2:ip2:port2>,...] [--endpoints-of-pod-ds] [--node-port &lt;port>] [--endpoint-internal-kube-apiserver] [--endpoint-external-kube-apiserver]</code></p><p>Tries to open a connection to the given <code>IP:port</code>. There are multipe variants:</p><ul><li>using an explicit list of endpoints with <code>--endpoints</code></li><li>using the known pod endpoints of the pod network daemon set</li><li>using a node port on all known nodes</li><li>the cluster internal address of the kube-apiserver (IP address of <code>kubernetes.default.svc.cluster.local</code>)</li><li>the external address of the kube-apiserver</li></ul><p>The checks run in a robin round fashion after an initial random shuffle. The global default period between two checks can overwritten with the <code>--period</code> option.
With <code>--scale-period</code> the period length is increased by a factor <code>sqrt(&lt;number-of-nodes>)</code> to reduce the number of checks per node.</p><p>Note that known nodes and pod endpoints are only updated by the controller. Changes are applied as soon as the changed config maps are discovered by the kubelets.
This typically happens within a minute.</p></li><li><p><code>checkHTTPSGet [--period &lt;duration>] [--scale-period] [--endpoints &lt;host1[:port1]>,&lt;host2[:port2]>,...] [--endpoint-internal-kube-apiserver] [--endpoint-external-kube-apiserver]</code></p><p>Tries to open a connection to the given <code>IP:port</code>. There are multipe variants:</p><ul><li>using an explicit list of endpoints with <code>--endpoints</code></li><li>the cluster internal address of the kube-apiserver</li><li>the external address of the kube-apiserver</li></ul><p>The checks run in a robin round fashion after an inital random shuffle. The global default period between two checks can overwritten with the <code>--period</code> option.
With <code>--scale-period</code> the period length is increased by a factor <code>sqrt(&lt;number-of-nodes>)</code> to reduce the number of checks per node.</p></li><li><p><code>nslookup [--period &lt;duration>] [--scale-period] [--names host1,host2,...] [--name-internal-kube-apiserver"] [--name-external-kube-apiserver]</code></p><p>Looks up hosts using the local resolver of the pod or the node (for agents running in the host network).</p></li><li><p><code>pingHost [--period &lt;duration>] [--scale-period] [--hosts &lt;host1:ip1>,&lt;host2:ip2>,...]</code></p><p>Robin round ping to all nodes or the provided host list. The node or host list is shuffled randomly on start.
The global default period between two pings can overwritten with the <code>--period</code> option.</p><p>The pod needs <code>NET_ADMIN</code> capabilities to be allowed to perform pings.</p></li></ol><h3 id=default-jobs-for-the-daemon-set-on-the-host-network>Default jobs for the daemon set on the <strong>host network</strong><a class=td-heading-self-link href=#default-jobs-for-the-daemon-set-on-the-host-network aria-label="Heading self-link"></a></h3><table><thead><tr><th>Job ID</th><th>Job Type</th><th>Description</th></tr></thead><tbody><tr><td><code>https-n2api-ext</code></td><td><code>checkHTTPSGet</code></td><td>HTTPS Get check from all pods of the daemon set of the host network to the external address of the Kube API server.</td></tr><tr><td><code>nslookup-n</code></td><td><code>nslookup</code></td><td>DNS Lookup of IP addresses for the domain name <code>europe-docker.pkg.dev</code>, and external name of Kube API server.</td></tr><tr><td><code>tcp-n2api-ext</code></td><td><code>checkTCPPort</code></td><td>TCP connection check from all pods of the daemon set of the host network to the external address of the Kube API server.</td></tr><tr><td><code>tcp-n2api-int</code></td><td><code>checkTCPPort</code></td><td>TCP connection check from all pods of the daemon set of the host network to the internal address of the Kube API server.</td></tr><tr><td><code>tcp-n2n</code></td><td><code>checkTCPPort</code></td><td>TCP connection check from all pods of the daemon set of the host network to the node port used by the NWPD agent on the host network.</td></tr><tr><td><code>tcp-n2p</code></td><td><code>checkTCPPort</code></td><td>TCP connection check from all pods of the daemon set of the host network to pod endpoints (pod IP, port of GRPC server) of the daemon set running in the pod network.</td></tr></tbody></table><p>The job IDs of the default configuration on the host (=node) network are using the naming convention <code>&lt;jobtype-shortcut>-n[2&lt;destination>][-(int|ext)]</code>.</p><h3 id=default-jobs-for-the-daemon-set-on-the-cluster-network>Default jobs for the daemon set on the <strong>cluster network</strong><a class=td-heading-self-link href=#default-jobs-for-the-daemon-set-on-the-cluster-network aria-label="Heading self-link"></a></h3><table><thead><tr><th>Job ID</th><th>Job Type</th><th>Description</th></tr></thead><tbody><tr><td><code>https-p2api-ext</code></td><td><code>checkHTTPSGet</code></td><td>HTTPS Get check from all pods of the daemon set on the cluster network to the external address of the Kube API server.</td></tr><tr><td><code>https-p2api-int</code></td><td><code>checkHTTPSGet</code></td><td>HTTPS Get check from all pods of the daemon set on the cluster network to the internal address of the Kube API server (<code>kubernetes.default.svc.cluster.local.:443</code>).</td></tr><tr><td><code>nslookup-p</code></td><td><code>nslookup</code></td><td>Lookup of IP addresses for external DNS name <code>europe-docker.pkg.dev</code>, and internal and external names of Kube API server.</td></tr><tr><td><code>tcp-p2api-ext</code></td><td><code>checkTCPPort</code></td><td>TCP connection check from all pods of the daemon set on the cluster network to the external address of the Kube API server.</td></tr><tr><td><code>tcp-p2api-int</code></td><td><code>checkTCPPort</code></td><td>TCP connection check from all pods of the daemon set of the cluster network to the internal address of the Kube API server.</td></tr><tr><td><code>tcp-p2n</code></td><td><code>checkTCPPort</code></td><td>TCP connection check from all pods of the daemon set of the cluster network to the node port used by the NWPD agent on the host network.</td></tr><tr><td><code>tcp-p2p</code></td><td><code>checkTCPPort</code></td><td>TCP connection check from all pods of the daemon set of the cluster network to pod endpoints (pod IP, port of GRPC server) of the daemon set running in the pod network.</td></tr></tbody></table><p>The job IDs of the default configuration on the cluster (=pod) network are using the naming convention <code>&lt;jobtype-shortcut>-p[2&lt;destination>][-(int|ext)]</code>.</p></div></div></main></div></div><footer class="footer row d-print-none"><div class="container-fluid footer-wrapper"><ul class=nav><li><a href=https://gardener.cloud/blog/>Blogs</a></li><li><a href=https://gardener.cloud/community/>Community</a></li><li><a href=https://gardener.cloud/adopter/>Adopters</a></li><li><a href=/docs/>Documentation</a></li></ul><img src=/images/lp/gardener-logo.svg alt="Logo Gardener" class=logo><ul class=media-wr><li><a target=_blank href=https://kubernetes.slack.com/archives/CB57N0BFG><img src=/images/branding/slack-logo-white.svg class=media-icon><div class=media-text>Slack</div></a></li><li><a target=_blank href=https://github.com/gardener><img src=/images/branding/github-mark-logo.png class=media-icon><div class=media-text>GitHub</div></a></li><li><a target=_blank href=https://www.youtube.com/channel/UCwUhwKFREV8Su0gwAJQX7tw><img src=/images/branding/youtube-logo-dark.svg class=media-icon><div class=media-text>YouTube</div></a></li><li><a target=_blank href=https://x.com/GardenerProject><img src=/images/branding/x-logo-white.svg class=media-icon><div class=media-text>X</div></a></li></ul><span class=copyright>Copyright 2019-2025 Gardener project authors.
<a href=https://www.sap.com/about/legal/terms-of-use.html>Terms of Use
<i class="fa fa-external-link" aria-hidden=true></i>
</a>|
<a href=https://www.sap.com/about/legal/terms-of-use.html>Privacy Statement
<i class="fa fa-external-link" aria-hidden=true></i>
</a>|
<a href=https://www.sap.com/about/legal/terms-of-use.html>Legal Disclosure
<i class="fa fa-external-link" aria-hidden=true></i></a></span></div></footer></div><script src=/js/main.min.69e2c1ae9320465ab10236d9ef752c6a4442c54b48b883b17c497b7c7d96a796.js integrity="sha256-aeLBrpMgRlqxAjbZ73UsakRCxUtIuIOxfEl7fH2Wp5Y=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script></body></html>