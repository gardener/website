<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.95.0"><link rel=canonical type=text/html href=https://gardener.cloud/docs/tutorials/><link rel=alternate type=application/rss+xml href=https://gardener.cloud/docs/tutorials/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Tutorials | Gardener</title><meta name=description content><meta property="og:title" content="Tutorials"><meta property="og:description" content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:type" content="website"><meta property="og:url" content="https://gardener.cloud/docs/tutorials/"><meta property="og:image" content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta itemprop=name content="Tutorials"><meta itemprop=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta name=twitter:title content="Tutorials"><meta name=twitter:description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><link rel=preload href=/scss/main.min.b5b806bb2cd9fe9ed809539377398aa9df0eb8ca0c983a6eae0b413d528d8f0e.css as=style><link href=/scss/main.min.b5b806bb2cd9fe9ed809539377398aa9df0eb8ca0c983a6eae0b413d528d8f0e.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7N3XF5XLGV"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7N3XF5XLGV",{anonymize_ip:!1})}</script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg width="90" height="90" viewBox="0 0 90 90" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>logo</title><desc>Created with Sketch.</desc><defs><path d="M41.8864954.994901575c.996545099999999-.479910833 2.6164002-.477918931 3.6088091.0L76.8159138 16.0781121C77.8124589 16.5580229 78.8208647 17.8257185 79.0659694 18.8995926l7.7355517 33.8916663C87.0476474 53.8696088 86.6852538 55.4484075 85.9984855 56.3095876L64.3239514 83.4885938C63.6343208 84.3533632 62.1740175 85.0543973 61.0725268 85.0543973H26.3092731c-1.1060816.0-2.5646564-.704623400000003-3.2514246-1.5658035L1.38331434 56.3095876C.693683723 55.4448182.335174016 53.865133.580278769 52.7912589L8.31583044 18.8995926C8.56195675 17.8212428 9.57347722 16.556031 10.5658861 16.0781121L41.8864954.994901575z" id="path-1"/><linearGradient x1="12.7542673%" y1="-18.6617048%" x2="88.2666158%" y2="84.6075483%" id="linearGradient-3"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="50%" y1="4.93673768%" x2="148.756007%" y2="175.514523%" id="linearGradient-4"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="19.1574381%" y1="-9.04800713%" x2="82.2203149%" y2="77.9084293%" id="linearGradient-5"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="57.4403751%" y1="26.3148481%" x2="137.966711%" y2="158.080556%" id="linearGradient-6"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="logo"><g id="Rectangle-2" transform="translate(1.000000, 0.000000)"><mask id="mask-2" fill="#fff"><use xlink:href="#path-1"/></mask><use id="Mask" fill="#009f76" xlink:href="#path-1"/><polygon fill="#000" opacity=".289628623" mask="url(#mask-2)" points="-17.6484375 54.5224609 30.8242188 25.0791016 63.4726562 58.5 24.7324219 92.6689453"/></g><path d="M56.8508631 39.260019C56.4193519 40.443987 55.6088085 41.581593 54.6736295 42.1938694l-8.0738997 5.2861089c-1.3854671.907087099999998-3.6247515.9116711-5.0172201.0L33.50861 42.1938694C32.123143 41.2867823 31 39.206345 31 37.545932V26.4150304c0-.725313.2131118-1.5301454.569268099999999-2.2825772L56.8508631 39.260019z" id="Combined-Shape" fill="url(#linearGradient-3)" transform="translate(43.925432, 36.147233) scale(-1, 1) translate(-43.925432, -36.147233)"/><path d="M56.0774672 25.1412464C56.4306829 25.8903325 56.6425556 26.6907345 56.6425556 27.4119019V38.5428034c0 1.6598979-1.1161415 3.73626640000001-2.50861 4.6479374l-8.0738997 5.286109c-1.3854671.907087000000004-3.6247516.911671000000005-5.0172201.0L32.9689261 43.1907408C32.2918101 42.7474223 31.6773514 42.0238435 31.2260376 41.206007L56.0774672 25.1412464z" id="Combined-Shape" fill="url(#linearGradient-4)" transform="translate(43.821278, 37.246598) scale(-1, 1) translate(-43.821278, -37.246598)"/><path d="M65.0702134 57.1846889C64.5985426 58.2007851 63.8367404 59.1236871 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.1597438 58.7930183 24 56.7816693 24 55.1323495V37.1145303C24 36.3487436 24.249712 35.5060005 24.6599102 34.7400631L65.0702134 57.1846889z" id="Combined-Shape" fill="url(#linearGradient-5)"/><path d="M65.0189476 34.954538C65.3636909 35.6617313 65.5692194 36.42021 65.5692194 37.1145303V55.1323495C65.5692194 56.7842831 64.4072119 58.7943252 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.9237304 59.2341061 25.3159155 58.5918431 24.8568495 57.8487596L65.0189476 34.954538z" id="Combined-Shape" fill="url(#linearGradient-6)"/></g></g></svg></span><span class=text-capitalize>Gardener</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/adopter><span>Adopters</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog><span>Blogs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community><span>Community</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs><span>Documentation</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.5f5ea78067f2e8211eb9699672da8215.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/tutorials/>Return to the regular view of this page</a>.</p></div><h1 class=title>Tutorials</h1><div class=content></div></div><div class=td-content><h1 id=pg-c29db379d9a38d027354d38e2e735f08>1 - Authenticating with an Identity Provider</h1><div class=lead>Use OpenID Connect to authenticate users to access shoot clusters</div><h2 id=prerequisites>Prerequisites</h2><p>Please read the following background material on <a href=https://kubernetes.io/docs/reference/access-authn-authz/authentication/#openid-connect-tokens>Authenticating</a>.</p><h2 id=overview>Overview</h2><p>Kubernetes on its own doesn’t provide any user management. In other words, users aren’t managed through Kubernetes resources. Whenever you refer to a human user it’s sufficient to use a unique ID, for example, an email address. Nevertheless, Gardener project owners can use an identity provider to authenticate user access for shoot clusters in the following way:</p><ol><li><a href=#configure-an-identity-provider>Configure an Identity Provider</a> using <strong>OpenID Connect</strong> (OIDC).</li><li><a href=#configure-a-local-kubectl-oidc-login>Configure a local kubectl oidc-login</a> to enable <code>oidc-login</code>.</li><li><a href=#configure-the-shoot-cluster>Configure the shoot cluster</a> to share details of the OIDC-compliant identity provider with the Kubernetes API Server.</li><li><a href=#authorize-an-authenticated-user>Authorize an authenticated user</a> using role-based access control (RBAC).</li><li><a href=#verify-the-result>Verify the result</a></li></ol><div class="alert alert-info" role=alert><h4 class=alert-heading>Note</h4>Gardener allows administrators to modify aspects of the control plane setup. It gives administrators full control of how the control plane is parameterized. While this offers much flexibility, administrators need to ensure that they don’t configure a control plane that goes beyond the service level agreements of the responsible operators team.</div><h2 id=configure-an-identity-provider>Configure an Identity Provider</h2><p>Create a tenant in an OIDC compatible Identity Provider. For simplicity, we use <em>Auth0</em>, which has a free plan.</p><ol><li><p>In your tenant, create a client application to use authentication with <code>kubectl</code>:</p><p><img src=/__resources/Create-client-application_c47ce0.png alt="Create client application"></p></li><li><p>Provide a <em>Name</em>, choose <em>Native</em> as application type, and choose <em>CREATE</em>.</p><p><img src=/__resources/Choose-application-type_392e78.png alt="Choose application type"></p></li><li><p>In the tab <em>Settings</em>, copy the following parameters to a local text file:</p><ul><li><p><em>Domain</em></p><p>Corresponds to the <strong>issuer</strong> in OIDC. It must be an <code>https</code>-secured endpoint (Auth0 requires a trailing <code>/</code> at the end). For more information, see <a href=https://openid.net/specs/openid-connect-core-1_0.html#Terminology>Issuer Identifier</a>.</p></li><li><p><em>Client ID</em></p></li><li><p><em>Client Secret</em></p><p><img src=/__resources/Basic-information_2f952f.png alt="Basic information"></p></li></ul></li><li><p>Configure the client to have a callback url of <code>http://localhost:8000</code>. This callback connects to your local <code>kubectl oidc-login</code> plugin:</p><p><img src=/__resources/Configure-callback_1a247f.png alt="Configure callback"></p></li><li><p>Save your changes.</p></li><li><p>Verify that <code>https://&lt;Auth0 Domain>/.well-known/openid-configuration</code> is reachable.</p></li><li><p>Choose <em>Users & Roles</em> > <em>Users</em> > <em>CREATE USERS</em> to create a user with a user and password:</p><p><img src=/__resources/Create-user_97a940.png alt="Create user"></p></li></ol><div class="alert alert-info" role=alert><h4 class=alert-heading>Note</h4>Users must have a <em>verified</em> email address.</div><h2 id=configure-a-local-kubectl-oidc-login>Configure a Local <code>kubectl</code> <code>oidc-login</code></h2><ol><li><p>Install the <code>kubectl</code> plugin <a href=https://github.com/int128/kubelogin>oidc-login</a>. We highly recommend the <a href=https://github.com/kubernetes-sigs/krew>krew</a> installation tool, which also makes other plugins easily available.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>kubectl krew install oidc-login
</span></span></code></pre></div><p>The response looks like this:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>Updated the local copy of plugin index.
</span></span><span style=display:flex><span>Installing plugin: oidc-login
</span></span><span style=display:flex><span>CAVEATS:
</span></span><span style=display:flex><span>\
</span></span><span style=display:flex><span>|  You need to setup the OIDC provider, Kubernetes API server, role binding and kubeconfig.
</span></span><span style=display:flex><span>|  See https://github.com/int128/kubelogin for more.
</span></span><span style=display:flex><span>/
</span></span><span style=display:flex><span>Installed plugin: oidc-login
</span></span></code></pre></div></li><li><p>Prepare a <code>kubeconfig</code> for later use:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>cp ~/.kube/config ~/.kube/config-oidc
</span></span></code></pre></div></li><li><p>Modify the configuration of <code>~/.kube/config-oidc</code> as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: Config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>contexts:
</span></span><span style=display:flex><span>- context:
</span></span><span style=display:flex><span>    cluster: shoot--project--mycluster
</span></span><span style=display:flex><span>    user: my-oidc
</span></span><span style=display:flex><span>  name: shoot--project--mycluster
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>users:
</span></span><span style=display:flex><span>- name: my-oidc
</span></span><span style=display:flex><span>  user:
</span></span><span style=display:flex><span>    exec:
</span></span><span style=display:flex><span>      apiVersion: client.authentication.k8s.io/v1beta1
</span></span><span style=display:flex><span>      command: kubectl
</span></span><span style=display:flex><span>      args:
</span></span><span style=display:flex><span>      - oidc-login
</span></span><span style=display:flex><span>      - get-token
</span></span><span style=display:flex><span>      - --oidc-issuer-url=https://&lt;Issuer&gt;/ 
</span></span><span style=display:flex><span>      - --oidc-client-id=&lt;Client ID&gt;
</span></span><span style=display:flex><span>      - --oidc-client-secret=&lt;Client Secret&gt;
</span></span><span style=display:flex><span>      - --oidc-extra-scope=email,offline_access,profile
</span></span></code></pre></div></li></ol><p>To test our OIDC-based authentication, the context <code>shoot--project--mycluster</code> of <code>~/.kube/config-oidc</code> is used in a later step. For now, continue to use the configuration <code>~/.kube/config</code> with administration rights for your cluster.</p><h2 id=configure-the-shoot-cluster>Configure the Shoot Cluster</h2><p>Modify the shoot cluster YAML as follows, using the client ID and the domain (as issuer) from the settings of the client application you created in Auth0:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>apiVersion: garden.sapcloud.io/v1beta1
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: mycluster
</span></span><span style=display:flex><span>  namespace: garden-project
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  kubernetes:
</span></span><span style=display:flex><span>    kubeAPIServer:
</span></span><span style=display:flex><span>      oidcConfig:
</span></span><span style=display:flex><span>        clientID: &lt;Client ID&gt;
</span></span><span style=display:flex><span>        issuerURL: <span style=color:#a31515>&#34;https://&lt;Issuer&gt;/&#34;</span>
</span></span><span style=display:flex><span>        usernameClaim: email
</span></span></code></pre></div><p>This change of the <code>Shoot</code> manifest triggers a reconciliation. Once the reconciliation is finished, your OIDC configuration is applied. It <strong>doesn&rsquo;t</strong> invalidate other certificate-based authentication methods. Wait for Gardener to reconcile the change. It can take up to 5 minutes.</p><h2 id=authorize-an-authenticated-user>Authorize an Authenticated User</h2><p>In Auth0, you created a user with a verified email address, <code>test@test.com</code> in our example. For simplicity, we authorize a single user identified by this email address with the cluster role <code>view</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: rbac.authorization.k8s.io/v1
</span></span><span style=display:flex><span>kind: ClusterRoleBinding
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: viewer-test
</span></span><span style=display:flex><span>roleRef:
</span></span><span style=display:flex><span>  apiGroup: rbac.authorization.k8s.io
</span></span><span style=display:flex><span>  kind: ClusterRole
</span></span><span style=display:flex><span>  name: view
</span></span><span style=display:flex><span>subjects:
</span></span><span style=display:flex><span>- apiGroup: rbac.authorization.k8s.io
</span></span><span style=display:flex><span>  kind: User
</span></span><span style=display:flex><span>  name: test@test.com
</span></span></code></pre></div><p>As administrator, apply the cluster role binding in your shoot cluster.</p><h2 id=verify-the-result>Verify the Result</h2><ol><li><p>To step into the shoes of your user, use the prepared <code>kubeconfig</code> file <code>~/.kube/config-oidc</code>, and switch to the context that uses <code>oidc-login</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>cd ~/.kube
</span></span><span style=display:flex><span>export KUBECONFIG=$(pwd)/config-oidc
</span></span><span style=display:flex><span>kubectl config use-context `shoot--project--mycluster`
</span></span></code></pre></div></li><li><p><code>kubectl</code> delegates the authentication to plugin <code>oidc-login</code> the first time the user uses <code>kubectl</code> to contact the API server, for example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>kubectl get all
</span></span></code></pre></div><p>The plugin opens a browser for an interactive authentication session with Auth0, and in parallel serves a local webserver for the configured callback.</p></li><li><p>Enter your login credentials.</p><p><img src=/__resources/Login-through-identity-provider_54293b.png alt="Login through identity provider"></p><p>You should get a successful response from the API server:</p><pre tabindex=0><code>Opening in existing browser session.
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   100.64.0.1   &lt;none&gt;        443/TCP   86m
</code></pre></li></ol><div class="alert alert-info" role=alert><h4 class=alert-heading>Note</h4><p>After a successful login, <code>kubectl</code> uses a token for authentication so that you don’t have to provide user and password for every new <code>kubectl</code> command. How long the token is valid can be configured. If you want to log in again earlier, reset plugin <code>oidc-login</code>:</p><ol><li>Delete directory <code>~/.kube/cache/oidc-login</code>.</li><li>Delete the browser cache.</li></ol></div><ol><li><p>To see if your user uses the cluster role <code>view</code>, do some checks with <code>kubectl auth can-i</code>.</p><ul><li><p>The response for the following commands should be <code>no</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>kubectl auth can-i create clusterrolebindings
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>kubectl auth can-i get secrets
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>kubectl auth can-i describe secrets
</span></span></code></pre></div></li><li><p>The response for the following commands should be <code>yes</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>kubectl auth can-i list pods
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-console data-lang=console><span style=display:flex><span>kubectl auth can-i get pods
</span></span></code></pre></div></li></ul></li></ol><p>If the last step is successful, you’ve configured your cluster to authenticate against an identity provider using OIDC.</p><h2 id=related-links>Related Links</h2><ul><li><a href=https://auth0.com/pricing/>Auth0 Pricing</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-7e234a5492bf6ac145bc63720536b8c8>2 - Dynamic Volume Provisioning</h1><div class=lead>Running a Postgres database on Kubernetes</div><h2 id=overview>Overview</h2><p>The example shows how to run a Postgres database on Kubernetes and how to dynamically provision and mount the storage
volumes needed by the database</p><h2 id=run-postgres-database>Run Postgres Database</h2><p>Define the following Kubernetes resources in a yaml file:</p><ul><li>PersistentVolumeClaim (PVC)</li><li>Deployment</li></ul><h3 id=persistentvolumeclaim>PersistentVolumeClaim</h3><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: v1
</span></span><span style=display:flex><span>kind: PersistentVolumeClaim
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: postgresdb-pvc
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  accessModes:
</span></span><span style=display:flex><span>    - ReadWriteOnce
</span></span><span style=display:flex><span>  resources:
</span></span><span style=display:flex><span>    requests:
</span></span><span style=display:flex><span>      storage: 9Gi
</span></span><span style=display:flex><span>  storageClassName: <span style=color:#a31515>&#39;default&#39;</span>
</span></span></code></pre></div><p>This defines a PVC using the storage class <code>default</code>. Storage classes abstract from the underlying storage provider as well
as other parameters, like disk-type (e.g.; solid-state vs standard disks).</p><p>The default storage class has the annotation <strong>{&ldquo;storageclass.kubernetes.io/is-default-class&rdquo;:&ldquo;true&rdquo;}</strong>.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>
</span></span><span style=display:flex><span>$ kubectl describe sc default
</span></span><span style=display:flex><span>Name:            default
</span></span><span style=display:flex><span>IsDefaultClass:  Yes
</span></span><span style=display:flex><span>Annotations:     kubectl.kubernetes.io/last-applied-configuration={<span style=color:#a31515>&#34;apiVersion&#34;</span>:<span style=color:#a31515>&#34;storage.k8s.io/v1beta1&#34;</span>,<span style=color:#a31515>&#34;kind&#34;</span>:<span style=color:#a31515>&#34;StorageClass&#34;</span>,<span style=color:#a31515>&#34;metadata&#34;</span>:{<span style=color:#a31515>&#34;annotations&#34;</span>:{<span style=color:#a31515>&#34;storageclass.kubernetes.io/is-default-class&#34;</span>:<span style=color:#a31515>&#34;true&#34;</span>},<span style=color:#a31515>&#34;labels&#34;</span>:{<span style=color:#a31515>&#34;addonmanager.kubernetes.io/mode&#34;</span>:<span style=color:#a31515>&#34;Exists&#34;</span>},<span style=color:#a31515>&#34;name&#34;</span>:<span style=color:#a31515>&#34;default&#34;</span>,<span style=color:#a31515>&#34;namespace&#34;</span>:<span style=color:#a31515>&#34;&#34;</span>},<span style=color:#a31515>&#34;parameters&#34;</span>:{<span style=color:#a31515>&#34;type&#34;</span>:<span style=color:#a31515>&#34;gp2&#34;</span>},<span style=color:#a31515>&#34;provisioner&#34;</span>:<span style=color:#a31515>&#34;kubernetes.io/aws-ebs&#34;</span>}
</span></span><span style=display:flex><span>,storageclass.kubernetes.io/is-default-class=true
</span></span><span style=display:flex><span>Provisioner:           kubernetes.io/aws-ebs
</span></span><span style=display:flex><span>Parameters:            type=gp2
</span></span><span style=display:flex><span>AllowVolumeExpansion:  &lt;unset&gt;
</span></span><span style=display:flex><span>MountOptions:          &lt;none&gt;
</span></span><span style=display:flex><span>ReclaimPolicy:         Delete
</span></span><span style=display:flex><span>VolumeBindingMode:     Immediate
</span></span><span style=display:flex><span>Events:                &lt;none&gt;
</span></span></code></pre></div><p>A Persistent Volume is automatically created when it is dynamically provisioned. In the following example, the PVC is defined
as &ldquo;postgresdb-pvc&rdquo;, and a corresponding PV &ldquo;pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb&rdquo; is created and associated with the PVC automatically.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl create -f .<span style=color:#a31515>\p</span>ostgres_deployment.yaml
</span></span><span style=display:flex><span>persistentvolumeclaim <span style=color:#a31515>&#34;postgresdb-pvc&#34;</span> created
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ kubectl get pv
</span></span><span style=display:flex><span>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                    STORAGECLASS   REASON    AGE
</span></span><span style=display:flex><span>pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Delete           Bound     default/postgresdb-pvc   default                  3s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ kubectl get pvc
</span></span><span style=display:flex><span>NAME             STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
</span></span><span style=display:flex><span>postgresdb-pvc   Bound     pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            default        8s
</span></span></code></pre></div><p>Notice that the <strong>RECLAIM POLICY</strong> is <strong>Delete</strong> (default value), which is one of the two reclaim policies, the other
one is <strong>Retain</strong>. (A third policy <strong>Recycle</strong> has been deprecated). In the case of <strong>Delete</strong>, the PV is deleted automatically
when the PVC is removed, and the data on the PVC will also be lost.</p><p>On the other hand, a PV with <strong>Retain</strong> policy will not be deleted when the PVC is removed, and moved to <strong>Release</strong> status, so
that data can be recovered by Administrators later.</p><p>You can use the <code>kubectl patch</code> command to change the reclaim policy as described in <a href=https://kubernetes.io/docs/tasks/administer-cluster/change-pv-reclaim-policy/>Change the Reclaim Policy of a PersistentVolume</a>
or use <code>kubectl edit pv &lt;pv-name></code> to edit it online as shown below:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pv
</span></span><span style=display:flex><span>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                    STORAGECLASS   REASON    AGE
</span></span><span style=display:flex><span>pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Delete           Bound     default/postgresdb-pvc   default                  44m
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># change the reclaim policy from &#34;Delete&#34; to &#34;Retain&#34;</span>
</span></span><span style=display:flex><span>$ kubectl edit pv pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb
</span></span><span style=display:flex><span>persistentvolume <span style=color:#a31515>&#34;pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb&#34;</span> edited
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># check the reclaim policy afterwards</span>
</span></span><span style=display:flex><span>$ kubectl get pv
</span></span><span style=display:flex><span>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                    STORAGECLASS   REASON    AGE
</span></span><span style=display:flex><span>pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Retain           Bound     default/postgresdb-pvc   default                  45m
</span></span></code></pre></div><h3 id=deployment>Deployment</h3><p>Once a PVC is created, you can use it in your container via <code>volumes.persistentVolumeClaim.claimName</code>. In the below
example, the PVC <strong>postgresdb-pvc</strong> is mounted as readable and writable, and in <code>volumeMounts</code> two paths in the container are mounted to subfolders in the volume.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: apps/v1
</span></span><span style=display:flex><span>kind: Deployment
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: postgres
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    app: postgres
</span></span><span style=display:flex><span>  annotations:
</span></span><span style=display:flex><span>    deployment.kubernetes.io/revision: <span style=color:#a31515>&#34;1&#34;</span>
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  replicas: 1
</span></span><span style=display:flex><span>  strategy:
</span></span><span style=display:flex><span>    type: RollingUpdate
</span></span><span style=display:flex><span>    rollingUpdate:
</span></span><span style=display:flex><span>      maxUnavailable: 1
</span></span><span style=display:flex><span>      maxSurge: 1
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      app: postgres
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      name: postgres
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        app: postgres
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      containers:
</span></span><span style=display:flex><span>        - name: postgres
</span></span><span style=display:flex><span>          image: <span style=color:#a31515>&#34;cpettech.docker.repositories.sap.ondemand.com/jtrack_postgres:howto&#34;</span>
</span></span><span style=display:flex><span>          env:
</span></span><span style=display:flex><span>            - name: POSTGRES_USER
</span></span><span style=display:flex><span>              value: postgres
</span></span><span style=display:flex><span>            - name: POSTGRES_PASSWORD
</span></span><span style=display:flex><span>              value: p5FVqfuJFrM42cVX9muQXxrC3r8S9yn0zqWnFR6xCoPqxqVQ
</span></span><span style=display:flex><span>            - name: POSTGRES_INITDB_XLOGDIR
</span></span><span style=display:flex><span>              value: <span style=color:#a31515>&#34;/var/log/postgresql/logs&#34;</span>
</span></span><span style=display:flex><span>          ports:
</span></span><span style=display:flex><span>            - containerPort: 5432
</span></span><span style=display:flex><span>          volumeMounts:
</span></span><span style=display:flex><span>            - mountPath: /var/lib/postgresql/data
</span></span><span style=display:flex><span>              name: postgre-db
</span></span><span style=display:flex><span>              subPath: data     <span style=color:green># https://github.com/kubernetes/website/pull/2292.  Solve the issue of crashing initdb due to non-empty directory (i.e. lost+found)</span>
</span></span><span style=display:flex><span>            - mountPath: /var/log/postgresql/logs
</span></span><span style=display:flex><span>              name: postgre-db
</span></span><span style=display:flex><span>              subPath: logs
</span></span><span style=display:flex><span>      volumes:
</span></span><span style=display:flex><span>        - name: postgre-db
</span></span><span style=display:flex><span>          persistentVolumeClaim:
</span></span><span style=display:flex><span>            claimName: postgresdb-pvc
</span></span><span style=display:flex><span>            readOnly: <span style=color:#00f>false</span>
</span></span><span style=display:flex><span>      imagePullSecrets:
</span></span><span style=display:flex><span>      - name: cpettechregistry
</span></span></code></pre></div><p>To check the mount points in the container:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get po
</span></span><span style=display:flex><span>NAME                        READY     STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>postgres-7f485fd768-c5jf9   1/1       Running   0          32m
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ kubectl exec -it postgres-7f485fd768-c5jf9 bash
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>root@postgres-7f485fd768-c5jf9:/# ls /var/lib/postgresql/data/
</span></span><span style=display:flex><span>base    pg_clog       pg_dynshmem  pg_ident.conf  pg_multixact  pg_replslot  pg_snapshots  pg_stat_tmp  pg_tblspc    PG_VERSION  postgresql.auto.conf  postmaster.opts
</span></span><span style=display:flex><span>global  pg_commit_ts  pg_hba.conf  pg_logical     pg_notify     pg_serial    pg_stat       pg_subtrans  pg_twophase  pg_xlog     postgresql.conf       postmaster.pid
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>root@postgres-7f485fd768-c5jf9:/# ls /var/log/postgresql/logs/
</span></span><span style=display:flex><span>000000010000000000000001  archive_status
</span></span></code></pre></div><h2 id=deleting-a-persistentvolumeclaim>Deleting a PersistentVolumeClaim</h2><p>In case of a <strong>Delete</strong> policy, deleting a PVC will also delete its associated PV. If <strong>Retain</strong> is the reclaim policy, the
PV will change status from <strong>Bound</strong> to <strong>Released</strong> when the PVC is deleted.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:green># Check pvc and pv before deletion</span>
</span></span><span style=display:flex><span>$ kubectl get pvc
</span></span><span style=display:flex><span>NAME             STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
</span></span><span style=display:flex><span>postgresdb-pvc   Bound     pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            default        50m
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>$ kubectl get pv
</span></span><span style=display:flex><span>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                    STORAGECLASS   REASON    AGE
</span></span><span style=display:flex><span>pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Retain           Bound     default/postgresdb-pvc   default                  50m
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># delete pvc</span>
</span></span><span style=display:flex><span>$ kubectl delete pvc postgresdb-pvc
</span></span><span style=display:flex><span>persistentvolumeclaim <span style=color:#a31515>&#34;postgresdb-pvc&#34;</span> deleted
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:green># pv changed to status &#34;Released&#34;</span>
</span></span><span style=display:flex><span>$ kubectl get pv
</span></span><span style=display:flex><span>NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM                    STORAGECLASS   REASON    AGE
</span></span><span style=display:flex><span>pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Retain           Released   default/postgresdb-pvc   default                  51m
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-d100c12a1d1b23c6d674069394a6bcf2>3 - GPU Enabled Cluster</h1><div class=lead>Setting up a GPU Enabled Cluster for Deep Learning</div><h2 id=disclaimer>Disclaimer</h2><p>Be aware, that the following sections might be opinionated. Kubernetes, and the GPU support in particular,
are rapidly evolving, which means that this guide is likely to be outdated sometime soon. For this reason,
<strong>contributions are highly appreciated</strong> to update this guide.</p><h2 id=create-a-cluster>Create a Cluster</h2><p>First thing first, let’s create a Kubernetes (K8s) cluster with GPU accelerated nodes. In this example we will use an AWS
<strong>p2.xlarge</strong> EC2 instance because it&rsquo;s the cheapest available option at the moment. Use such cheap instances
for learning to limit your resource costs. <strong>This costs around 1€/hour per GPU</strong></p><p><img src=/__resources/howto-gpu_88d839.png alt=gpu-selection></p><h2 id=install-nvidia-driver-as-daemonset>Install NVidia Driver as Daemonset</h2><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: apps/v1
</span></span><span style=display:flex><span>kind: DaemonSet
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: nvidia-driver-installer
</span></span><span style=display:flex><span>  namespace: kube-system
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    k8s-app: nvidia-driver-installer
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      name: nvidia-driver-installer
</span></span><span style=display:flex><span>      k8s-app: nvidia-driver-installer
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        name: nvidia-driver-installer
</span></span><span style=display:flex><span>        k8s-app: nvidia-driver-installer
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      hostPID: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>      initContainers:
</span></span><span style=display:flex><span>      - image: squat/modulus:4a1799e7aa0143bcbb70d354bab3e419b1f54972
</span></span><span style=display:flex><span>        name: modulus
</span></span><span style=display:flex><span>        args:
</span></span><span style=display:flex><span>        - compile
</span></span><span style=display:flex><span>        - nvidia
</span></span><span style=display:flex><span>        - <span style=color:#a31515>&#34;410.104&#34;</span>
</span></span><span style=display:flex><span>        securityContext:
</span></span><span style=display:flex><span>          privileged: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>        env:
</span></span><span style=display:flex><span>        - name: MODULUS_CHROOT
</span></span><span style=display:flex><span>          value: <span style=color:#a31515>&#34;true&#34;</span>
</span></span><span style=display:flex><span>        - name: MODULUS_INSTALL
</span></span><span style=display:flex><span>          value: <span style=color:#a31515>&#34;true&#34;</span>
</span></span><span style=display:flex><span>        - name: MODULUS_INSTALL_DIR
</span></span><span style=display:flex><span>          value: /opt/drivers
</span></span><span style=display:flex><span>        - name: MODULUS_CACHE_DIR
</span></span><span style=display:flex><span>          value: /opt/modulus/cache
</span></span><span style=display:flex><span>        - name: MODULUS_LD_ROOT
</span></span><span style=display:flex><span>          value: /root
</span></span><span style=display:flex><span>        - name: IGNORE_MISSING_MODULE_SYMVERS
</span></span><span style=display:flex><span>          value: <span style=color:#a31515>&#34;1&#34;</span>          
</span></span><span style=display:flex><span>        volumeMounts:
</span></span><span style=display:flex><span>        - name: etc-coreos
</span></span><span style=display:flex><span>          mountPath: /etc/coreos
</span></span><span style=display:flex><span>          readOnly: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>        - name: usr-share-coreos
</span></span><span style=display:flex><span>          mountPath: /usr/share/coreos
</span></span><span style=display:flex><span>          readOnly: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>        - name: ld-root
</span></span><span style=display:flex><span>          mountPath: /root
</span></span><span style=display:flex><span>        - name: module-cache
</span></span><span style=display:flex><span>          mountPath: /opt/modulus/cache
</span></span><span style=display:flex><span>        - name: module-install-dir-base
</span></span><span style=display:flex><span>          mountPath: /opt/drivers
</span></span><span style=display:flex><span>        - name: dev
</span></span><span style=display:flex><span>          mountPath: /dev
</span></span><span style=display:flex><span>      containers:
</span></span><span style=display:flex><span>      - image: <span style=color:#a31515>&#34;gcr.io/google-containers/pause:3.1&#34;</span>
</span></span><span style=display:flex><span>        name: pause
</span></span><span style=display:flex><span>      tolerations:
</span></span><span style=display:flex><span>      - key: <span style=color:#a31515>&#34;nvidia.com/gpu&#34;</span>
</span></span><span style=display:flex><span>        effect: <span style=color:#a31515>&#34;NoSchedule&#34;</span>
</span></span><span style=display:flex><span>        operator: <span style=color:#a31515>&#34;Exists&#34;</span>
</span></span><span style=display:flex><span>      volumes:
</span></span><span style=display:flex><span>      - name: etc-coreos
</span></span><span style=display:flex><span>        hostPath:
</span></span><span style=display:flex><span>          path: /etc/coreos
</span></span><span style=display:flex><span>      - name: usr-share-coreos
</span></span><span style=display:flex><span>        hostPath:
</span></span><span style=display:flex><span>          path: /usr/share/coreos
</span></span><span style=display:flex><span>      - name: ld-root
</span></span><span style=display:flex><span>        hostPath:
</span></span><span style=display:flex><span>          path: /
</span></span><span style=display:flex><span>      - name: module-cache
</span></span><span style=display:flex><span>        hostPath:
</span></span><span style=display:flex><span>          path: /opt/modulus/cache
</span></span><span style=display:flex><span>      - name: dev
</span></span><span style=display:flex><span>        hostPath:
</span></span><span style=display:flex><span>          path: /dev
</span></span><span style=display:flex><span>      - name: module-install-dir-base
</span></span><span style=display:flex><span>        hostPath:
</span></span><span style=display:flex><span>          path: /opt/drivers
</span></span></code></pre></div><h2 id=install-device-plugin>Install Device Plugin</h2><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: apps/v1
</span></span><span style=display:flex><span>kind: DaemonSet
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: nvidia-gpu-device-plugin
</span></span><span style=display:flex><span>  namespace: kube-system
</span></span><span style=display:flex><span>  labels:
</span></span><span style=display:flex><span>    k8s-app: nvidia-gpu-device-plugin
</span></span><span style=display:flex><span>    <span style=color:green>#addonmanager.kubernetes.io/mode: Reconcile</span>
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      k8s-app: nvidia-gpu-device-plugin
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        k8s-app: nvidia-gpu-device-plugin
</span></span><span style=display:flex><span>      annotations:
</span></span><span style=display:flex><span>        scheduler.alpha.kubernetes.io/critical-pod: <span style=color:#a31515>&#39;&#39;</span>
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      priorityClassName: system-node-critical
</span></span><span style=display:flex><span>      volumes:
</span></span><span style=display:flex><span>      - name: device-plugin
</span></span><span style=display:flex><span>        hostPath:
</span></span><span style=display:flex><span>          path: /var/lib/kubelet/device-plugins
</span></span><span style=display:flex><span>      - name: dev
</span></span><span style=display:flex><span>        hostPath:
</span></span><span style=display:flex><span>          path: /dev
</span></span><span style=display:flex><span>      containers:
</span></span><span style=display:flex><span>      - image: <span style=color:#a31515>&#34;k8s.gcr.io/nvidia-gpu-device-plugin@sha256:08509a36233c5096bb273a492251a9a5ca28558ab36d74007ca2a9d3f0b61e1d&#34;</span>
</span></span><span style=display:flex><span>        command: [<span style=color:#a31515>&#34;/usr/bin/nvidia-gpu-device-plugin&#34;</span>, <span style=color:#a31515>&#34;-logtostderr&#34;</span>, <span style=color:#a31515>&#34;-host-path=/opt/drivers/nvidia&#34;</span>]
</span></span><span style=display:flex><span>        name: nvidia-gpu-device-plugin
</span></span><span style=display:flex><span>        resources:
</span></span><span style=display:flex><span>          requests:
</span></span><span style=display:flex><span>            cpu: 50m
</span></span><span style=display:flex><span>            memory: 10Mi
</span></span><span style=display:flex><span>          limits:
</span></span><span style=display:flex><span>            cpu: 50m
</span></span><span style=display:flex><span>            memory: 10Mi
</span></span><span style=display:flex><span>        securityContext:
</span></span><span style=display:flex><span>          privileged: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>        volumeMounts:
</span></span><span style=display:flex><span>        - name: device-plugin
</span></span><span style=display:flex><span>          mountPath: /device-plugin
</span></span><span style=display:flex><span>        - name: dev
</span></span><span style=display:flex><span>          mountPath: /dev
</span></span><span style=display:flex><span>  updateStrategy:
</span></span><span style=display:flex><span>    type: RollingUpdate
</span></span></code></pre></div><h2 id=test>Test</h2><p>To run an example training on a GPU node, first start a base image with Tensorflow with GPU support & Keras:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: apps/v1
</span></span><span style=display:flex><span>kind: Deployment
</span></span><span style=display:flex><span>metadata:
</span></span><span style=display:flex><span>  name: deeplearning-workbench
</span></span><span style=display:flex><span>  namespace: default
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  replicas: 1
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      app: deeplearning-workbench
</span></span><span style=display:flex><span>  template:
</span></span><span style=display:flex><span>    metadata:
</span></span><span style=display:flex><span>      labels:
</span></span><span style=display:flex><span>        app: deeplearning-workbench
</span></span><span style=display:flex><span>    spec:
</span></span><span style=display:flex><span>      containers:
</span></span><span style=display:flex><span>      - name: deeplearning-workbench
</span></span><span style=display:flex><span>        image: afritzler/deeplearning-workbench
</span></span><span style=display:flex><span>        resources:
</span></span><span style=display:flex><span>          limits:
</span></span><span style=display:flex><span>            nvidia.com/gpu: 1
</span></span><span style=display:flex><span>      tolerations:
</span></span><span style=display:flex><span>      - key: <span style=color:#a31515>&#34;nvidia.com/gpu&#34;</span>
</span></span><span style=display:flex><span>        effect: <span style=color:#a31515>&#34;NoSchedule&#34;</span>
</span></span><span style=display:flex><span>        operator: <span style=color:#a31515>&#34;Exists&#34;</span>
</span></span></code></pre></div><div class="alert alert-info" role=alert><h4 class=alert-heading>Note</h4><p>the <code>tolerations</code> section above is not required if you deploy the <code>ExtendedResourceToleration</code>
admission controller to your cluster. You can do this in the <code>kubernetes</code> section of your Gardener
cluster <code>shoot.yaml</code> as follows:</p><pre tabindex=0><code>  kubernetes:
    kubeAPIServer:
      admissionPlugins:
      - name: ExtendedResourceToleration
</code></pre></div><p>Now exec into the container and start an example Keras training:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl exec -it deeplearning-workbench-8676458f5d-p4d2v -- /bin/bash
</span></span><span style=display:flex><span>cd /keras/example
</span></span><span style=display:flex><span>python imdb_cnn.py
</span></span></code></pre></div><h2 id=related-links>Related Links</h2><ul><li><a href=https://github.com/afritzler/kubernetes-gpu>Andreas Fritzler</a> from the Gardener Core team for the R&D, who has provided this setup.</li><li><a href=https://github.com/squat/modulus>Build and install NVIDIA driver on CoreOS</a></li><li><a href=https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/device-plugins/nvidia-gpu/daemonset.yaml>Nvidia Device Plugin</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-82db4b0a88ec43d5df912dae1cd481bf>4 - Install Knative in Gardener Clusters</h1><div class=lead>A walkthrough the steps for installing Knative in Gardener shoot clusters.</div><h2 id=overview>Overview</h2><p>This guide walks you through the installation of the latest version of Knative
using pre-built images on a <a href=https://gardener.cloud>Gardener</a> created cluster
environment. To set up your own Gardener, see the
<a href=https://github.com/gardener/gardener/blob/master/docs/README.md>documentation</a>
or have a look at the
<a href=https://github.com/gardener/landscape-setup-template>landscape-setup-template</a>
project. To learn more about this open source project, read the
<a href=https://kubernetes.io/blog/2018/05/17/gardener/>blog on kubernetes.io</a>.</p><h2 id=prerequsites>Prerequsites</h2><p>Knative requires a Kubernetes cluster v1.15 or newer.</p><h2 id=steps>Steps</h2><h3 id=install-and-configure-kubectl>Install and Configure kubectl</h3><ol><li><p>If you already have <code>kubectl</code> CLI, run <code>kubectl version --short</code> to check
the version. You need v1.10 or newer. If your <code>kubectl</code> is older, follow the
next step to install a newer version.</p></li><li><p><a href=https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl>Install the kubectl CLI</a>.</p></li></ol><h3 id=access-gardener>Access Gardener</h3><ol><li><p>Create a project in the Gardener dashboard. This will essentially create a
Kubernetes namespace with the name <code>garden-&lt;my-project></code>.</p></li><li><p><a href=https://kubernetes.io/docs/tasks/tools/install-kubectl/#configure-kubectl>Configure access to your Gardener project</a>
using a kubeconfig.</p><p>If you are not the Gardener Administrator already, you
can create a technical user in the Gardener dashboard.
Go to the &ldquo;Members&rdquo; section and add a service account.
You can then download the kubeconfig for your project.
You can skip this step if you create your cluster using the
user interface; it is only needed for programmatic access, make sure you set
<code>export KUBECONFIG=garden-my-project.yaml</code> in your shell.
<img src=/__resources/gardener_service_account_0a4a8a.png alt="Download kubeconfig for Gardener"></p></li></ol><h3 id=creating-a-kubernetes-cluster>Creating a Kubernetes Cluster</h3><p>You can create your cluster using <code>kubectl</code> CLI by providing a cluster
specification yaml file. You can find an example for GCP in the
<a href=https://github.com/gardener/gardener/blob/master/example/90-shoot.yaml>gardener/gardener repository</a>.
Make sure the namespace matches that of your project. Then just apply the
prepared so-called &ldquo;shoot&rdquo; cluster CRD with kubectl:</p><pre tabindex=0><code>kubectl apply --filename my-cluster.yaml
</code></pre><p>The easier alternative is to create the cluster following the cluster creation
wizard in the Gardener dashboard:
<img src=/__resources/gardener_shoot_creation_49a4ca.png alt="shoot creation" title="shoot creation via the dashboard"></p><h3 id=configure-kubectl-for-your-cluster>Configure kubectl for Your Cluster</h3><p>You can now download the kubeconfig for your freshly created cluster in the
Gardener dashboard or via the CLI as follows:</p><pre tabindex=0><code>kubectl --namespace shoot--my-project--my-cluster get secret kubecfg --output jsonpath={.data.kubeconfig} | base64 --decode &gt; my-cluster.yaml
</code></pre><p>This kubeconfig file has full administrators access to you cluster. For the rest
of this guide, be sure you have <code>export KUBECONFIG=my-cluster.yaml</code> set.</p><h2 id=installing-istio>Installing Istio</h2><p>Knative depends on Istio. If your cloud platform offers a managed Istio
installation, we recommend installing Istio that way, unless you need the
ability to customize your installation.</p><p>Otherwise, see the <a href=https://knative.dev/docs/install/installing-istio/>Installing Istio for Knative guide</a>
to install Istio.</p><p>You must install Istio on your Kubernetes cluster before continuing with these
instructions to install Knative.</p><h2 id=installing-cluster-local-gateway-for-serving-cluster-internal-traffic>Installing <code>cluster-local-gateway</code> for Serving Cluster-Internal Traffic</h2><p>If you installed Istio, you can install a <code>cluster-local-gateway</code> within your Knative cluster so that you can serve cluster-internal traffic. If you want to configure your revisions to use routes that are visible only within your cluster, <a href=https://knative.dev/docs/admin/install/knative-offerings/>install and use the <code>cluster-local-gateway</code></a>.</p><h2 id=installing-knative>Installing Knative</h2><p>The following commands install all available Knative components as well as the
standard set of observability plugins. Knative&rsquo;s installation guide - <a href=https://knative.dev/docs/admin/install/>Installing Knative</a>.</p><ol><li><p>If you are upgrading from Knative 0.3.x: Update your domain and static IP
address to be associated with the LoadBalancer <code>istio-ingressgateway</code> instead
of <code>knative-ingressgateway</code>. Then run the following to clean up leftover
resources:</p><pre tabindex=0><code>kubectl delete svc knative-ingressgateway -n istio-system
kubectl delete deploy knative-ingressgateway -n istio-system
</code></pre><p>If you have the Knative Eventing Sources component installed, you will also
need to delete the following resource before upgrading:</p><pre tabindex=0><code>kubectl delete statefulset/controller-manager -n knative-sources
</code></pre><p>While the deletion of this resource during the upgrade process will not
prevent modifications to Eventing Source resources, those changes will not be
completed until the upgrade process finishes.</p></li><li><p>To install Knative, first install the CRDs by running the <code>kubectl apply</code>
command once with the <code>-l knative.dev/crd-install=true</code> flag. This prevents
race conditions during the install, which cause intermittent errors:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply --selector knative.dev/crd-install=true <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>--filename https://github.com/knative/serving/releases/download/v0.12.1/serving.yaml <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>--filename https://github.com/knative/eventing/releases/download/v0.12.1/eventing.yaml <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>--filename https://github.com/knative/serving/releases/download/v0.12.1/monitoring.yaml
</span></span></code></pre></div></li><li><p>To complete the installation of Knative and its dependencies, run the
<code>kubectl apply</code> command again, this time without the <code>--selector</code> flag:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply --filename https://github.com/knative/serving/releases/download/v0.12.1/serving.yaml <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>--filename https://github.com/knative/eventing/releases/download/v0.12.1/eventing.yaml <span style=color:#a31515>\
</span></span></span><span style=display:flex><span><span style=color:#a31515></span>--filename https://github.com/knative/serving/releases/download/v0.12.1/monitoring.yaml
</span></span></code></pre></div></li><li><p>Monitor the Knative components until all of the components show a <code>STATUS</code> of
<code>Running</code>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get pods --namespace knative-serving
</span></span><span style=display:flex><span>kubectl get pods --namespace knative-eventing
</span></span><span style=display:flex><span>kubectl get pods --namespace knative-monitoring
</span></span></code></pre></div></li></ol><h2 id=set-your-custom-domain>Set Your Custom Domain</h2><ol><li>Fetch the external IP or CNAME of the knative-ingressgateway:</li></ol><pre tabindex=0><code>kubectl --namespace istio-system get service knative-ingressgateway
NAME                     TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                                      AGE
knative-ingressgateway   LoadBalancer   100.70.219.81   35.233.41.212   80:32380/TCP,443:32390/TCP,32400:32400/TCP   4d
</code></pre><ol start=2><li>Create a wildcard DNS entry in your custom domain to point to the above IP or
CNAME:</li></ol><pre tabindex=0><code>*.knative.&lt;my domain&gt; == A 35.233.41.212
# or CNAME if you are on AWS
*.knative.&lt;my domain&gt; == CNAME a317a278525d111e89f272a164fd35fb-1510370581.eu-central-1.elb.amazonaws.com
</code></pre><ol start=3><li>Adapt your Knative config-domain (set your domain in the data field):</li></ol><pre tabindex=0><code>kubectl --namespace knative-serving get configmaps config-domain --output yaml
apiVersion: v1
data:
  knative.&lt;my domain&gt;: &#34;&#34;
kind: ConfigMap
  name: config-domain
  namespace: knative-serving
</code></pre><h2 id=whats-next>What&rsquo;s Next</h2><p>Now that your cluster has Knative installed, you can see what Knative has to
offer.</p><p>Deploy your first app with the
<a href=https://knative.dev/docs/serving/getting-started-knative-app/>Getting Started with Knative App Deployment</a>
guide.</p><p>Get started with Knative Eventing by walking through one of the
<a href=https://knative.dev/docs/eventing/samples/>Eventing Samples</a>.</p><p><a href=https://knative.dev/docs/serving/installing-cert-manager/>Install Cert-Manager</a> if you want to use the
<a href=https://knative.dev/docs/serving/using-auto-tls/>automatic TLS cert provisioning feature</a>.</p><h2 id=cleaning-up>Cleaning Up</h2><p>Use the Gardener dashboard to delete your cluster, or execute the following with
kubectl pointing to your <code>garden-my-project.yaml</code> kubeconfig:</p><pre tabindex=0><code>kubectl --kubeconfig garden-my-project.yaml --namespace garden--my-project annotate shoot my-cluster confirmation.gardener.cloud/deletion=true

kubectl --kubeconfig garden-my-project.yaml --namespace garden--my-project delete shoot my-cluster
</code></pre></div></main></div></div><footer class="footer row d-print-none"><div class="container-fluid footer-wrapper"><ul class=nav><li><a href=https://gardener.cloud/blog/>Blogs</a></li><li><a href=https://gardener.cloud/community/>Community</a></li><li><a href=https://gardener.cloud/adopter/>Adopters</a></li><li><a href=/docs/>Documentation</a></li></ul><img src=/images/lp/gardener-logo.svg alt="Logo Gardener" class=logo><ul class=media-wr><li><a target=_blank href=https://kubernetes.slack.com/archives/CB57N0BFG><img src=/images/branding/slack-logo-white.svg class=media-icon><div class=media-text>Slack</div></a></li><li><a target=_blank href=https://github.com/gardener><img src=/images/branding/github-mark-logo.png class=media-icon><div class=media-text>GitHub</div></a></li><li><a target=_blank href=https://www.youtube.com/channel/UCwUhwKFREV8Su0gwAJQX7tw><img src=/images/branding/youtube-logo-dark.svg class=media-icon><div class=media-text>YouTube</div></a></li><li><a target=_blank href=https://twitter.com/GardenerProject><img src=/images/branding/twitter-logo-white.svg class=media-icon><div class=media-text>Twitter</div></a></li></ul><span class=copyright>Copyright 2019-2023 Gardener project authors. <a href=https://www.sap.com/corporate/en/legal/privacy.html>Privacy policy
<i class="fa fa-external-link" aria-hidden=true></i></a></span></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/mermaid@8.13.4/dist/mermaid.min.js integrity="sha512-JERecFUBbsm75UpkVheAuDOE8NdHjQBrPACfEQYPwvPG+fjgCpHAz1Jw2ci9EXmd3DdfiWth3O3CQvcfEg8gsA==" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.7b24c0fb082ffb2de6cb14d6c95e9f8053053709ffcf8c761ef8e9ad2f8021e4.js integrity="sha256-eyTA+wgv+y3myxTWyV6fgFMFNwn/z4x2HvjprS+AIeQ=" crossorigin=anonymous></script></body></html>