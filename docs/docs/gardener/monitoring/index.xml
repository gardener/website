<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gardener â€“ Monitoring</title><link>https://gardener.cloud/docs/gardener/monitoring/</link><description>Recent content in Monitoring on Gardener</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://gardener.cloud/docs/gardener/monitoring/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Alerting</title><link>https://gardener.cloud/docs/gardener/monitoring/alerting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/monitoring/alerting/</guid><description>
&lt;h1 id="alerting">Alerting&lt;/h1>
&lt;p>Gardener uses &lt;a href="https://prometheus.io/">Prometheus&lt;/a> to gather metrics from each component. A Prometheus is deployed in each shoot control plane (on the seed) which is responsible for gathering control plane and cluster metrics. Prometheus can be configured to fire alerts based on these metrics and send them to an &lt;a href="https://prometheus.io/docs/alerting/alertmanager/">alertmanager&lt;/a>. The alertmanager is responsible for sending the alerts to users and operators. This document describes how to setup alerting for:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#Alerting-for-Users">end-users/stakeholders/customers&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Alerting-for-Operators">operators/administrators&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="alerting-for-users">Alerting for Users&lt;/h1>
&lt;p>To receive email alerts as a user set the following values in the shoot spec:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>spec:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> monitoring:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> alerting:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> emailReceivers:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - john.doe@example.com
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>emailReceivers&lt;/code> is a list of emails that will receive alerts if something is wrong with the shoot cluster. A list of alerts for users can be found &lt;a href="https://gardener.cloud/docs/gardener/monitoring/user_alerts/">here&lt;/a>.&lt;/p>
&lt;h1 id="alerting-for-operators">Alerting for Operators&lt;/h1>
&lt;p>Currently, Gardener supports two options for alerting:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#Email-Alerting">Email Alerting&lt;/a>&lt;/li>
&lt;li>&lt;a href="#External-Alertmanager">Sending Alerts to an external alertmanager&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>A list of operator alerts can be found &lt;a href="https://gardener.cloud/docs/gardener/monitoring/operator_alerts/">here&lt;/a>.&lt;/p>
&lt;h2 id="email-alerting">Email Alerting&lt;/h2>
&lt;p>Gardener provides the option to deploy an alertmanager into each seed. This alertmanager is responsible for sending out alerts to operators for each shoot cluster in the seed. Only email alerts are supported by the alertmanager managed by Gardener. This is configurable by setting the Gardener controller manager configuration values &lt;code>alerting&lt;/code>. See &lt;a href="https://gardener.cloud/docs/gardener/usage/configuration/">this&lt;/a> on how to configure the Gardener&amp;rsquo;s SMTP secret. If the values are set, a secret with the label &lt;code>gardener.cloud/role: alerting&lt;/code> will be created in the garden namespace of the garden cluster. This secret will be used by each alertmanager in each seed.&lt;/p>
&lt;h2 id="external-alertmanager">External Alertmanager&lt;/h2>
&lt;p>The alertmanager supports different kinds of &lt;a href="https://prometheus.io/docs/alerting/configuration/">alerting configurations&lt;/a>. The alertmanager provided by Gardener only supports email alerts. If email is not sufficient, then alerts can be sent to an external alertmanager. Prometheus will send alerts to a URL and then alerts will be handled by the external alertmanager. This external alertmanager is operated and configured by the operator (i.e. Gardener does not configure or deploy this alertmanager). To configure sending alerts to an external alertmanager, create a secret in the virtual garden cluster in the garden namespace with the label: &lt;code>gardener.cloud/role: alerting&lt;/code>. This secret needs to contain a URL to the external alertmanager and information regarding authentication. Supported authentication types are:&lt;/p>
&lt;ul>
&lt;li>No Authentication (none)&lt;/li>
&lt;li>Basic Authentication (basic)&lt;/li>
&lt;li>Mutual TLS (certificate)&lt;/li>
&lt;/ul>
&lt;h3 id="remote-alertmanager-examples">Remote Alertmanager Examples&lt;/h3>
&lt;p>Note: the &lt;code>url&lt;/code> value cannot be prepended with &lt;code>http&lt;/code> or &lt;code>https&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># No Authentication&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>apiVersion: v1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: Secret
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>metadata:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> labels:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> gardener.cloud/role: alerting
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> name: alerting-auth
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> namespace: garden
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>data:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># No Authentication&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_type: base64(none)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> url: base64(external.alertmanager.foo)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Basic Auth&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_type: base64(basic)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> url: base64(extenal.alertmanager.foo)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> username: base64(admin)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> password: base64(password)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Mutual TLS&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_type: base64(certificate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> url: base64(external.alertmanager.foo)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> ca.crt: base64(ca)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tls.crt: base64(certificate)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> tls.key: base64(key)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> insecure_skip_verify: base64(false)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#008000"># Email Alerts (internal alertmanager)&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_type: base64(smtp)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_identity: base64(internal.alertmanager.auth_identity)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_password: base64(internal.alertmanager.auth_password)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> auth_username: base64(internal.alertmanager.auth_username)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> from: base64(internal.alertmanager.from)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> smarthost: base64(internal.alertmanager.smarthost)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> to: base64(internal.alertmanager.to)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>type: Opaque
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="configuring-your-external-alertmanager">Configuring your External Alertmanager&lt;/h3>
&lt;p>Please refer to the &lt;a href="https://prometheus.io/docs/alerting/alertmanager/">alertmanager&lt;/a> documentation on how to configure an alertmanager.&lt;/p>
&lt;p>We recommend you use at least the following inhibition rules in your alertmanager configuration to prevent excessive alerts:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>inhibit_rules:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Apply inhibition if the alert name is the same.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: critical
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: warning
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;alertname&amp;#39;&lt;/span>, &lt;span style="color:#a31515">&amp;#39;service&amp;#39;&lt;/span>, &lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Stop all alerts for type=shoot if there are VPN problems.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: vpn
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> type: shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;type&amp;#39;&lt;/span>, &lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Stop warning and critical alerts if there is a blocker&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: blocker
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: ^(critical|warning)$
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># If the API server is down inhibit no worker nodes alert. No worker nodes depends on kube-state-metrics which depends on the API server.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: kube-apiserver
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: nodes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># If API server is down inhibit kube-state-metrics alerts.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: kube-apiserver
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> severity: info
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># No Worker nodes depends on kube-state-metrics. Inhibit no worker nodes if kube-state-metrics is down.&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- source_match:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: kube-state-metrics-shoot
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> target_match_re:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> service: nodes
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> equal: [&lt;span style="color:#a31515">&amp;#39;cluster&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Below is a graph visualizing the inhibition rules:&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/alertInhibitionGraph_ceaef0.png" alt="inhibitionGraph">&lt;/p></description></item><item><title>Docs: Connectivity</title><link>https://gardener.cloud/docs/gardener/monitoring/connectivity/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/monitoring/connectivity/</guid><description>
&lt;h1 id="connectivity">Connectivity&lt;/h1>
&lt;h2 id="shoot-connectivity">Shoot Connectivity&lt;/h2>
&lt;p>We measure the connectivity from the shoot to the API Server. This is done via the &lt;code>blackbox exporter&lt;/code> which is deployed in the shoot&amp;rsquo;s &lt;code>kube-system&lt;/code> namespace. Prometheus will scrape the &lt;code>blackbox exporter&lt;/code> and then the exporter will try to access the API Server. Metrics are exposed if the connection was successful or not. This can be seen in the dashboard &lt;code>Kubernetes Control Plane Status&lt;/code> dashboard under the &lt;code>API Server Connectivity&lt;/code> panel. The &lt;code>shoot&lt;/code> line represents the connectivity from the shoot.&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/panel_393a41.png" alt="image">&lt;/p>
&lt;h2 id="seed-connectivity">Seed Connectivity&lt;/h2>
&lt;p>In addition to the shoot connectivity, we also measure the seed connectivity. This means trying to reach the API Server from the seed via the external fully qualified domain name of the API server. The connectivity is also displayed in the above panel as the &lt;code>seed&lt;/code> line. Both &lt;code>seed&lt;/code> and &lt;code>shoot&lt;/code> connectivity are shown below.&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/connectivity_b79584.png" alt="image">&lt;/p></description></item><item><title>Docs: Operator Alerts</title><link>https://gardener.cloud/docs/gardener/monitoring/operator_alerts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/monitoring/operator_alerts/</guid><description>
&lt;h1 id="operator-alerts">Operator Alerts&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Alertname&lt;/th>
&lt;th>Severity&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ApiServerUnreachableViaKubernetesService&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The Api server has been unreachable for 3 minutes via the kubernetes service in the shoot.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeletTooManyOpenFileDescriptorsSeed&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Seed-kubelet ({{ $labels.kubernetes_io_hostname }}) is using {{ $value }}% of the available file/socket descriptors. Kubelet could be under heavy load.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePersistentVolumeUsageCritical&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} is only {{ printf &amp;quot;%0.2f&amp;quot; $value }}% free.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePersistentVolumeFullInFourDays&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} is expected to fill up within four days. Currently {{ printf &amp;quot;%0.2f&amp;quot; $value }}% is available.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePodPendingControlPlane&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Pod {{ $labels.pod }} is stuck in &amp;quot;Pending&amp;quot; state for more than 30 minutes.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePodNotReadyControlPlane&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;code>Pod {{ $labels.pod }} is not ready for more than 30 minutes.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeStateMetricsShootDown&lt;/td>
&lt;td>info&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>There are no running kube-state-metric pods for the shoot cluster. No kubernetes resource metrics can be scraped.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeStateMetricsSeedDown&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>There are no running kube-state-metric pods for the seed cluster. No kubernetes resource metrics can be scraped.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NoWorkerNodes&lt;/td>
&lt;td>blocker&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;code>There are no worker nodes in the cluster or all of the worker nodes in the cluster are not schedulable.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>PrometheusCantScrape&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Prometheus failed to scrape metrics. Instance {{ $labels.instance }}, job {{ $labels.job }}.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>PrometheusConfigurationFailure&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Latest Prometheus configuration is broken and Prometheus is using the previous one.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VPNProbeAPIServerProxyFailed&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The API Server proxy functionality is not working. Probably the vpn connection from an API Server pod to the vpn-shoot endpoint on the Shoot workers does not work.&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>Docs: Profiling</title><link>https://gardener.cloud/docs/gardener/monitoring/profiling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/monitoring/profiling/</guid><description>
&lt;h1 id="profiling-gardener-components">Profiling Gardener Components&lt;/h1>
&lt;p>Similar to Kubernetes, Gardener components support profiling using &lt;a href="https://golang.org/doc/diagnostics#profiling">standard Go tools&lt;/a> for analyzing CPU and memory usage by different code sections and more.
This document shows how to enable and use profiling handlers with Gardener components.&lt;/p>
&lt;p>Enabling profiling handlers and the ports on which they are exposed differs between components.
However, once the handlers are enabled, they provide profiles via the same HTTP endpoint paths, from which you can retrieve them via &lt;code>curl&lt;/code>/&lt;code>wget&lt;/code> or directly using &lt;code>go tool pprof&lt;/code>.
(You might need to use &lt;code>kubectl port-forward&lt;/code> in order to access HTTP endpoints of Gardener components running in clusters.)&lt;/p>
&lt;p>For example (gardener-controller-manager):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ curl http://localhost:2718/debug/pprof/heap &amp;gt; /tmp/heap-controller-manager
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ go tool pprof /tmp/heap-controller-manager
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Type: inuse_space
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Time: Sep 3, 2021 at 10:05am (CEST)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Entering interactive mode (type &lt;span style="color:#a31515">&amp;#34;help&amp;#34;&lt;/span> &lt;span style="color:#00f">for&lt;/span> commands, &lt;span style="color:#a31515">&amp;#34;o&amp;#34;&lt;/span> &lt;span style="color:#00f">for&lt;/span> options)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(pprof)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>or&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ go tool pprof http://localhost:2718/debug/pprof/heap
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Fetching profile over HTTP from http://localhost:2718/debug/pprof/heap
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Saved profile in /Users/timebertt/pprof/pprof.alloc_objects.alloc_space.inuse_objects.inuse_space.008.pb.gz
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Type: inuse_space
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Time: Sep 3, 2021 at 10:05am (CEST)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>Entering interactive mode (type &lt;span style="color:#a31515">&amp;#34;help&amp;#34;&lt;/span> &lt;span style="color:#00f">for&lt;/span> commands, &lt;span style="color:#a31515">&amp;#34;o&amp;#34;&lt;/span> &lt;span style="color:#00f">for&lt;/span> options)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>(pprof)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="gardener-apiserver">gardener-apiserver&lt;/h2>
&lt;p>gardener-apiserver provides the same flags as kube-apiserver for enabling profiling handlers (enabled by default):&lt;/p>
&lt;pre tabindex="0">&lt;code>--contention-profiling Enable lock contention profiling, if profiling is enabled
--profiling Enable profiling via web interface host:port/debug/pprof/ (default true)
&lt;/code>&lt;/pre>&lt;p>The handlers are served on the same port as the API endpoints (configured via &lt;code>--secure-port&lt;/code>).
This means, you will also have to authenticate against the API server according to the configured authentication and authorization policy.&lt;/p>
&lt;p>For example, in the &lt;a href="https://gardener.cloud/docs/gardener/development/local_setup/">local-setup&lt;/a> you can use:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ curl -k --cert ./hack/local-development/local-garden/certificates/certs/default-admin.crt --key ./hack/local-development/local-garden/certificates/keys/default-admin.key https://localhost:8443/debug/pprof/heap &amp;gt; /tmp/heap-apiserver
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ go tool pprof /tmp/heap-apiserver
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="gardener-controller-manager-gardenlet">gardener-controller-manager, gardenlet&lt;/h2>
&lt;p>gardener-controller-manager and gardenlet allow enabling profiling handlers via their respective component configs (currently disabled by default):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: gardenlet.config.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: GardenletConfiguration
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>server:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> https:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port: 2720
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>debugging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enableProfiling: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enableContentionProfiling: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The handlers are served on the same port as configured in &lt;code>server.http(s).port&lt;/code> via HTTP or HTTPS respectively.&lt;/p>
&lt;p>For example (gardenlet with HTTPS configured):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ curl -k https://localhost:2720/debug/pprof/heap &amp;gt; /tmp/heap-gardenlet
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ go tool pprof /tmp/heap-gardenlet
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="gardener-admission-controller-gardener-scheduler">gardener-admission-controller, gardener-scheduler&lt;/h2>
&lt;p>gardener-admission-controller and gardener-scheduler also allow enabling profiling handlers via their respective component configs (currently disabled by default):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>apiVersion: admissioncontroller.config.gardener.cloud/v1alpha1
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>kind: AdmissionControllerConfiguration
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># ...&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>server:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> metrics:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> port: 2723
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>debugging:
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enableProfiling: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> enableContentionProfiling: &lt;span style="color:#00f">true&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>However, the handlers are served on the same port as configured in &lt;code>server.metrics.port&lt;/code> via HTTP.&lt;/p>
&lt;p>For example (gardener-admission-controller):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>$ curl http://localhost:2723/debug/pprof/heap &amp;gt; /tmp/heap-admission-controller
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>$ go tool pprof /tmp/heap-admission-controller
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="gardener-seed-admission-controller">gardener-seed-admission-controller&lt;/h2>
&lt;p>gardener-seed-admission-controller doesn&amp;rsquo;t support profiling yet. See &lt;a href="https://github.com/gardener/gardener/issues/4567">gardener/gardener#4567&lt;/a>.&lt;/p></description></item><item><title>Docs: User Alerts</title><link>https://gardener.cloud/docs/gardener/monitoring/user_alerts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/monitoring/user_alerts/</guid><description>
&lt;h1 id="user-alerts">User Alerts&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Alertname&lt;/th>
&lt;th>Severity&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ApiServerUnreachableViaKubernetesService&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The Api server has been unreachable for 3 minutes via the kubernetes service in the shoot.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeKubeletNodeDown&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The kubelet {{ $labels.instance }} has been unavailable/unreachable for more than 1 hour. Workloads on the affected node may not be schedulable.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeletTooManyOpenFileDescriptorsShoot&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Shoot-kubelet ({{ $labels.kubernetes_io_hostname }}) is using {{ $value }}% of the available file/socket descriptors. Kubelet could be under heavy load.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeletTooManyOpenFileDescriptorsShoot&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Shoot-kubelet ({{ $labels.kubernetes_io_hostname }}) is using {{ $value }}% of the available file/socket descriptors. Kubelet could be under heavy load.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePodPendingShoot&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Pod {{ $labels.pod }} is stuck in &amp;quot;Pending&amp;quot; state for more than 1 hour.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePodNotReadyShoot&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Pod {{ $labels.pod }} is not ready for more than 1 hour.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NoWorkerNodes&lt;/td>
&lt;td>blocker&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;code>There are no worker nodes in the cluster or all of the worker nodes in the cluster are not schedulable.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NodeExporterDown&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The NodeExporter has been down or unreachable from Prometheus for more than 1 hour.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>K8SNodeOutOfDisk&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Node {{ $labels.node }} has run out of disk space.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>K8SNodeMemoryPressure&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Node {{ $labels.node }} is under memory pressure.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>K8SNodeDiskPressure&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Node {{ $labels.node }} is under disk pressure&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VMRootfsFull&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Root filesystem device on instance {{ $labels.instance }} is almost full.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VMConntrackTableFull&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The nf_conntrack table is {{ $value }}% full.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VPNProbeAPIServerProxyFailed&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The API Server proxy functionality is not working. Probably the vpn connection from an API Server pod to the vpn-shoot endpoint on the Shoot workers does not work.&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item></channel></rss>