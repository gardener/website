<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gardener â€“ Development</title><link>https://gardener.cloud/docs/other-components/etcd-druid/development/</link><description>Recent content in Development on Gardener</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://gardener.cloud/docs/other-components/etcd-druid/development/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Local e2e Tests</title><link>https://gardener.cloud/docs/other-components/etcd-druid/development/local-e2e-tests/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/development/local-e2e-tests/</guid><description>
&lt;h1 id="e2e-test-suite">e2e Test Suite&lt;/h1>
&lt;p>Developers can run extended e2e tests, in addition to unit tests, for Etcd-Druid in or from
their local environments. This is recommended to verify the desired behavior of several features
and to avoid regressions in future releases.&lt;/p>
&lt;p>The very same tests typically run as part of the component&amp;rsquo;s release job as well as on demand, e.g.,
when triggered by Etcd-Druid maintainers for open pull requests.&lt;/p>
&lt;p>Testing Etcd-Druid automatically involves a certain test coverage for &lt;a href="https://github.com/gardener/etcd-backup-restore/">gardener/etcd-backup-restore&lt;/a>
which is deployed as a side-car to the actual &lt;code>etcd&lt;/code> container.&lt;/p>
&lt;h2 id="prerequisites">Prerequisites&lt;/h2>
&lt;p>The e2e test lifecycle is managed with the help of &lt;a href="https://skaffold.dev/">skaffold&lt;/a>. Every involved step like &lt;code>setup&lt;/code>,
&lt;code>deploy&lt;/code>, &lt;code>undeploy&lt;/code> or &lt;code>cleanup&lt;/code> is executed against a &lt;strong>Kubernetes&lt;/strong> cluster which makes it a mandatory prerequisite at the same time.
Only &lt;a href="https://skaffold.dev/">skaffold&lt;/a> itself with involved &lt;code>docker&lt;/code>, &lt;code>helm&lt;/code> and &lt;code>kubectl&lt;/code> executions as well as
the e2e-tests are executed locally. Required binaries are automatically downloaded if you use the corresponding &lt;code>make&lt;/code> target,
as described in this document.&lt;/p>
&lt;p>It&amp;rsquo;s expected that especially the &lt;code>deploy&lt;/code> step is run against a Kubernetes cluster which doesn&amp;rsquo;t contain an Druid deployment or any left-overs like &lt;code>druid.gardener.cloud&lt;/code> CRDs.
The &lt;code>deploy&lt;/code> step will likely fail in such scenarios.&lt;/p>
&lt;blockquote>
&lt;p>Tip: Create a fresh &lt;a href="https://kind.sigs.k8s.io/">KinD&lt;/a> cluster or a similar one with a small footprint before executing the tests.&lt;/p>
&lt;/blockquote>
&lt;h2 id="providers">Providers&lt;/h2>
&lt;p>The following providers are supported for e2e tests:&lt;/p>
&lt;ul>
&lt;li>AWS&lt;/li>
&lt;li>Azure&lt;/li>
&lt;li>GCP&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>Valid credentials need to be provided when tests happen with mentioned cloud providers.&lt;/p>
&lt;/blockquote>
&lt;h2 id="flow">Flow&lt;/h2>
&lt;p>An e2e test execution involves the following steps:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Step&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>setup&lt;/code>&lt;/td>
&lt;td>Create a storage bucket which is used for etcd backups (only with cloud providers).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>deploy&lt;/code>&lt;/td>
&lt;td>Build Docker image, upload it to registry (if remote cluster - see &lt;a href="https://skaffold.dev/docs/pipeline-stages/builders/docker/">Docker build&lt;/a>), deploy Helm chart (&lt;code>charts/druid&lt;/code>) to Kubernetes cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>test&lt;/code>&lt;/td>
&lt;td>Execute e2e tests as defined in &lt;code>test/e2e&lt;/code>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>undeploy&lt;/code>&lt;/td>
&lt;td>Remove the deployed artifacts from Kubernetes cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>cleanup&lt;/code>&lt;/td>
&lt;td>Delete storage bucket and Druid deployment from test cluster.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="make-target">Make target&lt;/h3>
&lt;p>Executing e2e-tests is as easy as executing the following command &lt;strong>with defined Env-Vars as desribed in the following
section and as needed for your test scenario&lt;/strong>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>make test-e2e
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="common-env-variables">Common Env Variables&lt;/h3>
&lt;p>The following environment variables influence how the flow described above is executed:&lt;/p>
&lt;ul>
&lt;li>&lt;code>PROVIDERS&lt;/code>: Providers used for testing (&lt;code>all&lt;/code>, &lt;code>aws&lt;/code>, &lt;code>azure&lt;/code>, &lt;code>gcp&lt;/code>). Multiple entries must be comma separated.
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: Some tests will use very first entry from env &lt;code>PROVIDERS&lt;/code> for e2e testing (ex: multi-node tests). So for multi-node tests to use specific provider, specify that provider as first entry in env &lt;code>PROVIDERS&lt;/code>.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>&lt;code>KUBECONFIG&lt;/code>: Kubeconfig pointing to cluster where Etcd-Druid will be deployed (preferably &lt;a href="https://kind.sigs.k8s.io">KinD&lt;/a>).&lt;/li>
&lt;li>&lt;code>TEST_ID&lt;/code>: Some ID which is used to create assets for and during testing.&lt;/li>
&lt;li>&lt;code>STEPS&lt;/code>: Steps executed by &lt;code>make&lt;/code> target (&lt;code>setup&lt;/code>, &lt;code>deploy&lt;/code>, &lt;code>test&lt;/code>, &lt;code>undeploy&lt;/code>, &lt;code>cleanup&lt;/code> - default: all steps).&lt;/li>
&lt;/ul>
&lt;h3 id="aws-env-variables">AWS Env Variables&lt;/h3>
&lt;ul>
&lt;li>&lt;code>AWS_ACCESS_KEY_ID&lt;/code>: Key ID of the user.&lt;/li>
&lt;li>&lt;code>AWS_SECRET_ACCESS_KEY&lt;/code>: Access key of the user.&lt;/li>
&lt;li>&lt;code>AWS_REGION&lt;/code>: Region in which the test bucket is created.&lt;/li>
&lt;/ul>
&lt;p>Example:&lt;/p>
&lt;pre tabindex="0">&lt;code>make \
AWS_ACCESS_KEY_ID=&amp;#34;abc&amp;#34; \
AWS_SECRET_ACCESS_KEY=&amp;#34;xyz&amp;#34; \
AWS_REGION=&amp;#34;eu-central-1&amp;#34; \
KUBECONFIG=&amp;#34;$HOME/.kube/config&amp;#34; \
PROVIDERS=&amp;#34;aws&amp;#34; \
TEST_ID=&amp;#34;some-test-id&amp;#34; \
STEPS=&amp;#34;setup,deploy,test,undeploy,cleanup&amp;#34; \
test-e2e
&lt;/code>&lt;/pre>&lt;h3 id="azure-env-variables">Azure Env Variables&lt;/h3>
&lt;ul>
&lt;li>&lt;code>STORAGE_ACCOUNT&lt;/code>: Storage account used for managing the storage container.&lt;/li>
&lt;li>&lt;code>STORAGE_KEY&lt;/code>: Key of storage account.&lt;/li>
&lt;/ul>
&lt;p>Example:&lt;/p>
&lt;pre tabindex="0">&lt;code>make \
STORAGE_ACCOUNT=&amp;#34;abc&amp;#34; \
STORAGE_KEY=&amp;#34;eHl6Cg==&amp;#34; \
KUBECONFIG=&amp;#34;$HOME/.kube/config&amp;#34; \
PROVIDERS=&amp;#34;azure&amp;#34; \
TEST_ID=&amp;#34;some-test-id&amp;#34; \
STEPS=&amp;#34;setup,deploy,test,undeploy,cleanup&amp;#34; \
test-e2e
&lt;/code>&lt;/pre>&lt;h3 id="gcp-env-variables">GCP Env Variables&lt;/h3>
&lt;ul>
&lt;li>&lt;code>GCP_SERVICEACCOUNT_JSON_PATH&lt;/code>: Path to the service account json file used for this test.&lt;/li>
&lt;li>&lt;code>GCP_PROJECT_ID&lt;/code>: ID of the GCP project.&lt;/li>
&lt;/ul>
&lt;p>Example:&lt;/p>
&lt;pre tabindex="0">&lt;code>make \
GCP_SERVICEACCOUNT_JSON_PATH=&amp;#34;/var/lib/secrets/serviceaccount.json&amp;#34; \
GCP_PROJECT_ID=&amp;#34;xyz-project&amp;#34; \
KUBECONFIG=&amp;#34;$HOME/.kube/config&amp;#34; \
PROVIDERS=&amp;#34;gcp&amp;#34; \
TEST_ID=&amp;#34;some-test-id&amp;#34; \
STEPS=&amp;#34;setup,deploy,test,undeploy,cleanup&amp;#34; \
test-e2e
&lt;/code>&lt;/pre>&lt;h2 id="e2e-test-with-localstack">e2e test with localstack&lt;/h2>
&lt;p>Above mentioned e2e tests need actual storage from cloud provider to be setup. But there is a tool named &lt;a href="https://docs.localstack.cloud/user-guide/aws/s3/">localstack&lt;/a> that enables to run e2e test with mock AWS storage. We can also provision KIND cluster for e2e tests. So, together with localstack and KIND cluster, we don&amp;rsquo;t need to depend on any actual cloud provider infrastructure to be setup to run e2e tests.&lt;/p>
&lt;h3 id="how-are-the-kind-cluster-and-localstack-set-up">How are the KIND cluster and localstack set up&lt;/h3>
&lt;p>KIND or Kubernetes-In-Docker is a kubernetes cluster that is set up inside a docker container. This cluster is with limited capability as it does not have much compute power. But this cluster can easily be setup inside a container and can be tear down easily just by removing a container. That&amp;rsquo;s why KIND cluster is very easy to use for e2e tests. &lt;code>Makefile&lt;/code> command helps to spin up a KIND cluster and use the cluster to run e2e tests.&lt;/p>
&lt;p>There is a docker image for localstack. The image is deployed as pod inside the KIND cluster through &lt;code>hack/e2e-test/infrastructure/localstack/localstack.yaml&lt;/code>. &lt;code>Makefile&lt;/code> takes care of deploying the yaml file in a KIND cluster.&lt;/p>
&lt;p>The developer needs to run &lt;code>make ci-e2e-kind&lt;/code> command. This command in turn runs &lt;code>hack/ci-e2e-kind.sh&lt;/code> which spin up the KIND cluster and deploy localstack in it and then run the e2e tests using localstack as mock AWS storage provider. e2e tests are actually run on host machine but deploy the druid controller inside KIND cluster. Druid controller spawns multinode ETCD clusters inside KIND cluster. e2e tests verify whether the druid controller performs its jobs correctly or not. Mock localstack storage is cleaned up after every e2e tests. That&amp;rsquo;s why the e2e tests need to access the localstack pod running inside KIND cluster. The network traffic between host machine and localstack pod is resolved via mapping localstack pod port to host port while setting up the KIND cluster via &lt;code>hack/e2e-test/infrastructure/kind/cluster.yaml&lt;/code>&lt;/p>
&lt;h3 id="how-to-execute-e2e-tests-with-localstack-and-kind-cluster">How to execute e2e tests with localstack and KIND cluster&lt;/h3>
&lt;p>The developer just needs to install KIND following &lt;a href="https://kind.sigs.k8s.io/docs/user/quick-start/">https://kind.sigs.k8s.io/docs/user/quick-start/&lt;/a> and start docker daemon. Additionaly, KIND cluster can be enabled via docker desktop.&lt;/p>
&lt;p>Check if KIND is working on your machine by running the following command:
&lt;code>kind create cluster --name kind-2&lt;/code>&lt;/p>
&lt;p>If successful, delete the cluster by:
&lt;code>kind delete cluster --name kind-2&lt;/code>&lt;/p>
&lt;p>Run the following &lt;code>make&lt;/code> command to perform e2e tests that will automatically take care of spinning up KIND clsuter and deploying localstack pod:
&lt;code>make ci-e2e-kind&lt;/code>&lt;/p></description></item><item><title>Docs: Metrics</title><link>https://gardener.cloud/docs/other-components/etcd-druid/development/metrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/development/metrics/</guid><description>
&lt;h1 id="monitoring">Monitoring&lt;/h1>
&lt;p>etcd-druid uses &lt;a href="http://prometheus.io/">Prometheus&lt;/a> for metrics reporting. The metrics can be used for real-time monitoring and debugging of compaction jobs.&lt;/p>
&lt;p>The simplest way to see the available metrics is to cURL the metrics endpoint &lt;code>/metrics&lt;/code>. The format is described &lt;a href="http://prometheus.io/docs/instrumenting/exposition_formats/">here&lt;/a>.&lt;/p>
&lt;p>Follow the &lt;a href="http://prometheus.io/docs/introduction/getting_started/">Prometheus getting started doc&lt;/a> to spin up a Prometheus server to collect etcd metrics.&lt;/p>
&lt;p>The naming of metrics follows the suggested &lt;a href="http://prometheus.io/docs/practices/naming/">Prometheus best practices&lt;/a>. All compaction related metrics are put under namespace &lt;code>etcddruid&lt;/code> and subsystem &lt;code>compaction&lt;/code>.&lt;/p>
&lt;h3 id="compaction">Compaction&lt;/h3>
&lt;p>These metrics give an idea about the compaction jobs that run after some interval in shoot control planes. Studying the metrices, we can deduce how many compaction job ran successfully, how many failed, how many delta events compacted etc.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>Type&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>etcddruid_compaction_jobs_total&lt;/td>
&lt;td>Total number of compaction jobs initiated by compaction controller.&lt;/td>
&lt;td>Counter&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>etcddruid_compaction_jobs_current&lt;/td>
&lt;td>Number of currently running compaction job.&lt;/td>
&lt;td>Gauge&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>etcddruid_compaction_job_duration_seconds&lt;/td>
&lt;td>Total time taken in seconds to finish a running compaction job.&lt;/td>
&lt;td>Histogram&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>etcddruid_compaction_num_delta_events&lt;/td>
&lt;td>Total number of etcd events to be compacted by a compaction job.&lt;/td>
&lt;td>Gauge&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>There are two labels for &lt;code>etcddruid_compaction_jobs_total&lt;/code> metrics. The label &lt;code>succeeded&lt;/code> shows how many of the compaction jobs are succeeded and label &lt;code>failed&lt;/code> shows how many of compaction jobs are failed.&lt;/p>
&lt;p>There are two labels for &lt;code>etcddruid_compaction_job_duration_seconds&lt;/code> metrics. The label &lt;code>succeeded&lt;/code> shows how much time taken by a successful job to complete and label &lt;code>failed&lt;/code> shows how much time taken by a failed compaction job.&lt;/p>
&lt;p>&lt;code>etcddruid_compaction_jobs_current&lt;/code> metric comes with label &lt;code>etcd_namespace&lt;/code> that indicates the namespace of the ETCD running in the control plane of a shoot cluster..&lt;/p>
&lt;h2 id="prometheus-supplied-metrics">Prometheus supplied metrics&lt;/h2>
&lt;p>The Prometheus client library provides a number of metrics under the &lt;code>go&lt;/code> and &lt;code>process&lt;/code> namespaces.&lt;/p></description></item></channel></rss>