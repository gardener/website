<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.83.1"><link rel=canonical type=text/html href=https://gardener.cloud/docs/gardener/extensions/><link rel=alternate type=application/rss+xml href=https://gardener.cloud/docs/gardener/extensions/index.xml><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=icon type=image/x-icon href=https://gardener.cloud/images/favicon.ico><link rel=icon type=image/png href=https://gardener.cloud/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://gardener.cloud/images/favicon-16x16.png sizes=16x16><title>Extensions | Gardener</title><meta name=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:title" content="Extensions"><meta property="og:description" content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:type" content="website"><meta property="og:url" content="https://gardener.cloud/docs/gardener/extensions/"><meta itemprop=name content="Extensions"><meta itemprop=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta name=twitter:card content="summary"><meta name=twitter:title content="Extensions"><meta name=twitter:description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><link rel=preload href=/scss/main.min.ca2e9ddee7809848b536632b41e4e4df665800778ffe11b75edde5bdd6c78963.css as=style><link href=/scss/main.min.ca2e9ddee7809848b536632b41e4e4df665800778ffe11b75edde5bdd6c78963.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://unpkg.com/lunr@2.3.8/lunr.min.js integrity=sha384-vRQ9bDyE0Wnu+lMfm57BlYLO0/XauFuKpVsZPs7KEDwYKktWi5+Kz3MP8++DFlRY crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg width="90" height="90" viewBox="0 0 90 90" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>logo</title><desc>Created with Sketch.</desc><defs><path d="M41.8864954.994901575c.996545099999999-.479910833 2.6164002-.477918931 3.6088091.0L76.8159138 16.0781121C77.8124589 16.5580229 78.8208647 17.8257185 79.0659694 18.8995926l7.7355517 33.8916663C87.0476474 53.8696088 86.6852538 55.4484075 85.9984855 56.3095876L64.3239514 83.4885938C63.6343208 84.3533632 62.1740175 85.0543973 61.0725268 85.0543973H26.3092731c-1.1060816.0-2.5646564-.704623400000003-3.2514246-1.5658035L1.38331434 56.3095876C.693683723 55.4448182.335174016 53.865133.580278769 52.7912589L8.31583044 18.8995926C8.56195675 17.8212428 9.57347722 16.556031 10.5658861 16.0781121L41.8864954.994901575z" id="path-1"/><linearGradient x1="12.7542673%" y1="-18.6617048%" x2="88.2666158%" y2="84.6075483%" id="linearGradient-3"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="50%" y1="4.93673768%" x2="148.756007%" y2="175.514523%" id="linearGradient-4"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="19.1574381%" y1="-9.04800713%" x2="82.2203149%" y2="77.9084293%" id="linearGradient-5"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="57.4403751%" y1="26.3148481%" x2="137.966711%" y2="158.080556%" id="linearGradient-6"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="logo"><g id="Rectangle-2" transform="translate(1.000000, 0.000000)"><mask id="mask-2" fill="#fff"><use xlink:href="#path-1"/></mask><use id="Mask" fill="#009f76" xlink:href="#path-1"/><polygon fill="#000" opacity=".289628623" mask="url(#mask-2)" points="-17.6484375 54.5224609 30.8242188 25.0791016 63.4726562 58.5 24.7324219 92.6689453"/></g><path d="M56.8508631 39.260019C56.4193519 40.443987 55.6088085 41.581593 54.6736295 42.1938694l-8.0738997 5.2861089c-1.3854671.907087099999998-3.6247515.9116711-5.0172201.0L33.50861 42.1938694C32.123143 41.2867823 31 39.206345 31 37.545932V26.4150304c0-.725313.2131118-1.5301454.569268099999999-2.2825772L56.8508631 39.260019z" id="Combined-Shape" fill="url(#linearGradient-3)" transform="translate(43.925432, 36.147233) scale(-1, 1) translate(-43.925432, -36.147233)"/><path d="M56.0774672 25.1412464C56.4306829 25.8903325 56.6425556 26.6907345 56.6425556 27.4119019V38.5428034c0 1.6598979-1.1161415 3.73626640000001-2.50861 4.6479374l-8.0738997 5.286109c-1.3854671.907087000000004-3.6247516.911671000000005-5.0172201.0L32.9689261 43.1907408C32.2918101 42.7474223 31.6773514 42.0238435 31.2260376 41.206007L56.0774672 25.1412464z" id="Combined-Shape" fill="url(#linearGradient-4)" transform="translate(43.821278, 37.246598) scale(-1, 1) translate(-43.821278, -37.246598)"/><path d="M65.0702134 57.1846889C64.5985426 58.2007851 63.8367404 59.1236871 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.1597438 58.7930183 24 56.7816693 24 55.1323495V37.1145303C24 36.3487436 24.249712 35.5060005 24.6599102 34.7400631L65.0702134 57.1846889z" id="Combined-Shape" fill="url(#linearGradient-5)"/><path d="M65.0189476 34.954538C65.3636909 35.6617313 65.5692194 36.42021 65.5692194 37.1145303V55.1323495C65.5692194 56.7842831 64.4072119 58.7943252 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.9237304 59.2341061 25.3159155 58.5918431 24.8568495 57.8487596L65.0189476 34.954538z" id="Combined-Shape" fill="url(#linearGradient-6)"/></g></g></svg></span><span class=text-capitalize>Gardener</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/adopter><span>Adopters</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog><span>Blogs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community><span>Community</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs><span>Documentation</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.2035d9813dafac83fe2a48b18d50f237.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/gardener/extensions/>Return to the regular view of this page</a>.</p></div><h1 class=title>Extensions</h1><div class=content></div></div><div class=td-content><h1 id=pg-976400864159d95d6036cf8762b0583b>1 - Admission</h1><h1 id=extension-admission>Extension Admission</h1><p>The extensions are expected to validate their respective resources for their extension specific configurations, when the resources are newly created or updated. For example, <a href=https://github.com/gardener/gardener/blob/master/extensions/README.md#infrastructure-provider>provider extensions</a> would validate <code>spec.provider.infrastructureConfig</code> and <code>spec.provider.controlPlaneConfig</code> in the <code>Shoot</code> resource and <code>spec.providerConfig</code> in the <code>CloudProfile</code> resource, <a href=https://github.com/gardener/gardener/blob/master/extensions/README.md#network-plugin>networking extensions</a> would validate <code>spec.networking.providerConfig</code> in the <code>Shoot</code> resource. As best practice, the validation should be performed only if there is a change in the <code>spec</code> of the resource. Please find an exemplary implementation <a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/admission/validator>here</a>.</p><p>When a resource is newly created or updated, Gardener adds an extension label for all the extension types referenced in the <code>spec</code> of the resource. This label is of the form <code>&lt;extension-type>.extensions.gardener.cloud/&lt;extension-name> : "true"</code>. For example, an extension label for provider extension type <code>aws</code>, looks like <code>provider.extensions.gardener.cloud/aws : "true"</code>. The extensions should add object selectors in their admission webhooks for these labels, to filter out the objects they are responsible for. At present, these labels are added to <code>BackupEntry</code>s, <code>BackupBucket</code>s, <code>CloudProfile</code>s, <code>Seed</code>s, and <code>Shoot</code>s. Please see <a href=https://github.com/gardener/gardener/tree/master/pkg/apis/core/v1beta1/constants/types_constants.go>this</a> for the full list of extension labels.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-14974039d50fb15810aafaf28cbdcf7d>2 - Backupbucket</h1><h1 id=contract-backupbucket-resource>Contract: <code>BackupBucket</code> resource</h1><p>The Gardener project features a sub-project called <a href=https://github.com/gardener/etcd-backup-restore>etcd-backup-restore</a> to take periodic backups of etcd backing Shoot clusters. It demands the bucket (or its equivalent in different object store providers) to be created and configured externally with appropriate credentials. The <code>BackupBucket</code> resource takes this responsibility in Gardener.</p><p>Before introducing the <code>BackupBucket</code> extension resource Gardener was using Terraform in order to create and manage these provider-specific resources (e.g., see <a href=https://github.com/gardener/gardener/tree/0.27.0/charts/seed-terraformer/charts/aws-backup>here</a>).
Now, Gardener commissions an external, provider-specific controller to take over this task. You can also refer to backupInfra proposal documentation to get idea about how the transition was done and understand the resource in broader scope.</p><h2 id=what-is-the-scope-of-bucket>What is the scope of bucket?</h2><p>A bucket will be provisioned per <code>Seed</code>. So, backup of every <code>Shoot</code> created on that <code>Seed</code> will be stored under different shoot specific prefix under the bucket.
For the backup of the <code>Shoot</code> rescheduled on different <code>Seed</code> it will continue to use the same bucket.</p><h2 id=what-is-the-lifespan-of-backupbucket>What is the lifespan of <code>BackupBucket</code>?</h2><p>The bucket associated with <code>BackupBucket</code> will be created at creation of <code>Seed</code>. And as per current implementation, it will be deleted on deletion of <code>Seed</code> and there isn&rsquo;t any <code>BackupEntry</code> resource associated with it.</p><p>In the future, we plan to introduce schedule for <code>BackupBucket</code> the deletion logic for <code>BackupBucket</code> resource, which will reschedule the it on different available <code>Seed</code>, on deletion or failure of health check for current associated <code>seed</code>. In that case, <code>BackupBucket</code> will be deleted only if there isn&rsquo;t any schedulable <code>Seed</code> available and there isn&rsquo;t any associated <code>BackupEntry</code> resource.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What needs to be implemented to support a new infrastructure provider?</h2><p>As part of the seed flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: BackupBucket
metadata:
  name: foo
spec:
  type: azure
  providerConfig:
    &lt;some-optional-provider-specific-backupbucket-configuration&gt;
  region: eu-west-1
  secretRef:
    name: backupprovider
    namespace: shoot--foo--bar
</code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used to create the needed resources. This provider secret will be configured
by Gardener operator in the <code>Seed</code> resource and propagated over there by seed controller.</p><p>After your controller has created the required bucket, if required it generates the secret to access the objects in buckets and put reference to it in <code>status</code>. This secret is
supposed to be used by Gardener or eventually <code>BackupEntry</code> resource and etcd-backup-restore component to backup the etcd.</p><p>In order to support a new infrastructure provider you need to write a controller that watches all <code>BackupBucket</code>s with <code>.spec.type=&lt;my-provider-name></code>. You can take a look at the below referenced example implementation for the Azure provider.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=/docs/gardener/api-reference/extensions/#backupbucket><code>BackupBucket</code> API Reference</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-azure/tree/master/pkg/controller/backupbucket>Exemplary implementation for the Azure provider</a></li><li><a href=/docs/gardener/extensions/backupentry/><code>BackupEntry</code> resource documentation</a></li><li><a href=/docs/gardener/proposals/02-backupinfra/>Shared bucket proposal</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-b1fda6ecdcfcb6e58a7f82c09b95f838>3 - Backupentry</h1><h1 id=contract-backupentry-resource>Contract: <code>BackupEntry</code> resource</h1><p>The Gardener project features a sub-project called <a href=https://github.com/gardener/etcd-backup-restore>etcd-backup-restore</a> to take periodic backups of etcd backing Shoot clusters. It demands the bucket (or its equivalent in different object store providers) access credentials to be created and configured externally with appropriate credentials. The <code>BackupEntry</code> resource takes this responsibility in Gardener to provide this information by creating a secret specific to the component. Said that, the core motivation for introducing this resource was to support retention of backups post deletion of <code>Shoot</code>. The etcd-backup-restore components takes responsibility of garbage collecting old backups out of the defined period. Once a shoot is deleted, we need to persist the backups for few days. Hence, Gardener uses the <code>BackupEntry</code> resource for this housekeeping work post deletion of a <code>Shoot</code>. The <code>BackupEntry</code> resource is responsible for shoot specific prefix under referred bucket.</p><p>Before introducing the <code>BackupEntry</code> extension resource Gardener was using Terraform in order to create and manage these provider-specific resources (e.g., see <a href=https://github.com/gardener/gardener/tree/0.27.0/charts/seed-terraformer/charts/aws-backup>here</a>).
Now, Gardener commissions an external, provider-specific controller to take over this task. You can also refer to backupInfra proposal documentation to get idea about how the transition was done and understand the resource in broader scope.</p><h2 id=what-is-the-lifespan-of-backupentry>What is the lifespan of <code>BackupEntry</code>?</h2><p>The bucket associated with <code>BackupEntry</code> will be created at using <code>BackupBucket</code> resource. The <code>BackupEntry</code> resource will be created as a part of a <code>Shoot</code> creation. But resource might continue to exist post deletion of a <code>Shoot</code> (see <a href=/docs/gardener/concepts/gardenlet/#backupentry-controller>this</a> for more details).</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What needs to be implemented to support a new infrastructure provider?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: BackupEntry
metadata:
  name: shoot--foo--bar
spec:
  type: azure
  providerConfig:
    &lt;some-optional-provider-specific-backup-bucket-configuration&gt;
  backupBucketProviderStatus:
    &lt;some-optional-provider-specific-backup-bucket-status&gt;
  region: eu-west-1
  bucketName: foo
  secretRef:
    name: backupprovider
    namespace: shoot--foo--bar
</code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used to create the needed resources. This provider secret will be propagated from <code>BackupBucket</code> resource by Shoot controller.</p><p>Your controller is supposed to create the <code>etcd-backup</code> secret in control-plane namespace of a shoot. This secret is supposed to be used by Gardener or eventually the etcd-backup-restore component to backup the etcd. The controller implementation should cleanup the objects created under shoot specific prefix in bucket equivalent to name of <code>BackupEntry</code> resource.</p><p>In order to support a new infrastructure provider you need to write a controller that watches all <code>BackupBucket</code>s with <code>.spec.type=&lt;my-provider-name></code>. You can take a look at the below referenced example implementation for the Azure provider.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=/docs/gardener/api-reference/extensions/#backupbucket><code>BackupEntry</code> API Reference</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-azure/tree/master/pkg/controller/backupentry>Exemplary implementation for the Azure provider</a></li><li><a href=/docs/gardener/extensions/backupbucket/><code>BackupBucket</code> resource documentation</a></li><li><a href=/docs/gardener/proposals/02-backupinfra/>Shared bucket proposal</a></li><li><a href=https://github.com/gardener/gardener/blob/master/pkg/controllermanager/apis/config/types.go#L101-%23L107>Gardener-controller-manager-component-config API specification</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-852c52090550872df673db8e9fb654ba>4 - Bastion</h1><h1 id=contract-bastion-resource>Contract: <code>Bastion</code> resource</h1><p>The Gardener project allows users to connect to Shoot worker nodes via SSH. As nodes are usually firewalled and not directly accessible from the public internet, <a href=/docs/gardener/proposals/15-manage-bastions-and-ssh-key-pair-rotation/>GEP-15</a> introduced the concept of &ldquo;Bastions&rdquo;. A bastion is a dedicated server that only serves to allow SSH ingress to the worker nodes.</p><p><code>Bastion</code> resources contain the user&rsquo;s public SSH key and IP address, in order to provision the server accordingly: The public key is put onto the Bastion and SSH ingress is only authorized for the given IP address (in fact, it&rsquo;s not a single IP address, but a set of IP ranges, however for most purposes a single IP is be used).</p><h2 id=what-is-the-lifespan-of-bastion>What is the lifespan of <code>Bastion</code>?</h2><p>Once a <code>Bastion</code> has been created in the garden, it will be replicated to the appropriate seed cluster, where a controller then reconciles a server and firewall rules etc. on the cloud provider used by the target Shoot. When the Bastion is ready (i.e. has a public IP), that IP is stored in the <code>Bastion</code>&rsquo;s status and from there is picked up by the garden cluster and <code>gardenctl</code> eventually.</p><p>To make multiple SSH sessions possible, the existence of the <code>Bastion</code> is not directly tied to the execution of <code>gardenctl</code>: users can exit out of <code>gardenctl</code> and use <code>ssh</code> manually to connect to the bastion and worker nodes.</p><p>However, <code>Bastion</code>s have an expiry date, after which they will be garbage collected.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What needs to be implemented to support a new infrastructure provider?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Bastion
metadata:
  name: mybastion
  namespace: shoot--foo--bar
spec:
  type: aws
  <span style=color:green># userData is base64-encoded cloud provider user data; this contains the</span>
  <span style=color:green># user&#39;s SSH key</span>
  userData: IyEvYmluL2Jhc2ggL....Nlcgo=
  ingress:
    - ipBlock:
        cidr: 192.88.99.0/32 <span style=color:green># this is most likely the user&#39;s IP address</span>
</code></pre></div><p>Your controller is supposed to create a new instance at the given cloud provider, firewall it to only allow SSH (TCP port 22) from the given IP blocks, and then to configure the firewall for the worker nodes to allow SSH from the bastion instance. When a <code>Bastion</code> is deleted, all these changes need to be reverted.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=/docs/gardener/api-reference/extensions/#bastion><code>Bastion</code> API Reference</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/bastion>Exemplary implementation for the AWS provider</a></li><li><a href=/docs/gardener/proposals/15-manage-bastions-and-ssh-key-pair-rotation/>GEP-15</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-1dcf839b2e87160673811784e7578d4a>5 - Cluster</h1><h1 id=cluster-resource><code>Cluster</code> resource</h1><p>As part of the extensibility epic a lot of responsibility that was previously taken over by Gardener directly has now been shifted to extension controllers running in the seed clusters.
These extensions often serve a well-defined purpose, e.g. the management of <a href=/docs/gardener/extensions/dns/>DNS records</a>, <a href=/docs/gardener/extensions/infrastructure/>infrastructure</a>, etc.
We have introduced a couple of extension CRDs in the seeds whose specification is written by Gardener, and which are acted up by the extensions.</p><p>However, the extensions sometimes require more information that is not directly part of the specification.
One example of that is the GCP infrastructure controller which needs to know the shoot&rsquo;s pod and service network.
Another example is the Azure infrastructure controller which requires some information out of the <code>CloudProfile</code> resource.
The problem is that Gardener does not know which extension requires which information so that it can write it into their specific CRDs.</p><p>In order to deal with this problem we have introduced the <code>Cluster</code> extension resource.
This CRD is written into the seeds, however, it does not contain a <code>status</code>, so it is not expected that something acts upon it.
Instead, you can treat it like a <code>ConfigMap</code> which contains data that might be interesting for you.
In the context of Gardener, seeds and shoots, and extensibility the <code>Cluster</code> resource contains the <code>CloudProfile</code>, <code>Seed</code>, and <code>Shoot</code> manifest.
Extension controllers can take whatever information they want out of it that might help completing their individual tasks.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---

apiVersion: extensions.gardener.cloud/v1alpha1
kind: Cluster
metadata:
  name: shoot--foo--bar
spec:
  cloudProfile:
    apiVersion: core.gardener.cloud/v1beta1
    kind: CloudProfile
    ...
  seed:
    apiVersion: core.gardener.cloud/v1beta1
    kind: Seed
    ...
  shoot:
    apiVersion: core.gardener.cloud/v1beta1
    kind: Shoot
    ...
</code></pre></div><p>The resource is written by Gardener before it starts the reconciliation flow of the shoot.</p><p>⚠️ All Gardener components use the <code>core.gardener.cloud/v1beta1</code> version, i.e., the <code>Cluster</code> resource will contain the objects in this version.</p><h2 id=important-information-that-should-be-taken-into-account>Important information that should be taken into account</h2><p>There are some fields in the <code>Shoot</code> specification that might be interesting to take into account.</p><ul><li><code>.spec.hibernation.enabled={true,false}</code>: Extension controllers might want to behave differently if the shoot is hibernated or not (probably they might want to scale down their control plane components, for example).</li><li><code>.status.lastOperation.state=Failed</code>: If Gardener sets the shoot&rsquo;s last operation state to <code>Failed</code> it means that Gardener won&rsquo;t automatically retry to finish the reconciliation/deletion flow because an error occurred that could not be resolved within the last <code>24h</code> (default). In this case end-users are expected to manually re-trigger the reconciliation flow in case they want Gardener to try again. Extension controllers are expected to follow the same principle. This means they have to read the shoot state out of the <code>Cluster</code> resource.</li></ul><h2 id=extension-resources-not-associated-with-a-shoot>Extension resources not associated with a shoot</h2><p>In some cases, Gardener may create extension resources that are not associated with a shoot, but are needed to support some functionality internal to Gardener. Such resources will be created in the <code>garden</code> namespace of a seed cluster.</p><p>For example, if the <a href=/docs/gardener/deployment/deploy_gardenlet_manually/>managed ingress controller</a> is active on the seed, Gardener will create a <a href=/docs/gardener/extensions/dns/>DNSProvider / DNSEntry</a> or a <a href=/docs/gardener/extensions/dnsrecord/>DNSRecord</a> resource(s) in the <code>garden</code> namespace of the seed cluster for the ingress DNS record.</p><p>Extension controllers that may be expected to reconcile extension resources in the <code>garden</code> namespace should make sure that they can tolerate the absence of a cluster resource. This means that they should not attempt to read the cluster resource in such cases, or if they do they should ignore the &ldquo;not found&rdquo; error.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_cluster.go><code>Cluster</code> API (Golang specification)</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-bd0f3158741613ba8829c3093bc71acd>6 - Containerruntime</h1><h1 id=gardener-container-runtime-extension>Gardener Container Runtime Extension</h1><p>At the lowest layers of a Kubernetes node is the software that, among other things, starts and stops containers. It is called “Container Runtime”.
The most widely known container runtime is Docker, but it is not alone in this space. In fact, the container runtime space has been rapidly evolving.</p><p>Kubernetes supports different container runtimes using Container Runtime Interface (CRI) – a plugin interface which enables kubelet to use a wide variety of container runtimes.</p><p>Gardener supports creation of Worker machines using CRI, more information can be found here: <a href=/docs/gardener/extensions/operatingsystemconfig/#cri-support>CRI Support</a>.</p><h2 id=motivation>Motivation</h2><p>Prior to the <code>Container Runtime Extensibility</code> concept, Gardener used Docker as the only
container runtime to use in shoot worker machines. Because of the wide variety of different container runtimes
offers multiple important features (for example enhanced security concepts) it is important to enable end users to use other container runtimes as well.</p><h2 id=the-containerruntime-extension-resource>The <code>ContainerRuntime</code> Extension Resource</h2><p>Here is what a typical <code>ContainerRuntime</code> resource would look-like:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: ContainerRuntime
metadata:
  name: my-container-runtime
spec:
  binaryPath: /var/bin/containerruntimes
  type: gvisor
  workerPool:
    name: worker-ubuntu
    selector:
      matchLabels:
        worker.gardener.cloud/pool: worker-ubuntu
</code></pre></div><p>Gardener deploys one <code>ContainerRuntime</code> resource per worker pool per CRI.
To exemplify this, consider a Shoot having two worker pools (<code>worker-one</code>, <code>worker-two</code>) using <code>containerd</code> as the CRI as well as <code>gvisor</code> and <code>kata</code> as enabled container runtimes.
Gardener would deploy four <code>ContainerRuntime</code> resources. For <code>worker-one</code>: one <code>ContainerRuntime</code> for type <code>gvisor</code> and one for type <code>kata</code>. The same resource are being deployed for <code>worker-two</code>.</p><h2 id=supporting-a-new-container-runtime-provider>Supporting a new Container Runtime Provider</h2><p>To add support for another container runtime (e.g., gvisor, kata-containers, etc.) a container runtime extension controller needs to be implemented. It should support Gardener&rsquo;s supported CRI plugins.</p><p>The container runtime extension should install the necessary resources into the shoot cluster (e.g., <code>RuntimeClass</code>es), and it should copy the runtime binaries to the relevant worker machines in path: <code>spec.binaryPath</code>.
Gardener labels the shoot nodes according to the CRI configured: <code>worker.gardener.cloud/cri-name=&lt;value></code> (e.g <code>worker.gardener.cloud/cri-name=containerd</code>) and multiple labels for each of the container runtimes configured for the shoot Worker machine:
<code>containerruntime.worker.gardener.cloud/&lt;container-runtime-type-value>=true</code> (e.g <code>containerruntime.worker.gardener.cloud/gvisor=true</code>).
The way to install the binaries is by creating a daemon set which copies the binaries from an image in a docker registry to the relevant labeled Worker&rsquo;s nodes (avoid downloading binaries from internet to also cater with isolated environments).</p><p>For additional reference, please have a look at the <a href=https://github.com/gardener/gardener-extension-runtime-gvisor>runtime-gvsior</a> provider extension, which provides more information on how to configure the necessary charts as well as the actuators required to reconcile container runtime inside the <code>Shoot</code> cluster to the desired state.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-6a93f55712b73e1c9926ae9a1827ffc1>7 - Controllerregistration</h1><h1 id=registering-extension-controllers>Registering Extension Controllers</h1><p>Extensions are registered in the garden cluster via <a href=https://github.com/gardener/gardener/blob/master/example/25-controllerregistration.yaml><code>ControllerRegistration</code></a> resources.
Gardener is evaluating the registrations and creates <a href=https://github.com/gardener/gardener/blob/master/example/25-controllerinstallation.yaml><code>ControllerInstallation</code></a> resources which describe the request &ldquo;please install this controller <code>X</code> to this seed <code>Y</code>&rdquo;.</p><p>Similar to how <code>CloudProfile</code> or <code>Seed</code> resources get into the system, the Gardener administrator must deploy the <code>ControllerRegistration</code> resources (this does not happen automatically in any way - the administrator decides which extensions shall be enabled).</p><p>The specification mainly describes which of Gardener&rsquo;s extension CRDs are managed, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: core.gardener.cloud/v1beta1
kind: ControllerDeployment
metadata:
  name: os-gardenlinux
type: helm
providerConfig:
  chart: H4sIFAAAAAAA/yk... <span style=color:green># &lt;base64-gzip-chart&gt;</span>
  values:
    foo: bar
---
apiVersion: core.gardener.cloud/v1beta1
kind: ControllerRegistration
metadata:
  name: os-gardenlinux
spec:
  deployment:
    deploymentRefs:
    - name: os-gardenlinux
  resources:
  - kind: OperatingSystemConfig
    type: gardenlinux
    primary: <span style=color:#00f>true</span>
</code></pre></div><p>This information tells Gardener that there is an extension controller that can handle <code>OperatingSystemConfig</code> resources of type <code>gardenlinux</code>.
A reference to the shown <code>ControllerDeployment</code> specifies how the deployment of the extension controller is accomplished.</p><p>Also, it specifies that this controller is the primary one responsible for the lifecycle of the <code>OperatingSystemConfig</code> resource.
Setting <code>primary</code> to <code>false</code> would allow to register additional, secondary controllers that may also watch/react on the <code>OperatingSystemConfig/coreos</code> resources, however, only the primary controller may change/update the main <code>status</code> of the extension object (that are used to &ldquo;communicate&rdquo; with the Gardenlet).
Particularly, only the primary controller may set <code>.status.lastOperation</code>, <code>.status.lastError</code>, <code>.status.observedGeneration</code>, and <code>.status.state</code>.
Secondary controllers may contribute to the <code>.status.conditions[]</code> if they like, of course.</p><p>Secondary controllers might be helpful in scenarios where additional tasks need to be completed which are not part of the reconciliation logic of the primary controller but separated out into a dedicated extension.</p><p>⚠️ There must be exactly one primary controller for every registered kind/type combination.
Also, please note that the <code>primary</code> field cannot be changed after creation of the <code>ControllerRegistration</code>.</p><h2 id=deploying-extension-controllers>Deploying Extension Controllers</h2><p>Submitting above <code>ControllerDeployment</code> and <code>ControllerRegistration</code> will create a <code>ControllerInstallation</code> resource:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: core.gardener.cloud/v1beta1
kind: ControllerInstallation
metadata:
  name: os-gardenlinux
spec:
  deploymentRef:
    name: networking-calico
  registrationRef:
    name: os-gardenlinux
  seedRef:
    name: aws-eu1
</code></pre></div><p>This resource expresses that Gardener requires the <code>os-gardenlinux</code> extension controller to run on the <code>aws-eu1</code> seed cluster.</p><p>The Gardener Controller Manager does automatically determine which extension is required on which seed cluster and will only create <code>ControllerInstallation</code> objects for those.
Also, it will automatically delete <code>ControllerInstallation</code>s referencing extension controllers that are no longer required on a seed (e.g., because all shoots on it have been deleted).
There are additional configuration options, please see <a href=#deployment-configuration-options>this section</a>.</p><h2 id=how-do-extension-controllers-get-deployed-to-seeds>How do extension controllers get deployed to seeds?</h2><p>After Gardener has written the <code>ControllerInstallation</code> resource some component must satisfy this request and start deploying the extension controller to the seed.
Depending on the complexity of the controller&rsquo;s lifecycle management, configuration, etc. there are two possible scenarios:</p><h3 id=scenario-1-deployed-by-gardener>Scenario 1: Deployed by Gardener</h3><p>In many cases the extension controllers are easy to deploy and configure.
It is sufficient to simply create a Helm chart (standardized way of packaging software in the Kubernetes context) and deploy it together with some static configuration values.
Gardener supports this scenario and allows to provide arbitrary deployment information in the <code>ControllerDeployment</code> resource&rsquo;s <code>.providerConfig</code> section:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>...
type: helm
providerConfig:
  chart: H4sIFAAAAAAA/yk...
  values:
    foo: bar
</code></pre></div><p>If <code>.type=helm</code> then Gardener itself will take over the responsibility the deployment.
It base64-decodes the provided Helm chart (<code>.providerConfig.chart</code>) and deploys it with the provided static configuration (<code>.providerConfig.values</code>).
The chart and the values can be updated at any time - Gardener will recognize and re-trigger the deployment process.</p><p>In order to allow extensions to get information about the garden and the seed cluster Gardener does mix-in certain properties into the values (root level) of every deployed Helm chart:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>gardener:
  garden:
    identifier: &lt;uuid-of-gardener-installation&gt;
  seed:
    identifier: &lt;seed-name&gt;
    region: europe
    spec: &lt;complete-seed-spec&gt;
</code></pre></div><p>Extensions can use this information in their Helm chart in case they require knowledge about the garden and the seed environment.
The list might be extended in the future.</p><p>ℹ️ Gardener uses the UUID of the <code>garden</code> <code>Namespace</code> object in the <code>.gardener.garden.identifier</code> property.</p><h3 id=scenario-2-deployed-by-a-non-human-kubernetes-operator>Scenario 2: Deployed by a (non-human) Kubernetes operator</h3><p>Some extension controllers might be more complex and require additional domain-specific knowledge wrt. lifecycle or configuration.
In this case, we encourage to follow the Kubernetes operator pattern and deploy a dedicated operator for this extension into the garden cluster.
The <code>ControllerDeployments</code>&rsquo;s <code>.type</code> field would then not be <code>helm</code>, and no Helm chart or values need to be provided there.
Instead, the operator itself knows how to deploy the extension into the seed.
It must watch <code>ControllerInstallation</code> resources and act one those referencing a <code>ControllerRegistration</code> the operator is responsible for.</p><p>In order to let Gardener know that the extension controller is ready and running in the seed the <code>ControllerInstallation</code>&rsquo;s <code>.status</code> field supports two conditions: <code>RegistrationValid</code> and <code>InstallationSuccessful</code> - both must be provided by the responsible operator:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>...
status:
  conditions:
  - lastTransitionTime: <span style=color:#a31515>&#34;2019-01-22T11:51:11Z&#34;</span>
    lastUpdateTime: <span style=color:#a31515>&#34;2019-01-22T11:51:11Z&#34;</span>
    message: Chart could be rendered successfully.
    reason: RegistrationValid
    status: <span style=color:#a31515>&#34;True&#34;</span>
    type: Valid
  - lastTransitionTime: <span style=color:#a31515>&#34;2019-01-22T11:51:12Z&#34;</span>
    lastUpdateTime: <span style=color:#a31515>&#34;2019-01-22T11:51:12Z&#34;</span>
    message: Installation of new resources succeeded.
    reason: InstallationSuccessful
    status: <span style=color:#a31515>&#34;True&#34;</span>
    type: Installed
</code></pre></div><p>Additionally, the <code>.status</code> field has a <code>providerStatus</code> section into which the operator can (optionally) put any arbitrary data associated with this installation.</p><h2 id=extensions-in-the-garden-cluster-itself>Extensions in the garden cluster itself</h2><p>The <code>Shoot</code> resource itself will contain some provider-specific data blobs.
As a result, some extensions might also want to run in the garden cluster, e.g., to provide <code>ValidatingWebhookConfiguration</code>s for validating the correctness of their provider-specific blobs:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: core.gardener.cloud/v1beta1
kind: Shoot
metadata:
  name: johndoe-aws
  namespace: garden-dev
spec:
  ...
  cloud:
    type: aws
    region: eu-west-1
    providerConfig:
      apiVersion: aws.cloud.gardener.cloud/v1alpha1
      kind: InfrastructureConfig
      networks:
        vpc: <span style=color:green># specify either &#39;id&#39; or &#39;cidr&#39;</span>
        <span style=color:green># id: vpc-123456</span>
          cidr: 10.250.0.0/16
        internal:
        - 10.250.112.0/22
        public:
        - 10.250.96.0/22
        workers:
        - 10.250.0.0/19
      zones:
      - eu-west-1a
...
</code></pre></div><p>In the above example, Gardener itself does not understand the AWS-specific provider configuration for the infrastructure.
However, if this part of the <code>Shoot</code> resource should be validated then you should run an AWS-specific component in the garden cluster that registers a webhook. You can do it similarly if you want to default some fields of a resource (by using a <code>MutatingWebhookConfiguration</code>).</p><p>Again, similar to how Gardener is deployed to the garden cluster, these components must be deployed and managed by the Gardener administrator.</p><h3 id=extension-resource-configurations><code>Extension</code> resource configurations</h3><p>The <code>Extension</code> resource allows injecting arbitrary steps into the shoot reconciliation flow that are unknown to Gardener.
Hence, it is slightly special and allows further configuration when registering it:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: core.gardener.cloud/v1beta1
kind: ControllerRegistration
metadata:
  name: extension-foo
spec:
  resources:
  - kind: Extension
    type: foo
    primary: <span style=color:#00f>true</span>
    globallyEnabled: <span style=color:#00f>true</span>
    reconcileTimeout: 30s
</code></pre></div><p>The <code>globallyEnabled=true</code> option specifies that the <code>Extension/foo</code> object shall be created by default for all shoots (unless they opted out by setting <code>.spec.extensions[].enabled=false</code> in the <code>Shoot</code> spec).</p><p>The <code>reconcileTimeout</code> tells Gardener how long it should wait during its shoot reconciliation flow for the <code>Extension/foo</code>&rsquo;s reconciliation to finish.</p><h3 id=deployment-configuration-options>Deployment configuration options</h3><p>The <code>.spec.deployment</code> resource allows to configure a deployment <code>policy</code>.
There are the following policies:</p><ul><li><code>OnDemand</code> (default): Gardener will demand the deployment and deletion of the extension controller to/from seed clusters dynamically. It will automatically determine (based on other resources like <code>Shoot</code>s) whether it is required and decide accordingly.</li><li><code>Always</code>: Gardener will demand the deployment of the extension controller to seed clusters independent of whether it is actually required or not. This might be helpful if you want to add a new component/controller to all seed clusters by default. Another use-case is to minimize the durations until extension controllers get deployed and ready in case you have highly fluctuating seed clusters.</li><li><code>AlwaysExceptNoShoots</code>: Similar to <code>Always</code>, but if the seed does not have any shoots then the extension is not being deployed. It will be deleted from a seed after the last shoot has been removed from it.</li></ul><p>Also, the <code>.spec.deployment.seedSelector</code> allows to specify a label selector for seed clusters.
Only if it matches the labels of a seed then it will be deployed to it.
Please note that a seed selector can only be specified for secondary controllers (<code>primary=false</code> for all <code>.spec.resources[]</code>).</p></div><div class=td-content style=page-break-before:always><h1 id=pg-863811f5b98898fe3fba05a3241b77ae>8 - Controlplane</h1><h1 id=contract-controlplane-resource>Contract: <code>ControlPlane</code> resource</h1><p>Most Kubernetes clusters require a <code>cloud-controller-manager</code> or CSI drivers in order to work properly.
Before introducing the <code>ControlPlane</code> extension resource Gardener was having several different Helm charts for the <code>cloud-controller-manager</code> deployments for the various providers.
Now, Gardener commissions an external, provider-specific controller to take over this task.</p><h2 id=which-control-plane-resources-are-required>Which control plane resources are required?</h2><p>As mentioned in the <a href=/docs/gardener/extensions/controlplane-webhooks/>controlplane customization webhooks</a> document Gardener shall not deploy any <code>cloud-controller-manager</code> or any other provider-specific component.
Instead, it creates a <code>ControlPlane</code> CRD that should be picked up by provider extensions.
Its purpose is to trigger the deployment of such provider-specific components in the shoot namespace in the seed cluster.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What needs to be implemented to support a new infrastructure provider?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: ControlPlane
metadata:
  name: control-plane
  namespace: shoot--foo--bar
spec:
  type: openstack
  region: europe-west1
  secretRef:
    name: cloudprovider
    namespace: shoot--foo--bar
  providerConfig:
    apiVersion: openstack.provider.extensions.gardener.cloud/v1alpha1
    kind: ControlPlaneConfig
    loadBalancerProvider: provider
    zone: eu-1a
    cloudControllerManager:
      featureGates:
        CustomResourceValidation: <span style=color:#00f>true</span>
  infrastructureProviderStatus:
    apiVersion: openstack.provider.extensions.gardener.cloud/v1alpha1
    kind: InfrastructureStatus
    networks:
      floatingPool:
        id: vpc-1234
      subnets:
      - purpose: nodes
        id: subnetid
</code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used for the shoot cluster.
However, the most important section is the <code>.spec.providerConfig</code> and the <code>.spec.infrastructureProviderStatus</code>.
The first one contains an embedded declaration of the provider specific configuration for the control plane (that cannot be known by Gardener itself).
You are responsible for designing how this configuration looks like.
Gardener does not evaluate it but just copies this part from what has been provided by the end-user in the <code>Shoot</code> resource.
The second one contains the output of the <a href=/docs/gardener/extensions/infrastructure/><code>Infrastructure</code> resource</a> (that might be relevant for the CCM config).</p><p>In order to support a new control plane provider you need to write a controller that watches all <code>ControlPlane</code>s with <code>.spec.type=&lt;my-provider-name></code>.
You can take a look at the below referenced example implementation for the Alicloud provider.</p><p>The control plane controller as part of the <code>ControlPlane</code> reconciliation, often deploys resources (e.g. pods/deployments) into the Shoot namespace in the <code>Seed</code> as part of its <code>ControlPlane</code> reconciliation loop.
Because the namespace contains <a href=https://kubernetes.io/docs/concepts/services-networking/network-policies/>network policies</a> that per default <a href=https://kubernetes.io/docs/concepts/services-networking/network-policies/#default-deny-all-ingress-and-all-egress-traffic>deny all ingress and egress traffic</a>,
the pods may need to have proper labels matching to the selectors of the network policies in order to allow the required network traffic.
Otherwise, they won&rsquo;t be allowed to talk to certain other components (e.g., the kube-apiserver of the shoot).
Please <a href=https://github.com/gardener/gardener/tree/master/docs/development/seed_network_policies.md>see this document</a> for more information.</p><h2 id=non-provider-specific-information-required-for-infrastructure-creation>Non-provider specific information required for infrastructure creation</h2><p>Most providers might require further information that is not provider specific but already part of the shoot resource.
One example for this is the <a href=https://github.com/gardener/gardener-extension-provider-gcp/tree/master/pkg/controller/controlplane>GCP control plane controller</a> which needs the Kubernetes version of the shoot cluster (because it already uses the in-tree Kubernetes cloud-controller-manager).
As Gardener cannot know which information is required by providers it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information that is not part of the <code>Infrastructure</code> resource itself.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_controlplane.go><code>ControlPlane</code> API (Golang specification)</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-alicloud/tree/master/pkg/controller/controlplane>Exemplary implementation for the Alicloud provider</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-3a3deb3218151c4ac388e35f40184d2a>9 - Controlplane Exposure</h1><h1 id=contract-controlplane-resource-with-purpose-exposure>Contract: <code>ControlPlane</code> resource with purpose <code>exposure</code></h1><p>Some Kubernetes clusters require an additional deployments required by the seed cloud provider in order to work properly, e.g. AWS Load Balancer Readvertiser.
Before using ControlPlane resources with purpose <code>exposure</code> Gardener was having different Helm charts for the deployments for the various providers.
Now, Gardener commissions an external, provider-specific controller to take over this task.</p><h2 id=which-control-plane-resources-are-required>Which control plane resources are required?</h2><p>As mentioned in the <a href=/docs/gardener/extensions/controlplane/>controlplane</a> document Gardener shall not deploy any other provider-specific component.
Instead, it creates a <code>ControlPlane</code> CRD with purpose <code>exposure</code> that should be picked up by provider extensions.
Its purpose is to trigger the deployment of such provider-specific components in the shoot namespace in the seed cluster that are needed to expose the kube-apiserver.</p><p>The shoot cluster&rsquo;s kube-apiserver are exposed via a <code>Service</code> of type <code>LoadBalancer</code> from the shoot provider (you may run the control plane of an Azure shoot in a GCP seed) it&rsquo;s the seed provider extension controller that should act on the <code>ControlPlane</code> resources with purpose <code>exposure</code>.</p><p>If <a href=/docs/gardener/proposals/08-shoot-apiserver-via-sni/>SNI</a> is enabled, then the <code>Service</code> from above is of type <code>ClusterIP</code> and Gardner will not create <code>ControlPlane</code> resources with purpose <code>exposure</code>.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What needs to be implemented to support a new infrastructure provider?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: extensions.gardener.cloud/v1alpha1
kind: ControlPlane
metadata:
  name: control-plane-exposure
  namespace: shoot--foo--bar
spec:
  type: aws
  purpose: exposure
  region: europe-west1
  secretRef:
    name: cloudprovider
    namespace: shoot--foo--bar
</code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used for the shoot cluster.
It is most likely not needed, however, still added for some potential corner cases.
If you don&rsquo;t need it then just ignore it.
The <code>.spec.region</code> contains the region of the seed cluster.</p><p>In order to support a control plane provider with purpose <code>exposure</code> you need to write a controller or expand the existing <a href=/docs/gardener/extensions/controlplane/>controlplane controller</a> that watches all <code>ControlPlane</code>s with <code>.spec.type=&lt;my-provider-name></code> and purpose <code>exposure</code>.
You can take a look at the below referenced example implementation for the AWS provider.</p><h2 id=non-provider-specific-information-required-for-infrastructure-creation>Non-provider specific information required for infrastructure creation</h2><p>Most providers might require further information that is not provider specific but already part of the shoot resource.
As Gardener cannot know which information is required by providers it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_controlplane.go><code>ControlPlane</code> API (Golang specification)</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/controlplane>Exemplary implementation for the AWS provider</a></li><li><a href=https://github.com/gardener/aws-lb-readvertiser>AWS Load Balancer Readvertiser</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-b8aa124fe8bedbc5e039bbe785060c38>10 - Controlplane Webhooks</h1><h1 id=controlplane-customization-webhooks>Controlplane customization webhooks</h1><p>Gardener creates the Shoot controlplane in several steps of the Shoot flow. At different point of this flow, it:</p><ul><li>deploys standard controlplane components such as kube-apiserver, kube-controller-manager, and kube-scheduler by creating the corresponding deployments, services, and other resources in the Shoot namespace.</li><li>initiates the deployment of custom controlplane components by <a href=/docs/gardener/extensions/controlplane/>ControlPlane controllers</a> by creating a <code>ControlPlane</code> resource in the Shoot namespace.</li></ul><p>In order to apply any provider-specific changes to the configuration provided by Gardener for the standard controlplane components, cloud extension providers can install mutating admission webhooks for the resources created by Gardener in the Shoot namespace.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-cloud-provider>What needs to be implemented to support a new cloud provider?</h2><p>In order to support a new cloud provider you should install &ldquo;controlplane&rdquo; mutating webhooks for any of the following resources:</p><ul><li>Deployment with name <code>kube-apiserver</code>, <code>kube-controller-manager</code>, or <code>kube-scheduler</code></li><li>Service with name <code>kube-apiserver</code></li><li><code>OperatingSystemConfig</code> with any name and purpose <code>reconcile</code></li></ul><p>See <a href=#contract-specification>Contract Specification</a> for more details on the contract that Gardener and webhooks should adhere to regarding the content of the above resources.</p><p>You can install 3 different kinds of controlplane webhooks:</p><ul><li><code>Shoot</code>, or <code>controlplane</code> webhooks apply changes needed by the Shoot cloud provider, for example the <code>--cloud-provider</code> command line flag of <code>kube-apiserver</code> and <code>kube-controller-manager</code>. Such webhooks should only operate on Shoot namespaces labeled with <code>shoot.gardener.cloud/provider=&lt;provider></code>.</li><li><code>Seed</code>, or <code>controlplaneexposure</code> webhooks apply changes needed by the Seed cloud provider, for example annotations on the <code>kube-apiserver</code> service to ensure cloud-specific load balancers are correctly provisioned for a service of type <code>LoadBalancer</code>. Such webhooks should only operate on Shoot namespaces labeled with <code>seed.gardener.cloud/provider=&lt;provider></code>.</li></ul><p>The labels <code>shoot.gardener.cloud/provider</code> and <code>shoot.gardener.cloud/provider</code> are added by Gardener when it creates the Shoot namespace.</p><h2 id=contract-specification>Contract Specification</h2><p>This section specifies the contract that Gardener and webhooks should adhere to in order to ensure smooth interoperability. Note that this contract can&rsquo;t be specified formally and is therefore easy to violate, especially by Gardener. The Gardener team will nevertheless do its best to adhere to this contract in the future and to ensure via additional measures (tests, validations) that it&rsquo;s not unintentionally broken. If it needs to be changed intentionally, this can only happen after proper communication has taken place to ensure that the affected provider webhooks could be adapted to work with the new version of the contract.</p><p><strong>Note:</strong> The contract described below may not necessarily be what Gardener does currently (as of May 2019). Rather, it reflects the target state after changes for <a href=/docs/gardener/extensions/overview/>Gardener extensibility</a> have been introduced.</p><h3 id=kube-apiserver>kube-apiserver</h3><p>To deploy kube-apiserver, Gardener <strong>shall</strong> create a deployment and a service both named <code>kube-apiserver</code> in the Shoot namespace. They can be mutated by webhooks to apply any provider-specific changes to the standard configuration provided by Gardener.</p><p>The pod template of the <code>kube-apiserver</code> deployment <strong>shall</strong> contain a container named <code>kube-apiserver</code>.</p><p>The <code>command</code> field of the <code>kube-apiserver</code> container <strong>shall</strong> contain the <a href=https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/>kube-apiserver command line</a>. It <strong>shall</strong> contain a number of provider-independent flags that should be ignored by webhooks, such as:</p><ul><li>admission plugins (<code>--enable-admission-plugins</code>, <code>--disable-admission-plugins</code>)</li><li>secure communications (<code>--etcd-cafile</code>, <code>--etcd-certfile</code>, <code>--etcd-keyfile</code>, &mldr;)</li><li>audit log (<code>--audit-log-*</code>)</li><li>ports (<code>--insecure-port</code>, <code>--secure-port</code>)</li></ul><p>The kube-apiserver command line <strong>shall not</strong> contain any provider-specific flags, such as:</p><ul><li><code>--cloud-provider</code></li><li><code>--cloud-config</code></li></ul><p>These flags can be added by webhooks if needed.</p><p>The <code>kube-apiserver</code> command line <strong>may</strong> contain a number of additional provider-independent flags. In general, webhooks should ignore these unless they are known to interfere with the desired kube-apiserver behavior for the specific provider. Among the flags to be considered are:</p><ul><li><code>--endpoint-reconciler-type</code></li><li><code>--advertise-address</code></li><li><code>--feature-gates</code></li></ul><p>Gardener <strong>may</strong> use <a href=/docs/gardener/proposals/08-shoot-apiserver-via-sni/>SNI</a> to expose the apiserver (<code>APIServerSNI</code> feature gate). In this case, Gardener <strong>shall</strong> label the <code>kube-apiserver</code>&rsquo;s <code>Deployment</code> with <code>core.gardener.cloud/apiserver-exposure: gardener-managed</code> label and expects that the <code>--endpoint-reconciler-type</code> and <code>--advertise-address</code> flags are not modified.</p><p>The <code>--enable-admission-plugins</code> flag <strong>may</strong> contain admission plugins that are not compatible with CSI plugins such as <code>PersistentVolumeLabel</code>. Webhooks should therefore ensure that such admission plugins are either explicitly enabled (if CSI plugins are not used) or disabled (otherwise).</p><p>The <code>env</code> field of the <code>kube-apiserver</code> container <strong>shall not</strong> contain any provider-specific environment variables (so it will be empty). If any provider-specific environment variables are needed, they should be added by webhooks.</p><p>The <code>volumes</code> field of the pod template of the <code>kube-apiserver</code> deployment, and respectively the <code>volumeMounts</code> field of the <code>kube-apiserver</code> container <strong>shall not</strong> contain any provider-specific <code>Secret</code> or <code>ConfigMap</code> resources. If such resources should be mounted as volumes, this should be done by webhooks.</p><p>The <code>kube-apiserver</code> <code>Service</code> <strong>may</strong> be of type <code>LoadBalancer</code>, but <strong>shall not</strong> contain any provider-specific annotations that may be needed to actually provision a load balancer resource in the Seed provider&rsquo;s cloud. If any such annotations are needed, they should be added by webhooks (typically <code>controlplaneexposure</code> webhooks).</p><p>The <code>kube-apiserver</code> <code>Service</code> <strong>shall</strong> be of type <code>ClusterIP</code>, if Gardener is using <a href=/docs/gardener/proposals/08-shoot-apiserver-via-sni/>SNI</a> to expose the apiserver (<code>APIServerSNI</code> feature gate). In this case, Gardener <strong>shall</strong> label this <code>Service</code> with <code>core.gardener.cloud/apiserver-exposure: gardener-managed</code> label and expects that no mutations happen.</p><h3 id=kube-controller-manager>kube-controller-manager</h3><p>To deploy kube-controller-manager, Gardener <strong>shall</strong> create a deployment named <code>kube-controller-manager</code> in the Shoot namespace. It can be mutated by webhooks to apply any provider-specific changes to the standard configuration provided by Gardener.</p><p>The pod template of the <code>kube-controller-manager</code> deployment <strong>shall</strong> contain a container named <code>kube-controller-manager</code>.</p><p>The <code>command</code> field of the <code>kube-controller-manager</code> container <strong>shall</strong> contain the <a href=https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/>kube-controller-manager command line</a>. It <strong>shall</strong> contain a number of provider-independent flags that should be ignored by webhooks, such as:</p><ul><li><code>--kubeconfig</code>, <code>--authentication-kubeconfig</code>, <code>--authorization-kubeconfig</code></li><li><code>--leader-elect</code></li><li>secure communications (<code>--tls-cert-file</code>, <code>--tls-private-key-file</code>, &mldr;)</li><li>cluster CIDR and identity (<code>--cluster-cidr</code>, <code>--cluster-name</code>)</li><li>sync settings (<code>--concurrent-deployment-syncs</code>, <code>--concurrent-replicaset-syncs</code>)</li><li>horizontal pod autoscaler (<code>--horizontal-pod-autoscaler-*</code>)</li><li>ports (<code>--port</code>, <code>--secure-port</code>)</li></ul><p>The kube-controller-manager command line <strong>shall not</strong> contain any provider-specific flags, such as:</p><ul><li><code>--cloud-provider</code></li><li><code>--cloud-config</code></li><li><code>--configure-cloud-routes</code></li><li><code>--external-cloud-volume-plugin</code></li></ul><p>These flags can be added by webhooks if needed.</p><p>The kube-controller-manager command line <strong>may</strong> contain a number of additional provider-independent flags. In general, webhooks should ignore these unless they are known to interfere with the desired kube-controller-manager behavior for the specific provider. Among the flags to be considered are:</p><ul><li><code>--feature-gates</code></li></ul><p>The <code>env</code> field of the <code>kube-controller-manager</code> container <strong>shall not</strong> contain any provider-specific environment variables (so it will be empty). If any provider-specific environment variables are needed, they should be added by webhooks.</p><p>The <code>volumes</code> field of the pod template of the <code>kube-controller-manager</code> deployment, and respectively the <code>volumeMounts</code> field of the <code>kube-controller-manager</code> container <strong>shall not</strong> contain any provider-specific <code>Secret</code> or <code>ConfigMap</code> resources. If such resources should be mounted as volumes, this should be done by webhooks.</p><h3 id=kube-scheduler>kube-scheduler</h3><p>To deploy kube-scheduler, Gardener <strong>shall</strong> create a deployment named <code>kube-scheduler</code> in the Shoot namespace. It can be mutated by webhooks to apply any provider-specific changes to the standard configuration provided by Gardener.</p><p>The pod template of the <code>kube-scheduler</code> deployment <strong>shall</strong> contain a container named <code>kube-scheduler</code>.</p><p>The <code>command</code> field of the <code>kube-scheduler</code> container <strong>shall</strong> contain the <a href=https://kubernetes.io/docs/reference/command-line-tools-reference/kube-scheduler/>kube-scheduler command line</a>. It <strong>shall</strong> contain a number of provider-independent flags that should be ignored by webhooks, such as:</p><ul><li><code>--config</code></li><li><code>--authentication-kubeconfig</code>, <code>--authorization-kubeconfig</code></li><li>secure communications (<code>--tls-cert-file</code>, <code>--tls-private-key-file</code>, &mldr;)</li><li>ports (<code>--port</code>, <code>--secure-port</code>)</li></ul><p>The kube-scheduler command line <strong>may</strong> contain additional provider-independent flags. In general, webhooks should ignore these unless they are known to interfere with the desired kube-controller-manager behavior for the specific provider. Among the flags to be considered are:</p><ul><li><code>--feature-gates</code></li></ul><p>The kube-scheduler command line can&rsquo;t contain provider-specific flags, and it makes no sense to specify provider-specific environment variables or mount provider-specific <code>Secret</code> or <code>ConfigMap</code> resources as volumes.</p><h3 id=etcd-main-and-etcd-events>etcd-main and etcd-events</h3><p>To deploy etcd, Gardener <strong>shall</strong> create 2 <a href=https://github.com/gardener/etcd-druid/blob/1d427e9167adac1476d1847c0e265c2c09d6bc62/config/samples/druid_v1alpha1_etcd.yaml>Etcd</a> named <code>etcd-main</code> and <code>etcd-events</code> in the Shoot namespace. They can be mutated by webhooks to apply any provider-specific changes to the standard configuration provided by Gardener.</p><p>Gardener <strong>shall</strong> configure the <code>Etcd</code> resource completely to set up an etcd cluster which uses the default storage class of the seed cluster.</p><h3 id=cloud-controller-manager>cloud-controller-manager</h3><p>Gardener <strong>shall not</strong> deploy a cloud-controller-manager. If it is needed, it should be added by a <a href=/docs/gardener/extensions/controlplane/><code>ControlPlane</code> controller</a></p><h3 id=csi-controllers>CSI controllers</h3><p>Gardener <strong>shall not</strong> deploy a CSI controller. If it is needed, it should be added by a <a href=/docs/gardener/extensions/controlplane/><code>ControlPlane</code> controller</a></p><h3 id=kubelet>kubelet</h3><p>To specify the kubelet configuration, Gardener <strong>shall</strong> create a <a href=/docs/gardener/extensions/operatingsystemconfig/><code>OperatingSystemConfig</code> resource</a> with any name and purpose <code>reconcile</code> in the Shoot namespace. It can therefore also be mutated by webhooks to apply any provider-specific changes to the standard configuration provided by Gardener. Gardener <strong>may</strong> write multiple such resources with different <code>type</code> to the same Shoot namespaces if multiple OSs are used.</p><p>The OSC resource <strong>shall</strong> contain a unit named <code>kubelet.service</code>, containing the corresponding systemd unit configuration file. The <code>[Service]</code> section of this file <strong>shall</strong> contain a single <code>ExecStart</code> option having the <a href=https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/>kubelet command line</a> as its value.</p><p>The OSC resource <strong>shall</strong> contain a file with path <code>/var/lib/kubelet/config/kubelet</code>, which contains a <code>KubeletConfiguration</code> resource in YAML format. Most of the flags that can be specified in the kubelet command line can alternatively be specified as options in this configuration as well.</p><p>The kubelet command line <strong>shall</strong> contain a number of provider-independent flags that should be ignored by webhooks, such as:</p><ul><li><code>--config</code></li><li><code>--bootstrap-kubeconfig</code>, <code>--kubeconfig</code></li><li><code>--network-plugin</code> (and, if it equals <code>cni</code>, also <code>--cni-bin-dir</code> and <code>--cni-conf-dir</code>)</li><li><code>--node-labels</code></li></ul><p>The kubelet command line <strong>shall not</strong> contain any provider-specific flags, such as:</p><ul><li><code>--cloud-provider</code></li><li><code>--cloud-config</code></li><li><code>--provider-id</code></li></ul><p>These flags can be added by webhooks if needed.</p><p>The kubelet command line / configuration <strong>may</strong> contain a number of additional provider-independent flags / options. In general, webhooks should ignore these unless they are known to interfere with the desired kubelet behavior for the specific provider. Among the flags / options to be considered are:</p><ul><li><code>--enable-controller-attach-detach</code> (<code>enableControllerAttachDetach</code>) - should be set to <code>true</code> if CSI plugins are used, but in general can also be ignored since its default value is also <code>true</code>, and this should work both with and without CSI plugins.</li><li><code>--feature-gates</code> (<code>featureGates</code>) - should contain a list of specific feature gates if CSI plugins are used. If CSI plugins are not used, the corresponding feature gates can be ignored since enabling them should not harm in any way.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-719af9bdc56f6cf5b7e123daddb6f6a4>11 - Conventions</h1><h1 id=general-conventions>General conventions</h1><p>All the extensions that are registered to Gardener are deployed to the seed clusters, on which they are required (also see <a href=/docs/gardener/extensions/controllerregistration/>ControllerRegistration</a>).</p><p>Some of these extensions might need to create global resources in the seed (e.g., <code>ClusterRole</code>s), i.e., it&rsquo;s important to have a naming scheme to avoid conflicts as it cannot be checked or validated upfront that two extensions don&rsquo;t use the same names.</p><p>Consequently, this page should help answering some general questions that might come up when it comes to developing an extension.</p><h2 id=is-there-a-naming-scheme-for-global-resources>Is there a naming scheme for (global) resources?</h2><p>As there is no formal process to validate non-existence of conflicts between two extensions please follow these naming schemes when creating resources (especially, when creating global resources, but it&rsquo;s in general a good idea for most created resources):</p><p><em>The resource name should be prefixed with <code>extensions.gardener.cloud:&lt;extension-type>-&lt;extension-name>:&lt;resource-name></code></em>, for example:</p><ul><li><code>extensions.gardener.cloud:provider-aws:machine-controller-manager</code></li><li><code>extensions.gardener.cloud:extension-certificate-service:cert-broker</code></li></ul><h2 id=how-to-create-resources-in-the-shoot-cluster>How to create resources in the shoot cluster?</h2><p>Some extensions might not only create resources in the seed cluster itself but also in the shoot cluster. Usually, every extension comes with a <code>ServiceAccount</code> and the required RBAC permissions when it gets installed to the seed.
However, there are no credentials for the shoot for every extension.</p><p>Gardener creates a kubeconfig for itself that it uses to interact with the shoot cluster.
This kubeconfig is stored as a <code>Secret</code> with name <a href=https://github.com/gardener/gardener/blob/master/pkg/apis/core/v1beta1/constants/types_constants.go><code>gardener</code></a> in the shoot namespace.
Extension controllers may use this kubeconfig to interact with the shoot cluster if desired (it has full administrator privileges and no further RBAC rules are required).
Instead, they could also create their own kubeconfig for every shoot (which, of course, is better for auditing reasons, but not yet enforced at this point in time).</p><p>If you need to deploy a non-DaemonSet resource you need to ensure that it only runs on nodes that are allowed to host system components and extensions.
To do that you need to configure a <code>nodeSelector</code> as following:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>nodeSelector:
 worker.gardener.cloud/system-components: <span style=color:#a31515>&#34;true&#34;</span>
</code></pre></div><h2 id=how-to-create-certificates-for-the-shoot-cluster>How to create certificates for the shoot cluster?</h2><p>Gardener creates several certificate authorities (CA) that are used to create server certificates for various components.
For example, the shoot&rsquo;s etcd has its own CA, the kube-aggregator has its own CA as well, and both are different to the actual cluster&rsquo;s CA.</p><p>Extensions should do the same and generate dedicated CAs for their components (e.g. for signing a server certificate for cloud-controller-manager). They should not depend on the CA secrets managed by gardenlet.
You can take a look at the <a href=/docs/gardener/development/secrets_management/>Secrets Management document</a> for more details on how this can be achieved.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-e378f2a8255d95d82baa75cd98a3b43b>12 - Dns</h1><h1 id=contract-dnsprovider-and-dnsentry-resources>Contract: <code>DNSProvider</code> and <code>DNSEntry</code> resources</h1><p>Every shoot cluster requires external DNS records that are publicly resolvable.
The management of these DNS records requires provider-specific knowledge which is to be developed outside of the Gardener&rsquo;s core repository.</p><h2 id=what-does-gardener-create-dns-records-for>What does Gardener create DNS records for?</h2><h3 id=internal-domain-name>Internal domain name</h3><p>Every shoot cluster&rsquo;s kube-apiserver running in the seed is exposed via a load balancer that has a public endpoint (IP or hostname).
This endpoint is used by end-users and also by system components (that are running in another network, e.g., the kubelet or kube-proxy) to talk to the cluster.
In order to be robust against changes of this endpoint (e.g., caused due to re-creation of the load balancer or move of the control plane to another seed cluster) Gardener creates a so-called <em>internal domain name</em> for every shoot cluster.
The <em>internal domain name</em> is a publicly resolvable DNS record that points to the load balancer of the kube-apiserver.
Gardener uses this domain name in the kubeconfigs of all system components (instead of writing the load balancer endpoint directly into it.
This way Gardener does not need to recreate all the kubeconfigs if the endpoint changes - it just needs to update the DNS record.</p><h3 id=external-domain-name>External domain name</h3><p>The internal domain name is not configurable by end-users directly but dictated by the Gardener administrator.
However, end-users usually prefer to have another DNS name, maybe even using their own domain sometimes to access their Kubernetes clusters.
Gardener supports that by creating another DNS record, named <em>external domain name</em>, that actually points to the <em>internal domain name</em>.
The kubeconfig handed out to end-users does contain this <em>external domain name</em>, i.e., users can access their clusters with the DNS name they like to.</p><p>As not every end-user has an own domain it is possible for Gardener administrators to configure so-called <em>default domains</em>.
If configured, shoots that do not specify a domain explicitly get an <em>external domain name</em> based on a default domain (unless explicitly stated that this shoot should not get an external domain name (<code>.spec.dns.provider=unmanaged</code>).</p><h3 id=domain-name-for-ingress-deprecated>Domain name for ingress (deprecated)</h3><p>Gardener allows to deploy a <code>nginx-ingress-controller</code> into a shoot cluster (deprecated).
This controller is exposed via a public load balancer (again, either IP or hostname).
Gardener creates a wildcard DNS record pointing to this load balancer.
<code>Ingress</code> resources can later use this wildcard DNS record to expose underlying applications.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-dns-provider>What needs to be implemented to support a new DNS provider?</h2><p>As part of the shoot flow Gardener will create two special resources in the seed cluster that need to be reconciled by an extension controller.
The first resource (<code>DNSProvider</code>) is a declaration of a DNS provider (e.g., <code>aws-route53</code>, <code>google-clouddns</code>, &mldr;) with a reference to a <code>Secret</code> object that contains the provider-specific credentials in order to talk to the provider&rsquo;s API.
It also allows to specify two lists of domains that shall be allowed or disallowed to be used for DNS entries:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: v1
kind: Secret
metadata:
  name: aws-credentials
  namespace: default
type: Opaque
data:
  <span style=color:green># aws-route53 specific credentials here</span>
---
apiVersion: dns.gardener.cloud/v1alpha1
kind: DNSProvider
metadata:
  name: my-aws-account
  namespace: default
spec:
  type: aws-route53
  secretRef:
    name: aws-credentials
  domains:
    include:
    - dev.my-fancy-domain.com
    exclude:
    - staging.my-fancy-domain.com
    - prod.my-fancy-domain.com
</code></pre></div><p>When reconciling this resource the DNS controller has to read information about available DNS zones to figure out which domains can actually be supported by the provided credentials.
Based on the constraints given in the <code>DNSProvider</code> resources <code>.spec.domains.{include|exclude}</code> fields it shall later only allow certain DNS entries.
Gardener waits until the <code>status</code> indicates that the registration went well:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: dns.gardener.cloud/v1alpha1
kind: DNSProvider
...
status:
  state: Ready
  message: everything ok
</code></pre></div><p>Other possible states are <code>Pending</code>, <code>Error</code>, and <code>Invalid</code>.
The DNS controller may provide an explanation of the <code>.status.state</code> in the <code>.status.message</code> field.</p><p>Now Gardener may create <code>DNSEntry</code> objects that represent the ask to create an actual external DNS record:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: dns.gardener.cloud/v1alpha1
kind: DNSEntry
metadata:
  name: dns
  namespace: default
spec:
  dnsName: apiserver.cluster1.dev.my-fancy-domain.com
  ttl: 600
  targets:
  - 8.8.8.8
</code></pre></div><p>It has to be automatically determined whether the to-be-created DNS record is of type <code>A</code> or <code>CNAME</code>.
The spec shall also allow the creation of <code>TXT</code> records, e.g.:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: dns.gardener.cloud/v1alpha1
kind: DNSEntry
metadata:
  name: dns
  namespace: default
spec:
  dnsName: data.apiserver.cluster1.dev.my-fancy-domain.com
  ttl: 120
  text: |<span style=color:#a31515>
</span><span style=color:#a31515>    </span>    content for the DNS TXT record
</code></pre></div><p>The <code>status</code> section of this resource looks similar like the <code>DNSProvider</code>&rsquo;s.
Gardener is (as of today) only evaluating the <code>.status.state</code> and <code>.status.message</code> fields.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/external-dns-management/tree/master/pkg/apis/dns/v1alpha1><code>DNSProvider</code> and <code>DNSEntry</code> API (Golang specification)</a></li><li><a href=https://github.com/gardener/external-dns-management>external-dns-management project in Gardener&rsquo;s GitHub organization</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-6b0bf831ee5197821c0717de33be3996>13 - Dnsrecor</h1><h1 id=contract-dnsrecord-resources>Contract: <code>DNSRecord</code> resources</h1><p>Every shoot cluster requires external DNS records that are publicly resolvable.
The management of these DNS records requires provider-specific knowledge which is to be developed outside the Gardener&rsquo;s core repository.</p><p>Currently, Gardener uses <a href=/docs/gardener/extensions/dns/><code>DNSProvider</code> and <code>DNSEntry</code> resources</a>. However, this introduces undesired coupling of Gardener to a controller that does not adhere to the Gardener extension contracts. Because of this, we plan to stop using <code>DNSProvider</code> and <code>DNSEntry</code> resources for Gardener DNS records in the future and use the <code>DNSRecord</code> resources described here instead.</p><h2 id=what-does-gardener-create-dns-records-for>What does Gardener create DNS records for?</h2><h3 id=internal-domain-name>Internal domain name</h3><p>Every shoot cluster&rsquo;s kube-apiserver running in the seed is exposed via a load balancer that has a public endpoint (IP or hostname).
This endpoint is used by end-users and also by system components (that are running in another network, e.g., the kubelet or kube-proxy) to talk to the cluster.
In order to be robust against changes of this endpoint (e.g., caused due to re-creation of the load balancer or move of the DNS record to another seed cluster) Gardener creates a so-called <em>internal domain name</em> for every shoot cluster.
The <em>internal domain name</em> is a publicly resolvable DNS record that points to the load balancer of the kube-apiserver.
Gardener uses this domain name in the kubeconfigs of all system components, instead of using directly the load balancer endpoint.
This way Gardener does not need to recreate all kubeconfigs if the endpoint changes - it just needs to update the DNS record.</p><h3 id=external-domain-name>External domain name</h3><p>The internal domain name is not configurable by end-users directly but configured by the Gardener administrator.
However, end-users usually prefer to have another DNS name, maybe even using their own domain sometimes to access their Kubernetes clusters.
Gardener supports that by creating another DNS record, named <em>external domain name</em>, that actually points to the <em>internal domain name</em>.
The kubeconfig handed out to end-users does contain this <em>external domain name</em>, i.e., users can access their clusters with the DNS name they like to.</p><p>As not every end-user has an own domain it is possible for Gardener administrators to configure so-called <em>default domains</em>.
If configured, shoots that do not specify a domain explicitly get an <em>external domain name</em> based on a default domain (unless explicitly stated that this shoot should not get an external domain name (<code>.spec.dns.provider=unmanaged</code>).</p><h3 id=ingress-domain-name-deprecated>Ingress domain name (deprecated)</h3><p>Gardener allows to deploy a <code>nginx-ingress-controller</code> into a shoot cluster (deprecated).
This controller is exposed via a public load balancer (again, either IP or hostname).
Gardener creates a wildcard DNS record pointing to this load balancer.
<code>Ingress</code> resources can later use this wildcard DNS record to expose underlying applications.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-dns-provider>What needs to be implemented to support a new DNS provider?</h2><p>As part of the shoot flow Gardener will create a number of <code>DNSRecord</code> resources in the seed cluster (one for each of the DNS records mentioned above) that need to be reconciled by an extension controller.
This resource contains the following information:</p><ul><li>The DNS provider type (e.g., <code>aws-route53</code>, <code>google-clouddns</code>, &mldr;)</li><li>A reference to a <code>Secret</code> object that contains the provider-specific credentials used to communicate with the provider&rsquo;s API.</li><li>The fully qualified domain name (FQDN) of the DNS record, e.g. &ldquo;api.&lt;shoot domain>&rdquo;.</li><li>The DNS record type, one of <code>A</code>, <code>CNAME</code>, or <code>TXT</code>.</li><li>The DNS record values, that is a list of IP addresses for A records, a single hostname for CNAME records, or a list of texts for TXT records.</li></ul><p>Optionally, the <code>DNSRecord</code> resource may contain also the following information:</p><ul><li>The region of the DNS record. If not specified, the region specified in the referenced <code>Secret</code> shall be used. If that is also not specified, the extension controller shall use a certain default region.</li><li>The DNS hosted zone of the DNS record. If not specified, it shall be determined automatically by the extension controller by getting all hosted zones of the account and searching for the longest zone name that is a suffix of the fully qualified domain name (FQDN) mentioned above.</li><li>The TTL of the DNS record in seconds. If not specified, it shall be set by the extension controller to 120.</li></ul><p><strong>Example <code>DNSRecord</code></strong>:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: v1
kind: Secret
metadata:
  name: dnsrecord-bar-external
  namespace: shoot--foo--bar
type: Opaque
data:
  <span style=color:green># aws-route53 specific credentials here</span>
---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: DNSRecord
metadata:
  name: dnsrecord-external
  namespace: default
spec:
  type: aws-route53
  secretRef:
    name: dnsrecord-bar-external
    namespace: shoot--foo--bar
<span style=color:green># region: eu-west-1</span>
<span style=color:green># zone: ZFOO</span>
  name: api.bar.foo.my-fancy-domain.com
  recordType: A
  values:
  - 1.2.3.4
<span style=color:green># ttl: 600</span>
</code></pre></div><p>In order to support a new DNS record provider you need to write a controller that watches all <code>DNSRecord</code>s with <code>.spec.type=&lt;my-provider-name></code>.
You can take a look at the below referenced example implementation for the AWS route53 provider.</p><h2 id=key-names-in-secrets-containing-provider-specific-credentials>Key names in secrets containing provider-specific credentials</h2><p>For compatibility with existing setups, extension controllers shall support two different namings of keys in secrets containing provider-specific credentials:</p><ul><li>The naming used by the <a href=https://github.com/gardener/external-dns-management>external-dns-management DNS controller</a>. For example on AWS, the key names are <code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, and <code>AWS_REGION</code>.</li><li>The naming used by other provider-specific extension controllers, e.g. for <a href=/docs/gardener/extensions/infrastructure/>infrastructure</a>. For example on AWS, the key names are <code>accessKeyId</code>, <code>secretAccessKey</code>, and <code>region</code>.</li></ul><h2 id=avoiding-reading-the-dns-hosted-zones>Avoiding reading the DNS hosted zones</h2><p>If the DNS hosted zone is not specified in the <code>DNSRecord</code> resource, during the first reconciliation the extension controller shall determine the correct DNS hosted zone for the specified FQDN and write it to the status of the resource:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: DNSRecord
metadata:
  name: dnsrecord-external
  namespace: shoot--foo--bar
spec:
  ...
status:
  lastOperation: ...
  zone: ZFOO
</code></pre></div><p>On subsequent reconciliations, the extension controller shall use the zone from the status and avoid reading the DNS hosted zones from the provider.
If the <code>DNSRecord</code> resource specifies a zone in <code>.spec.zone</code> and the extension controller has written a value to <code>.status.zone</code>, the first one shall be considered with higher priority by the extension controller.</p><h2 id=non-provider-specific-information-required-for-dns-record-creation>Non-provider specific information required for DNS record creation</h2><p>Some providers might require further information that is not provider specific but already part of the shoot resource.
As Gardener cannot know which information is required by providers it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information that is not part of the <code>DNSRecord</code> resource itself.</p><h2 id=using-dnsrecord-instead-of-dnsprovider-and-dnsentry-resources>Using <code>DNSRecord</code> instead of <code>DNSProvider</code> and <code>DNSEntry</code> resources</h2><p>Currently, Gardener will create <code>DNSRecord</code> resources only if the feature gate <code>UseDNSRecords</code> is enabled on <code>gardener-apiserver</code>, <code>gardener-controller-manager</code>, and <code>gardenlet</code> (it should be enabled on all three of them for the feature to work properly).
If this feature gate is enabled, all three DNS records mentioned above (internal, external, and ingress) will be managed via <code>DNSRecords</code> and not <code>DNSProvider</code> / <code>DNSEntry</code>.
<code>DNSProvider</code> resources will still be created for all providers listed in <code>spec.dns.providers</code>, including the one marked as <code>primary: true</code>.
These providers can be used for <code>DNSEntry</code> resources needed by workloads deployed on the shoot cluster.</p><p>If the feature gate is disabled, Gardener will not create any <code>DNSRecord</code> resources and use <code>DNSProvider</code> / <code>DNSEntry</code> resources for its DNS records.
The feature gate was introduced in <code>v1.27</code> and was in <code>Alpha</code> stage (disabled by default) until <code>v1.38</code> (including). With <code>v1.39</code> the feature gate is graduated to <code>Beta</code> and it is enabled by default.</p><p>In order to successfully reconcile a shoot with the feature gate enabled, extension controllers for <code>DNSRecord</code> resources for types used in the default, internal and custom domain secrets should be registered via <code>ControllerRegistration</code> resources.</p><h3 id=support-for-dnsrecord-resources-in-the-provider-extensions>Support for <code>DNSRecord</code> resources in the provider extensions</h3><p>The following table contains information about the provider extension version that adds support for <code>DNSRecord</code> resources:</p><table><thead><tr><th>Extension</th><th>Version</th></tr></thead><tbody><tr><td>provider-alicloud</td><td><code>v1.26.0</code></td></tr><tr><td>provider-aws</td><td><code>v1.27.0</code></td></tr><tr><td>provider-azure</td><td><code>v1.21.0</code></td></tr><tr><td>provider-gcp</td><td><code>v1.18.0</code></td></tr><tr><td>provider-openstack</td><td><code>v1.21.0</code></td></tr><tr><td>provider-vsphere</td><td>N/A</td></tr><tr><td>provider-equinix-metal</td><td>N/A</td></tr><tr><td>provider-kubevirt</td><td>N/A</td></tr><tr><td>provider-openshift</td><td>N/A</td></tr></tbody></table><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_dnsrecord.go><code>DNSRecord</code> API (Golang specification)</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/dnsrecord>Sample implementation for the AWS route53 provider</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-8d41cfc635f0777d1f5003241ea79535>14 - Extension</h1><h1 id=contract-extension-resource>Contract: <code>Extension</code> resource</h1><p>Gardener defines common procedures which must be passed to create a functioning shoot cluster. Well known steps are represented by special resources like <code>Infrastructure</code>, <code>OperatingSystemConfig</code> or <code>DNS</code>. These resources are typically reconciled by dedicated controllers setting up the infrastructure on the hyperscaler or managing DNS entries, etc..</p><p>But, some requirements don&rsquo;t match with those special resources or don&rsquo;t depend on being proceeded at a specific step in the creation / deletion flow of the shoot. They require a more generic hook. Therefore, Gardener offers the <code>Extension</code> resource.</p><h2 id=what-is-required-to-register-and-support-an-extension-type>What is required to register and support an Extension type?</h2><p>Gardener creates one <code>Extension</code> resource per registered extension type in <code>ControllerRegistration</code> per shoot.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: core.gardener.cloud/v1beta1
kind: ControllerRegistration
metadata:
  name: extension-example
spec:
  resources:
  - kind: Extension
    type: example
    globallyEnabled: <span style=color:#00f>true</span>
</code></pre></div><p>If <code>spec.resources[].globallyEnabled</code> is <code>true</code> then the <code>Extension</code> resources of the given <code>type</code> is created for every shoot cluster. Set to <code>false</code>, the <code>Extension</code> resource is only created if configured in the <code>Shoot</code> manifest.</p><p>The <code>Extension</code> resources are created in the shoot namespace of the seed cluster.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Extension
metadata:
  name: example
  namespace: shoot--foo--bar
spec:
  type: example
  providerConfig: {}
</code></pre></div><p>Your controller needs to reconcile <code>extensions.extensions.gardener.cloud</code>. Since there can exist multiple <code>Extension</code> resources per shoot, each one holds a <code>spec.type</code> field to let controllers check their responsibility (similar to all other extension resources of Gardener).</p><h2 id=providerconfig>ProviderConfig</h2><p>It is possible to provide data in the <code>Shoot</code> resource which is copied to <code>spec.providerConfig</code> of the <code>Extension</code> resource.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: core.gardener.cloud/v1beta1
kind: Shoot
metadata:
  name: bar
  namespace: garden-foo
spec:
  extensions:
  - type: example
    providerConfig:
      foo: bar
...
</code></pre></div><p>results in</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Extension
metadata:
  name: example
  namespace: shoot--foo--bar
spec:
  type: example
  providerConfig:
    foo: bar
</code></pre></div><h2 id=shoot-reconciliation-flow-and-extension-status>Shoot reconciliation flow and Extension status</h2><p>Gardener creates Extension resources as part of the Shoot reconciliation. Moreover, it is guaranteed that the <a href=/docs/gardener/extensions/cluster/>Cluster</a> resource exists before the <code>Extension</code> resource is created.</p><p>For an <code>Extension</code> controller it is crucial to maintain the <code>Extension</code>&rsquo;s status correctly. At the end Gardener checks the status of each <code>Extension</code> and only reports a successful shoot reconciliation if the state of the last operation is <code>Succeeded</code>.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: extensions.gardener.cloud/v1alpha1
kind: Extension
metadata:
  generation: 1
  name: example
  namespace: shoot--foo--bar
spec:
  type: example
status:
  lastOperation:
    state: Succeeded
  observedGeneration: 1
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-079331a6be1955be3c4c16acf0c583c1>15 - Healthcheck Library</h1><h1 id=health-check-library>Health Check Library</h1><h2 id=goal>Goal</h2><p>Typically an extension reconciles a specific resource (Custom Resource Definitions (CRDs)) and creates/modifies resources in the cluster (via helm, managed resources, kubectl, &mldr;).
We call these API Objects &lsquo;dependent objects&rsquo; - as they are bound to the lifecycle of the extension.</p><p>The goal of this library is to enable extensions to setup health checks for their &lsquo;dependent objects&rsquo; with minimal effort.</p><h2 id=usage>Usage</h2><p>The library provides a generic controller with the ability to register any resource that satisfies the <a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types.go>extension object interface</a>.
An example is <a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_worker.go>the <code>Worker</code> CRD</a>.</p><p>Health check functions for commonly used dependent objects can be reused and registered with the controller, such as:</p><ul><li>Deployment</li><li>DaemonSet</li><li>StatefulSet</li><li>ManagedResource (Gardener specific)</li></ul><p>See below example <a href=https://github.com/gardener/gardener-extension-provider-aws/blob/master/pkg/controller/healthcheck/add.go>taken from the provider-aws</a>.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go>health.DefaultRegisterExtensionForHealthCheck(
               aws.Type,
               extensionsv1alpha1.SchemeGroupVersion.WithKind(extensionsv1alpha1.WorkerResource),
               <span style=color:#00f>func</span>() runtime.Object { <span style=color:#00f>return</span> &amp;extensionsv1alpha1.Worker{} },
               mgr, <span style=color:green>// controller runtime manager
</span><span style=color:green></span>               opts, <span style=color:green>// options for the health check controller
</span><span style=color:green></span>               <span style=color:#00f>nil</span>, <span style=color:green>// custom predicates
</span><span style=color:green></span>               <span style=color:#00f>map</span>[extensionshealthcheckcontroller.HealthCheck]<span style=color:#2b91af>string</span>{
                       general.CheckManagedResource(genericactuator.McmShootResourceName): string(gardencorev1beta1.ShootSystemComponentsHealthy),
                       general.CheckSeedDeployment(aws.MachineControllerManagerName):      string(gardencorev1beta1.ShootEveryNodeReady),
                       worker.SufficientNodesAvailable():                                  string(gardencorev1beta1.ShootEveryNodeReady),
               })
</code></pre></div><p>This creates a health check controller that reconciles the <code>extensions.gardener.cloud/v1alpha1.Worker</code> resource with the spec.type &lsquo;aws&rsquo;.
Three health check functions are registered that are executed during reconciliation.
Each health check is mapped to a single <code>HealthConditionType</code> that results in conditions with the same <code>condition.type</code> (see below).
To contribute to the Shoot&rsquo;s health, the following can be used: <code>SystemComponentsHealthy</code>, <code>EveryNodeReady</code>, <code>ControlPlaneHealthy</code>.
The Gardener/Gardenlet checks each extension for conditions matching these types.
However extensions are free to choose any <code>HealthConditionType</code>.
More information <a href=/docs/gardener/extensions/shoot-health-status-conditions/>can be found here</a>.</p><p>A health check has to <a href=https://github.com/gardener/gardener/blob/master/extensions/pkg/controller/healthcheck/actuator.go>satisfy below interface</a>.
You can find implementation examples <a href=https://github.com/gardener/gardener/tree/master/extensions/pkg/controller/healthcheck/general>here</a>.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=color:#00f>type</span> HealthCheck <span style=color:#00f>interface</span> {
    <span style=color:green>// Check is the function that executes the actual health check
</span><span style=color:green></span>    Check(context.Context, types.NamespacedName) (*SingleCheckResult, <span style=color:#2b91af>error</span>)
    <span style=color:green>// InjectSeedClient injects the seed client
</span><span style=color:green></span>    InjectSeedClient(client.Client)
    <span style=color:green>// InjectShootClient injects the shoot client
</span><span style=color:green></span>    InjectShootClient(client.Client)
    <span style=color:green>// SetLoggerSuffix injects the logger
</span><span style=color:green></span>    SetLoggerSuffix(<span style=color:#2b91af>string</span>, <span style=color:#2b91af>string</span>)
    <span style=color:green>// DeepCopy clones the healthCheck
</span><span style=color:green></span>    DeepCopy() HealthCheck
}
</code></pre></div><p>The health check controller regularly (default: <code>30s</code>) reconciles the extension resource and executes the registered health checks for the dependent objects.
As a result, the controller writes condition(s) to the status of the extension containing the health check result.
In our example, two checks are mapped to <code>ShootEveryNodeReady</code> and one to <code>ShootSystemComponentsHealthy</code>, leading to conditions with two distinct <code>HealthConditionTypes</code> (condition.type)</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>status:
  conditions:
    - lastTransitionTime: <span style=color:#a31515>&#34;20XX-10-28T08:17:21Z&#34;</span>
      lastUpdateTime: <span style=color:#a31515>&#34;20XX-11-28T08:17:21Z&#34;</span>
      message: (1/1) Health checks successful
      reason: HealthCheckSuccessful
      status: <span style=color:#a31515>&#34;True&#34;</span>
      type: SystemComponentsHealthy
    - lastTransitionTime: <span style=color:#a31515>&#34;20XX-10-28T08:17:21Z&#34;</span>
      lastUpdateTime: <span style=color:#a31515>&#34;20XX-11-28T08:17:21Z&#34;</span>
      message: (2/2) Health checks successful
      reason: HealthCheckSuccessful
      status: <span style=color:#a31515>&#34;True&#34;</span>
      type: EveryNodeReady
</code></pre></div><p>Please note that there are four statuses: <code>True</code>, <code>False</code>, <code>Unknown</code>, and <code>Progressing</code>.</p><ul><li><code>True</code> should be used for successful health checks.</li><li><code>False</code> should be used for unsuccessful/failing health checks.</li><li><code>Unknown</code> should be used when there was an error trying to determine the health status.</li><li><code>Progressing</code> should be used to indicate that the health status did not succeed but for expected reasons (e.g., a cluster scale up/down could make the standard health check fail because something is wrong with the <code>Machines</code>, however, it&rsquo;s actually an expected situation and known to be completed within a few minutes.)</li></ul><p>Health checks that report <code>Progressing</code> should also provide a timeout after which this &ldquo;progressing situation&rdquo; is expected to be completed.
The health check library will automatically transition the status to <code>False</code> if the timeout was exceeded.</p><h2 id=additional-considerations>Additional Considerations</h2><p>It is up to the extension to decide how to conduct health checks, though it is recommended to make use of the build-in health check functionality of <code>managed-resources</code> for trivial checks.
By <a href=https://github.com/gardener/gardener/blob/master/extensions/pkg/controller/worker/genericactuator/machine_controller_manager.go>deploying the depending resources via managed resources</a>, the <a href=https://github.com/gardener/gardener-resource-manager>gardener resource manager</a> conducts basic checks for different API objects out-of-the-box (e.g <code>Deployments</code>, <code>DaemonSets</code>, &mldr;) - and writes health conditions.
In turn, the library contains a health check function to gather the health information from managed resources.</p><p>More sophisticated health checks should be implemented by the extension controller itself (implementing the <code>HealthCheck</code> interface).</p></div><div class=td-content style=page-break-before:always><h1 id=pg-21a79d22424671ff092806dd096f0b8e>16 - Infrastructure</h1><h1 id=contract-infrastructure-resource>Contract: <code>Infrastructure</code> resource</h1><p>Every Kubernetes cluster requires some low-level infrastructure to be setup in order to work properly.
Examples for that are networks, routing entries, security groups, IAM roles, etc.
Before introducing the <code>Infrastructure</code> extension resource Gardener was using Terraform in order to create and manage these provider-specific resources (e.g., see <a href=https://github.com/gardener/gardener/tree/0.20.0/charts/seed-terraformer/charts/aws-infra>here</a>).
Now, Gardener commissions an external, provider-specific controller to take over this task.</p><h2 id=which-infrastructure-resources-are-required>Which infrastructure resources are required?</h2><p>Unfortunately, there is no general answer to this question as it is highly provider specific.
Consider the above mentioned resources, i.e. VPC, subnets, route tables, security groups, IAM roles, SSH key pairs.
Most of the resources are required in order to create VMs (the shoot cluster worker nodes), load balancers, and volumes.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-infrastructure-provider>What needs to be implemented to support a new infrastructure provider?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Infrastructure
metadata:
  name: infrastructure
  namespace: shoot--foo--bar
spec:
  type: azure
  region: eu-west-1
  secretRef:
    name: cloudprovider
    namespace: shoot--foo--bar
  providerConfig:
    apiVersion: azure.provider.extensions.gardener.cloud/v1alpha1
    kind: InfrastructureConfig
    resourceGroup:
      name: mygroup
    networks:
      vnet: <span style=color:green># specify either &#39;name&#39; or &#39;cidr&#39;</span>
      <span style=color:green># name: my-vnet</span>
        cidr: 10.250.0.0/16
      workers: 10.250.0.0/19
</code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used to create the needed resources.
However, the most important section is the <code>.spec.providerConfig</code>.
It contains an embedded declaration of the provider specific configuration for the infrastructure (that cannot be known by Gardener itself).
You are responsible for designing how this configuration looks like.
Gardener does not evaluate it but just copies this part from what has been provided by the end-user in the <code>Shoot</code> resource.</p><p>After your controller has created the required resources in your provider&rsquo;s infrastructure it needs to generate an output that can be used by other controllers in subsequent steps.
An example for that is the <code>Worker</code> extension resource controller.
It is responsible for creating virtual machines (shoot worker nodes) in this prepared infrastructure.
Everything that it needs to know in order to do that (e.g., the network IDs, security group names, etc. (again: provider-specific)) needs to be provided as output in the <code>Infrastructure</code> resource:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Infrastructure
metadata:
  name: infrastructure
  namespace: shoot--foo--bar
spec:
  ...
status:
  lastOperation: ...
  providerStatus:
    apiVersion: azure.provider.extensions.gardener.cloud/v1alpha1
    kind: InfrastructureStatus
    resourceGroup:
      name: mygroup
    networks:
      vnet:
        name: my-vnet
      subnets:
      - purpose: nodes
        name: my-subnet
    availabilitySets:
    - purpose: nodes
      id: av-set-id
      name: av-set-name
    routeTables:
    - purpose: nodes
      name: route-table-name
    securityGroups:
    - purpose: nodes
      name: sec-group-name
</code></pre></div><p>In order to support a new infrastructure provider you need to write a controller that watches all <code>Infrastructure</code>s with <code>.spec.type=&lt;my-provider-name></code>.
You can take a look at the below referenced example implementation for the Azure provider.</p><h2 id=dynamic-nodes-network-for-shoot-clusters>Dynamic nodes network for shoot clusters</h2><p>Some environments do not allow end-users to statically define a CIDR for the network that shall be used for the shoot worker nodes.
In these cases it is possible for the extension controllers to dynamically provision a network for the nodes (as part of their reconciliation loops), and to provide the CIDR in the <code>status</code> of the <code>Infrastructure</code> resource:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Infrastructure
metadata:
  name: infrastructure
  namespace: shoot--foo--bar
spec:
  ...
status:
  lastOperation: ...
  providerStatus: ...
  nodesCIDR: 10.250.0.0/16
</code></pre></div><p>Gardener will pick this <code>nodesCIDR</code> and use it to configure the VPN components to establish network connectivity between the control plane and the worker nodes.
If the <code>Shoot</code> resource already specifies a nodes CIDR in <code>.spec.networking.nodes</code> and the extension controller provides also a value in <code>.status.nodesCIDR</code> in the <code>Infrastructure</code> resource then the latter one will always be considered with higher priority by Gardener.</p><h2 id=non-provider-specific-information-required-for-infrastructure-creation>Non-provider specific information required for infrastructure creation</h2><p>Some providers might require further information that is not provider specific but already part of the shoot resource.
One example for this is the <a href=https://github.com/gardener/gardener-extension-provider-gcp/tree/master/pkg/controller/infrastructure>GCP infrastructure controller</a> which needs the pod and the service network of the cluster in order to prepare and configure the infrastructure correctly.
As Gardener cannot know which information is required by providers it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information that is not part of the <code>Infrastructure</code> resource itself.</p><h2 id=implementation-details>Implementation details</h2><h3 id=actuator-interface><code>Actuator</code> interface</h3><p>Most existing infrastructure controller implementations follow a common pattern where a generic <code>Reconciler</code> delegates to <a href=https://github.com/gardener/gardener/blob/master/extensions/pkg/controller/infrastructure/actuator.go>an <code>Actuator</code> interface</a> that contains the methods <code>Reconcile</code>, <code>Delete</code>, <code>Migrate</code>, and <code>Restore</code>. These methods are called by the generic <code>Reconciler</code> for the respective operations, and should be implemented by the extension according to the contract described here and the <a href=/docs/gardener/extensions/migration/>migration guidelines</a>.</p><h3 id=configvalidator-interface><code>ConfigValidator</code> interface</h3><p>For infrastructure controllers, the generic <code>Reconciler</code> also delegates to <a href=https://github.com/gardener/gardener/blob/master/extensions/pkg/controller/infrastructure/configvalidator.go>a <code>ConfigValidator</code> interface</a> that contains a single <code>Validate</code> method. This method is called by the generic <code>Reconciler</code> at the beginning of every reconciliation, and can be implemented by the extension to validate the <code>.spec.providerConfig</code> part of the <code>Infrastructure</code> resource with the respective cloud provider, typically the existence and validity of cloud provider resources such as AWS VPCs or GCP Cloud NAT IPs.</p><p>The <code>Validate</code> method returns a list of errors. If this list is non-empty, the generic <code>Reconciler</code> will fail with an error. This error will have the error code <code>ERR_CONFIGURATION_PROBLEM</code>, unless there is at least one error in the list that has its <code>ErrorType</code> field set to <code>field.ErrorTypeInternal</code>.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_infrastructure.go><code>Infrastructure</code> API (Golang specification)</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-azure/tree/master/pkg/controller/infrastructure>Sample implementation for the Azure provider</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/infrastructure/configvalidator.go>Sample ConfigValidator implementation</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-95017ccbee8525055e43da8a42034f57>17 - Logging And Monitoring</h1><h1 id=logging-and-monitoring-for-extensions>Logging and Monitoring for Extensions</h1><p>Gardener provides an integrated logging and monitoring stack for alerting, monitoring and troubleshooting of its managed components by operators or end users. For further information how to make use of it in these roles, refer to the corresponding guides for <a href=https://github.com/gardener/logging/tree/master/docs/usage/README.md>exploring logs</a> and for <a href=https://grafana.com/docs/grafana/latest/getting-started/getting-started/#all-users>monitoring with Grafana</a>.</p><p>The components that constitute the logging and monitoring stack are managed by Gardener. By default, it deploys <a href=https://prometheus.io/>Prometheus</a>, <a href=https://prometheus.io/docs/alerting/latest/alertmanager/>Alertmanager</a> and <a href=https://grafana.com/>Grafana</a> into the <code>garden</code> namespace of all seed clusters. If the <code>Logging</code> <a href=/docs/gardener/deployment/feature_gates/>feature gate</a> in the <code>gardenlet</code> configuration is enabled, it will deploy <a href=https://fluentbit.io/>fluent-bit</a> and <a href=https://grafana.com/oss/loki/>Loki</a> in the <code>garden</code> namespace too.</p><p>Each shoot namespace hosts managed logging and monitoring components. As part of the shoot reconciliation flow, Gardener deploys a shoot-specific Prometheus, Grafana and, if configured, an Alertmanager into the shoot namespace, next to the other control plane components. If the <code>Logging</code> feature gate is enabled and the <a href=/docs/gardener/usage/shoot_purposes/#behavioral-differences>shoot purpose</a> is not <code>testing</code>, it deploys a shoot-specific Loki in the shoot namespace too.</p><p>The logging and monitoring stack is extensible by configuration. Gardener extensions can take advantage of that and contribute configurations encoded in <code>ConfigMap</code>s for their own, specific dashboards, alerts, log parsers and other supported assets and integrate with it. As with other Gardener resources, they will be continuously reconciled.</p><p>This guide is about the roles and extensibility options of the logging and monitoring stack components, and how to integrate extensions with:</p><ul><li><a href=#monitoring>Monitoring</a></li><li><a href=#logging>Logging</a></li></ul><h2 id=monitoring>Monitoring</h2><p>The central Prometheus instance in the <code>garden</code> namespace fetches metrics and data from all seed cluster nodes and all seed cluster pods.
It uses the <a href=https://prometheus.io/docs/prometheus/latest/federation/>federation</a> concept to allow the shoot-specific instances to scrape only the metrics for the pods of the control plane they are responsible for.
This mechanism allows to scrape the metrics for the nodes/pods once for the whole cluster, and to have them distributed afterwards.</p><p>The shoot-specific metrics are then made available to operators and users in the shoot Grafana, using the shoot Prometheus as data source.</p><p>Extension controllers might deploy components as part of their reconciliation next to the shoot&rsquo;s control plane.
Examples for this would be a cloud-controller-manager or CSI controller deployments. Extensions that want to have their managed control plane components integrated with monitoring can contribute their per-shoot configuration for scraping Prometheus metrics, Alertmanager alerts or Grafana dashboards.</p><h3 id=extensions-monitoring-integration>Extensions monitoring integration</h3><p>Before deploying the shoot-specific Prometheus instance, Gardener will read all <code>ConfigMap</code>s in the shoot namespace, which are labeled with <code>extensions.gardener.cloud/configuration=monitoring</code>.
Such <code>ConfigMap</code>s may contain four fields in their <code>data</code>:</p><ul><li><code>scrape_config</code>: This field contains Prometheus scrape configuration for the component(s) and metrics that shall be scraped.</li><li><code>alerting_rules</code>: This field contains Alertmanager rules for alerts that shall be raised.</li><li>(deprecated)<code>dashboard_operators</code>: This field contains a Grafana dashboard in JSON that is only relevant for Gardener operators.</li><li>(deprecated)<code>dashboard_users</code>: This field contains a Grafana dashboard in JSON that is only relevant for Gardener users (shoot owners).</li></ul><p><strong>Example:</strong> A <code>ControlPlane</code> controller deploying a <code>cloud-controller-manager</code> into the shoot namespace wants to integrate monitoring configuration for scraping metrics, alerting rules, dashboards and logging configuration for exposing logs to the end users.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: v1
kind: ConfigMap
metadata:
  name: extension-controlplane-monitoring-ccm
  namespace: shoot--project--name
  labels:
    extensions.gardener.cloud/configuration: monitoring
data:
  scrape_config: |<span style=color:#a31515>
</span><span style=color:#a31515>    - job_name: cloud-controller-manager
</span><span style=color:#a31515>      scheme: https
</span><span style=color:#a31515>      tls_config:
</span><span style=color:#a31515>        insecure_skip_verify: true
</span><span style=color:#a31515>      authorization:
</span><span style=color:#a31515>        type: Bearer
</span><span style=color:#a31515>        credentials_file: /var/run/secrets/gardener.cloud/shoot/token/token
</span><span style=color:#a31515>      honor_labels: false
</span><span style=color:#a31515>      kubernetes_sd_configs:
</span><span style=color:#a31515>      - role: endpoints
</span><span style=color:#a31515>        namespaces:
</span><span style=color:#a31515>          names: [shoot--project--name]
</span><span style=color:#a31515>      relabel_configs:
</span><span style=color:#a31515>      - source_labels:
</span><span style=color:#a31515>        - __meta_kubernetes_service_name
</span><span style=color:#a31515>        - __meta_kubernetes_endpoint_port_name
</span><span style=color:#a31515>        action: keep
</span><span style=color:#a31515>        regex: cloud-controller-manager;metrics
</span><span style=color:#a31515>      # common metrics
</span><span style=color:#a31515>      - action: labelmap
</span><span style=color:#a31515>        regex: __meta_kubernetes_service_label_(.+)
</span><span style=color:#a31515>      - source_labels: [ __meta_kubernetes_pod_name ]
</span><span style=color:#a31515>        target_label: pod
</span><span style=color:#a31515>      metric_relabel_configs:
</span><span style=color:#a31515>      - process_max_fds
</span><span style=color:#a31515>      - process_open_fds</span>    

  alerting_rules: |<span style=color:#a31515>
</span><span style=color:#a31515>    cloud-controller-manager.rules.yaml: |
</span><span style=color:#a31515>      groups:
</span><span style=color:#a31515>      - name: cloud-controller-manager.rules
</span><span style=color:#a31515>        rules:
</span><span style=color:#a31515>        - alert: CloudControllerManagerDown
</span><span style=color:#a31515>          expr: absent(up{job=&#34;cloud-controller-manager&#34;} == 1)
</span><span style=color:#a31515>          for: 15m
</span><span style=color:#a31515>          labels:
</span><span style=color:#a31515>            service: cloud-controller-manager
</span><span style=color:#a31515>            severity: critical
</span><span style=color:#a31515>            type: seed
</span><span style=color:#a31515>            visibility: all
</span><span style=color:#a31515>          annotations:
</span><span style=color:#a31515>            description: All infrastructure specific operations cannot be completed (e.g. creating load balancers or persistent volumes).
</span><span style=color:#a31515>            summary: Cloud controller manager is down.</span>    
</code></pre></div><h2 id=logging>Logging</h2><p>In Kubernetes clusters, container logs are non-persistent and do not survive stopped and destroyed containers. Gardener addresses this problem for the components hosted in a seed cluster, by introducing its own managed logging solution. It is integrated with the Gardener monitoring stack to have all troubleshooting context in one place.</p><p><img src=/__resources/logging-architecture_c8dc32.png alt="&ldquo;Cluster Logging Topology&rdquo;" title="Cluster Logging Topology"></p><p>Gardener logging consists of components in three roles - log collectors and forwarders, log persistency and exploration/consumption interfaces. All of them live in the seed clusters in multiple instances:</p><ul><li>Logs are persisted by Loki instances deployed as StatefulSets - one per shoot namespace, if the <code>Logging</code> feature gate is enabled and the <a href=/docs/gardener/usage/shoot_purposes/#behavioral-differences>shoot purpose</a> is not <code>testing</code>, and one in the <code>garden</code> namespace. The shoot instances store logs from the control plane components hosted there. The <code>garden</code> Loki instance is responsible for logs from the rest of the seed namespaces - <code>kube-system</code>, <code>garden</code> <code>extension-*</code> and others.</li><li>Fluent-bit DaemonSets deployed on each seed node collect logs from it. A custom plugin takes care to distribute the collected log messages to the Loki instances that they are intended for. This allows to fetch the logs once for the whole cluster, and to distribute them afterwards.</li><li>Grafana is the UI component used to explore monitoring and log data together for easier troubleshooting and in context. Grafana instances are configured to use the coresponding Loki instances, sharing the same namespace, as data providers. There is one Grafana Deployment in the <code>garden</code> namespace and two Deployments per shoot namespace (one exposed to the end users and one for the operators).</li></ul><p>Logs can be produced from various sources, such as containers or systemd, and in different formats. The fluent-bit design supports configurable <a href=https://docs.fluentbit.io/manual/concepts/data-pipeline>data pipeline</a> to address that problem. Gardener provides such <a href=https://github.com/gardener/gardener/blob/master/charts/seed-bootstrap/charts/fluent-bit/templates/fluent-bit-configmap.yaml>configuration</a> for logs produced by all its core managed components as a <code>ConfigMap</code>. Extensions can contribute their own, specific configurations as <code>ConfigMap</code>s too. See for example the <a href=https://github.com/gardener/gardener-extension-provider-aws/blob/master/charts/gardener-extension-provider-aws/templates/configmap-logging.yaml>logging configuration</a> for the Gardener AWS provider extension. The Gardener reconciliation loop watches such resources and updates the fluent-bit agents dynamically.</p><h4 id=fluent-bit-log-parsers-and-filters>Fluent-bit log parsers and filters</h4><p>To integrate with Gardener logging, extensions can and <em>should</em> specify how fluent-bit will handle the logs produced by the managed components that they contribute to Gardener. Normally, that would require to configure a <em>parser</em> for the specific logging format, if none of the available is applicable, and a <em>filter</em> defining how to apply it. For a complete reference for the configuration options, refer to fluent-bit&rsquo;s <a href=https://docs.fluentbit.io/manual/>documentation</a>.</p><p><strong>Note:</strong> At the moment only <em>parser</em> and <em>filter</em> configurations are supported.</p><p>To contribute its own configuration to the fluent-bit agents data pipelines, an extension must provide it as a <code>ConfigMap</code> labeled <code>extensions.gardener.cloud/configuration=logging</code> and deployed in the seed&rsquo;s <code>garden</code> namespace. Unlike the monitoring stack, where configurations are deployed per shoot, here a <em>single</em> configuration <code>ConfigMap</code> is sufficient and it applies to all fluent-bit agents in the seed. Its <code>data</code> field can have the following properties:</p><ul><li><code>filter-kubernetes.conf</code> - configuration for data pipeline <a href=https://docs.fluentbit.io/manual/concepts/data-pipeline/filter>filters</a></li><li><code>parser.conf</code> - configuration for data pipeline <a href=https://docs.fluentbit.io/manual/concepts/data-pipeline/parser>parsers</a></li></ul><p><strong>Note:</strong> Take care to provide the correct data pipeline elements in the coresponding data field and not to mix them.</p><p><strong>Example:</strong> Logging configuration for provider-specific (OpenStack) worker controller deploying a <code>machine-controller-manager</code> component into a shoot namespace that reuses the <code>kubeapiserverParser</code> defined in <a href=https://github.com/gardener/gardener/blob/master/charts/seed-bootstrap/charts/fluent-bit/templates/fluent-bit-configmap.yaml#L304-L309>fluent-bit-configmap.yaml</a> to parse the component logs</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: v1
kind: ConfigMap
metadata:
  name: gardener-extension-provider-openstack-logging-config
  namespace: garden
  labels:
    extensions.gardener.cloud/configuration: logging
data:
  filter-kubernetes.conf: |<span style=color:#a31515>
</span><span style=color:#a31515>    [FILTER]
</span><span style=color:#a31515>        Name                parser
</span><span style=color:#a31515>        Match               kubernetes.machine-controller-manager*openstack-machine-controller-manager*
</span><span style=color:#a31515>        Key_Name            log
</span><span style=color:#a31515>        Parser              kubeapiserverParser
</span><span style=color:#a31515>        Reserve_Data        True</span>    
</code></pre></div><h5 id=how-to-expose-logs-to-the-users>How to expose logs to the users</h5><p>To expose logs from extension components to the users, the extension owners have to specify a <code>modify</code> filter which will add <code>__gardener_multitenant_id__=operator;user</code> entry to the log record. This entry contains all of the tenants, which have to receive this log. The tenants are semicolon separated. This specific dedicated entry will be extracted and removed from the log in the <code>gardener fluent-bit-to-loki</code> output plugin and added to the label set of that log. Then it will be parsed and removed from the label set. Any whitespace will be truncated during the parsing. The extension components logs can be found in <code>Controlplane Logs Dashboard</code> Grafana dashboard.</p><p><strong>Example:</strong> In this example we configure fluent-bit when it finds a log with field <code>tag</code>, which match the <code>Condition</code>, to add <code>__gardener_multitenant_id__=operator;user</code> into the log record.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: v1
kind: ConfigMap
metadata:
  name: gardener-extension-provider-aws-logging-config
  namespace: garden
  labels:
    extensions.gardener.cloud/configuration: logging
data:
  filter-kubernetes.conf: |<span style=color:#a31515>
</span><span style=color:#a31515>    [FILTER]
</span><span style=color:#a31515>        Name          modify
</span><span style=color:#a31515>        Match         kubernetes.*
</span><span style=color:#a31515>        Condition     Key_value_matches tag ^kubernetes\.var\.log\.containers\.(cloud-controller-manager-.+?_.+?_aws-cloud-controller-manager|csi-driver-controller-.+?_.+?_aws-csi)_.+?
</span><span style=color:#a31515>        Add           __gardener_multitenant_id__ operator;user</span>    
</code></pre></div><p>In this case we have predefined filter which copies the log&rsquo;s tag into the log record under the <code>tag</code> field. The tag consists of the container logs directories path, plus <code>&lt;pod_name>_&lt;shoot_controlplane_namespace>_&lt;container_name>_&lt;container_id></code>, so here we say:</p><blockquote><p>When you see a record from pod <code>cloud-controller-manager</code> and some of the <code>aws-cloud-controller-manager</code>, <code>csi-driver-controller</code> or <code>aws-csi</code> containers add <code>__gardener_multitenant_id__</code> key with <code>operator;user</code> value into the log record.</p></blockquote><p>Further details how to define parsers and use them with examples can be found in the following <a href=/docs/gardener/development/log_parsers/>guide</a>.</p><h4 id=grafana>Grafana</h4><p>The three types of Grafana instances found in a seed cluster are configured to expose logs of different origin in their dashboards:</p><ul><li>Garden Grafana dashboards expose logs from non-shoot namespaces of the seed clusters<ul><li><a href=https://github.com/gardener/gardener/blob/master/charts/seed-bootstrap/dashboards/pod-logs.json>Pod Logs</a></li><li><a href=https://github.com/gardener/gardener/blob/master/charts/seed-bootstrap/dashboards/extensions-dashboard.json>Extensions</a></li><li><a href=https://github.com/gardener/gardener/blob/master/charts/seed-bootstrap/dashboards/systemd-logs.json>Systemd Logs</a></li></ul></li><li>Shoot User Grafana dashboards expose a subset of the logs shown to operators<ul><li>Kube Apiserver</li><li>Kube Controller Manager</li><li>Kube Scheduler</li><li>Cluster Autoscaler</li><li>VPA components</li></ul></li><li>Shoot Operator Grafana dashboards expose logs from the shoot cluster namespace where they belong<ul><li>All user&rsquo;s dashboards</li><li><a href=https://github.com/gardener/gardener/blob/master/charts/seed-monitoring/charts/grafana/dashboards/operators/kubernetes-pods-dashboard.json>Kubernetes Pods</a></li></ul></li></ul><p>If the type of logs exposed in the Grafana instances needs to be changed, it is necessary to update the coresponding instance dashboard configurations.</p><h2 id=tips>Tips</h2><ul><li>Be careful to match exactly the log names that you need for a particular parser in your filters configuration. The regular expression you will supply will match names in the form <code>kubernetes.pod_name.&lt;metadata>.container_name</code>. If there are extensions with the same container and pod names, they will all match the same parser in a filter. That may be a desired effect, if they all share the same log format. But it will be a problem if they don&rsquo;t. To solve it, either the pod or container names must be unique, and the regular expression in the filter has to match that unique pattern. A recommended approach is to prefix containers with the extension name and tune the regular expression to match it. For example, using <code>myextension-container</code> as container name, and a regular expression <code>kubernetes.mypod.*myextension-container</code> will guarantee match of the right log name. Make sure that the regular expression does not match more than you expect. For example, <code>kubernetes.systemd.*systemd.*</code> will match both <code>systemd-service</code> and <code>systemd-monitor-service</code>. You will want to be as specific as possible.</li><li>It&rsquo;s a good idea to put the logging configuration into the Helm chart that also deploys the extension <em>controller</em>, while the monitoring configuration can be part of the Helm chart/deployment routine that deploys the <em>component</em> managed by the controller.</li></ul><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/gardener/issues/1351>GitHub issue describing the concept</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-gcp/blob/master/charts/internal/seed-controlplane/charts/cloud-controller-manager/templates/configmap-observability.yaml>Exemplary implementation (monitoring) for the GCP provider</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-openstack/blob/master/charts/gardener-extension-provider-openstack/templates/configmap-logging.yaml>Exemplary implementation (logging) for the OpenStack provider</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-107acf6f6b69c9ac1c403a4f60e455d7>18 - Managedresources</h1><h1 id=deploy-resources-to-the-shoot-cluster>Deploy resources to the Shoot cluster</h1><p>We have introduced a component called <a href=/docs/gardener/concepts/resource-manager/><code>gardener-resource-manager</code></a> that is deployed as part of every shoot control plane in the seed.
One of its tasks is to manage CRDs, so called <code>ManagedResource</code>s.
Managed resources contain Kubernetes resources that shall be created, reconciled, updated, and deleted by the gardener-resource-manager.</p><p>Extension controllers may create these <code>ManagedResource</code>s in the shoot namespace if they need to create any resource in the shoot cluster itself, for example RBAC roles (or anything else).</p><h2 id=where-can-i-find-more-examples-and-more-information-how-to-use-managedresources>Where can I find more examples and more information how to use <code>ManagedResource</code>s?</h2><p>Please take a look at the <a href=/docs/gardener/concepts/resource-manager/>respective documentation</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-fb6f6dc9c480f0bfbe05fce71647dcf7>19 - Migration</h1><h1 id=control-plane-migration>Control Plane Migration</h1><p><em>Control Plane Migration</em> is a new Gardener feature that has been recently implemented as proposed in <a href=/docs/gardener/proposals/07-shoot-control-plane-migration/>GEP-7 Shoot Control Plane Migration</a>. It should be properly supported by all extensions controllers. This document outlines some important points that extension maintainers should keep in mind to properly support migration in their extensions.</p><h2 id=overall-principles>Overall Principles</h2><p>The following principles should always be upheld:</p><ul><li>All state maintained by the extension that is external from the seed cluster, for example infrastructure resources in a cloud provider, DNS entries, etc., should be kept during the migration. No such state should be deleted and then recreated, as this might cause disruption in the availability of the shoot cluster.</li><li>All Kubernetes resources maintained by the extension in the shoot cluster itself should also be kept during the migration. No such resources should be deleted and then recreated.</li></ul><h2 id=migrate-and-restore-operations>Migrate and Restore Operations</h2><p>Two new operations have been introduced in Gardener. They can be specified as values of the <code>gardener.cloud/operation</code> annotation on an extension resource to indicate that an operation different from a normal <code>reconcile</code> should be performed by the corresponding extension controller:</p><ul><li>The <code>migrate</code> operation is used to ask the extension controller in the source seed to stop reconciling extension resources (in case they are requeued due to errors) and perform cleanup activities, if such are required. These cleanup activities might involve removing finalizers on resources in the shoot namespace that have been previously created by the extension controller and deleting them without actually deleting any resources external to the seed cluster.</li><li>The <code>restore</code> operation is used to ask extension controller in the destination seed to restore any state saved in the extension resource <code>status</code>, before performing the actual reconciliation.</li></ul><p>Unlike the <a href=/docs/gardener/extensions/reconcile-trigger/>reconcile operation</a>, extension controllers must remove the <code>gardener.cloud/operation</code> annotation at the end of a successful reconciliation when the current operation is <code>migrate</code> or <code>restore</code>, not at the beginning of a reconciliation.</p><h2 id=cleaning-up-source-seed-resources>Cleaning-up Source Seed Resources</h2><p>All resources in the source seed that have been created by an extension controller, for example secrets, config maps, <a href=/docs/gardener/extensions/managedresources/>managed resources</a>, etc. should be properly cleaned up by the extension controller when the current operation is <code>migrate</code>. As mentioned above, such resources should be deleted without actually deleting any resources external to the seed cluster.</p><p>For many custom resources, for example MCM resources, the above requirement means in practice that any finalizers should be removed before deleting the resource, in addition to ensuring that the resource deletion is not reconciled by its respective controller if there is no finalizer. For managed resources, the above requirement means in practice that the <code>spec.keepObjects</code> field should be set to <code>true</code> before deleting the extension resource.</p><p>Here it is assumed that any resources that contain state needed by the extension controller can be safely deleted, since any such state has been saved as described in <a href=#saving-and-restoring-extension-states>Saving and Restoring Extension States</a> at the end of the last successful reconciliation.</p><h2 id=saving-and-restoring-extension-states>Saving and Restoring Extension States</h2><p>Some extension controllers create and maintain their own state when reconciling extension resources. For example, most infrastructure controllers use Terraform and maintain the terraform state in a special config map in the shoot namespace. This state must be properly migrated to the new seed cluster during control plane migration, so that subsequent reconciliations in the new seed could find and use it appropriately.</p><p>All extension controllers that require such state migration must save their state in the <code>status.state</code> field of their extension resource at the end of a successful reconciliation. They must also restore their state from that same field upon reconciling an extension resource when the current operation is <code>restore</code>, as specified by the <code>gardener.cloud/operation</code> annotation, before performing the actual reconciliation.</p><p>As an example, an infrastructure controller that uses Terraform must save the terraform state in the <code>status.state</code> field of the <code>Infrastructure</code> resource. An <code>Infrastructure</code> resource with a properly saved state might look as follows:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: extensions.gardener.cloud/v1alpha1
kind: Infrastructure
metadata:
  name: infrastructure
  namespace: shoot--foo--bar
spec:
  type: azure
  region: eu-west-1
  secretRef:
    name: cloudprovider
    namespace: shoot--foo--bar
  providerConfig:
    apiVersion: azure.provider.extensions.gardener.cloud/v1alpha1
    kind: InfrastructureConfig
    resourceGroup:
      name: mygroup
    ...
status:
  state: |<span style=color:#a31515>
</span><span style=color:#a31515>    {
</span><span style=color:#a31515>      &#34;version&#34;: 3,
</span><span style=color:#a31515>      &#34;terraform_version&#34;: &#34;0.11.14&#34;,
</span><span style=color:#a31515>      &#34;serial&#34;: 2,
</span><span style=color:#a31515>      &#34;lineage&#34;: &#34;3a1e2faa-e7b6-f5f0-5043-368dd8ea6c10&#34;,
</span><span style=color:#a31515>      ...
</span><span style=color:#a31515>    }</span>    
</code></pre></div><p>Extension controllers that do not use a saved state and therefore do not require state migration could leave the <code>status.state</code> field as <code>nil</code> at the end of a successful reconciliation, and just perform a normal reconciliation when the current operation is <code>restore</code>.</p><p>In addition, extension controllers that use <a href=/docs/gardener/extensions/referenced-resources/>referenced resources</a> (usually secrets) must also make sure that these resources are added to the <code>status.resources</code> field of their extension resource at the end of a successful reconciliation, so they could be properly migrated by Gardener to the destination seed.</p><h2 id=implementation-details>Implementation Details</h2><h3 id=migrate-and-restore-actuator-methods>Migrate and Restore Actuator Methods</h3><p>Most extension controller implementations follow a common pattern where a generic <code>Reconciler</code> implementation delegates to an <code>Actuator</code> interface that contains the methods <code>Reconcile</code> and <code>Delete</code>, provided by the extension. The two new methods <code>Migrate</code> and <code>Restore</code> have been added to all such <code>Actuator</code> interfaces, see <a href=https://github.com/gardener/gardener/blob/master/extensions/pkg/controller/infrastructure/actuator.go>the infrastructure <code>Actuator</code> interface</a> as an example. These methods are called by the generic reconcilers for the <a href=#migrate-and-restore-operations>migrate and restore operations</a> respectively, and should be implemented by the extension according to the above guidelines.</p><h3 id=extension-controllers-based-on-generic-actuators>Extension Controllers Based on Generic Actuators</h3><p>In practice, the implementation of many extension controllers (for example, the controlplane and worker controllers in most provider extensions) are based on a <em>generic <code>Actuator</code> implementation</em> that only delegates to extension methods for behavior that is truly provider specific. In all such cases, the <code>Migrate</code> and <code>Restore</code> methods have already been implemented properly in the generic actuators and there is nothing more to do in the extension itself.</p><p>In some rare cases, extension controllers based on a generic actuator might still introduce a custom <code>Actuator</code> implementation to override some of the generic actuator methods in order to enhance or change their behavior in a certain way. In such cases, the <code>Migrate</code> and <code>Restore</code> methods might need to be overridden as well, see the <a href=https://github.com/gardener/gardener-extension-provider-azure/tree/master/pkg/controller/controlplane>Azure controlplane controller</a> as an example.</p><h3 id=extension-controllers-not-based-on-generic-actuators>Extension Controllers Not Based on Generic Actuators</h3><p>The implementation of some extension controllers (for example, the infrastructure controllers in all provider extensions) are not based on a generic <code>Actuator</code> implementation. Such extension controllers must always provide a proper implementation of the <code>Migrate</code> and <code>Restore</code> methods according to the above guidelines, see the <a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/infrastructure>AWS infrastructure controller</a> as an example. In practice this might result in code duplication between the different extensions, since the <code>Migrate</code> and <code>Restore</code> code is usually not provider or OS-specific.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-6abc753b67fb6ebd6b625067c168bcb1>20 - Network</h1><h1 id=gardener-network-extension>Gardener Network Extension</h1><p>Gardener is an open-source project that provides a nested user model. Basically, there are two types of services provided by Gardener to its users:</p><ul><li>Managed: end-users only request a Kubernetes cluster (Clusters-as-a-Service)</li><li>Hosted: operators utilize Gardener to provide their own managed version of Kubernetes (Cluster-Provisioner-as-a-service)</li></ul><p>Whether an operator or an end-user, it makes sense to provide choice. For example, for an end-user it might make sense to
choose a network-plugin that would support enforcing network policies (some plugins does not come with network-policy support by default).
For operators however, choice only matters for delegation purposes i.e., when providing an own managed-service, it becomes important to also provide choice over which network-plugins to use.</p><p>Furthermore, Gardener provisions clusters on different cloud-providers with different networking requirements. For example, Azure does not support Calico Networking [1], this leads to the introduction of manual exceptions in static add-on charts which is error prone and can lead to failures during upgrades.</p><p>Finally, every provider is different, and thus the network always needs to adapt to the infrastructure needs to provide better performance. Consistency does not necessarily lie in the implementation but in the interface.</p><h2 id=motivation>Motivation</h2><p>Prior to the <code>Network Extensibility</code> concept, Gardener followed a mono network-plugin support model (i.e., Calico). Although this seemed to be the easier approach, it did not completely reflect the real use-case.
The goal of the Gardener Network Extensions is to support different network plugins, therefore, the specification for the network resource won&rsquo;t be fixed and will be customized based on the underlying network plugin.</p><p>To do so, a <code>ProviderConfig</code> field in the spec will be provided where each plugin will define. Below is an example for how to deploy Calico as the cluster network plugin.</p><h2 id=the-network-extensions-resource>The Network Extensions Resource</h2><p>Here is what a typical <code>Network</code> resource would look-like:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Network
metadata:
  name: my-network
spec:
  podCIDR: 100.244.0.0/16
  serviceCIDR: 100.32.0.0/13
  type: calico
  providerConfig:
    apiVersion: calico.networking.extensions.gardener.cloud/v1alpha1
    kind: NetworkConfig
    backend: bird
    ipam:
      cidr: usePodCIDR
      type: host-local
</code></pre></div><p>The above resources is divided into two parts (more information can be found <a href=/docs/extensions/network-extensions/gardener-extension-networking-calico/docs/usage-as-end-user/>here</a>):</p><ul><li>global configuration (e.g., podCIDR, serviceCIDR, and type)</li><li>provider specific config (e.g., for calico we can choose to configure a <code>bird</code> backend)</li></ul><blockquote><p><strong>Note</strong>: certain cloud-provider extensions might have webhooks that would modify the network-resource to fit into their network specific context. As previously mentioned, Azure does not support IPIP, as a result, the <a href=https://github.com/gardener/gardener-extension-provider-azure>Azure provider extension</a> implements a <a href=https://github.com/gardener/gardener-extension-provider-azure/blob/master/pkg/webhook/network/mutate.go>webhook</a> to mutate the backend and set it to <code>None</code> instead of <code>bird</code>.</p></blockquote><h2 id=supporting-a-new-network-extension-provider>Supporting a new Network Extension Provider</h2><p>To add support for another networking provider (e.g., weave, Cilium, Flannel, etc.) a network extension controller needs to be implemented which would optionally have its own custom configuration specified in the <code>spec.providerConfig</code> in the <code>Network</code> resource. For example, if support for a network plugin named <code>gardenet</code> is required, the following <code>Network</code> resource would be created:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Network
metadata:
  name: my-network
spec:
  podCIDR: 100.244.0.0/16
  serviceCIDR: 100.32.0.0/13
  type: gardenet
  providerConfig:
    apiVersion: gardenet.networking.extensions.gardener.cloud/v1alpha1
    kind: NetworkConfig
    gardenetCustomConfigField: &lt;value&gt;
    ipam:
      cidr: usePodCIDR
      type: host-local
</code></pre></div><p>Once applied, the presumably implemented <code>Gardenet</code> extension controller, would pick the configuration up, parse the <code>providerConfig</code> and create the necessary resources in the shoot.</p><p>For additional reference, please have a look at the <a href=https://github.com/gardener/gardener-extension-networking-calico>networking-calico</a> provider extension, which provides more information on how to configure the necessary charts as well as the actuators required to reconcile networking inside the <code>Shoot</code> cluster to the desired state.</p><h2 id=supporting-kube-proxy-less-service-routing>Supporting <code>kube-proxy</code> less Service Routing</h2><p>Some networking extensions support service routing without the <code>kube-proxy</code> component. This is why Gardener supports disabling of <code>kube-proxy</code> for service routing by setting <code>.spec.kubernetes.kubeproxy.enabled</code> to <code>false</code> in the <code>Shoot</code> specification. The implicit contract of the flag is: If <code>kube-proxy</code> is disabled then the networking extension is responsible for the service routing.
The networking extensions need to handle this twofold:</p><ol><li>During the reconciliation of the networking resources, the extension needs to check whether <code>kube-proxy</code> takes care of the service routing or the networking extension itself should handle it. In case the networking extension should be responsible according to <code>.spec.kubernetes.kubeproxy.enabled</code> (but is unable to perform the service routing) it should raise an error during the reconciliation. If the networking extension should handle the service routing it may reconfigure itself accordingly.</li><li>(optional) In case the networking extension does not support taking over the service routing (in some scenarios), it is recommended to also provide a validating admission webhook to reject corresponding changes early on. The validation may take the current operating mode of the networking extension into consideration.</li></ol><h2 id=references>References</h2><p>[1] <a href=https://docs.projectcalico.org/v3.0/reference/public-cloud/azure>Azure support for Calico Networking</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-d758265b318aa3c4194c99f8fe8e2760>21 - Operatingsystemconfig</h1><h1 id=contract-operatingsystemconfig-resource>Contract: <code>OperatingSystemConfig</code> resource</h1><p>Gardener uses the machine API and leverages the functionalities of the <a href=https://github.com/gardener/machine-controller-manager>machine-controller-manager</a> (MCM) in order to manage the worker nodes of a shoot cluster.
The machine-controller-manager itself simply takes a reference to an OS-image and (optionally) some user-data (a script or configuration that is executed when a VM is bootstrapped), and forwards both to the provider&rsquo;s API when creating VMs.
MCM does not have any restrictions regarding supported operating systems as it does not modify or influence the machine&rsquo;s configuration in any way - it just creates/deletes machines with the provided metadata.</p><p>Consequently, Gardener needs to provide this information when interacting with the machine-controller-manager.
This means that basically every operating system is possible to be used as long as there is some implementation that generates the OS-specific configuration in order to provision/bootstrap the machines.</p><p>⚠️ Currently, there are a few requirements:</p><ol><li>The operating system must have built-in <a href=https://www.docker.com/>Docker</a> support.</li><li>The operating system must have <a href=https://www.freedesktop.org/wiki/Software/systemd/>systemd</a> support.</li><li>The operating system must have <a href=https://www.gnu.org/software/wget/><code>wget</code></a> pre-installed.</li><li>The operating system must have <a href=https://stedolan.github.io/jq/><code>jq</code></a> pre-installed.</li></ol><p>The reasons for that will become evident later.</p><h2 id=what-does-the-user-data-bootstrapping-the-machines-contain>What does the user-data bootstrapping the machines contain?</h2><p>Gardener installs a few components onto every worker machine in order to allow it to join the shoot cluster.
There is the <code>kubelet</code> process, some scripts for continuously checking the health of <code>kubelet</code> and <code>docker</code>, but also configuration for log rotation, CA certificates, etc.
The complete configuration you can find <a href=https://github.com/gardener/gardener/tree/master/pkg/operation/botanist/component/extensions/operatingsystemconfig/original/components>here</a>. We are calling this the &ldquo;original&rdquo; user-data.</p><h2 id=how-does-gardener-bootstrap-the-machines>How does Gardener bootstrap the machines?</h2><p>Usually, you would submit all the components you want to install onto the machine as part of the user-data during creation time.
However, some providers do have a size limitation (like ~16KB) for that user-data.
That&rsquo;s why we do not send the &ldquo;original&rdquo; user-data to the machine-controller-manager (who forwards it then to the provider&rsquo;s API).
Instead, we only send a small script that downloads the &ldquo;original&rdquo; data and applies it on the machine directly.
This way we can extend the &ldquo;original&rdquo; user-data without any size restrictions - plus we can modify it without the necessity of re-creating the machine (because we run a script that downloads and updates it continuously).</p><p>The high-level flow is as follows:</p><ol><li><p>For every worker pool <code>X</code> in the <code>Shoot</code> specification, Gardener creates a <code>Secret</code> named <code>cloud-config-&lt;X></code> in the <code>kube-system</code> namespace of the shoot cluster. The secret contains the &ldquo;original&rdquo; user-data.</p></li><li><p>Gardener generates a kubeconfig with minimal permissions just allowing reading these secrets. It is used by the <code>downloader</code> script later.</p></li><li><p>Gardener provides the <code>downloader</code> script, the kubeconfig, and the machine image stated in the <code>Shoot</code> specification to the machine-controller-manager.</p></li><li><p>Based on this information the machine-controller-manager creates the VM.</p></li><li><p>After the VM has been provisioned the <code>downloader</code> script starts and fetches the appropriate <code>Secret</code> for its worker pool (containing the &ldquo;original&rdquo; user-data) and applies it.</p></li></ol><h3 id=detailed-bootstrap-flow-with-a-worker-generated-bootstrap-token>Detailed bootstrap flow with a worker generated bootstrap-token</h3><p>With gardener v1.23 a file with the content <code>&lt;&lt;BOOTSTRAP_TOKEN>></code> is added to the <code>cloud-config-&lt;worker-group>-downloader</code> <code>OperatingSystemConfig</code> (part of step 2 in the graphic below).
Via the OS extension the new file (with its content in clear-text) gets passed to the corresponding <code>Worker</code> resource.</p><p>The <code>Worker</code> controller has to guarantee that:</p><ul><li>a bootstrap token is created.</li><li>the <code>&lt;&lt;BOOTSTRAP_TOKEN>></code> in the user data is replaced by the generated token.
One implementation of that is depicted in the picture where the machine-controller-manager creates a temporary token and replaces the placeholder.</li></ul><p>As part of the user-data the bootstrap-token is placed on the newly created VM under a defined path.
The cloud-config-script will then refer to the file path of the added bootstrap token in the kubelet-bootstrap script.</p><p><img src=/__resources/bootstrap_token_c9a050.png alt="Bootstrap flow with shortlived bootstrapTokens"></p><h3 id=compatibility-matrix-for-node-bootstrap-token>Compatibility matrix for node bootstrap-token</h3><p>With Gardener v1.23, we replaced the long-valid bootstrap-token shared between nodes with a short-lived token unique for each node, ref: <a href=https://github.com/gardener/gardener/issues/3898>#3898</a>.</p><p>❗ When updating to Gardener version >=1.35 the old bootstrap-token will be removed. You are required to update your extensions to the following versions when updating Gardener:</p><table><thead><tr><th>Extension</th><th>Version</th><th>Release Date</th><th>Pull Request</th></tr></thead><tbody><tr><td>os-gardenlinux</td><td>v0.9.0</td><td>2 Jul</td><td><a href=https://github.com/gardener/gardener-extension-os-gardenlinux/pull/29>https://github.com/gardener/gardener-extension-os-gardenlinux/pull/29</a></td></tr><tr><td>os-suse-chost</td><td>v1.11.0</td><td>2 Jul</td><td><a href=https://github.com/gardener/gardener-extension-os-suse-chost/pull/41>https://github.com/gardener/gardener-extension-os-suse-chost/pull/41</a></td></tr><tr><td>os-ubuntu</td><td>v1.11.0</td><td>2 Jul</td><td><a href=https://github.com/gardener/gardener-extension-os-ubuntu/pull/42>https://github.com/gardener/gardener-extension-os-ubuntu/pull/42</a></td></tr><tr><td>os-flatcar</td><td>v1.7.0</td><td>2 Jul</td><td><a href=https://github.com/gardener/gardener-extension-os-coreos/pull/24>https://github.com/gardener/gardener-extension-os-coreos/pull/24</a></td></tr><tr><td>infrastructure-provider using Machine Controller Manager</td><td>varies</td><td>~ end of 2019</td><td><a href=https://github.com/gardener/machine-controller-manager/pull/351>https://github.com/gardener/machine-controller-manager/pull/351</a></td></tr></tbody></table><p>⚠️ If you run a provider extension that does not use Machine Controller Manager (MCM) you need to implement the functionality of creating a temporary bootstrap-token before updating your Gardener version to v1.35 or higher.
All provider extensions maintained in <a href=https://github.com/gardener/>https://github.com/gardener/</a> use MCM.</p><h2 id=how-does-gardener-update-the-user-data-on-already-existing-machines>How does Gardener update the user-data on already existing machines?</h2><p>With ongoing development and new releases of Gardener some new components could be required to get installed onto every shoot worker VM, or existing components need to be changed.
Gardener achieves that by simply updating the user-data inside the <code>Secret</code>s mentioned above (step 1).
The <code>downloader</code> script is continuously (every 30s) reading the secret&rsquo;s content (which might include an updated user-data) and storing it onto the disk.
In order to re-apply the (new) downloaded data the secrets do not only contain the &ldquo;original&rdquo; user-data but also another short script (called &ldquo;execution&rdquo; script).
This script checks whether the downloaded user-data differs from the one previously applied - and if required - re-applies it.
After that it uses <code>systemctl</code> to restart the installed <code>systemd</code> units.</p><p>With the help of the execution script Gardener can centrally control how machines are updated without the need of OS providers to (re-)implement that logic.
However, as stated in the mentioned requirements above, the execution script assumes existence of Docker and <code>systemd</code>.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-operating-system>What needs to be implemented to support a new operating system?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: OperatingSystemConfig
metadata:
  name: pool-01-original
  namespace: default
spec:
  type: &lt;my-operating-system&gt;
  purpose: reconcile
  reloadConfigFilePath: /var/lib/cloud-config-downloader/cloud-config
  units:
  - name: docker.service
    dropIns:
    - name: 10-docker-opts.conf
      content: |<span style=color:#a31515>
</span><span style=color:#a31515>        [Service]
</span><span style=color:#a31515>        Environment=&#34;DOCKER_OPTS=--log-opt max-size=60m --log-opt max-file=3&#34;</span>        
  - name: docker-monitor.service
    command: start
    enable: <span style=color:#00f>true</span>
    content: |<span style=color:#a31515>
</span><span style=color:#a31515>      [Unit]
</span><span style=color:#a31515>      Description=Docker-monitor daemon
</span><span style=color:#a31515>      After=kubelet.service
</span><span style=color:#a31515>      [Install]
</span><span style=color:#a31515>      WantedBy=multi-user.target
</span><span style=color:#a31515>      [Service]
</span><span style=color:#a31515>      Restart=always
</span><span style=color:#a31515>      EnvironmentFile=/etc/environment
</span><span style=color:#a31515>      ExecStart=/opt/bin/health-monitor docker</span>      
  files:
  - path: /var/lib/kubelet/ca.crt
    permissions: 0644
    encoding: b64
    content:
      secretRef:
        name: default-token-5dtjz
        dataKey: token
  - path: /etc/sysctl.d/99-k8s-general.conf
    permissions: 0644
    content:
      inline:
        data: |<span style=color:#a31515>
</span><span style=color:#a31515>          # A higher vm.max_map_count is great for elasticsearch, mongo, or other mmap users
</span><span style=color:#a31515>          # See https://github.com/kubernetes/kops/issues/1340
</span><span style=color:#a31515>          vm.max_map_count = 135217728</span>          
</code></pre></div><p>In order to support a new operating system you need to write a controller that watches all <code>OperatingSystemConfig</code>s with <code>.spec.type=&lt;my-operating-system></code>.
For those it shall generate a configuration blob that fits to your operating system.
For example, a CoreOS controller might generate a <a href=https://coreos.com/os/docs/latest/cloud-config.html>CoreOS cloud-config</a> or <a href=https://coreos.com/ignition/docs/latest/what-is-ignition.html>Ignition</a>, SLES might generate <a href=https://cloudinit.readthedocs.io/en/latest/>cloud-init</a>, and others might simply generate a bash script translating the <code>.spec.units</code> into <code>systemd</code> units, and <code>.spec.files</code> into real files on the disk.</p><p><code>OperatingSystemConfig</code>s can have two purposes which can be used (or ignored) by the extension controllers: either <code>provision</code> or <code>reconcile</code>.</p><ul><li>The <code>provision</code> purpose is used by Gardener for the user-data that it later passes to the machine-controller-manager (and then to the provider&rsquo;s API) when creating new VMs. It contains the <code>downloader</code> unit.</li><li>The <code>reconcile</code> purpose contains the &ldquo;original&rdquo; user-data (that is then stored in <code>Secret</code>s in the shoot&rsquo;s <code>kube-system</code> namespace (see step 1). This is downloaded and applies late (see step 5).</li></ul><p>As described above, the &ldquo;original&rdquo; user-data must be re-applicable to allow in-place updates.
The way how this is done is specific to the generated operating system config (e.g., for CoreOS cloud-init the command is <code>/usr/bin/coreos-cloudinit --from-file=&lt;path></code>, whereas SLES would run <code>cloud-init --file &lt;path> single -n write_files --frequency=once</code>).
Consequently, besides the generated OS config, the extension controller must also provide a command for re-application an updated version of the user-data.
As visible in the mentioned examples the command requires a path to the user-data file.
Gardener will provide the path to the file in the <code>OperatingSystemConfig</code>s <code>.spec.reloadConfigFilePath</code> field (only if <code>.spec.purpose=reconcile</code>).
As soon as Gardener detects that the user data has changed it will reload the systemd daemon and restart all the units provided in the <code>.status.units[]</code> list (see below example). The same logic applies during the very first application of the whole configuration.</p><p>After generation extension controllers are asked to store their OS config inside a <code>Secret</code> (as it might contain confidential data) in the same namespace.
The secret&rsquo;s <code>.data</code> could look like this:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: v1
kind: Secret
metadata:
  name: osc-result-pool-01-original
  namespace: default
  ownerReferences:
  - apiVersion: extensions.gardener.cloud/v1alpha1
    blockOwnerDeletion: <span style=color:#00f>true</span>
    controller: <span style=color:#00f>true</span>
    kind: OperatingSystemConfig
    name: pool-01-original
    uid: 99c0c5ca-19b9-11e9-9ebd-d67077b40f82
data:
  cloud_config: base64(generated-user-data)
</code></pre></div><p>Finally, the secret&rsquo;s metadata, the OS-specific command to re-apply the configuration, and the list of <code>systemd</code> units that shall be considered to be restarted if an updated version of the user-data is re-applied must be provided in the <code>OperatingSystemConfig</code>&rsquo;s <code>.status</code> field:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>...
status:
  cloudConfig:
    secretRef:
      name: osc-result-pool-01-original
      namespace: default
  command: /usr/bin/coreos-cloudinit --from-file=/var/lib/cloud-config-downloader/cloud-config
  lastOperation:
    description: Successfully generated cloud config
    lastUpdateTime: <span style=color:#a31515>&#34;2019-01-23T07:45:23Z&#34;</span>
    progress: 100
    state: Succeeded
    type: Reconcile
  observedGeneration: 5
  units:
  - docker-monitor.service
</code></pre></div><p>(The <code>.status.command</code> field is optional and must only be provided if <code>.spec.reloadConfigFilePath</code> exists).</p><p>Once the <code>.status</code> indicates that the extension controller finished reconciling Gardener will continue with the next step of the shoot reconciliation flow.</p><h2 id=cri-support>CRI Support</h2><p>Gardener supports specifying Container Runtime Interface (CRI) configuration in the <code>OperatingSystemConfig</code> resource. If the <code>.spec.cri</code> section exists then the <code>name</code> property is mandatory. The only supported values for <code>cri.name</code> at the moment are: <code>containerd</code> and <code>docker</code>, which uses the in-tree dockershim.
For example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: OperatingSystemConfig
metadata:
  name: pool-01-original
  namespace: default
spec:
  type: &lt;my-operating-system&gt;
  purpose: reconcile
  reloadConfigFilePath: /var/lib/cloud-config-downloader/cloud-config
  cri:
    name: containerd
...
</code></pre></div><p>To support ContainerD, an OS extension must :</p><ol><li>The operating system must have built-in <a href=https://containerd.io/>ContainerD</a> and the <a href=https://github.com/projectatomic/containerd/blob/master/docs/cli.md/>Client CLI</a></li><li>ContainerD must listen on its default socket path: <code>unix:///run/containerd/containerd.sock</code></li><li>ContainerD must be configured to work with the default configuration file in: <code>/etc/containerd/config.toml</code> (Created by Gardener).</li></ol><p>If CRI configurations are not supported it is recommended create a validating webhook running in the garden cluster that prevents specifying the <code>.spec.providers.workers[].cri</code> section in the <code>Shoot</code> objects.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_operatingsystemconfig.go><code>OperatingSystemConfig</code> API (Golang specification)</a></li><li><a href=https://github.com/gardener/gardener/blob/master/pkg/operation/botanist/component/extensions/operatingsystemconfig/downloader/templates/scripts/download-cloud-config.tpl.sh><code>downloader</code> script</a> (fetching the &ldquo;original&rdquo; user-data and the execution script)</li><li><a href=https://github.com/gardener/gardener/tree/master/pkg/operation/botanist/component/extensions/operatingsystemconfig/original/components>Original user-data templates</a></li><li><a href=https://github.com/gardener/gardener/blob/master/pkg/operation/botanist/component/extensions/operatingsystemconfig/executor/templates/scripts/execute-cloud-config.tpl.sh>Execution script</a> (applying the &ldquo;original&rdquo; user-data)</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-5809410418b357cb13756988bdf0a8b8>22 - Overview</h1><h1 id=extensibility-overview>Extensibility overview</h1><p>Initially, everything was developed in-tree in the Gardener project. All cloud providers and the configuration for all the supported operating systems were released together with the Gardener core itself.
But as the project grew, it got more and more difficult to add new providers and maintain the existing code base.
As a consequence and in order to become agile and flexible again, we proposed <a href=/docs/gardener/proposals/01-extensibility/>GEP-1</a> (Gardener Enhancement Proposal).
The document describes an out-of-tree extension architecture that keeps the Gardener core logic independent of provider-specific knowledge (similar to what Kubernetes has achieved with <a href=https://github.com/kubernetes/enhancements/issues/88>out-of-tree cloud providers</a> or with <a href=https://github.com/kubernetes/community/pull/1258>CSI volume plugins</a>).</p><h2 id=basic-concepts>Basic concepts</h2><p>Gardener keeps running in the &ldquo;garden cluster&rdquo; and implements the core logic of shoot cluster reconciliation/deletion.
Extensions are Kubernetes controllers themselves (like Gardener) and run in the seed clusters.
As usual, we try to use Kubernetes wherever applicable.
We rely on Kubernetes extension concepts in order to enable extensibility for Gardener.
The main ideas of GEP-1 are the following:</p><ol><li><p>During the shoot reconciliation process Gardener will write CRDs into the seed cluster that are watched and managed by the extension controllers. They will reconcile (based on the <code>.spec</code>) and report whether everything went well or errors occurred in the CRD&rsquo;s <code>.status</code> field.</p></li><li><p>Gardener keeps deploying the provider-independent control plane components (etcd, kube-apiserver, etc.). However, some of these components might still need little customization by providers, e.g., additional configuration, flags, etc. In this case, the extension controllers register webhooks in order to manipulate the manifests.</p></li></ol><p><strong>Example 1</strong>:</p><p>Gardener creates a new AWS shoot cluster and requires the preparation of infrastructure in order to proceed (networks, security groups, etc.).
It writes the following CRD into the seed cluster:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: extensions.gardener.cloud/v1alpha1
kind: Infrastructure
metadata:
  name: infrastructure
  namespace: shoot--core--aws-01
spec:
  type: aws
  providerConfig:
    apiVersion: aws.provider.extensions.gardener.cloud/v1alpha1
    kind: InfrastructureConfig
    networks:
      vpc:
        cidr: 10.250.0.0/16
      internal:
      - 10.250.112.0/22
      public:
      - 10.250.96.0/22
      workers:
      - 10.250.0.0/19
    zones:
    - eu-west-1a
  dns:
    apiserver: api.aws-01.core.example.com
  region: eu-west-1
  secretRef:
    name: my-aws-credentials
  sshPublicKey: |<span style=color:#a31515>
</span><span style=color:#a31515>    </span>    base64(key)
</code></pre></div><p>Please note that the <code>.spec.providerConfig</code> is a raw blob and not evaluated or known in any way by Gardener.
Instead, it was specified by the user (in the <code>Shoot</code> resource) and just &ldquo;forwarded&rdquo; to the extension controller.
Only the AWS controller understands this configuration and will now start provisioning/reconciling the infrastructure.
It reports in the <code>.status</code> field the result:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>status:
  observedGeneration: ...
  state: ...
  lastError: ..
  lastOperation: ...
  providerStatus:
    apiVersion: aws.provider.extensions.gardener.cloud/v1alpha1
    kind: InfrastructureStatus
    vpc:
      id: vpc-1234
      subnets:
      - id: subnet-acbd1234
        name: workers
        zone: eu-west-1
      securityGroups:
      - id: sg-xyz12345
        name: workers
    iam:
      nodesRoleARN: &lt;some-arn&gt;
      instanceProfileName: foo
    ec2:
      keyName: bar
</code></pre></div><p>Gardener waits until the <code>.status.lastOperation</code>/<code>.status.lastError</code> indicates that the operation reached a final state and either continuous with the next step or stops and reports the potential error.
The extension-specific output in <code>.status.providerStatus</code> is - similar to <code>.spec.providerConfig</code> - not evaluated and simply forwarded to CRDs in subsequent steps.</p><p><strong>Example 2</strong>:</p><p>Gardener deploys the control plane components into the seed cluster, e.g. the <code>kube-controller-manager</code> deployment with the following flags:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: apps/v1
kind: Deployment
...
spec:
  template:
    spec:
      containers:
      - command:
        - /usr/local/bin/kube-controller-manager
        - --allocate-node-cidrs=true
        - --attach-detach-reconcile-sync-period=1m0s
        - --controllers=*,bootstrapsigner,tokencleaner
        - --cluster-cidr=100.96.0.0/11
        - --cluster-name=shoot--core--aws-01
        - --cluster-signing-cert-file=/srv/kubernetes/ca/ca.crt
        - --cluster-signing-key-file=/srv/kubernetes/ca/ca.key
        - --concurrent-deployment-syncs=10
        - --concurrent-replicaset-syncs=10
...
</code></pre></div><p>The AWS controller requires some additional flags in order to make the cluster functional.
It needs to provide a Kubernetes cloud-config and also some cloud-specific flags.
Consequently, it registers a <code>MutatingWebhookConfiguration</code> on <code>Deployment</code>s and adds these flags to the container:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>        - --cloud-provider=external
        - --external-cloud-volume-plugin=aws
        - --cloud-config=/etc/kubernetes/cloudprovider/cloudprovider.conf
</code></pre></div><p>Of course, it would have needed to create a <code>ConfigMap</code> containing the cloud config and to add the proper <code>volume</code> and <code>volumeMounts</code> to the manifest as well.</p><p>(Please note for this special example: The Kubernetes community is also working on making the <code>kube-controller-manager</code> provider-independent.
However, there will most probably be still components other than the <code>kube-controller-manager</code> which need to be adapted by extensions.)</p><p>If you are interested in writing an extension, or generally in digging deeper to find out the nitty-gritty details of the extension concepts please read <a href=/docs/gardener/proposals/01-extensibility/>GEP-1</a>.
We are truly looking forward to your feedback!</p><h2 id=current-status>Current status</h2><p>Meanwhile, the out-of-tree extension architecture of Gardener is in place and has been productively validated. We are tracking all internal and external extensions of Gardener in the repo: <a href=https://github.com/gardener/gardener/tree/master/extensions#known-extension-implementations>Gardener Extensions Library</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d20ec57f1c788e4c86ed68fe624544eb>23 - Project Roles</h1><h1 id=extending-project-roles>Extending project roles</h1><p>The <code>Project</code> resource allows to specify a list of roles for every member (<code>.spec.members[*].roles</code>).
There are a few standard roles defined by Gardener itself.
Please consult <a href=/docs/gardener/usage/projects/>this document</a> for further information.</p><p>However, extension controllers running in the garden cluster may also create <code>CustomResourceDefinition</code>s that project members might be able to CRUD.
For this purpose Gardener also allows to specify extension roles.</p><p>An extension role is prefixed with <code>extension:</code>, e.g.</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: core.gardener.cloud/v1beta1
kind: Project
metadata:
  name: dev
spec:
  members:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: alice.doe@example.com
    role: admin
    roles:
    - owner
    - extension:foo
</code></pre></div><p>The project controller will, for every extension role, create a <code>ClusterRole</code> with name <code>name: gardener.cloud:extension:project:&lt;projectName>:&lt;roleName></code>, i.e., for above example: <code>name: gardener.cloud:extension:project:dev:foo</code>.
This <code>ClusterRole</code> aggregates other <code>ClusterRole</code>s that are labeled with <code>rbac.gardener.cloud/aggregate-to-extension-role=foo</code> which might be created by extension controllers.</p><p>Extension that might want to contribute to the core <code>admin</code> or <code>viewer</code> roles can use the labels <code>rbac.gardener.cloud/aggregate-to-project-member=true</code> or <code>rbac.gardener.cloud/aggregate-to-project-viewer=true</code>, respectively.</p><p>Please note that the names of the extension roles are restricted to 20 characters!</p><p>Moreover, the project controller will also create a corresponding <code>RoleBinding</code> with the same name in the project namespace.
It will automatically assign all members that are assigned to this extension role.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-45f5e5c8792c123831d7123647c5db0c>24 - Provider Local</h1><h1 id=local-provider-extension>Local Provider Extension</h1><p>The &ldquo;local provider&rdquo; extension is used to allow the usage of seed and shoot clusters which run entirely locally without any real infrastructure or cloud provider involved.
It implements Gardener&rsquo;s extension contract (<a href=/docs/gardener/proposals/01-extensibility/>GEP-1</a>) and thus comprises several controllers and webhooks acting on resources in seed and shoot clusters.</p><p>The code is maintained in <a href=https://github.com/gardener/gardener/tree/master/pkg/provider-local><code>pkg/provider-local</code></a>.</p><h2 id=motivation>Motivation</h2><p>The motivation for maintaining such extension is the following:</p><ul><li>🛡 Output Qualification: Run fast and cost-efficient end-to-end tests, locally and in CI systems (increased confidence ⛑ before merging pull requests)</li><li>⚙️ Development Experience: Develop Gardener entirely on a local machine without any external resources involved (improved costs 💰 and productivity 🚀)</li><li>🤝 Open Source: Quick and easy setup for a first evaluation of Gardener and a good basis for first contributions</li></ul><h2 id=current-limitations>Current Limitations</h2><p>The following enlists the current limitations of the implementation.
Please note that all of them are no technical limitations/blockers but simply advanced scenarios that we haven&rsquo;t had invested yet into.</p><ol><li><p>Shoot clusters can only have one node when <code>.spec.networking.type=local</code>.</p><p><em>We use <a href=https://github.com/kubernetes-sigs/kind/blob/main/images/kindnetd/README.md>kindnetd</a> as CNI plugin in shoot clusters and didn&rsquo;t invest into making it work with multiple worker nodes.</em></p></li><li><p><code>NetworkPolicy</code>s are not effective.</p><p><em><code>kindnetd</code> does not ship any controller for Kubernetes <code>NetworkPolicy</code>s, hence, they are not effective. Typically, the same applies for the local seed cluster unless a different CNI plugin is pro-actively installed.</em></p></li><li><p>Shoot clusters don&rsquo;t support persistent storage.</p><p><em>We don&rsquo;t install any CSI plugin into the shoot cluster yet, hence, there is no persistent storage for shoot clusters.</em></p></li><li><p>No support for ETCD backups.</p><p><em>We have not yet implemented the <a href=/docs/gardener/extensions/backupbucket/><code>BackupBucket</code></a>/<a href=/docs/gardener/extensions/backupentry/><code>BackupEntry</code></a> extension API, hence, there is no support for ETCD backups.</em></p></li><li><p>No owner TXT <code>DNSRecord</code>s (hence, no <a href=/docs/gardener/proposals/17-shoot-control-plane-migration-bad-case/>&ldquo;bad-case&rdquo; control plane migration</a>).</p><p><em>In order to realize DNS (see <a href=#implementation-details>Implementation Details</a> section below), the <code>/etc/hosts</code> file is manipulated. This does not work for TXT records. In the future, we could look into using <a href=https://coredns.io/>CoreDNS</a> instead.</em></p></li><li><p>No load balancers for Shoot clusters.</p><p><em>We have not yet developed a <code>cloud-controller-manager</code> which could reconcile load balancer <code>Service</code>s in the shoot cluster. Hence, when the gardenlet&rsquo;s <code>ReversedVPN</code> feature gate is disabled then the <code>kube-system/vpn-shoot</code> <code>Service</code> must be manually patched (with <code>{"status": {"loadBalancer": {"ingress": [{"hostname": "vpn-shoot"}]}}}</code>) to make the reconciliation work.</em></p></li><li><p>Only one shoot cluster possible when gardenlet&rsquo;s <code>APIServerSNI</code> feature gate is disabled.</p><p><em>When <a href=/docs/gardener/proposals/08-shoot-apiserver-via-sni/><code>APIServerSNI</code></a> is disabled then gardenlet uses load balancer <code>Service</code>s in order to expose the shoot clusters' <code>kube-apiserver</code>s. Typically, local Kubernetes clusters don&rsquo;t support this. In this case, the local extension uses the host IP to expose the <code>kube-apiserver</code>, however, this can only be done once.</em></p></li><li><p>Dependency-Watchdog cannot be enabled.</p><p><em>The <code>dependency-watchdog</code> needs to be able to resolve the shoot cluster&rsquo;s DNS names. It is not yet able to do so, hence, it cannot be enabled.</em></p></li><li><p><code>Ingress</code>es exposed in the seed cluster are not reachable.</p><p><em>There is no DNS resolution for the domains used for <code>Ingress</code>es in the seed cluster yet, hence, they are not reachable. Consequently, the <a href=/docs/gardener/deployment/configuring_logging/#enable-logs-from-the-shoots-node-systemd-services>shoot node logging</a> feature does not work end-to-end.</em></p></li></ol><h2 id=implementation-details>Implementation Details</h2><p>This section contains information about how the respective controllers and webhooks are implemented and what their purpose is.</p><h3 id=bootstrapping>Bootstrapping</h3><p>The Helm chart of the <code>provider-local</code> extension defined in its <a href=/docs/gardener/extensions/controllerregistration/><code>ControllerDeployment</code></a> contains a special deployment for a <a href=https://coredns.io/>CoreDNS</a> instance in a <code>gardener-extension-provider-local-coredns</code> namespace in the seed cluster.</p><p>This CoreDNS instance is responsible for enabling the components running in the shoot clusters to be able to resolve the DNS names when they communicate with their <code>kube-apiserver</code>s.</p><p>It contains static configuration to resolve the DNS names based on <code>local.gardener.cloud</code> to either the <code>istio-ingressgateway.istio-ingress.svc</code> or the <code>kube-apiserver.&lt;shoot-namespace>.svc</code> addresses (depending on whether the <code>--apiserver-sni-enabled</code> flag is set to <code>true</code> or <code>false</code>).</p><h3 id=controllers>Controllers</h3><p>There are controllers for all resources in the <code>extensions.gardener.cloud/v1alpha1</code> API group except for <code>BackupBucket</code> and <code>BackupEntry</code>s.</p><h4 id=controlplane><code>ControlPlane</code></h4><p>This controller is not deploying anything since we haven&rsquo;t invested yet into a <code>cloud-controller-manager</code> or CSI solution.
For the latter, we could probably use the <a href=https://github.com/rancher/local-path-provisioner>local-path-provisioner</a>.</p><h4 id=dnsrecord><code>DNSRecord</code></h4><p>This controller manipulates the <code>/etc/hosts</code> file and adds a new line for each <code>DNSRecord</code> it observes.
This enables accessing the shoot clusters from the respective machine, however, it also requires to run the extension with elevated privileges (<code>sudo</code>).</p><p>The <code>/etc/hosts</code> would be extended as follows:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text># Begin of gardener-extension-provider-local section
10.84.23.24 api.local.local.external.local.gardener.cloud
10.84.23.24 api.local.local.internal.local.gardener.cloud
...
# End of gardener-extension-provider-local section
</code></pre></div><h4 id=infrastructure><code>Infrastructure</code></h4><p>This controller generates a <code>NetworkPolicy</code> which allows the control plane pods (like <code>kube-apiserver</code>) to communicate with the worker machine pods (see <a href=#worker><code>Worker</code> section</a>)).</p><p>In addition, it creates a <code>Service</code> named <code>vpn-shoot</code> which is only used in case the gardenlet&rsquo;s <code>ReversedVPN</code> feature gate is disabled.
This <code>Service</code> enables the <code>vpn-seed</code> containers in the <code>kube-apiserver</code> pods in the seed cluster to communicate with the <code>vpn-shoot</code> pod running in the shoot cluster.</p><h4 id=network><code>Network</code></h4><p>This controller deploys a <code>ManagedResource</code> which contains the <a href=https://github.com/kubernetes-sigs/kind/blob/main/images/kindnetd/README.md>kindnetd</a> <code>DaemonSet</code> which is used as CNI in the shoot clusters.</p><h4 id=operatingsystemconfig><code>OperatingSystemConfig</code></h4><p>This controller leverages the standard <a href=https://github.com/gardener/gardener/tree/master/extensions/pkg/controller/operatingsystemconfig/oscommon><code>oscommon</code> library</a> in order to render a simple cloud-init template which can later be executed by the shoot worker nodes.</p><p>The shoot worker nodes are <code>Pod</code>s with a container based on the <code>kindest/node</code> image. This is maintained in <a href=https://github.com/gardener/machine-controller-manager-provider-local/tree/master/node>https://github.com/gardener/machine-controller-manager-provider-local/tree/master/node</a> and has a special <code>run-userdata</code> systemd service which executes the cloud-init generated earlier by the <code>OperatingSystemConfig</code> controller.</p><h4 id=worker><code>Worker</code></h4><p>This controller leverages the standard <a href=https://github.com/gardener/gardener/tree/master/extensions/pkg/controller/worker/genericactuator>generic <code>Worker</code> actuator</a> in order to deploy the <a href=https://github.com/gardener/machine-controller-manager><code>machine-controller-manager</code></a> as well as the <a href=https://github.com/gardener/machine-controller-manager-provider-local><code>machine-controller-manager-provider-local</code></a>.</p><p>Additionally, it generates the <a href=https://github.com/gardener/machine-controller-manager-provider-local/blob/master/kubernetes/machine-class.yaml><code>MachineClass</code>es</a> and the <code>MachineDeployment</code>s based on the specification of the <code>Worker</code> resources.</p><h4 id=dnsprovider><code>DNSProvider</code></h4><p>Due to legacy reasons, the gardenlet still creates <code>DNSProvider</code> resources part of the <a href=https://github.com/gardener/external-dns-management/><code>dns.gardener.cloud/v1alpha1</code> API group</a>.
Since those are only needed in conjunction with the <a href=https://github.com/gardener/gardener-extension-shoot-dns-service><code>shoot-dns-service</code> extension</a> and have no relevance for the local provider, it just sets their <code>status.state=Ready</code> to please the expectations.
In the future, this controller can be dropped when the gardenlet no longer creates such <code>DNSProvider</code>s.</p><h4 id=service><code>Service</code></h4><p>This controller reconciles the <code>istio-ingress/istio-ingressgateway</code> <code>Service</code> in the seed cluster if the <code>--apiserver-sni-enabled</code> flag is set to <code>true</code> (default).
Otherwise, it reconciles the <code>kube-apiserver</code> <code>Service</code> in the shoot namespaces in the seed cluster.</p><p>All such <code>Service</code>s are of type <code>LoadBalancer</code>.
Since the local Kubernetes clusters used as seed typically don&rsquo;t support such services, this controller sets the <code>.status.ingress.loadBalancer.ip[0]</code> to the IP of the host.</p><h4 id=node><code>Node</code></h4><p>This controller reconciles the <code>Node</code>s of <a href=https://kind.sigs.k8s.io/>kind</a> clusters.
Typically, the <code>.status.{capacity,allocatable}</code> values are determined by the resources configured for the Docker daemon (see for example <a href=https://docs.docker.com/desktop/mac/#resources>this</a> for Mac).
Since many of the <code>Pod</code>s deployed by Gardener have quite high <code>.spec.resources.{requests,limits}</code>, the kind <code>Node</code>s easily get filled up and only a few <code>Pod</code>s can be scheduled (even if they barely consume any of their reserved resources).
In order to improve the user experience, the controller submits an empty patch which triggers the &ldquo;Node webhook&rdquo; (see below section) in case the <code>.status.{capacity,allocatable}</code> values are not high enough.
The webhook will increase the capacity of the <code>Node</code>s to allow all <code>Pod</code>s to be scheduled.</p><h4 id=health-checks>Health Checks</h4><p>The health check controller leverages the <a href=/docs/gardener/extensions/healthcheck-library/>health check library</a> in order to</p><ul><li>check the health of the <code>ManagedResource/extension-controlplane-shoot-webhooks</code> and populate the <code>SystemComponentsHealthy</code> condition in the <code>ControlPlane</code> resource.</li><li>check the health of the <code>ManagedResource/extension-networking-local</code> and populate the <code>SystemComponentsHealthy</code> condition in the <code>Network</code> resource.</li><li>check the health of the <code>ManagedResource/extension-worker-mcm-shoot</code> and populate the <code>SystemComponentsHealthy</code> condition in the <code>Worker</code> resource.</li><li>check the health of the <code>Deployment/machine-controller-manager</code> and populate the <code>ControlPlaneHealthy</code> condition in the <code>Worker</code> resource.</li><li>check the health of the <code>Node</code>s and populate the <code>EveryNodeReady</code> condition in the <code>Worker</code> resource.</li></ul><h3 id=webhooks>Webhooks</h3><h4 id=control-plane>Control Plane</h4><p>This webhook reacts on the <code>OperatingSystemConfig</code> containing the configuration of the kubelet and sets the <code>failSwapOn</code> to <code>false</code> (independent of what is configured in the <code>Shoot</code> spec) (<a href=https://github.com/kubernetes-sigs/kind/blob/b6bc112522651d98c81823df56b7afa511459a3b/site/content/docs/design/node-image.md#design>ref</a>).</p><h4 id=control-plane-exposure>Control Plane Exposure</h4><p>This webhook reacts on the <code>kube-apiserver</code> <code>Service</code> in shoot namespaces in the seed in case the gardenlet&rsquo;s <code>APIServerSNI</code> feature gate is disabled.
It sets the <code>nodePort</code> to <code>30443</code> to enable communication from the host (this requires a port mapping to work when creating the local cluster).</p><h4 id=machine-pod>Machine Pod</h4><p>This webhook reacts on <code>Pod</code>s created when the <code>machine-controller-manager</code> reconciles <code>Machine</code>s.
It sets the <code>.spec.dnsPolicy=None</code> and <code>.spec.dnsConfig.nameServers</code> to the cluster IP of the <code>coredns</code> <code>Service</code> created in the <code>gardener-extension-provider-local-coredns</code> namespaces (see the <a href=#bootstrapping>Bootstrapping section</a> for more details).</p><h4 id=node-1>Node</h4><p>This webhook reacts on <a href=https://kind.sigs.k8s.io/>kind</a> <code>Node</code>s and sets the <code>.status.{allocatable,capacity}.cpu="100"</code> and <code>.status.{allocatable,capacity}.memory="100Gi"</code> fields.
See also the above section about the &ldquo;Node controller&rdquo; for more information.</p><h4 id=shoot>Shoot</h4><p>This webhook reacts on the <code>ConfigMap</code> used by the <code>kube-proxy</code> and sets the <code>maxPerCore</code> field to <code>0</code> since other values don&rsquo;t work well in conjunction with the <code>kindest/node</code> image which is used as base for the shoot worker machine pods (<a href=https://github.com/kubernetes-sigs/kind/blob/fa7d86470f4c0e924fc4c2e767ec8491c45f4304/pkg/cluster/internal/kubeadm/config.go#L283-L285>ref</a>).</p><h2 id=future-work>Future Work</h2><p>Future work could mostly focus on resolving above listed <a href=#limitations>limitations</a>, i.e.,</p><ul><li>Add storage support for shoot clusters.</li><li>Implement a <code>cloud-controller-manager</code> and deploy it via the <a href=#controlplane><code>ControlPlane</code> controller</a>.</li><li>Implement support for <code>BackupBucket</code> and <code>BackupEntry</code>s to enable ETCD backups for shoot clusters (based on the support for local disks in <a href=https://github.com/gardener/etcd-backup-restore><code>etcd-backup-restore</code></a>).</li><li>Switch from <code>kindnetd</code> to a different CNI plugin which supports <code>NetworkPolicy</code>s.</li><li>Properly implement <code>.spec.machineTypes</code> in the <code>CloudProfile</code>s (i.e., configure <code>.spec.resources</code> properly for the created shoot worker machine pods).</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-874f35cd0bbeb8acb3c1033b641e3d43>25 - Reconcile Trigger</h1><h1 id=reconcile-trigger>Reconcile trigger</h1><p>Gardener dictates the time of reconciliation for resources of the API group <code>extensions.gardener.cloud</code>.
It does that by annotating the respected resource with <code>gardener.cloud/operation=reconcile</code>.
Extension controllers shall react to this annotation and start reconciling the resource.
They have to remove this annotation as soon as they begin with their reconcile operation and maintain the <code>status</code> of the extension resource accordingly.</p><p>The reason for this behaviour is that it is possible to configure Gardener to reconcile only in the shoots' maintenance time windows.
In order to avoid that extension controllers reconcile outside of the shoot&rsquo;s maintenance time window we have introduced this contract.
This way extension controllers don&rsquo;t need to care about when the shoot maintenance time window happens.
Gardener keeps control and decides when the shoot shall be reconciled/updated.</p><p>Our <a href=https://github.com/gardener/gardener/blob/master/extensions>extension controller library</a> provides all the required utilities to conveniently implement this behaviour.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-df45cc83f21d97b2fdcceee7d9127056>26 - Referenced Resources</h1><h1 id=referenced-resources>Referenced Resources</h1><p>The Shoot resource can include a list of resources (usually secrets) that can be referenced by name in extension <code>providerConfig</code> and other Shoot sections, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>kind: Shoot
apiVersion: core.gardener.cloud/v1beta1
metadata:
  name: crazy-botany
  namespace: garden-dev
  ...
spec:
  ...
  extensions:
  - type: foobar
    providerConfig:
      apiVersion: foobar.extensions.gardener.cloud/v1alpha1
      kind: FooBarConfig
      foo: bar
      secretRef: foobar-secret
  resources:
  - name: foobar-secret
    resourceRef:
      apiVersion: v1
      kind: Secret
      name: my-foobar-secret
</code></pre></div><p>Gardener expects to find these referenced resources in the project namespace (e.g. <code>garden-dev</code>) and will copy them to the Shoot namespace in the Seed cluster when reconciling a Shoot, adding a prefix to their names to avoid naming collisions with Gardener&rsquo;s own resources.</p><p>Extension controllers can resolve the references to these resources by accessing the Shoot via the <code>Cluster</code> resource. To properly read a referenced resources, extension controllers should use the utility function <code>GetObjectByReference</code> from the <code>extensions/pkg/controller</code> package, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go>    ...
    ref = &amp;autoscalingv1.CrossVersionObjectReference{
        APIVersion: <span style=color:#a31515>&#34;v1&#34;</span>,
        Kind:       <span style=color:#a31515>&#34;Secret&#34;</span>,
        Name:       <span style=color:#a31515>&#34;foo&#34;</span>,
    }
    secret := &amp;corev1.Secret{}
    <span style=color:#00f>if</span> err := controller.GetObjectByReference(ctx, client, ref, <span style=color:#a31515>&#34;shoot--test--foo&#34;</span>, secret); err != <span style=color:#00f>nil</span> {
        <span style=color:#00f>return</span> err
    }
    <span style=color:green>// Use secret
</span><span style=color:green></span>    ...
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-0a10283207035fd65241bff1e92982ef>27 - Shoot Health Status Conditions</h1><h1 id=contributing-to-shoot-health-status-conditions>Contributing to shoot health status conditions</h1><p>Gardener checks regularly (every minute by default) the health status of all shoot clusters.
It categorizes its checks into four different types:</p><ul><li><code>APIServerAvailable</code>: This type indicates whether the shoot&rsquo;s kube-apiserver is available or not.</li><li><code>ControlPlaneHealthy</code>: This type indicates whether all the control plane components deployed to the shoot&rsquo;s namespace in the seed do exist and are running fine.</li><li><code>EveryNodeReady</code>: This type indicates whether all <code>Node</code>s and all <code>Machine</code> objects report healthiness.</li><li><code>SystemComponentsHealthy</code>: This type indicates whether all system components deployed to the <code>kube-system</code> namespace in the shoot do exist and are running fine.</li></ul><p>Every <code>Shoot</code> resource has a <code>status.conditions[]</code> list that contains the mentioned types, together with a <code>status</code> (<code>True</code>/<code>False</code>) and a descriptive message/explanation of the <code>status</code>.</p><p>Most extension controllers are deploying components and resources as part of their reconciliation flows into the seed or shoot cluster.
A prominent example for this is the <code>ControlPlane</code> controller that usually deploys a cloud-controller-manager or CSI controllers as part of the shoot control plane.
Now that the extensions deploy resources into the cluster, especially resources that are essential for the functionality of the cluster, they might want to contribute to Gardener&rsquo;s checks mentioned above.</p><h2 id=what-can-extensions-do-to-contribute-to-gardeners-health-checks>What can extensions do to contribute to Gardener&rsquo;s health checks?</h2><p>Every extension resource in Gardener&rsquo;s <code>extensions.gardener.cloud/v1alpha1</code> API group also has a <code>status.conditions[]</code> list (like the <code>Shoot</code>).
Extension controllers can write conditions to the resource they are acting on and use a type that also exist in the shoot&rsquo;s conditions.
One exception is that <code>APIServerAvailable</code> can&rsquo;t be used as the Gardener clearly can identify the status of this condition and it doesn&rsquo;t make sense for extensions to try to contribute/modify it.</p><p>As an example for the <code>ControlPlane</code> controller let&rsquo;s take a look at the following resource:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: extensions.gardener.cloud/v1alpha1
kind: ControlPlane
metadata:
  name: control-plane
  namespace: shoot--foo--bar
spec:
  ...
status:
  conditions:
  - type: ControlPlaneHealthy
    status: <span style=color:#a31515>&#34;False&#34;</span>
    reason: DeploymentUnhealthy
    message: &#39;Deployment cloud-controller-manager is unhealthy: condition &#34;Available&#34; has
      invalid status False (expected True) due to MinimumReplicasUnavailable: Deployment
      does not have minimum availability.&#39;
    lastUpdateTime: <span style=color:#a31515>&#34;2014-05-25T12:44:27Z&#34;</span>
  - type: ConfigComputedSuccessfully
    status: <span style=color:#a31515>&#34;True&#34;</span>
    reason: ConfigCreated
    message: The cloud-provider-config has been successfully computed.
    lastUpdateTime: <span style=color:#a31515>&#34;2014-05-25T12:43:27Z&#34;</span>
</code></pre></div><p>The extension controller has declared in its extension resource that one of the deployments it is responsible for is unhealthy.
Also, it has written a second condition using a type that is unknown by Gardener.</p><p>Gardener will pick the list of conditions and recognize that the there is one with a type <code>ControlPlaneHealthy</code>.
It will merge it with its own <code>ControlPlaneHealthy</code> condition and report it back to the <code>Shoot</code>&rsquo;s status:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: core.gardener.cloud/v1beta1
kind: Shoot
metadata:
  labels:
    shoot.gardener.cloud/status: unhealthy
  name: some-shoot
  namespace: garden-core
spec:
status:
  conditions:
  - type: APIServerAvailable
    status: <span style=color:#a31515>&#34;True&#34;</span>
    reason: HealthzRequestSucceeded
    message: API server /healthz endpoint responded with success status code. [response_time:31ms]
    lastUpdateTime: <span style=color:#a31515>&#34;2014-05-23T08:26:52Z&#34;</span>
    lastTransitionTime: <span style=color:#a31515>&#34;2014-05-25T12:45:13Z&#34;</span>
  - type: ControlPlaneHealthy
    status: <span style=color:#a31515>&#34;False&#34;</span>
    reason: ControlPlaneUnhealthyReport
    message: &#39;Deployment cloud-controller-manager is unhealthy: condition &#34;Available&#34; has
      invalid status False (expected True) due to MinimumReplicasUnavailable: Deployment
      does not have minimum availability.&#39;
    lastUpdateTime: <span style=color:#a31515>&#34;2014-05-25T12:45:13Z&#34;</span>
    lastTransitionTime: <span style=color:#a31515>&#34;2014-05-25T12:45:13Z&#34;</span>
  ...
</code></pre></div><p>Hence, the only duty extensions have is to maintain the health status of their components in the extension resource they are managing.
This can be accomplished using the <a href=/docs/gardener/extensions/healthcheck-library/>health check library for extensions</a>.</p><h2 id=error-codes>Error Codes</h2><p>The Gardener API includes some well-defined error codes, e.g., <code>ERR_INFRA_UNAUTHORIZED</code>, <code>ERR_INFRA_DEPENDENCIES</code>, etc.
Extension may set these error codes in the <code>.status.conditions[].codes[]</code> list in case it makes sense.
Gardener will pick them up and will similarly merge them into the <code>.status.conditions[].codes[]</code> list in the <code>Shoot</code>:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>status:
  conditions:
  - type: ControlPlaneHealthy
    status: <span style=color:#a31515>&#34;False&#34;</span>
    reason: DeploymentUnhealthy
    message: &#39;Deployment cloud-controller-manager is unhealthy: condition &#34;Available&#34; has
      invalid status False (expected True) due to MinimumReplicasUnavailable: Deployment
      does not have minimum availability.&#39;
    lastUpdateTime: <span style=color:#a31515>&#34;2014-05-25T12:44:27Z&#34;</span>
    codes:
    - ERR_INFRA_UNAUTHORIZED 
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-a2e99bb1eae354d266924368862541f8>28 - Shoot Maintenance</h1><h1 id=shoot-maintenance>Shoot maintenance</h1><p>There is a general <a href=/docs/gardener/usage/shoot_maintenance/>document about shoot maintenance</a> that you might want to read.
Here, we describe how you can influence certain operations that happen during a shoot maintenance.</p><h2 id=restart-control-plane-controllers>Restart Control Plane Controllers</h2><p>As outlined in above linked document, Gardener offers to restart certain control plane controllers running in the seed during a shoot maintenance.</p><p>Extension controllers can extend the amount of pods being affected by these restarts.
If your Gardener extension manages pods of a shoot&rsquo;s control plane (shoot namespace in seed) and it could potentially profit from a regular restart please consider labeling it with <code>maintenance.gardener.cloud/restart=true</code>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-be099eb6107ce0525e229d5cfa5bf30b>29 - Shoot Webhooks</h1><h1 id=shoot-resource-customization-webhooks>Shoot resource customization webhooks</h1><p>Gardener deploys several components/resources into the shoot cluster.
Some of these resources are essential (like the <code>kube-proxy</code>), others are optional addons (like the <code>kubernetes-dashboard</code> or the <code>nginx-ingress-controller</code>).
In either case, some provider extensions might need to mutate these resources and inject provider-specific bits into it.</p><h2 id=whats-the-approach-to-implement-such-mutations>What&rsquo;s the approach to implement such mutations?</h2><p>Similar to how <a href=/docs/gardener/extensions/controlplane-webhooks/>control plane components in the seed</a> are modified we are using <code>MutatingWebhookConfiguration</code>s to achieve the same for resources in the shoot.
Both, the provider extension and the kube-apiserver of the shoot cluster are running in the same seed.
Consequently, the kube-apiserver can talk cluster-internally to the provider extension webhook which makes such operations even faster.</p><h2 id=how-is-the-mutatingwebhookconfiguration-object-created-in-the-shoot>How is the <code>MutatingWebhookConfiguration</code> object created in the shoot?</h2><p>The preferred approach is to use a <code>ManagedResource</code> (see also <a href=/docs/gardener/extensions/managedresources/>this document</a>) in the seed cluster.
This way the <code>gardener-resource-manager</code> ensures that end-users cannot delete/modify the webhook configuration.
The provider extension doesn&rsquo;t need to care about the same.</p><h2 id=what-else-is-needed>What else is needed?</h2><p>The shoot&rsquo;s kube-apiserver must be allowed to talk to the provider extension.
To achieve this you need to create a <code>NetworkPolicy</code> in the shoot namespace.
Our <a href=https://github.com/gardener/gardener/blob/master/extensions>extension controller library</a> provides easy-to-use utilities and hooks to implement such a webhook.
Please find an exemplary implementation <a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/webhook/shoot>here</a> and <a href=https://github.com/gardener/gardener-extension-provider-aws/blob/566fe4dd588c93821bc9d22c452203867457c930/cmd/gardener-extension-provider-aws/app/app.go#L170-L174>here</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-aa66bdf689454ea90b099d33515cef79>30 - Worker</h1><h1 id=contract-worker-resource>Contract: <code>Worker</code> resource</h1><p>While the control plane of a shoot cluster is living in the seed and deployed as native Kubernetes workload, the worker nodes of the shoot clusters are normal virtual machines (VMs) in the end-users infrastructure account.
The Gardener project features a sub-project called <a href=https://github.com/gardener/machine-controller-manager>machine-controller-manager</a>.
This controller is extending the Kubernetes API using custom resource definitions to represent actual VMs as <code>Machine</code> objects inside a Kubernetes system.
This approach unlocks the possibility to manage virtual machines in the Kubernetes style and benefit from all its design principles.</p><h2 id=what-is-the-machine-controller-manager-exactly-doing>What is the machine-controller-manager exactly doing?</h2><p>Generally, there are provider-specific <code>MachineClass</code> objects (<code>AWSMachineClass</code>, <code>AzureMachineClass</code>, etc.; similar to <code>StorageClass</code>), and <code>MachineDeployment</code>, <code>MachineSet</code>, and <code>Machine</code> objects (similar to <code>Deployment</code>, <code>ReplicaSet</code>, and <code>Pod</code>).
A machine class describes <strong>where</strong> and <strong>how</strong> to create virtual machines (in which networks, region, availability zone, SSH key, user-data for bootstrapping, etc.) while a <code>Machine</code> results in an actual virtual machine.
You can read up <a href=https://github.com/gardener/machine-controller-manager>more information</a> in the machine-controller-manager&rsquo;s <a href=https://github.com/gardener/machine-controller-manager>repository</a>.</p><p>Before the introduction of the <code>Worker</code> extension resource Gardener was deploying the machine-controller-manager, the machine classes, and the machine deployments itself.
Now, Gardener commissions an external, provider-specific controller to take over these tasks.</p><h2 id=what-needs-to-be-implemented-to-support-a-new-worker-provider>What needs to be implemented to support a new worker provider?</h2><p>As part of the shoot flow Gardener will create a special CRD in the seed cluster that needs to be reconciled by an extension controller, for example:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Worker
metadata:
  name: bar
  namespace: shoot--foo--bar
spec:
  type: azure
  region: eu-west-1
  secretRef:
    name: cloudprovider
    namespace: shoot--foo--bar
  infrastructureProviderStatus:
    apiVersion: aws.provider.extensions.gardener.cloud/v1alpha1
    kind: InfrastructureStatus
    ec2:
      keyName: shoot--foo--bar-ssh-publickey
    iam:
      instanceProfiles:
      - name: shoot--foo--bar-nodes
        purpose: nodes
      roles:
      - arn: arn:aws:iam::0123456789:role/shoot--foo--bar-nodes
        purpose: nodes
    vpc:
      id: vpc-0123456789
      securityGroups:
      - id: sg-1234567890
        purpose: nodes
      subnets:
      - id: subnet-01234
        purpose: nodes
        zone: eu-west-1b
      - id: subnet-56789
        purpose: public
        zone: eu-west-1b
      - id: subnet-0123a
        purpose: nodes
        zone: eu-west-1c
      - id: subnet-5678a
        purpose: public
        zone: eu-west-1c
  pools:
  - name: cpu-worker
    minimum: 3
    maximum: 5
    maxSurge: 1
    maxUnavailable: 0
    machineType: m4.large
    machineImage:
      name: coreos
      version: 1967.5.0
    nodeTemplate:
      capacity:
        cpu: 2
        gpu: 0
        memory: 8Gi
    userData: c29tZSBkYXRhIHRvIGJvb3RzdHJhcCB0aGUgVk0K
    volume:
      size: 20Gi
      type: gp2
    zones:
    - eu-west-1b
    - eu-west-1c
    machineControllerManager:
      drainTimeout: 10m
      healthTimeout: 10m
      creationTimeout: 10m
      maxEvictRetries: 30
      nodeConditions:
      - ReadonlyFilesystem
      - DiskPressure
      - KernelDeadlock
</code></pre></div><p>The <code>.spec.secretRef</code> contains a reference to the provider secret pointing to the account that shall be used to create the needed virtual machines.
Also, as you can see, Gardener copies the output of the infrastructure creation (<code>.spec.infrastructureProviderStatus</code>), see <a href=/docs/gardener/extensions/infrastructure/><code>Infrastructure</code> resource</a>, into the <code>.spec</code>.</p><p>In the <code>.spec.pools[]</code> field the desired worker pools are listed.
In the above example, one pool with machine type <code>m4.large</code> and <code>min=3</code>, <code>max=5</code> machines shall be spread over two availability zones (<code>eu-west-1b</code>, <code>eu-west-1c</code>).
This information together with the infrastructure status must be used to determine the proper configuration for the machine classes.</p><p>The <code>spec.pools[].nodeTemplate.capacity</code> field contains the resource information of the machine like <code>cpu</code>, <code>gpu</code> and <code>memory</code>. This info is used by Cluster Autoscaler to generate <code>nodeTemplate</code> during scaling the <code>nodeGroup</code> from zero.</p><p>The <code>spec.pools[].machineControllerManager</code> field allows to configure the settings for machine-controller-manager component. Providers must populate these settings on worker-pool to the related <a href=https://github.com/gardener/machine-controller-manager/blob/master/kubernetes/machine_objects/machine-deployment.yaml#L30-L34>fields</a> in MachineDeployment.</p><p>When seeing such a resource your controller must make sure that it deploys the machine-controller-manager next to the control plane in the seed cluster.
After that, it must compute the desired machine classes and the desired machine deployments.
Typically, one class maps to one deployment, and one class/deployment is created per availability zone.
Following this convention, the created resource would look like this:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: v1
kind: Secret
metadata:
  name: shoot--foo--bar-cpu-worker-z1-3db65
  namespace: shoot--foo--bar
  labels:
    gardener.cloud/purpose: machineclass
type: Opaque
data:
  providerAccessKeyId: eW91ci1hd3MtYWNjZXNzLWtleS1pZAo=
  providerSecretAccessKey: eW91ci1hd3Mtc2VjcmV0LWFjY2Vzcy1rZXkK
  userData: c29tZSBkYXRhIHRvIGJvb3RzdHJhcCB0aGUgVk0K
---
apiVersion: machine.sapcloud.io/v1alpha1
kind: AWSMachineClass
metadata:
  name: shoot--foo--bar-cpu-worker-z1-3db65
  namespace: shoot--foo--bar
spec:
  ami: ami-0123456789 <span style=color:green># Your controller must map the stated version to the provider specific machine image information, in the AWS case the AMI.</span>
  blockDevices:
  - ebs:
      volumeSize: 20
      volumeType: gp2
  iam:
    name: shoot--foo--bar-nodes
  keyName: shoot--foo--bar-ssh-publickey
  machineType: m4.large
  networkInterfaces:
  - securityGroupIDs:
    - sg-1234567890
    subnetID: subnet-01234
  region: eu-west-1
  secretRef:
    name: shoot--foo--bar-cpu-worker-z1-3db65
    namespace: shoot--foo--bar
  tags:
    kubernetes.io/cluster/shoot--foo--bar: <span style=color:#a31515>&#34;1&#34;</span>
    kubernetes.io/role/node: <span style=color:#a31515>&#34;1&#34;</span>
---
apiVersion: machine.sapcloud.io/v1alpha1
kind: MachineDeployment
metadata:
  name: shoot--foo--bar-cpu-worker-z1
  namespace: shoot--foo--bar
spec:
  replicas: 2
  selector:
    matchLabels:
      name: shoot--foo--bar-cpu-worker-z1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        name: shoot--foo--bar-cpu-worker-z1
    spec:
      class:
        kind: AWSMachineClass
        name: shoot--foo--bar-cpu-worker-z1-3db65
</code></pre></div><p>for the first availability zone <code>eu-west-1b</code>, and</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>apiVersion: v1
kind: Secret
metadata:
  name: shoot--foo--bar-cpu-worker-z2-5z6as
  namespace: shoot--foo--bar
  labels:
    gardener.cloud/purpose: machineclass
type: Opaque
data:
  providerAccessKeyId: eW91ci1hd3MtYWNjZXNzLWtleS1pZAo=
  providerSecretAccessKey: eW91ci1hd3Mtc2VjcmV0LWFjY2Vzcy1rZXkK
  userData: c29tZSBkYXRhIHRvIGJvb3RzdHJhcCB0aGUgVk0K
---
apiVersion: machine.sapcloud.io/v1alpha1
kind: AWSMachineClass
metadata:
  name: shoot--foo--bar-cpu-worker-z2-5z6as
  namespace: shoot--foo--bar
spec:
  ami: ami-0123456789 <span style=color:green># Your controller must map the stated version to the provider specific machine image information, in the AWS case the AMI.</span>
  blockDevices:
  - ebs:
      volumeSize: 20
      volumeType: gp2
  iam:
    name: shoot--foo--bar-nodes
  keyName: shoot--foo--bar-ssh-publickey
  machineType: m4.large
  networkInterfaces:
  - securityGroupIDs:
    - sg-1234567890
    subnetID: subnet-0123a
  region: eu-west-1
  secretRef:
    name: shoot--foo--bar-cpu-worker-z2-5z6as
    namespace: shoot--foo--bar
  tags:
    kubernetes.io/cluster/shoot--foo--bar: <span style=color:#a31515>&#34;1&#34;</span>
    kubernetes.io/role/node: <span style=color:#a31515>&#34;1&#34;</span>
---
apiVersion: machine.sapcloud.io/v1alpha1
kind: MachineDeployment
metadata:
  name: shoot--foo--bar-cpu-worker-z1
  namespace: shoot--foo--bar
spec:
  replicas: 1
  selector:
    matchLabels:
      name: shoot--foo--bar-cpu-worker-z1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        name: shoot--foo--bar-cpu-worker-z1
    spec:
      class:
        kind: AWSMachineClass
        name: shoot--foo--bar-cpu-worker-z2-5z6as
</code></pre></div><p>for the second availability zone <code>eu-west-1c</code>.</p><p>Another convention is the 5-letter hash at the end of the machine class names.
Most controllers compute a checksum out of the specification of the machine class.
This helps to trigger a rolling update of the worker nodes if, for example, the machine image version changes.
In this case, a new checksum will be generated which results in the creation of a new machine class.
The <code>MachineDeployment</code>&rsquo;s machine class reference (<code>.spec.template.spec.class.name</code>) is updated which triggers the rolling update process in the machine-controller-manager.
However, all of this is only a convention that eases writing the controller, but you can do it completely differently if you desire - as long as you make sure that the described behaviours are implemented correctly.</p><p>After the machine classes and machine deployments have been created the machine-controller-manager will start talking to the provider&rsquo;s IaaS API and create the virtual machines.
Gardener makes sure that the content of the <code>userData</code> field that is used to bootstrap the machines contain the required configuration for installation of the kubelet and registering the VM as worker node in the shoot cluster.
The <code>Worker</code> extension controller shall wait until all the created <code>MachineDeployment</code>s indicate healthiness/readiness before it ends the control loop.</p><h2 id=does-gardener-need-some-information-that-must-be-returned-back>Does Gardener need some information that must be returned back?</h2><p>Another important benefit of the machine-controller-manager&rsquo;s design principles (extending the Kubernetes API using CRDs) is that the <a href=https://github.com/gardener/autoscaler>cluster-autoscaler</a> can be used <strong>without</strong> any provider-specific implementation.
We have forked the <a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler>upstream Kubernetes community&rsquo;s cluster-autoscaler</a> and extended it so that it understands the machine API.
Definitely, we will merge it back into the community&rsquo;s versions once it has been adapted properly.</p><p>Our cluster-autoscaler only needs to know the minimum and maximum number of replicas <strong>per</strong> <code>MachineDeployment</code> and is ready to act without that it needs to talk to the provider APIs (it just modifies the <code>.spec.replicas</code> field in the <code>MachineDeployment</code> object).
Gardener deploys this autoscaler if there is at least one worker pool that specifies <code>max>min</code>.
In order to know how it needs to configure it, the provider-specific <code>Worker</code> extension controller must expose which <code>MachineDeployment</code>s it had created and how the <code>min</code>/<code>max</code> numbers should look like.</p><p>Consequently, your controller should write this information into the <code>Worker</code> resource&rsquo;s <code>.status.machineDeployments</code> field:</p><div class=highlight><pre style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml>---
apiVersion: extensions.gardener.cloud/v1alpha1
kind: Worker
metadata:
  name: worker
  namespace: shoot--foo--bar
spec:
  ...
status:
  lastOperation: ...
  machineDeployments:
  - name: shoot--foo--bar-cpu-worker-z1
    minimum: 2
    maximum: 3
  - name: shoot--foo--bar-cpu-worker-z2
    minimum: 1
    maximum: 2
</code></pre></div><p>In order to support a new worker provider you need to write a controller that watches all <code>Worker</code>s with <code>.spec.type=&lt;my-provider-name></code>.
You can take a look at the below referenced example implementation for the AWS provider.</p><h2 id=that-sounds-like-a-lot-that-needs-to-be-done-can-you-help-me>That sounds like a lot that needs to be done, can you help me?</h2><p>All of the described behaviour is mostly the same for every provider.
The only difference is maybe the version/configuration of the machine-controller-manager, and the machine class specification itself.
You can take a look at our <a href=https://github.com/gardener/gardener/blob/master/extensions>extension library</a>, especially the <a href=https://github.com/gardener/gardener/tree/master/extensions/pkg/controller/worker>worker controller</a> part where you will find a lot of utilities that you can use.
Also, using the library you only need to implement your provider specifics - all the things that can be handled generically can be taken for free and do not need to be re-implemented.
Take a look at the <a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/worker>AWS worker controller</a> for finding an example.</p><h2 id=non-provider-specific-information-required-for-worker-creation>Non-provider specific information required for worker creation</h2><p>All the providers require further information that is not provider specific but already part of the shoot resource.
One example for such information is whether the shoot is hibernated or not.
In this case all the virtual machines should be deleted/terminated, and after that the machine controller-manager should be scaled down.
You can take a look at the <a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/worker>AWS worker controller</a> to see how it reads this information and how it is used.
As Gardener cannot know which information is required by providers it simply mirrors the <code>Shoot</code>, <code>Seed</code>, and <code>CloudProfile</code> resources into the seed.
They are part of the <a href=/docs/gardener/extensions/cluster/><code>Cluster</code> extension resource</a> and can be used to extract information that is not part of the <code>Worker</code> resource itself.</p><h2 id=references-and-additional-resources>References and additional resources</h2><ul><li><a href=https://github.com/gardener/gardener/blob/master/pkg/apis/extensions/v1alpha1/types_worker.go><code>Worker</code> API (Golang specification)</a></li><li><a href=https://github.com/gardener/gardener/blob/master/extensions>Extension controller library</a></li><li><a href=https://github.com/gardener/gardener/tree/master/extensions/pkg/controller/worker>Generic worker controller</a></li><li><a href=https://github.com/gardener/gardener-extension-provider-aws/tree/master/pkg/controller/worker>Exemplary implementation for the AWS provider</a></li></ul></div></main></div></div><footer class="footer row d-print-none"><div class="container-fluid footer-wrapper"><ul class=nav><li><a href=https://gardener.cloud/blog/>Blogs</a></li><li><a href=https://gardener.cloud/community/>Community</a></li><li><a href=https://gardener.cloud/adopter/>Adopters</a></li><li><a href=/docs/>Documentation</a></li></ul><img src=/images/lp/gardener-logo.svg alt="Logo Gardener" class=logo><ul class=media-wr><li><a target=_blank href=https://kubernetes.slack.com/archives/CB57N0BFG><img src=/images/branding/slack-logo-white.svg class=media-icon><div class=media-text>Slack</div></a></li><li><a target=_blank href=https://github.com/gardener><img src=/images/branding/github-mark-logo.png class=media-icon><div class=media-text>GitHub</div></a></li><li><a target=_blank href=https://www.youtube.com/channel/UCwUhwKFREV8Su0gwAJQX7tw><img src=/images/branding/youtube-logo-dark.svg class=media-icon><div class=media-text>YouTube</div></a></li><li><a target=_blank href=https://twitter.com/GardenerProject><img src=/images/branding/twitter-logo-white.svg class=media-icon><div class=media-text>Twitter</div></a></li></ul><span class=copyright>Copyright 2019-2022 Gardener project authors. <a href=https://www.sap.com/corporate/en/legal/privacy.html>Privacy policy
<i class="fa fa-external-link" aria-hidden=true></i></a></span></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js integrity=sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/mermaid@8.9.2/dist/mermaid.min.js integrity=sha384-uQikAXnCAqsMb3ygtdqBYvcwvHUkzGIpjdGyy9owhURXHUxLC5LgTcSxJQH/RzjK crossorigin=anonymous></script><script src=/js/main.min.ef8e0714aff556fd5a9768ed6ecabd2964dd962cd9f89762a373947bb53bc742.js integrity="sha256-744HFK/1Vv1al2jtbsq9KWTdlizZ+Jdio3OUe7U7x0I=" crossorigin=anonymous></script></body></html>