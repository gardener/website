<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.83.1"><link rel=canonical type=text/html href=https://gardener.cloud/docs/tutorials/><link rel=alternate type=application/rss+xml href=https://gardener.cloud/docs/tutorials/index.xml><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel=icon type=image/x-icon href=https://gardener.cloud/images/favicon.ico><link rel=icon type=image/png href=https://gardener.cloud/images/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=https://gardener.cloud/images/favicon-16x16.png sizes=16x16><title>Tutorials | Gardener</title><meta name=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:title" content="Tutorials"><meta property="og:description" content="Walkthroughs of common use case implementations and goals that require a set of tasks to accomplish"><meta property="og:type" content="website"><meta property="og:url" content="https://gardener.cloud/docs/tutorials/"><meta itemprop=name content="Tutorials"><meta itemprop=description content="Walkthroughs of common use case implementations and goals that require a set of tasks to accomplish"><meta name=twitter:card content="summary"><meta name=twitter:title content="Tutorials"><meta name=twitter:description content="Walkthroughs of common use case implementations and goals that require a set of tasks to accomplish"><link rel=preload href=/scss/main.min.122f9effc36493edf1f25030c2ce7965b16b3b0eaeb02528b9a50e0fa9110c15.css as=style><link href=/scss/main.min.122f9effc36493edf1f25030c2ce7965b16b3b0eaeb02528b9a50e0fa9110c15.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://unpkg.com/lunr@2.3.8/lunr.min.js integrity=sha384-vRQ9bDyE0Wnu+lMfm57BlYLO0/XauFuKpVsZPs7KEDwYKktWi5+Kz3MP8++DFlRY crossorigin=anonymous></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg width="90" height="90" viewBox="0 0 90 90" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>logo</title><desc>Created with Sketch.</desc><defs><path d="M41.8864954.994901575c.996545099999999-.479910833 2.6164002-.477918931 3.6088091.0L76.8159138 16.0781121C77.8124589 16.5580229 78.8208647 17.8257185 79.0659694 18.8995926l7.7355517 33.8916663C87.0476474 53.8696088 86.6852538 55.4484075 85.9984855 56.3095876L64.3239514 83.4885938C63.6343208 84.3533632 62.1740175 85.0543973 61.0725268 85.0543973H26.3092731c-1.1060816.0-2.5646564-.704623400000003-3.2514246-1.5658035L1.38331434 56.3095876C.693683723 55.4448182.335174016 53.865133.580278769 52.7912589L8.31583044 18.8995926C8.56195675 17.8212428 9.57347722 16.556031 10.5658861 16.0781121L41.8864954.994901575z" id="path-1"/><linearGradient x1="12.7542673%" y1="-18.6617048%" x2="88.2666158%" y2="84.6075483%" id="linearGradient-3"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="50%" y1="4.93673768%" x2="148.756007%" y2="175.514523%" id="linearGradient-4"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="19.1574381%" y1="-9.04800713%" x2="82.2203149%" y2="77.9084293%" id="linearGradient-5"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="57.4403751%" y1="26.3148481%" x2="137.966711%" y2="158.080556%" id="linearGradient-6"><stop stop-color="#fff" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="logo"><g id="Rectangle-2" transform="translate(1.000000, 0.000000)"><mask id="mask-2" fill="#fff"><use xlink:href="#path-1"/></mask><use id="Mask" fill="#009f76" xlink:href="#path-1"/><polygon fill="#000" opacity=".289628623" mask="url(#mask-2)" points="-17.6484375 54.5224609 30.8242188 25.0791016 63.4726562 58.5 24.7324219 92.6689453"/></g><path d="M56.8508631 39.260019C56.4193519 40.443987 55.6088085 41.581593 54.6736295 42.1938694l-8.0738997 5.2861089c-1.3854671.907087099999998-3.6247515.9116711-5.0172201.0L33.50861 42.1938694C32.123143 41.2867823 31 39.206345 31 37.545932V26.4150304c0-.725313.2131118-1.5301454.569268099999999-2.2825772L56.8508631 39.260019z" id="Combined-Shape" fill="url(#linearGradient-3)" transform="translate(43.925432, 36.147233) scale(-1, 1) translate(-43.925432, -36.147233)"/><path d="M56.0774672 25.1412464C56.4306829 25.8903325 56.6425556 26.6907345 56.6425556 27.4119019V38.5428034c0 1.6598979-1.1161415 3.73626640000001-2.50861 4.6479374l-8.0738997 5.286109c-1.3854671.907087000000004-3.6247516.911671000000005-5.0172201.0L32.9689261 43.1907408C32.2918101 42.7474223 31.6773514 42.0238435 31.2260376 41.206007L56.0774672 25.1412464z" id="Combined-Shape" fill="url(#linearGradient-4)" transform="translate(43.821278, 37.246598) scale(-1, 1) translate(-43.821278, -37.246598)"/><path d="M65.0702134 57.1846889C64.5985426 58.2007851 63.8367404 59.1236871 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.1597438 58.7930183 24 56.7816693 24 55.1323495V37.1145303C24 36.3487436 24.249712 35.5060005 24.6599102 34.7400631L65.0702134 57.1846889z" id="Combined-Shape" fill="url(#linearGradient-5)"/><path d="M65.0189476 34.954538C65.3636909 35.6617313 65.5692194 36.42021 65.5692194 37.1145303V55.1323495C65.5692194 56.7842831 64.4072119 58.7943252 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.9237304 59.2341061 25.3159155 58.5918431 24.8568495 57.8487596L65.0189476 34.954538z" id="Combined-Shape" fill="url(#linearGradient-6)"/></g></g></svg></span><span class=text-capitalize>Gardener</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/adopter><span>Adopters</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog><span>Blogs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community><span>Community</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs><span>Documentation</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.f7119bd7d3e738a7d90ab79dda53d649.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"></div><div class="d-none d-xl-block col-xl-2 td-toc d-print-none"></div><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/tutorials/>Return to the regular view of this page</a>.</p></div><h1 class=title>Tutorials</h1><div class=lead>Walkthroughs of common use case implementations and goals that require a set of tasks to accomplish</div><div class=content></div></div><div class=td-content><h1 id=pg-c29db379d9a38d027354d38e2e735f08>1 - Authenticating with an Identity Provider</h1><div class=lead>Authenticating with an Identity Provider using OpenID Connect</div><p>Use an identity provider to authenticate users to access shoot clusters.</p><h2 id=prerequisites>Prerequisites</h2><p>Please read the following background material on <a href=https://kubernetes.io/docs/reference/access-authn-authz/authentication/#openid-connect-tokens>Authenticating</a>.</p><h2 id=overview>Overview</h2><p>Kubernetes on its own doesn’t provide any user management. In other words, users aren’t managed through Kubernetes resources. Whenever you refer to a human user it’s sufficient to use a unique ID, for example, an email address. Nevertheless, Gardener project owners can use an identity provider to authenticate user access for shoot clusters in the following way:</p><ol><li><a href=#configure-an-identity-provider>Configure an Identity Provider</a> using <strong>OpenID Connect</strong> (OIDC).</li><li><a href=#configure-a-local-kubectl-oidc-login>Configure a local kubectl oidc-login</a> to enable <code>oidc-login</code>.</li><li><a href=#configure-the-shoot-cluster>Configure the shoot cluster</a> to share details of the OIDC-compliant identity provider with the Kubernetes API Server.</li><li><a href=#authorize-an-authenticated-user>Authorize an authenticated user</a> using role-based access control (RBAC).</li><li><a href=#verify-the-result>Verify the result</a></li></ol><blockquote><p>Gardener allows administrators to modify aspects of the control plane setup. It gives administrators full control of how the control plane is parameterized. While this offers much flexibility, administrators need to ensure that they don’t configure a control plane that goes beyond the service level agreements of the responsible operators team.</p></blockquote><h2 id=configure-an-identity-provider>Configure an Identity Provider</h2><p>Create a tenant in an OIDC compatible Identity Provider. For simplicity, we use <em>Auth0</em>, which has a free plan.</p><ol><li><p>In your tenant, create a client application to use authentication with <code>kubectl</code>:</p><p><img src=/__resources/Create-client-application_9ff006.png alt="Create client application"></p></li><li><p>Provide a <em>Name</em>, choose <em>Native</em> as application type, and choose <em>CREATE</em>.</p><p><img src=/__resources/Choose-application-type_08fa62.png alt="Choose application type"></p></li><li><p>On tab <em>Settings</em>, copy the following parameters to a local text file:</p><ul><li><p><em>Domain</em></p><blockquote><p>Corresponds to the <strong>issuer</strong> in OIDC. It must be an <code>https</code>-secured endpoint (Auth0 requires a trailing <code>/</code> at the end). More information: <a href=https://openid.net/specs/openid-connect-core-1_0.html#Terminology>Issuer Identifier</a>.</p></blockquote></li><li><p><em>Client ID</em></p></li><li><p><em>Client Secret</em></p><p><img src=/__resources/Basic-information_a3f3a1.png alt="Basic information"></p></li></ul></li><li><p>Configure the client to have a callback url of http://localhost:8000. This callback connects to your local <code>kubectl oidc-login</code> plugin:</p><p><img src=/__resources/Configure-callback_a7c1eb.png alt="Configure callback"></p></li><li><p>Save your changes.</p></li><li><p>Verify that <code>https://&lt;Auth0 Domain>/.well-known/openid-configuration</code> is reachable.</p></li><li><p>Choose <em>Users & Roles</em> > <em>Users</em> > <em>CREATE USERS</em> to create a user with a user and password:</p><p><img src=/__resources/Create-user_e28cd3.png alt="Create user"></p><blockquote><p>Users must have a <em>verified</em> email address.</p></blockquote></li></ol><h2 id=configure-a-local-kubectl-oidc-login>Configure a local <code>kubectl</code> <code>oidc-login</code></h2><ol><li><p>Install the <code>kubectl</code> plugin <a href=https://github.com/int128/kubelogin>oidc-login</a>. We highly recommend the <a href=https://github.com/kubernetes-sigs/krew>krew</a> install tool, which also makes other plugins easily available.</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl krew install oidc-login
</code></pre></div><p>The response looks like this:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>Updated the local copy of plugin index.
Installing plugin: oidc-login
CAVEATS:
\
|  You need to setup the OIDC provider, Kubernetes API server, role binding and kubeconfig.
|  See https://github.com/int128/kubelogin for more.
/
Installed plugin: oidc-login
</code></pre></div></li><li><p>Prepare a <code>kubeconfig</code> for later use:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>cp ~/.kube/config ~/.kube/config-oidc
</code></pre></div></li><li><p>Modify the configuration of <code>~/.kube/config-oidc</code> as follows:</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Config</span><span class=w>
</span><span class=w>
</span><span class=w></span><span class=nn>...</span><span class=w>
</span><span class=w>
</span><span class=w></span><span class=nt>contexts</span><span class=p>:</span><span class=w>
</span><span class=w></span>- <span class=nt>context</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>cluster</span><span class=p>:</span><span class=w> </span><span class=l>shoot--project--mycluster</span><span class=w>
</span><span class=w>    </span><span class=nt>user</span><span class=p>:</span><span class=w> </span><span class=l>my-oidc</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>shoot--project--mycluster</span><span class=w>
</span><span class=w>
</span><span class=w></span><span class=nn>...</span><span class=w>
</span><span class=w>
</span><span class=w></span><span class=nt>users</span><span class=p>:</span><span class=w>
</span><span class=w></span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>my-oidc</span><span class=w>
</span><span class=w>  </span><span class=nt>user</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>exec</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>client.authentication.k8s.io/v1beta1</span><span class=w>
</span><span class=w>      </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>kubectl</span><span class=w>
</span><span class=w>      </span><span class=nt>args</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=l>oidc-login</span><span class=w>
</span><span class=w>      </span>- <span class=l>get-token</span><span class=w>
</span><span class=w>      </span>- --<span class=l>oidc-issuer-url=https://&lt;Issuer&gt;/ </span><span class=w>
</span><span class=w>      </span>- --<span class=l>oidc-client-id=&lt;Client ID&gt;</span><span class=w>
</span><span class=w>      </span>- --<span class=l>oidc-client-secret=&lt;Client Secret&gt;</span><span class=w>
</span><span class=w>      </span>- --<span class=l>oidc-extra-scope=email,offline_access,profile</span><span class=w>
</span></code></pre></div></li></ol><p>To test our OIDC-based authentication, context <code>shoot--project--mycluster</code> of <code>~/.kube/config-oidc</code> is used in a later step. For now, continue to use the configuration <code>~/.kube/config</code> with administration rights for your cluster.</p><h2 id=configure-the-shoot-cluster>Configure the shoot cluster</h2><p>Modify the shoot cluster YAML as follows, using the client ID and the domain (as issuer) from the settings of the client application you created in Auth0:</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Shoot</span><span class=w>
</span><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>garden.sapcloud.io/v1beta1</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mycluster</span><span class=w>
</span><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>garden-project</span><span class=w>
</span><span class=w></span><span class=nn>...</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>kubernetes</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>kubeAPIServer</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>oidcConfig</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>clientID</span><span class=p>:</span><span class=w> </span><span class=l>&lt;Client ID&gt;</span><span class=w>
</span><span class=w>        </span><span class=nt>issuerURL</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;https://&lt;Issuer&gt;/&#34;</span><span class=w>
</span><span class=w>        </span><span class=nt>usernameClaim</span><span class=p>:</span><span class=w> </span><span class=l>email</span><span class=w>
</span></code></pre></div><p>This change of the <code>Shoot</code> manifest triggers a reconciliation. Once the reconciliation is finished, your OIDC configuration is applied. It <strong>doesn&rsquo;t</strong> invalidate other certificate-based authentication methods. Wait for Gardener to reconcile the change. It can take up to 5 minutes.</p><h2 id=authorize-an-authenticated-user>Authorize an authenticated user</h2><p>In Auth0, you created a user with a verified email address, <code>test@test.com</code> in our example. For simplicity, we authorize a single user identified by this email address with cluster role <code>view</code>:</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>rbac.authorization.k8s.io/v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ClusterRoleBinding</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>viewer-test</span><span class=w>
</span><span class=w></span><span class=nt>roleRef</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>apiGroup</span><span class=p>:</span><span class=w> </span><span class=l>rbac.authorization.k8s.io</span><span class=w>
</span><span class=w>  </span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ClusterRole</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>view</span><span class=w>
</span><span class=w></span><span class=nt>subjects</span><span class=p>:</span><span class=w>
</span><span class=w></span>- <span class=nt>apiGroup</span><span class=p>:</span><span class=w> </span><span class=l>rbac.authorization.k8s.io</span><span class=w>
</span><span class=w>  </span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>User</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>test@test.com</span><span class=w>
</span></code></pre></div><p>As administrator, apply the cluster role binding in your shoot cluster.</p><h2 id=verify-the-result>Verify the result</h2><ol><li><p>To step into the shoes of your user, use the prepared <code>kubeconfig</code> file <code>~/.kube/config-oidc</code>, and switch to the context that uses <code>oidc-login</code>:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>cd ~/.kube
export KUBECONFIG=$(pwd)/config-oidc
kubectl config use-context `shoot--project--mycluster`
</code></pre></div></li><li><p><code>kubectl</code> delegates the authentication to plugin <code>oidc-login</code> the first time the user uses <code>kubectl</code> to contact the API server, for example:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl get all
</code></pre></div><p>The plugin opens a browser for an interactive authentication session with Auth0, and in parallel serves a local webserver for the configured callback.</p></li><li><p>Enter your login credentials.</p><p><img src=/__resources/Login-through-identity-provider_471b16.png alt="Login through identity provider"></p><p>You should get a successful response from the API server:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>Opening in existing browser session.
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   100.64.0.1   &lt;none&gt;        443/TCP   86m
</code></pre></div><blockquote><p>After a successful login, <code>kubectl</code> uses a token for authentication so that you don’t have to provide user and password for every new <code>kubectl</code> command. How long the token is valid can be configured. If you want to log in again earlier, reset plugin <code>oidc-login</code>:</p><ol><li>Delete directory <code>~/.kube/cache/oidc-login</code>.</li><li>Delete the browser cache.</li></ol></blockquote></li><li><p>To see if your user uses cluster role <code>view</code>, do some checks with <code>kubectl auth can-i</code>.</p><ul><li><p>The response for the following commands should be <code>no</code>:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl auth can-i create clusterrolebindings
</code></pre></div><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl auth can-i get secrets
</code></pre></div><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl auth can-i describe secrets
</code></pre></div></li><li><p>The response for the following commands should be <code>yes</code>:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl auth can-i list pods
</code></pre></div><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl auth can-i get pods
</code></pre></div></li></ul></li></ol><p>If the last step is successful, you’ve configured your cluster to authenticate against an identity provider using OIDC.</p><h2 id=related-links>Related Links</h2><p><a href=https://auth0.com/pricing/>Auth0 Pricing</a></p></div><div class=td-content style=page-break-before:always><h1 id=pg-7e234a5492bf6ac145bc63720536b8c8>2 - Dynamic Volume Provisioning</h1><div class=lead>Running a Postgres database on Kubernetes and dynamically provision and mount the storage volumes needed by the database</div><h2 id=introduction>Introduction</h2><p>The example shows how to run a postgres database on Kubernetes and how to dynamically provision and mount the storage
volumes needed by the database</p><h2 id=run-postgres-database>Run postgres database</h2><p>Define the following Kubernetes resources in a yaml file</p><ul><li>PersistentVolumeClaim (PVC)</li><li>Deployment</li></ul><h4 id=persistentvolumeclaim>PersistentVolumeClaim</h4><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>PersistentVolumeClaim</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>postgresdb-pvc</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>accessModes</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=l>ReadWriteOnce</span><span class=w>
</span><span class=w>  </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>storage</span><span class=p>:</span><span class=w> </span><span class=l>9Gi</span><span class=w>
</span><span class=w>  </span><span class=nt>storageClassName</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;default&#39;</span><span class=w>
</span></code></pre></div><p>This defines a PVC using storage class <code>default</code>. Storage classes abstract from the underlying storage provider as well
as other parameters, like disk-type (e.g.; solid-state vs standard disks).</p><p>The default storage class has annotation <strong>{&ldquo;storageclass.kubernetes.io/is-default-class&rdquo;:&ldquo;true&rdquo;}</strong>.</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>
$ kubectl describe sc default
Name:            default
IsDefaultClass:  Yes
Annotations:     kubectl.kubernetes.io/last-applied-configuration<span class=o>={</span><span class=s2>&#34;apiVersion&#34;</span>:<span class=s2>&#34;storage.k8s.io/v1beta1&#34;</span>,<span class=s2>&#34;kind&#34;</span>:<span class=s2>&#34;StorageClass&#34;</span>,<span class=s2>&#34;metadata&#34;</span>:<span class=o>{</span><span class=s2>&#34;annotations&#34;</span>:<span class=o>{</span><span class=s2>&#34;storageclass.kubernetes.io/is-default-class&#34;</span>:<span class=s2>&#34;true&#34;</span><span class=o>}</span>,<span class=s2>&#34;labels&#34;</span>:<span class=o>{</span><span class=s2>&#34;addonmanager.kubernetes.io/mode&#34;</span>:<span class=s2>&#34;Exists&#34;</span><span class=o>}</span>,<span class=s2>&#34;name&#34;</span>:<span class=s2>&#34;default&#34;</span>,<span class=s2>&#34;namespace&#34;</span>:<span class=s2>&#34;&#34;</span><span class=o>}</span>,<span class=s2>&#34;parameters&#34;</span>:<span class=o>{</span><span class=s2>&#34;type&#34;</span>:<span class=s2>&#34;gp2&#34;</span><span class=o>}</span>,<span class=s2>&#34;provisioner&#34;</span>:<span class=s2>&#34;kubernetes.io/aws-ebs&#34;</span><span class=o>}</span>
,storageclass.kubernetes.io/is-default-class<span class=o>=</span><span class=nb>true</span>
Provisioner:           kubernetes.io/aws-ebs
Parameters:            <span class=nv>type</span><span class=o>=</span>gp2
AllowVolumeExpansion:  &lt;unset&gt;
MountOptions:          &lt;none&gt;
ReclaimPolicy:         Delete
VolumeBindingMode:     Immediate
Events:                &lt;none&gt;

</code></pre></div><p>A Persistent Volume is automatically created when it is dynamically provisioned. In following example, the PVC is defined
as &ldquo;postgresdb-pvc&rdquo;, and a corresponding PV &ldquo;pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb&rdquo; is created and associated with pvc automatically.</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ kubectl create -f .<span class=se>\p</span>ostgres_deployment.yaml
persistentvolumeclaim <span class=s2>&#34;postgresdb-pvc&#34;</span> created

$ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                    STORAGECLASS   REASON    AGE
pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Delete           Bound     default/postgresdb-pvc   default                  3s

$ kubectl get pvc
NAME             STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
postgresdb-pvc   Bound     pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            default        8s
</code></pre></div><p>Notice that the <strong>RECLAIM POLICY</strong> is <strong>Delete</strong> (default value), which is one of the two reclaim policies, the other
one is <strong>Retain</strong>. (A third policy <strong>Recycle</strong> has been deprecated). In case of <strong>Delete</strong>, the PV is deleted automatically
when the PVC is removed, and the data on the PVC will also be lost.</p><p>On the other hand, PV with <strong>Retain</strong> policy will not be deleted when the PVC is removed, and moved to <strong>Release</strong> status, so
that data can be recovered by Administrators later.</p><p>You can use the <code>kubectl patch</code> command to change the reclaim policy as described here <a href=https://kubernetes.io/docs/tasks/administer-cluster/change-pv-reclaim-policy/>here</a>
or use <code>kubectl edit pv &lt;pv-name></code> to edit online as below:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                    STORAGECLASS   REASON    AGE
pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Delete           Bound     default/postgresdb-pvc   default                  44m

<span class=c1># change the relcaim policy from &#34;Delete&#34; to &#34;Retain&#34;</span>
$ kubectl edit pv pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb
persistentvolume <span class=s2>&#34;pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb&#34;</span> edited

<span class=c1># check the reclaim policy afterwards</span>
$ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                    STORAGECLASS   REASON    AGE
pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Retain           Bound     default/postgresdb-pvc   default                  45m
</code></pre></div><h4 id=deployment>Deployment</h4><p>Once a PVC is created, you can use it in your container via <code>volumes.persistentVolumeClaim.claimName</code>. In below
example, pvc <strong>postgresdb-pvc</strong> is mounted as readable and writable, and in <code>volumeMounts</code> two paths in the container are mounted to subfolders in the volume.</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Deployment</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>postgres</span><span class=w>
</span><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>default</span><span class=w>
</span><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>postgres</span><span class=w>
</span><span class=w>  </span><span class=nt>annotations</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>deployment.kubernetes.io/revision</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;1&#34;</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span><span class=w>  </span><span class=nt>strategy</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>RollingUpdate</span><span class=w>
</span><span class=w>    </span><span class=nt>rollingUpdate</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>maxUnavailable</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span><span class=w>      </span><span class=nt>maxSurge</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>postgres</span><span class=w>
</span><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>postgres</span><span class=w>
</span><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>postgres</span><span class=w>
</span><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>postgres</span><span class=w>
</span><span class=w>          </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;cpettech.docker.repositories.sap.ondemand.com/jtrack_postgres:howto&#34;</span><span class=w>
</span><span class=w>          </span><span class=nt>env</span><span class=p>:</span><span class=w>
</span><span class=w>            </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>POSTGRES_USER</span><span class=w>
</span><span class=w>              </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=l>postgres</span><span class=w>
</span><span class=w>            </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>POSTGRES_PASSWORD</span><span class=w>
</span><span class=w>              </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=l>p5FVqfuJFrM42cVX9muQXxrC3r8S9yn0zqWnFR6xCoPqxqVQ</span><span class=w>
</span><span class=w>            </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>POSTGRES_INITDB_XLOGDIR</span><span class=w>
</span><span class=w>              </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;/var/log/postgresql/logs&#34;</span><span class=w>
</span><span class=w>          </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span><span class=w>            </span>- <span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>5432</span><span class=w>
</span><span class=w>          </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span><span class=w>            </span>- <span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/var/lib/postgresql/data</span><span class=w>
</span><span class=w>              </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>postgre-db</span><span class=w>
</span><span class=w>              </span><span class=nt>subPath</span><span class=p>:</span><span class=w> </span><span class=l>data    </span><span class=w> </span><span class=c># https://github.com/kubernetes/website/pull/2292.  Solve the issue of crashing initdb due to non-empty directory (i.e. lost+found)</span><span class=w>
</span><span class=w>            </span>- <span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/var/log/postgresql/logs</span><span class=w>
</span><span class=w>              </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>postgre-db</span><span class=w>
</span><span class=w>              </span><span class=nt>subPath</span><span class=p>:</span><span class=w> </span><span class=l>logs</span><span class=w>
</span><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>postgre-db</span><span class=w>
</span><span class=w>          </span><span class=nt>persistentVolumeClaim</span><span class=p>:</span><span class=w>
</span><span class=w>            </span><span class=nt>claimName</span><span class=p>:</span><span class=w> </span><span class=l>postgresdb-pvc</span><span class=w>
</span><span class=w>            </span><span class=nt>readOnly</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>
</span><span class=w>      </span><span class=nt>imagePullSecrets</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>cpettechregistry</span><span class=w>
</span><span class=w>
</span></code></pre></div><p>To check the mount points in the container:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ kubectl get po
NAME                        READY     STATUS    RESTARTS   AGE
postgres-7f485fd768-c5jf9   1/1       Running   <span class=m>0</span>          32m

$ kubectl <span class=nb>exec</span> -it postgres-7f485fd768-c5jf9 bash

root@postgres-7f485fd768-c5jf9:/# ls /var/lib/postgresql/data/
base    pg_clog       pg_dynshmem  pg_ident.conf  pg_multixact  pg_replslot  pg_snapshots  pg_stat_tmp  pg_tblspc    PG_VERSION  postgresql.auto.conf  postmaster.opts
global  pg_commit_ts  pg_hba.conf  pg_logical     pg_notify     pg_serial    pg_stat       pg_subtrans  pg_twophase  pg_xlog     postgresql.conf       postmaster.pid

root@postgres-7f485fd768-c5jf9:/# ls /var/log/postgresql/logs/
<span class=m>000000010000000000000001</span>  archive_status

</code></pre></div><h4 id=deleting-a-persistentvolumeclaim>Deleting a PersistentVolumeClaim</h4><p>In case of &ldquo;Delete&rdquo; policy, deleting a PVC will also delete its associated PV. If &ldquo;Retain&rdquo; is the reclaim policy, the
PV will change status from <strong>Bound</strong> to <strong>Released</strong> when PVC is deleted.</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash><span class=c1># Check pvc and pv before deletion</span>
$ kubectl get pvc
NAME             STATUS    VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
postgresdb-pvc   Bound     pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            default        50m

$ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM                    STORAGECLASS   REASON    AGE
pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Retain           Bound     default/postgresdb-pvc   default                  50m

<span class=c1># delete pvc</span>
$ kubectl delete pvc postgresdb-pvc
persistentvolumeclaim <span class=s2>&#34;postgresdb-pvc&#34;</span> deleted

<span class=c1># pv changed to status &#34;Released&#34;</span>
$ kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM                    STORAGECLASS   REASON    AGE
pvc-06c81c30-72ea-11e8-ada2-aa3b2329c8bb   9Gi        RWO            Retain           Released   default/postgresdb-pvc   default                  51m
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-c90be487b1be659d530b3635ace83618>3 - Gardener yourself a Shoot with Istio, custom Domains, and Certificates</h1><p>As we ramp up more and more friends of Gardener, I thought it worthwile to explore and write a tutorial about how to simply</p><ul><li>create a Gardener managed Kubernetes Cluster (Shoot) via kubectl,</li><li>install Istio as a preferred, production ready Ingress/Service Mesh (instead of the Nginx Ingress addon),</li><li>attach your own custom domain to be managed by Gardener,</li><li>combine everything with certificates from Let&rsquo;s Encrypt.</li></ul><p>Here are some pre-pointers that you will need to go deeper:</p><ul><li><a href=https://gardener.cloud/docs/guides/administer_shoots/create-delete-shoot/>CRUD Gardener Shoot</a></li><li><a href=https://gardener.cloud/docs/guides/administer_shoots/create-delete-shoot/>DNS Management</a></li><li><a href=https://gardener.cloud/docs/concepts/networking/cert-managment/>Certificate Management</a></li><li><a href=https://gardener.cloud/docs/guides/administer_shoots/dns_names/>Tutorial Domain Names</a></li><li><a href=https://gardener.cloud/docs/guides/administer_shoots/request_cert/>Tutorial Certificates</a></li></ul><div class="alert alert-primary" role=alert><h4 class=alert-heading>Tip</h4>If you try my instructions and fail, then read the alternative title of this tutorial as "Shoot yourself in foot with Gardener, custom Domains, Istio and Certificates".</div><h2 id=first-things-first>First Things First</h2><p>Login to your Gardener landscape, setup a project with adequate infrastructure credentials and then navigate to your account. Note down the name of your secret. I chose the GCP infrastructure from the vast possible options that my Gardener provides me with, so i had named the secret as <code>shoot-operator-gcp</code>.</p><p>From the Access widget (leave the default settings) download your personalized <code>kubeconfig</code> into <code>~/.kube/kubeconfig-garden-myproject</code>. Follow the instructions to setup <code>kubelogin</code>:</p><p><img src=/__resources/access_1f1c85.png alt=access></p><p>For convinience, let us set an alias command with</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash><span class=nb>alias</span> <span class=nv>kgarden</span><span class=o>=</span><span class=s2>&#34;kubectl --kubeconfig ~/.kube/kubeconfig-garden-myproject.yaml&#34;</span>
</code></pre></div><p><code>kgarden</code> now gives you all botanical powers and connects you directly with your Gardener.</p><p>You should now be able to run <code>kgarden get shoots</code>, automatically get an oidc token, and list already running clusters/shoots.</p><h2 id=prepare-your-custom-domain>Prepare your Custom Domain</h2><p>I am going to use <a href=https://www.cloudflare.com/>Cloud Flare</a> as programmatic DNS of my custom domain <code>mydomain.io</code>. Please follow detailed instructions from Cloud Flare on how to delegate your domain (the free account does not support delegating subdomains). Alternatively, AWS Route53 (and most others) support <a href=https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/CreatingNewSubdomain.html>delegating subdomains</a>.</p><p>I needed to follow these <a href=https://github.com/gardener/external-dns-management/blob/master/docs/cloudflare/README.md>instructions</a> and created the following secret:</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Secret</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>cloudflare-mydomain-io</span><span class=w>
</span><span class=w></span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>Opaque</span><span class=w>
</span><span class=w></span><span class=nt>data</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>CLOUDFLARE_API_TOKEN</span><span class=p>:</span><span class=w> </span><span class=l>useYOURownDAMITzNDU2Nzg5MDEyMzQ1Njc4OQ==</span><span class=w>
</span></code></pre></div><p>Apply this secret into your project with <code>kgarden create -f cloudflare-mydomain-io.yaml</code>.</p><p>Our <a href=https://github.com/gardener/external-dns-management/>External DNS Manager</a> also supports Amazon Route53, Google CloudDNS, AliCloud DNS, Azure DNS, or OpenStack Designate. Check it out.</p><h2 id=prepare-gardener-extensions>Prepare Gardener Extensions</h2><p>I now need to prepare the Gardener extensions <code>shoot-dns-service</code> and <code>shoot-cert-service</code> and set the parameters accordingly.</p><div class="alert alert-info" role=alert>Please note, that the availability of Gardener Extensions depends on how your administrator has configured the Gardener landscape. Please contact your Gardener administrator in case you experience any issues during activation.</div><p>The following snipplet allows Gardener to manage my entire custom domain, whereas with the <code>include:</code> attribute I restrict all dynamic entries under the subdomain <code>gsicdc.mydomain.io</code>:</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=w>  </span><span class=nt>dns</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>providers</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>domains</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>include</span><span class=p>:</span><span class=w>
</span><span class=w>            </span>- <span class=l>gsicdc.mydomain.io</span><span class=w>
</span><span class=w>        </span><span class=nt>primary</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>
</span><span class=w>        </span><span class=nt>secretName</span><span class=p>:</span><span class=w> </span><span class=l>cloudflare-mydomain-io</span><span class=w>
</span><span class=w>        </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>cloudflare-dns</span><span class=w>
</span><span class=w>  </span><span class=nt>extensions</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>shoot-dns-service</span><span class=w>
</span></code></pre></div><p>The next snipplet allows Gardener to manage certificates automatically from <em><a href=https://letsencrypt.org/>Let&rsquo;s Encrypt</a></em> on <code>mydomain.io</code> for me:</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=w>  </span><span class=nt>extensions</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>shoot-cert-service</span><span class=w>
</span><span class=w>      </span><span class=nt>providerConfig</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>service.cert.extensions.gardener.cloud/v1alpha1</span><span class=w>
</span><span class=w>        </span><span class=nt>issuers</span><span class=p>:</span><span class=w>
</span><span class=w>          </span>- <span class=nt>email</span><span class=p>:</span><span class=w> </span><span class=l>me@mail.com</span><span class=w>
</span><span class=w>            </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mydomain</span><span class=w>
</span><span class=w>            </span><span class=nt>server</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;https://acme-v02.api.letsencrypt.org/directory&#39;</span><span class=w>
</span><span class=w>          </span>- <span class=nt>email</span><span class=p>:</span><span class=w> </span><span class=l>me@mail.com</span><span class=w>
</span><span class=w>            </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mydomain-staging</span><span class=w>
</span><span class=w>            </span><span class=nt>server</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;https://acme-staging-v02.api.letsencrypt.org/directory&#39;</span><span class=w>
</span></code></pre></div><div class="alert alert-info" role=alert>Adjust the snipplets with your parameters (don't forget your email). And please use the mydomain-staging issuer while you are testing and learning. Otherwise, Let's Encrypt will rate limit your frequent requests and you can wait a week until you can continue.</div><p>References for <a href=https://letsencrypt.org>Let&rsquo;s Encrypt</a>:</p><ul><li><a href=https://letsencrypt.org/docs/rate-limits/>Rate limit</a></li><li><a href=https://letsencrypt.org/docs/staging-environment/>Staging environment</a></li><li><a href=https://letsencrypt.org/docs/challenge-types/>Challenge Types</a></li><li><a href=https://community.letsencrypt.org/t/acme-v2-production-environment-wildcards/55578>Wildcard Certificates</a></li></ul><h2 id=create-the-gardener-shoot-cluster>Create the Gardener Shoot Cluster</h2><p>Remember I chose to create the Shoot on GCP, so below is the simplest declarative shoot or cluster order document. Notice that I am referring to the infrastructure credentials with <code>shoot-operator-gcp</code> and I combined the above snipplets into the yaml file:</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>core.gardener.cloud/v1beta1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Shoot</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>gsicdc</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>dns</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>providers</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>domains</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>include</span><span class=p>:</span><span class=w>
</span><span class=w>          </span>- <span class=l>gsicdc.mydomain.io</span><span class=w>
</span><span class=w>      </span><span class=nt>primary</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>
</span><span class=w>      </span><span class=nt>secretName</span><span class=p>:</span><span class=w> </span><span class=l>cloudflare-mydomain-io</span><span class=w>
</span><span class=w>      </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>cloudflare-dns</span><span class=w>
</span><span class=w>  </span><span class=nt>extensions</span><span class=p>:</span><span class=w>
</span><span class=w>  </span>- <span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>shoot-dns-service</span><span class=w>
</span><span class=w>  </span>- <span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>shoot-cert-service</span><span class=w>
</span><span class=w>    </span><span class=nt>providerConfig</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>service.cert.extensions.gardener.cloud/v1alpha1</span><span class=w>
</span><span class=w>      </span><span class=nt>issuers</span><span class=p>:</span><span class=w>
</span><span class=w>        </span>- <span class=nt>email</span><span class=p>:</span><span class=w> </span><span class=l>me@mail.com</span><span class=w>
</span><span class=w>          </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mydomain</span><span class=w>
</span><span class=w>          </span><span class=nt>server</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;https://acme-v02.api.letsencrypt.org/directory&#39;</span><span class=w>
</span><span class=w>        </span>- <span class=nt>email</span><span class=p>:</span><span class=w> </span><span class=l>me@mail.com</span><span class=w>
</span><span class=w>          </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>mydomain-staging</span><span class=w>
</span><span class=w>          </span><span class=nt>server</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;https://acme-staging-v02.api.letsencrypt.org/directory&#39;</span><span class=w>
</span><span class=w>  </span><span class=nt>cloudProfileName</span><span class=p>:</span><span class=w> </span><span class=l>gcp</span><span class=w>
</span><span class=w>  </span><span class=nt>kubernetes</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>allowPrivilegedContainers</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>    </span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=m>1.18.2</span><span class=w>
</span><span class=w>  </span><span class=nt>maintenance</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>autoUpdate</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>kubernetesVersion</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>      </span><span class=nt>machineImageVersion</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>  </span><span class=nt>networking</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>nodes</span><span class=p>:</span><span class=w> </span><span class=m>10.250.0.0</span><span class=l>/16</span><span class=w>
</span><span class=w>    </span><span class=nt>pods</span><span class=p>:</span><span class=w> </span><span class=m>100.96.0.0</span><span class=l>/11</span><span class=w>
</span><span class=w>    </span><span class=nt>services</span><span class=p>:</span><span class=w> </span><span class=m>100.64.0.0</span><span class=l>/13</span><span class=w>
</span><span class=w>    </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>calico</span><span class=w>
</span><span class=w>  </span><span class=nt>provider</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>controlPlaneConfig</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>gcp.provider.extensions.gardener.cloud/v1alpha1</span><span class=w>
</span><span class=w>      </span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ControlPlaneConfig</span><span class=w>
</span><span class=w>      </span><span class=nt>zone</span><span class=p>:</span><span class=w> </span><span class=l>europe-west1-d</span><span class=w>
</span><span class=w>    </span><span class=nt>infrastructureConfig</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>gcp.provider.extensions.gardener.cloud/v1alpha1</span><span class=w>
</span><span class=w>      </span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>InfrastructureConfig</span><span class=w>
</span><span class=w>      </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>workers</span><span class=p>:</span><span class=w> </span><span class=m>10.250.0.0</span><span class=l>/16</span><span class=w>
</span><span class=w>    </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>gcp</span><span class=w>
</span><span class=w>    </span><span class=nt>workers</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>machine</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>image</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>gardenlinux</span><span class=w>
</span><span class=w>          </span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=m>11.29.2</span><span class=w>
</span><span class=w>        </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>n1-standard-2</span><span class=w>
</span><span class=w>      </span><span class=nt>maxSurge</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span><span class=w>      </span><span class=nt>maxUnavailable</span><span class=p>:</span><span class=w> </span><span class=m>0</span><span class=w>
</span><span class=w>      </span><span class=nt>maximum</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span><span class=w>      </span><span class=nt>minimum</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>my-workerpool</span><span class=w>
</span><span class=w>      </span><span class=nt>volume</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>size</span><span class=p>:</span><span class=w> </span><span class=l>50Gi</span><span class=w>
</span><span class=w>        </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>pd-standard</span><span class=w>
</span><span class=w>      </span><span class=nt>zones</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=l>europe-west1-d</span><span class=w>
</span><span class=w>  </span><span class=nt>purpose</span><span class=p>:</span><span class=w> </span><span class=l>testing</span><span class=w>
</span><span class=w>  </span><span class=nt>region</span><span class=p>:</span><span class=w> </span><span class=l>europe-west1</span><span class=w>
</span><span class=w>  </span><span class=nt>secretBindingName</span><span class=p>:</span><span class=w> </span><span class=l>shoot-operator-gcp</span><span class=w>
</span></code></pre></div><p>Create your cluster and wait for it to be ready (about 5 to 7min).</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ kgarden create -f gsicdc.yaml
shoot.core.gardener.cloud/gsicdc created

$ kgarden get shoot gsicdc --watch
NAME     CLOUDPROFILE   VERSION   SEED   DOMAIN                                        HIBERNATION   OPERATION    PROGRESS   APISERVER     CONTROL       NODES     SYSTEM    AGE
gsicdc   gcp            1.18.2    gcp    gsicdc.myproject.shoot.devgarden.cloud   Awake         Processing   <span class=m>38</span>         Progressing   Progressing   Unknown   Unknown   83s
...
gsicdc   gcp            1.18.2    gcp    gsicdc.myproject.shoot.devgarden.cloud   Awake         Succeeded    <span class=m>100</span>        True          True          True          False         6m7s
</code></pre></div><p>Get access to your freshly baked cluster and set your <code>KUBECONFIG</code>:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ kgarden get secrets gsicdc.kubeconfig -o <span class=nv>jsonpath</span><span class=o>={</span>.data.kubeconfig<span class=o>}</span> <span class=p>|</span> base64 -d &gt;kubeconfig-gsicdc.yaml

$ <span class=nb>export</span> <span class=nv>KUBECONFIG</span><span class=o>=</span><span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>/kubeconfig-gsicdc.yaml
$ kubectl get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT<span class=o>(</span>S<span class=o>)</span>   AGE
service/kubernetes   ClusterIP   100.64.0.1   &lt;none&gt;        443/TCP   89m
</code></pre></div><h2 id=install-istio>Install Istio</h2><p>Please follow the Istio installation <a href=https://istio.io/docs/setup/getting-started/>instructions</a> and download <code>istioctl</code>. If you are on a Mac, I recommend</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ brew install istioctl
</code></pre></div><p>I want to install Istio with a default profile and SDS enabled. Furthermore I pass the following annotations to the service object <code>istio-ingressgateway</code> in the <code>istio-system</code> namespace.</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=w>  </span><span class=nt>annotations</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>cert.gardener.cloud/issuer</span><span class=p>:</span><span class=w> </span><span class=l>mydomain-staging</span><span class=w>
</span><span class=w>    </span><span class=nt>cert.gardener.cloud/secretname</span><span class=p>:</span><span class=w> </span><span class=l>wildcard-tls</span><span class=w>
</span><span class=w>    </span><span class=nt>dns.gardener.cloud/class</span><span class=p>:</span><span class=w> </span><span class=l>garden</span><span class=w>
</span><span class=w>    </span><span class=nt>dns.gardener.cloud/dnsnames</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;*.gsicdc.mydomain.io&#34;</span><span class=w>
</span><span class=w>    </span><span class=nt>dns.gardener.cloud/ttl</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;120&#34;</span><span class=w>
</span></code></pre></div><p>With these annotations three things now happen automagically:</p><ol><li>The <a href=/docs/concepts/networking/dns-managment>External DNS Manager</a>, provided to you as a service (<code>dns.gardener.cloud/class: garden</code>), picks up the request and creates the wildcard DNS entry <code>*.gsicdc.mydomain.io</code> with a time to live of 120sec at your DNS provider. My provider Cloud Flare is very very quick (as opposed to some other services). You should be able to verify the entry with <code>dig lovemygardener.gsicdc.mydomain.io</code> within seconds.</li><li>The <a href=https://gardener.cloud/docs/concepts/networking/cert-managment/>Certificate Mangement</a> picks up the request as well and initates a DNS01 protocol exchange with Let&rsquo;s Encrypt; using the staging environment referred to with the issuer behind <code>mydomain-staging</code>.</li><li>After aproximately 70sec (give and take) you will receive the wildcard certificate in the <code>wildcard-tls</code> secret in the namespace <code>istio-system</code>.</li></ol><div class="alert alert-info" role=alert>Notice, that the namespace for the certificate secret is often the cause of many troubeshooting sessions: the secret must reside in the same namespace of the gateway.</div><p>Here is the istio-install script:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ <span class=nb>export</span> <span class=nv>domainname</span><span class=o>=</span><span class=s2>&#34;*.gsicdc.mydomain.io&#34;</span>
$ <span class=nb>export</span> <span class=nv>issuer</span><span class=o>=</span><span class=s2>&#34;mydomain-staging&#34;</span>

$ cat <span class=s>&lt;&lt;EOF | istioctl install -y -f -
</span><span class=s>apiVersion: install.istio.io/v1alpha1
</span><span class=s>kind: IstioOperator
</span><span class=s>spec:
</span><span class=s>  profile: default
</span><span class=s>  components:
</span><span class=s>    ingressGateways:
</span><span class=s>    - name: istio-ingressgateway
</span><span class=s>      enabled: true
</span><span class=s>      k8s:
</span><span class=s>        serviceAnnotations:
</span><span class=s>          cert.gardener.cloud/issuer: &#34;${issuer}&#34;
</span><span class=s>          cert.gardener.cloud/secretname: wildcard-tls
</span><span class=s>          dns.gardener.cloud/class: garden
</span><span class=s>          dns.gardener.cloud/dnsnames: &#34;${domainname}&#34;
</span><span class=s>          dns.gardener.cloud/ttl: &#34;120&#34; 
</span><span class=s>EOF</span>
</code></pre></div><p>Verify that setup is working and that DNS and certificates have been created/delivered:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ kubectl -n istio-system describe service istio-ingressgateway
&lt;snip&gt;
Events:
  Type    Reason                Age                From                     Message
  ----    ------                ----               ----                     -------
  Normal  EnsuringLoadBalancer  58s                service-controller       Ensuring load balancer
  Normal  reconcile             58s                cert-controller-manager  created certificate object istio-system/istio-ingressgateway-service-pwqdm
  Normal  cert-annotation       58s                cert-controller-manager  wildcard-tls: cert request is pending
  Normal  cert-annotation       54s                cert-controller-manager  wildcard-tls: certificate pending: certificate requested, preparing/waiting <span class=k>for</span> successful DNS01 challenge
  Normal  cert-annotation       28s                cert-controller-manager  wildcard-tls: certificate ready
  Normal  EnsuredLoadBalancer   26s                service-controller       Ensured load balancer
  Normal  reconcile             26s                dns-controller-manager   created dns entry object shoot--core--gsicdc/istio-ingressgateway-service-p9qqb
  Normal  dns-annotation        26s                dns-controller-manager   *.gsicdc.mydomain.io: dns entry is pending
  Normal  dns-annotation        21s <span class=o>(</span>x3 over 21s<span class=o>)</span>  dns-controller-manager   *.gsicdc.mydomain.io: dns entry active

$ dig lovemygardener.gsicdc.mydomain.io

<span class=p>;</span> &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; lovemygardener.gsicdc.mydomain.io
&lt;snip&gt;
<span class=p>;;</span> ANSWER SECTION:
lovemygardener.gsicdc.mydomain.io. <span class=m>120</span> IN A	35.195.120.62
&lt;snip&gt;
</code></pre></div><p>There you have it, the wildcard-tls certificate is ready and the *.gsicdc.mydomain.io dns entry is active. Traffic will be going your way.</p><h2 id=handy-tools-to-install>Handy tools to install</h2><p>Another set of fine tools to use are <a href=https://get-kapp.io/>kapp</a> (formerly known as k14s), <a href=https://k9scli.io/>k9s</a> and <a href=https://httpie.org/>HTTPie</a>. While we are at it, let&rsquo;s install them all. If you are on a Mac, I recommend:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>brew tap vmware-tanzu/carvel
brew install ytt kbld kapp kwt imgpkg vendir
brew install derailed/k9s/k9s
brew install httpie
</code></pre></div><h2 id=ingress-to-your-service>Ingress to your service</h2><div class="alert alert-info" role=alert>Networking is a central part of Kubernetes, but it can be challenging to understand exactly how it is expected to work. You should learn about Kubernetes networking, and first try to debug problems yourself. With a solid managed cluster from Gardener, it is always PEBCAK!</div><p>Kubernetes Ingress is a subject that is evolving to much broader standard. Please watch <a href="https://www.youtube.com/watch?v=cduG0FrjdJA">Evolving the Kubernetes Ingress APIs to GA and Beyond</a> for a good introduction. In this example, I did not want to use the Kubernetes <code>Ingress</code> compatibility option of Istio. Instead, I used <code>VirtualService</code> and <code>Gateway</code> from the Istio&rsquo;s API group <code>networking.istio.io/v1beta1</code> directly, and enabled istio-injection generically for the namespace.</p><p>I use <a href=https://httpbin.org/>httpbin</a> as service that I want to expose to the internet, or where my ingress should be routed to (depends on your point of view, I guess).</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Namespace</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>production</span><span class=w>
</span><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>istio-injection</span><span class=p>:</span><span class=w> </span><span class=l>enabled</span><span class=w>
</span><span class=w></span><span class=nn>---</span><span class=w>
</span><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Service</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>httpbin</span><span class=w>
</span><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>production</span><span class=w>
</span><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>httpbin</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span><span class=w>  </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>http</span><span class=w>
</span><span class=w>    </span><span class=nt>port</span><span class=p>:</span><span class=w> </span><span class=m>8000</span><span class=w>
</span><span class=w>    </span><span class=nt>targetPort</span><span class=p>:</span><span class=w> </span><span class=m>80</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>httpbin</span><span class=w>
</span><span class=w></span><span class=nn>---</span><span class=w>
</span><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Deployment</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>httpbin</span><span class=w>
</span><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>production</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>httpbin</span><span class=w>
</span><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>httpbin</span><span class=w>
</span><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>docker.io/kennethreitz/httpbin</span><span class=w>
</span><span class=w>        </span><span class=nt>imagePullPolicy</span><span class=p>:</span><span class=w> </span><span class=l>IfNotPresent</span><span class=w>
</span><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>httpbin</span><span class=w>
</span><span class=w>        </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span><span class=w>        </span>- <span class=nt>containerPort</span><span class=p>:</span><span class=w> </span><span class=m>80</span><span class=w>
</span><span class=w></span><span class=nn>---</span><span class=w>
</span><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>networking.istio.io/v1beta1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Gateway</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>httpbin-gw</span><span class=w>
</span><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>production</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>istio</span><span class=p>:</span><span class=w> </span><span class=l>ingressgateway</span><span class=w> </span><span class=c>#! use istio default ingress gateway</span><span class=w>
</span><span class=w>  </span><span class=nt>servers</span><span class=p>:</span><span class=w>
</span><span class=w>  </span>- <span class=nt>port</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>number</span><span class=p>:</span><span class=w> </span><span class=m>80</span><span class=w>
</span><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>http</span><span class=w>
</span><span class=w>      </span><span class=nt>protocol</span><span class=p>:</span><span class=w> </span><span class=l>HTTP</span><span class=w>
</span><span class=w>    </span><span class=nt>tls</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>httpsRedirect</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>    </span><span class=nt>hosts</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=s2>&#34;httpbin.gsicdc.mydomain.io&#34;</span><span class=w>
</span><span class=w>  </span>- <span class=nt>port</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>number</span><span class=p>:</span><span class=w> </span><span class=m>443</span><span class=w>
</span><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>https</span><span class=w>
</span><span class=w>      </span><span class=nt>protocol</span><span class=p>:</span><span class=w> </span><span class=l>HTTPS</span><span class=w>
</span><span class=w>    </span><span class=nt>tls</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>mode</span><span class=p>:</span><span class=w> </span><span class=l>SIMPLE</span><span class=w>
</span><span class=w>      </span><span class=nt>credentialName</span><span class=p>:</span><span class=w> </span><span class=l>wildcard-tls</span><span class=w>
</span><span class=w>    </span><span class=nt>hosts</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=s2>&#34;httpbin.gsicdc.mydomain.io&#34;</span><span class=w>
</span><span class=w></span><span class=nn>---</span><span class=w>
</span><span class=w></span><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>networking.istio.io/v1beta1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>VirtualService</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>httpbin-vs</span><span class=w>
</span><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>production</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>hosts</span><span class=p>:</span><span class=w>
</span><span class=w>  </span>- <span class=s2>&#34;httpbin.gsicdc.mydomain.io&#34;</span><span class=w>
</span><span class=w>  </span><span class=nt>gateways</span><span class=p>:</span><span class=w>
</span><span class=w>  </span>- <span class=l>httpbin-gw</span><span class=w>
</span><span class=w>  </span><span class=nt>http</span><span class=p>:</span><span class=w>
</span><span class=w>  </span>- <span class=nt>match</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>uri</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>regex</span><span class=p>:</span><span class=w> </span><span class=l>/.*</span><span class=w>
</span><span class=w>    </span><span class=nt>route</span><span class=p>:</span><span class=w>
</span><span class=w>    </span>- <span class=nt>destination</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>port</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>number</span><span class=p>:</span><span class=w> </span><span class=m>8000</span><span class=w>
</span><span class=w>        </span><span class=nt>host</span><span class=p>:</span><span class=w> </span><span class=l>httpbin</span><span class=w>
</span><span class=w></span><span class=nn>---</span><span class=w>
</span></code></pre></div><p>Let us now deploy the whole package of Kubernetes primitives using <code>kapp</code>:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ kapp deploy -a httpbin -f httpbin-kapp.yaml
Target cluster <span class=s1>&#39;https://api.gsicdc.myproject.shoot.devgarden.cloud&#39;</span> <span class=o>(</span>nodes: shoot--myproject--gsicdc-my-workerpool-z1-6586c8f6cb-x24kh<span class=o>)</span>

Changes

Namespace   Name        Kind            Conds.  Age  Op      Wait to    Rs  Ri
<span class=o>(</span>cluster<span class=o>)</span>   production  Namespace       -       -    create  reconcile  -   -
production  httpbin     Deployment      -       -    create  reconcile  -   -
^           httpbin     Service         -       -    create  reconcile  -   -
^           httpbin-gw  Gateway         -       -    create  reconcile  -   -
^           httpbin-vs  VirtualService  -       -    create  reconcile  -   -

Op:      <span class=m>5</span> create, <span class=m>0</span> delete, <span class=m>0</span> update, <span class=m>0</span> noop
Wait to: <span class=m>5</span> reconcile, <span class=m>0</span> delete, <span class=m>0</span> noop

Continue? <span class=o>[</span>yN<span class=o>]</span>: y

5:36:31PM: ---- applying <span class=m>1</span> changes <span class=o>[</span>0/5 <span class=k>done</span><span class=o>]</span> ----
&lt;snip&gt;
5:37:00PM: ok: reconcile deployment/httpbin <span class=o>(</span>apps/v1<span class=o>)</span> namespace: production
5:37:00PM: ---- applying <span class=nb>complete</span> <span class=o>[</span>5/5 <span class=k>done</span><span class=o>]</span> ----
5:37:00PM: ---- waiting <span class=nb>complete</span> <span class=o>[</span>5/5 <span class=k>done</span><span class=o>]</span> ----

Succeeded
</code></pre></div><p>Let&rsquo;s finaly test the service (Of course you can use the browser as well):</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ http httpbin.gsicdc.mydomain.io
HTTP/1.1 <span class=m>301</span> Moved Permanently
content-length: <span class=m>0</span>
date: Wed, <span class=m>13</span> May <span class=m>2020</span> 21:29:13 GMT
location: https://httpbin.gsicdc.mydomain.io/
server: istio-envoy

$ curl -k https://httpbin.gsicdc.mydomain.io/ip
<span class=o>{</span>
    <span class=s2>&#34;origin&#34;</span>: <span class=s2>&#34;10.250.0.2&#34;</span>
<span class=o>}</span>
</code></pre></div><p>Quod erat demonstrandum.
The proof of exchanging the issuer is now left to the reader.</p><div class="alert alert-primary" role=alert><h4 class=alert-heading>Tip</h4>Remember that the certificate is actually not valid because it is issued from the Let's encrypt staging environment. Thus, we needed "curl -k" or "http --verify no".</div><p>Hint: use the interactive k9s tool.
<img src=/__resources/k9s_e59227.png alt=k9s></p><h2 id=cleanup>Cleanup</h2><p>Remove the cloud native application:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ kapp ls
Apps in namespace <span class=s1>&#39;default&#39;</span>

Name     Namespaces            Lcs   Lca
httpbin  <span class=o>(</span>cluster<span class=o>)</span>,production  <span class=nb>true</span>  17m

$ kapp delete -a httpbin
...
Continue? <span class=o>[</span>yN<span class=o>]</span>: y
...
11:47:47PM: ---- waiting <span class=nb>complete</span> <span class=o>[</span>8/8 <span class=k>done</span><span class=o>]</span> ----

Succeeded
</code></pre></div><p>Remove Istio:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>$ istioctl x uninstall --purge
clusterrole.rbac.authorization.k8s.io <span class=s2>&#34;prometheus-istio-system&#34;</span> deleted
clusterrolebinding.rbac.authorization.k8s.io <span class=s2>&#34;prometheus-istio-system&#34;</span> deleted
...
</code></pre></div><p>Delete your Shoot:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>kgarden annotate shoot gsicdc confirmation.gardener.cloud/deletion<span class=o>=</span><span class=nb>true</span> --overwrite
kgarden delete shoot gsicdc --wait<span class=o>=</span><span class=nb>false</span>
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-d100c12a1d1b23c6d674069394a6bcf2>4 - GPU Enabled Cluster</h1><div class=lead>Setting up a GPU Enabled Cluster for Deep Learning</div><h2 id=intro>Intro</h2><p>Be aware, that the following sections might be opinionated. Kubernetes, and the GPU support in particular,
are rapidly evolving, which means that this guide is likely to be outdated sometime soon. For this reason,
<strong>contributions are highly appreciated</strong> to update this guide.</p><h2 id=create-a-cluster>Create a Cluster</h2><p>First thing first, let’s create a k8s cluster with GPU accelerated nodes. In this example we will use AWS
<strong>p2.xlarge</strong> EC2 instance because it&rsquo;s the cheapest available option at the moment. Use such cheap instances
for learning to limit your resource costs. <strong>This costs around 1€/hour per GPU</strong></p><p><img src=/__resources/howto-gpu_4413ce.png alt=gpu-selection></p><h2 id=install-nvidia-driver-as-daemonset>Install NVidia Driver as Daemonset</h2><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>DaemonSet</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-driver-installer</span><span class=w>
</span><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>kube-system</span><span class=w>
</span><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-driver-installer</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-driver-installer</span><span class=w>
</span><span class=w>      </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-driver-installer</span><span class=w>
</span><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-driver-installer</span><span class=w>
</span><span class=w>        </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-driver-installer</span><span class=w>
</span><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>hostPID</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>      </span><span class=nt>initContainers</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>squat/modulus:4a1799e7aa0143bcbb70d354bab3e419b1f54972</span><span class=w>
</span><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>modulus</span><span class=w>
</span><span class=w>        </span><span class=nt>args</span><span class=p>:</span><span class=w>
</span><span class=w>        </span>- <span class=l>compile</span><span class=w>
</span><span class=w>        </span>- <span class=l>nvidia</span><span class=w>
</span><span class=w>        </span>- <span class=s2>&#34;410.104&#34;</span><span class=w>
</span><span class=w>        </span><span class=nt>securityContext</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>privileged</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>        </span><span class=nt>env</span><span class=p>:</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>MODULUS_CHROOT</span><span class=w>
</span><span class=w>          </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>MODULUS_INSTALL</span><span class=w>
</span><span class=w>          </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>MODULUS_INSTALL_DIR</span><span class=w>
</span><span class=w>          </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=l>/opt/drivers</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>MODULUS_CACHE_DIR</span><span class=w>
</span><span class=w>          </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=l>/opt/modulus/cache</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>MODULUS_LD_ROOT</span><span class=w>
</span><span class=w>          </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=l>/root</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>IGNORE_MISSING_MODULE_SYMVERS</span><span class=w>
</span><span class=w>          </span><span class=nt>value</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;1&#34;</span><span class=w>          
</span><span class=w>        </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>etc-coreos</span><span class=w>
</span><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/etc/coreos</span><span class=w>
</span><span class=w>          </span><span class=nt>readOnly</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>usr-share-coreos</span><span class=w>
</span><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/usr/share/coreos</span><span class=w>
</span><span class=w>          </span><span class=nt>readOnly</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>ld-root</span><span class=w>
</span><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/root</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>module-cache</span><span class=w>
</span><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/opt/modulus/cache</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>module-install-dir-base</span><span class=w>
</span><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/opt/drivers</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>dev</span><span class=w>
</span><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/dev</span><span class=w>
</span><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;gcr.io/google-containers/pause:3.1&#34;</span><span class=w>
</span><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>pause</span><span class=w>
</span><span class=w>      </span><span class=nt>tolerations</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;nvidia.com/gpu&#34;</span><span class=w>
</span><span class=w>        </span><span class=nt>effect</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;NoSchedule&#34;</span><span class=w>
</span><span class=w>        </span><span class=nt>operator</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Exists&#34;</span><span class=w>
</span><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>etc-coreos</span><span class=w>
</span><span class=w>        </span><span class=nt>hostPath</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/etc/coreos</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>usr-share-coreos</span><span class=w>
</span><span class=w>        </span><span class=nt>hostPath</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/usr/share/coreos</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>ld-root</span><span class=w>
</span><span class=w>        </span><span class=nt>hostPath</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>module-cache</span><span class=w>
</span><span class=w>        </span><span class=nt>hostPath</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/opt/modulus/cache</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>dev</span><span class=w>
</span><span class=w>        </span><span class=nt>hostPath</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/dev</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>module-install-dir-base</span><span class=w>
</span><span class=w>        </span><span class=nt>hostPath</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/opt/drivers</span><span class=w>
</span></code></pre></div><h2 id=install-device-plugin>Install Device Plugin</h2><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>DaemonSet</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-gpu-device-plugin</span><span class=w>
</span><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>kube-system</span><span class=w>
</span><span class=w>  </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-gpu-device-plugin</span><span class=w>
</span><span class=w>    </span><span class=c>#addonmanager.kubernetes.io/mode: Reconcile</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-gpu-device-plugin</span><span class=w>
</span><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>k8s-app</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-gpu-device-plugin</span><span class=w>
</span><span class=w>      </span><span class=nt>annotations</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>scheduler.alpha.kubernetes.io/critical-pod</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;&#39;</span><span class=w>
</span><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>priorityClassName</span><span class=p>:</span><span class=w> </span><span class=l>system-node-critical</span><span class=w>
</span><span class=w>      </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>device-plugin</span><span class=w>
</span><span class=w>        </span><span class=nt>hostPath</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/var/lib/kubelet/device-plugins</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>dev</span><span class=w>
</span><span class=w>        </span><span class=nt>hostPath</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/dev</span><span class=w>
</span><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;k8s.gcr.io/nvidia-gpu-device-plugin@sha256:08509a36233c5096bb273a492251a9a5ca28558ab36d74007ca2a9d3f0b61e1d&#34;</span><span class=w>
</span><span class=w>        </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&#34;/usr/bin/nvidia-gpu-device-plugin&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;-logtostderr&#34;</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;-host-path=/opt/drivers/nvidia&#34;</span><span class=p>]</span><span class=w>
</span><span class=w>        </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nvidia-gpu-device-plugin</span><span class=w>
</span><span class=w>        </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>requests</span><span class=p>:</span><span class=w>
</span><span class=w>            </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=l>50m</span><span class=w>
</span><span class=w>            </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>10Mi</span><span class=w>
</span><span class=w>          </span><span class=nt>limits</span><span class=p>:</span><span class=w>
</span><span class=w>            </span><span class=nt>cpu</span><span class=p>:</span><span class=w> </span><span class=l>50m</span><span class=w>
</span><span class=w>            </span><span class=nt>memory</span><span class=p>:</span><span class=w> </span><span class=l>10Mi</span><span class=w>
</span><span class=w>        </span><span class=nt>securityContext</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>privileged</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span><span class=w>        </span><span class=nt>volumeMounts</span><span class=p>:</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>device-plugin</span><span class=w>
</span><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/device-plugin</span><span class=w>
</span><span class=w>        </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>dev</span><span class=w>
</span><span class=w>          </span><span class=nt>mountPath</span><span class=p>:</span><span class=w> </span><span class=l>/dev</span><span class=w>
</span><span class=w>  </span><span class=nt>updateStrategy</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>type</span><span class=p>:</span><span class=w> </span><span class=l>RollingUpdate</span><span class=w>
</span></code></pre></div><h2 id=test>Test</h2><p>To run an example training on a GPU node, start first a base image with Tensorflow with GPU support & Keras</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>apps/v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>Deployment</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>deeplearning-workbench</span><span class=w>
</span><span class=w>  </span><span class=nt>namespace</span><span class=p>:</span><span class=w> </span><span class=l>default</span><span class=w>
</span><span class=w></span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>replicas</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span><span class=w>  </span><span class=nt>selector</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>matchLabels</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>deeplearning-workbench</span><span class=w>
</span><span class=w>  </span><span class=nt>template</span><span class=p>:</span><span class=w>
</span><span class=w>    </span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>labels</span><span class=p>:</span><span class=w>
</span><span class=w>        </span><span class=nt>app</span><span class=p>:</span><span class=w> </span><span class=l>deeplearning-workbench</span><span class=w>
</span><span class=w>    </span><span class=nt>spec</span><span class=p>:</span><span class=w>
</span><span class=w>      </span><span class=nt>containers</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>deeplearning-workbench</span><span class=w>
</span><span class=w>        </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>afritzler/deeplearning-workbench</span><span class=w>
</span><span class=w>        </span><span class=nt>resources</span><span class=p>:</span><span class=w>
</span><span class=w>          </span><span class=nt>limits</span><span class=p>:</span><span class=w>
</span><span class=w>            </span><span class=nt>nvidia.com/gpu</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span><span class=w>      </span><span class=nt>tolerations</span><span class=p>:</span><span class=w>
</span><span class=w>      </span>- <span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;nvidia.com/gpu&#34;</span><span class=w>
</span><span class=w>        </span><span class=nt>effect</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;NoSchedule&#34;</span><span class=w>
</span><span class=w>        </span><span class=nt>operator</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;Exists&#34;</span><span class=w>
</span></code></pre></div><p>Note: the <code>tolerations</code> section above is not required if you deploy the <code>ExtendedResourceToleration</code>
admission controller to your cluster. You can do this in the <code>kubernetes</code> section of your Gardener
cluster <code>shoot.yaml</code> as follows:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>  kubernetes:
    kubeAPIServer:
      admissionPlugins:
      - name: ExtendedResourceToleration
</code></pre></div><p>Now exec into the container and start an example Keras training</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>kubectl <span class=nb>exec</span> -it deeplearning-workbench-8676458f5d-p4d2v -- /bin/bash
<span class=nb>cd</span> /keras/example
python imdb_cnn.py
</code></pre></div><h2 id=acknowledgments--references>Acknowledgments & References</h2><ul><li><a href=https://github.com/afritzler/kubernetes-gpu>Andreas Fritzler</a> from the Gardener Core team for the R&D and providing this setup.</li><li><a href=https://github.com/squat/modulus>Build and install NVIDIA driver on CoreOS</a></li><li><a href=https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/device-plugins/nvidia-gpu/daemonset.yaml>Nvidia Device Plugin</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-82db4b0a88ec43d5df912dae1cd481bf>5 - Install Knative in Gardener clusters</h1><div class=lead>A walkthrough the steps for installing Knative in Gardener shoot clusters.</div><p>This guide walks you through the installation of the latest version of Knative
using pre-built images on a <a href=https://gardener.cloud>Gardener</a> created cluster
environment. To set up your own Gardener, see the
<a href=https://github.com/gardener/gardener/blob/master/docs/README.md>documentation</a>
or have a look at the
<a href=https://github.com/gardener/landscape-setup-template>landscape-setup-template</a>
project. To learn more about this open source project, read the
<a href=https://kubernetes.io/blog/2018/05/17/gardener/>blog on kubernetes.io</a>.</p><h2 id=before-you-begin>Before you begin</h2><p>Knative requires a Kubernetes cluster v1.15 or newer.</p><h3 id=install-and-configure-kubectl>Install and configure kubectl</h3><ol><li><p>If you already have <code>kubectl</code> CLI, run <code>kubectl version --short</code> to check
the version. You need v1.10 or newer. If your <code>kubectl</code> is older, follow the
next step to install a newer version.</p></li><li><p><a href=https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl>Install the kubectl CLI</a>.</p></li></ol><h3 id=access-gardener>Access Gardener</h3><ol><li><p>Create a project in the Gardener dashboard. This will essentially create a
Kubernetes namespace with the name <code>garden-&lt;my-project></code>.</p></li><li><p><a href=https://kubernetes.io/docs/tasks/tools/install-kubectl/#configure-kubectl>Configure access to your Gardener project</a>
using a kubeconfig. If you are not the Gardener Administrator already, you
can create a technical user in the Gardener dashboard: go to the &ldquo;Members&rdquo;
section and add a service account. You can then download the kubeconfig for
your project. You can skip this step if you create your cluster using the
user interface; it is only needed for programmatic access, make sure you set
<code>export KUBECONFIG=garden-my-project.yaml</code> in your shell.
<img src=/__resources/gardener_service_account_0a4a8a.png alt="Download kubeconfig for Gardener" title="downloading the kubeconfig using a service account"></p></li></ol><h3 id=creating-a-kubernetes-cluster>Creating a Kubernetes cluster</h3><p>You can create your cluster using <code>kubectl</code> cli by providing a cluster
specification yaml file. You can find an example for GCP
<a href=https://github.com/gardener/gardener/blob/master/example/90-shoot.yaml>here</a>.
Make sure the namespace matches that of your project. Then just apply the
prepared so-called &ldquo;shoot&rdquo; cluster crd with kubectl:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl apply --filename my-cluster.yaml
</code></pre></div><p>The easier alternative is to create the cluster following the cluster creation
wizard in the Gardener dashboard:
<img src=/__resources/gardener_shoot_creation_49a4ca.png alt="shoot creation" title="shoot creation via the dashboard"></p><h3 id=configure-kubectl-for-your-cluster>Configure kubectl for your cluster</h3><p>You can now download the kubeconfig for your freshly created cluster in the
Gardener dashboard or via cli as follows:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl --namespace shoot--my-project--my-cluster get secret kubecfg --output jsonpath={.data.kubeconfig} | base64 --decode &gt; my-cluster.yaml
</code></pre></div><p>This kubeconfig file has full administrators access to you cluster. For the rest
of this guide be sure you have <code>export KUBECONFIG=my-cluster.yaml</code> set.</p><h2 id=installing-istio>Installing Istio</h2><p>Knative depends on Istio. If your cloud platform offers a managed Istio
installation, we recommend installing Istio that way, unless you need the
ability to customize your installation.</p><p>Otherwise, see the <a href=https://knative.dev/docs/install/installing-istio/>Installing Istio for Knative guide</a>
to install Istio.</p><p>You must install Istio on your Kubernetes cluster before continuing with these
instructions to install Knative.</p><h2 id=installing-cluster-local-gateway-for-serving-cluster-internal-traffic>Installing <code>cluster-local-gateway</code> for serving cluster-internal traffic</h2><p>If you installed Istio, you can install a <code>cluster-local-gateway</code> within your Knative cluster so that you can serve cluster-internal traffic. If you want to configure your revisions to use routes that are visible only within your cluster, <a href=https://knative.dev/docs/admin/install/knative-offerings/>install and use the <code>cluster-local-gateway</code></a>.</p><h2 id=installing-knative>Installing Knative</h2><p>The following commands install all available Knative components as well as the
standard set of observability plugins. Knative&rsquo;s installation guide - <a href=https://knative.dev/docs/admin/install/>Installing Knative</a>.</p><ol><li><p>If you are upgrading from Knative 0.3.x: Update your domain and static IP
address to be associated with the LoadBalancer <code>istio-ingressgateway</code> instead
of <code>knative-ingressgateway</code>. Then run the following to clean up leftover
resources:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl delete svc knative-ingressgateway -n istio-system
kubectl delete deploy knative-ingressgateway -n istio-system
</code></pre></div><p>If you have the Knative Eventing Sources component installed, you will also
need to delete the following resource before upgrading:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl delete statefulset/controller-manager -n knative-sources
</code></pre></div><p>While the deletion of this resource during the upgrade process will not
prevent modifications to Eventing Source resources, those changes will not be
completed until the upgrade process finishes.</p></li><li><p>To install Knative, first install the CRDs by running the <code>kubectl apply</code>
command once with the <code>-l knative.dev/crd-install=true</code> flag. This prevents
race conditions during the install, which cause intermittent errors:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>kubectl apply --selector knative.dev/crd-install<span class=o>=</span><span class=nb>true</span> <span class=se>\
</span><span class=se></span>--filename https://github.com/knative/serving/releases/download/v0.12.1/serving.yaml <span class=se>\
</span><span class=se></span>--filename https://github.com/knative/eventing/releases/download/v0.12.1/eventing.yaml <span class=se>\
</span><span class=se></span>--filename https://github.com/knative/serving/releases/download/v0.12.1/monitoring.yaml
</code></pre></div></li><li><p>To complete the install of Knative and its dependencies, run the
<code>kubectl apply</code> command again, this time without the <code>--selector</code> flag, to
complete the install of Knative and its dependencies:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>kubectl apply --filename https://github.com/knative/serving/releases/download/v0.12.1/serving.yaml <span class=se>\
</span><span class=se></span>--filename https://github.com/knative/eventing/releases/download/v0.12.1/eventing.yaml <span class=se>\
</span><span class=se></span>--filename https://github.com/knative/serving/releases/download/v0.12.1/monitoring.yaml
</code></pre></div></li><li><p>Monitor the Knative components until all of the components show a <code>STATUS</code> of
<code>Running</code>:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>kubectl get pods --namespace knative-serving
kubectl get pods --namespace knative-eventing
kubectl get pods --namespace knative-monitoring
</code></pre></div></li></ol><h2 id=set-your-custom-domain>Set your custom domain</h2><ol><li>Fetch the external IP or CNAME of the knative-ingressgateway</li></ol><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl --namespace istio-system get service knative-ingressgateway
NAME                     TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                                      AGE
knative-ingressgateway   LoadBalancer   100.70.219.81   35.233.41.212   80:32380/TCP,443:32390/TCP,32400:32400/TCP   4d
</code></pre></div><ol start=2><li>Create a wildcard DNS entry in your custom domain to point to above IP or
CNAME</li></ol><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>*.knative.&lt;my domain&gt; == A 35.233.41.212
# or CNAME if you are on AWS
*.knative.&lt;my domain&gt; == CNAME a317a278525d111e89f272a164fd35fb-1510370581.eu-central-1.elb.amazonaws.com
</code></pre></div><ol start=3><li>Adapt your knative config-domain (set your domain in the data field)</li></ol><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl --namespace knative-serving get configmaps config-domain --output yaml
apiVersion: v1
data:
  knative.&lt;my domain&gt;: &#34;&#34;
kind: ConfigMap
  name: config-domain
  namespace: knative-serving
</code></pre></div><h2 id=whats-next>What&rsquo;s next</h2><p>Now that your cluster has Knative installed, you can see what Knative has to
offer.</p><p>To deploy your first app with the
<a href=https://knative.dev/docs/serving/getting-started-knative-app/>Getting Started with Knative App Deployment</a>
guide.</p><p>Get started with Knative Eventing by walking through one of the
<a href=https://knative.dev/docs/eventing/samples/>Eventing Samples</a>.</p><p><a href=https://knative.dev/docs/serving/installing-cert-manager/>Install Cert-Manager</a> if you want to use the
<a href=https://knative.dev/docs/serving/using-auto-tls/>automatic TLS cert provisioning feature</a>.</p><h2 id=cleaning-up>Cleaning up</h2><p>Use the Gardener dashboard to delete your cluster, or execute the following with
kubectl pointing to your <code>garden-my-project.yaml</code> kubeconfig:</p><div class=highlight><pre class=chroma><code class=language-fallback data-lang=fallback>kubectl --kubeconfig garden-my-project.yaml --namespace garden--my-project annotate shoot my-cluster confirmation.gardener.cloud/deletion=true

kubectl --kubeconfig garden-my-project.yaml --namespace garden--my-project delete shoot my-cluster
</code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-b25746ecc02152f58a677e6b79819ba8>6 - Shared storage with S3 backend</h1><div class=lead>Using S3 bucket as shared storage for pods</div><h2 id=shared-storage-with-s3-backend>Shared storage with S3 backend</h2><p>The storage is definitely the most complex and important part of an application setup, once this part is
completed, 80% of the tasks are completed.</p><p>Mounting an S3 bucket into a pod using FUSE allows you to access the data as if it were on the local disk. The
mount is a pointer to an S3 location, so the data is never synced locally. Once mounted, any pod can read or even write
from that directory without the need for explicit keys.</p><p>However, it can be used to import and parse large amounts of data into a database.</p><h2 id=overview>Overview</h2><p><img src=https://github.com/freegroup/kube-s3/raw/master/images/s3-mount.png alt=s3-mount></p><h2 id=limitations>Limitations</h2><p>Generally S3 cannot offer the same performance or semantics as a local file system. More specifically:</p><ul><li>random writes or appends to files require rewriting the entire file</li><li>metadata operations such as listing directories have poor performance due to network latency</li><li>eventual consistency can temporarily yield stale data(Amazon S3 Data Consistency Model)</li><li>no atomic renames of files or directories</li><li>no coordination between multiple clients mounting the same bucket</li><li>no hard links</li></ul><h2 id=before-you-begin>Before you Begin</h2><p>You need to have a Kubernetes cluster, and the kubectl command-line tool must be configured to communicate with
your cluster. If you do not already have a cluster, you can create one by using the <a href=https://gardener.cloud/>Gardener</a>.</p><p>Ensure that you have create the &ldquo;imagePullSecret&rdquo; in your cluster.</p><div class=highlight><pre class=chroma><code class=language-sh data-lang=sh>kubectl create secret docker-registry artifactory --docker-server<span class=o>=</span>&lt;YOUR-REGISTRY&gt;.docker.repositories.sap.ondemand.com --docker-username<span class=o>=</span>&lt;USERNAME&gt; --docker-password<span class=o>=</span>&lt;PASSWORD&gt; --docker-email<span class=o>=</span>&lt;EMAIL&gt; -n &lt;NAMESPACE&gt;
</code></pre></div><h2 id=setup>Setup</h2><p>The first step is to clone this repository. Next is the Secret for the AWS API credentials of the user that has
full access to our S3 bucket. Copy the <code>configmap_secrets_template.yaml</code> to <code>configmap_secrets.yaml</code> and place
your secrets at the right place</p><div class=highlight><pre class=chroma><code class=language-yaml data-lang=yaml><span class=nt>apiVersion</span><span class=p>:</span><span class=w> </span><span class=l>v1</span><span class=w>
</span><span class=w></span><span class=nt>kind</span><span class=p>:</span><span class=w> </span><span class=l>ConfigMap</span><span class=w>
</span><span class=w></span><span class=nt>metadata</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>s3-config</span><span class=w>
</span><span class=w></span><span class=nt>data</span><span class=p>:</span><span class=w>
</span><span class=w>  </span><span class=nt>S3_BUCKET</span><span class=p>:</span><span class=w> </span><span class=l>&lt;YOUR-S3-BUCKET-NAME&gt;</span><span class=w>
</span><span class=w>  </span><span class=nt>AWS_KEY</span><span class=p>:</span><span class=w> </span><span class=l>&lt;YOUR-AWS-TECH-USER-ACCESS-KEY&gt;</span><span class=w>
</span><span class=w>  </span><span class=nt>AWS_SECRET_KEY</span><span class=p>:</span><span class=w> </span><span class=l>&lt;YOUR-AWS-TECH-USER-SECRET&gt;</span><span class=w>
</span></code></pre></div><h2 id=build-and-deploy>Build and deploy</h2><p>Change the settings in the <code>build.sh</code> file with your docker registry settings.</p><div class=highlight><pre class=chroma><code class=language-sh data-lang=sh><span class=cp>#!/usr/bin/env bash
</span><span class=cp></span>
<span class=c1>########################################################################################################################</span>
<span class=c1># PREREQUISTITS</span>
<span class=c1>########################################################################################################################</span>
<span class=c1>#</span>
<span class=c1># - ensure that you have a valid Artifactory or other Docker registry account</span>
<span class=c1># - Create your image pull secret in your namespace</span>
<span class=c1>#   kubectl create secret docker-registry artifactory --docker-server=&lt;YOUR-REGISTRY&gt;.docker.repositories.sap.ondemand.com --docker-username=&lt;USERNAME&gt; --docker-password=&lt;PASSWORD&gt; --docker-email=&lt;EMAIL&gt; -n &lt;NAMESPACE&gt;</span>
<span class=c1># - change the settings below arcording your settings</span>
<span class=c1>#</span>
<span class=c1># usage:</span>
<span class=c1># Call this script with the version to build and push to the registry. After build/push the</span>
<span class=c1># yaml/* files are deployed into your cluster</span>
<span class=c1>#</span>
<span class=c1>#  ./build.sh 1.0</span>
<span class=c1>#</span>
<span class=nv>VERSION</span><span class=o>=</span><span class=nv>$1</span>
<span class=nv>PROJECT</span><span class=o>=</span>kube-s3
<span class=nv>REPOSITORY</span><span class=o>=</span>cp-enablement.docker.repositories.sap.ondemand.com


<span class=c1># causes the shell to exit if any subcommand or pipeline returns a non-zero status.</span>
<span class=nb>set</span> -e
<span class=c1># set debug mode</span>
<span class=c1>#set -x</span>

.
.
.
.

</code></pre></div><p>Create the S3Fuse Pod and check the status:</p><div class=highlight><pre class=chroma><code class=language-sh data-lang=sh><span class=c1># build and push the image to your docker registry</span>
./build.sh 1.0 

<span class=c1># check that the pods are up and running</span>
kubectl get pods

</code></pre></div><h2 id=check-success>Check success</h2><p>Create a demo Pod and check the status:</p><div class=highlight><pre class=chroma><code class=language-sh data-lang=sh>kubectl apply -f ./yaml/example_pod.yaml

<span class=c1># wait some second to get the pod up and running...</span>
kubectl get pods

<span class=c1># go into the pd and check that the /var/s3 is mounted with your S3 bucket content inside</span>
kubectl <span class=nb>exec</span> -ti test-pd  sh

<span class=c1># inside the pod</span>
ls -la /var/s3

</code></pre></div><h2 id=why-does-this-work>Why does this work?</h2><p>Docker engine 1.10 added a new feature which allows containers to share the host mount namespace. This feature makes
it possible to mount a s3fs container file system to a host file system through a shared mount, providing a persistent
network storage with S3 backend.</p><p>The key part is mountPath: <code>/var/s3:shared</code> which enables the volume to be mounted as shared inside the pod. When the
container starts it will mount the S3 bucket onto <code>/var/s3</code> and consequently the data will be available under
<code>/mnt/data-s3fs</code> on the host and thus to any other container/pod running on it (and has <code>/mnt/data-s3fs</code> mounted too).</p></div></main></div></div><footer class="footer row d-print-none"><div class="container-fluid footer-wrapper"><ul class=nav><li><a href=/blog/>Blogs</a></li><li><a href=/community/>Community</a></li><li><a href=/adopter/>Adopters</a></li><li><a href=/docs/>Documentation</a></li></ul><img src=/images/lp/gardener-logo.svg alt="Logo Gardener" class=logo><ul class=media-wr><li><a target=_blank href=https://kubernetes.slack.com/archives/CB57N0BFG><img src=/images/branding/slack-logo-white.svg class=media-icon><div class=media-text>Slack</div></a></li><li><a target=_blank href=https://github.com/gardener><img src=/images/branding/github-mark-logo.png class=media-icon><div class=media-text>GitHub</div></a></li><li><a target=_blank href=https://www.youtube.com/channel/UCwUhwKFREV8Su0gwAJQX7tw><img src=/images/branding/youtube-logo-dark.svg class=media-icon><div class=media-text>YouTube</div></a></li><li><a target=_blank href=https://twitter.com/GardenerProject><img src=/images/branding/twitter-logo-white.svg class=media-icon><div class=media-text>Twitter</div></a></li></ul><span class=copyright>Copyright 2019-2021 Gardener project authors. <a href=https://www.sap.com/corporate/en/legal/privacy.html>Privacy policy
<i class="fa fa-external-link" aria-hidden=true></i></a></span></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js integrity=sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF crossorigin=anonymous></script><script src=/js/main.min.3b172c13b62c2bea8b1c9d2599cddc8cf89718a92d792c680871c81ba43d8c85.js integrity="sha256-OxcsE7YsK+qLHJ0lmc3cjPiXGKkteSxoCHHIG6Q9jIU=" crossorigin=anonymous></script></body></html>