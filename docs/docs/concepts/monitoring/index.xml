<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gardener â€“ Monitoring</title><link>https://gardener.cloud/docs/concepts/monitoring/</link><description>Recent content in Monitoring on Gardener</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://gardener.cloud/docs/concepts/monitoring/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: Alerting</title><link>https://gardener.cloud/docs/concepts/monitoring/alerting/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/concepts/monitoring/alerting/</guid><description>
&lt;h1 id="alerting">Alerting&lt;/h1>
&lt;p>Gardener uses &lt;a href="https://prometheus.io/">Prometheus&lt;/a> to gather metrics from each component. A Prometheus is deployed in each shoot control plane (on the seed) which is responsible for gathering control plane and cluster metrics. Prometheus can be configured to fire alerts based on these metrics and send them to an &lt;a href="https://prometheus.io/docs/alerting/alertmanager/">alertmanager&lt;/a>. The alertmanager is responsible for sending the alerts to users and operators. This document describes how to setup alerting for:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#Alerting-for-Users">end-users/stakeholders/customers&lt;/a>&lt;/li>
&lt;li>&lt;a href="#Alerting-for-Operators">operators/administrators&lt;/a>&lt;/li>
&lt;/ul>
&lt;h1 id="alerting-for-users">Alerting for Users&lt;/h1>
&lt;p>To receive email alerts as a user set the following values in the shoot spec:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="nt">spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">monitoring&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">alerting&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">emailReceivers&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>- &lt;span class="l">john.doe@example.com&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>emailReceivers&lt;/code> is a list of emails that will receive alerts if something is wrong with the shoot cluster. A list of alerts for users can be found &lt;a href="https://gardener.cloud/docs/concepts/monitoring/user_alerts">here&lt;/a>.&lt;/p>
&lt;h1 id="alerting-for-operators">Alerting for Operators&lt;/h1>
&lt;p>Currently, Gardener supports two options for alerting:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="#Email-Alerting">Email Alerting&lt;/a>&lt;/li>
&lt;li>&lt;a href="#External-Alertmanager">Sending Alerts to an external alertmanager&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>A list of operator alerts can be found &lt;a href="https://gardener.cloud/docs/concepts/monitoring/operator_alerts">here&lt;/a>.&lt;/p>
&lt;h2 id="email-alerting">Email Alerting&lt;/h2>
&lt;p>Gardener provides the option to deploy an alertmanager into each seed. This alertmanager is responsible for sending out alerts to operators for each shoot cluster in the seed. Only email alerts are supported by the alertmanager managed by Gardener. This is configurable by setting the Gardener controller manager configuration values &lt;code>alerting&lt;/code>. See &lt;a href="https://github.com/gardener/gardener/blob/master/docs/usage/configuration.md">this&lt;/a> on how to configure the Gardener&amp;rsquo;s SMTP secret. If the values are set, a secret with the label &lt;code>gardener.cloud/role: alerting&lt;/code> will be created in the garden namespace of the garden cluster. This secret will be used by each alertmanager in each seed.&lt;/p>
&lt;h2 id="external-alertmanager">External Alertmanager&lt;/h2>
&lt;p>The alertmanager supports different kinds of &lt;a href="https://prometheus.io/docs/alerting/configuration/">alerting configurations&lt;/a>. The alertmanager provided by Gardener only supports email alerts. If email is not sufficient, then alerts can be sent to an external alertmanager. Prometheus will send alerts to a URL and then alerts will be handled by the external alertmanager. This external alertmanager is operated and configured by the operator (i.e. Gardener does not configure or deploy this alertmanager). To configure sending alerts to an external alertmanager, create a secret in the virtual garden cluster in the garden namespace with the label: &lt;code>gardener.cloud/role: alerting&lt;/code>. This secret needs to contain a URL to the external alertmanager and information regarding authentication. Supported authentication types are:&lt;/p>
&lt;ul>
&lt;li>No Authentication (none)&lt;/li>
&lt;li>Basic Authentication (basic)&lt;/li>
&lt;li>Mutual TLS (certificate)&lt;/li>
&lt;/ul>
&lt;h3 id="remote-alertmanager-examples">Remote Alertmanager Examples&lt;/h3>
&lt;p>Note: the &lt;code>url&lt;/code> value cannot be prepended with &lt;code>http&lt;/code> or &lt;code>https&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="c"># No Authentication&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">apiVersion&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">v1&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">kind&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Secret&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">labels&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">gardener.cloud/role&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">alerting&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">alerting-auth&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">namespace&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">garden&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">data&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># No Authentication&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">auth_type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(none)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">url&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(external.alertmanager.foo)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># Basic Auth&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">auth_type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(basic)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">url&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(extenal.alertmanager.foo)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">username&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(admin)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">password&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(password)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># Mutual TLS&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">auth_type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(certificate)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">url&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(external.alertmanager.foo)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">ca.crt&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(ca)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">tls.crt&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(certificate)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">tls.key&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(key)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">insecure_skip_verify&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(false)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># Email Alerts (internal alertmanager)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">auth_type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(smtp)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">auth_identity&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(internal.alertmanager.auth_identity)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">auth_password&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(internal.alertmanager.auth_password)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">auth_username&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(internal.alertmanager.auth_username)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">from&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(internal.alertmanager.from)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">smarthost&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(internal.alertmanager.smarthost)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">to&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">base64(internal.alertmanager.to)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Opaque&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="configuring-your-external-alertmanager">Configuring your External Alertmanager&lt;/h3>
&lt;p>Please refer to the &lt;a href="https://prometheus.io/docs/alerting/alertmanager/">alertmanager&lt;/a> documentation on how to configure an alertmanager.&lt;/p>
&lt;p>We recommend you use at least the following inhibition rules in your alertmanager configuration to prevent excessive alerts:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="nt">inhibit_rules&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="c"># Apply inhibition if the alert name is the same.&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>- &lt;span class="nt">source_match&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">severity&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">critical&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">target_match&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">severity&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">warning&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">equal&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;alertname&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;service&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;cluster&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="c"># Stop all alerts for type=shoot if there are VPN problems.&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>- &lt;span class="nt">source_match&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">service&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">vpn&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">target_match_re&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">shoot&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">equal&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;type&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;cluster&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="c"># Stop warning and critical alerts if there is a blocker&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>- &lt;span class="nt">source_match&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">severity&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">blocker&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">target_match_re&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">severity&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">^(critical|warning)$&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">equal&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;cluster&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="c"># If the API server is down inhibit no worker nodes alert. No worker nodes depends on kube-state-metrics which depends on the API server.&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>- &lt;span class="nt">source_match&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">service&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">kube-apiserver&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">target_match_re&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">service&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">nodes&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">equal&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;cluster&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="c"># If API server is down inhibit kube-state-metrics alerts.&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>- &lt;span class="nt">source_match&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">service&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">kube-apiserver&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">target_match_re&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">severity&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">info&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">equal&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;cluster&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="c"># No Worker nodes depends on kube-state-metrics. Inhibit no worker nodes if kube-state-metrics is down.&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>- &lt;span class="nt">source_match&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">service&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">kube-state-metrics-shoot&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">target_match_re&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">service&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">nodes&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">equal&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;cluster&amp;#39;&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Below is a graph visualizing the inhibition rules:&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/alertInhibitionGraph_ceaef0.png" alt="inhibitionGraph">&lt;/p></description></item><item><title>Docs: Extending the Monitoring Stack</title><link>https://gardener.cloud/docs/concepts/monitoring/extending/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/concepts/monitoring/extending/</guid><description>
&lt;h1 id="extending-the-monitoring-stack">Extending the Monitoring Stack&lt;/h1>
&lt;p>This document provides instructions to extend the Shoot cluster monitoring stack by integrating new scrape targets, alerts and dashboards.&lt;/p>
&lt;p>Please ensure that you have understood the basic principles of &lt;a href="https://prometheus.io/docs/introduction/overview/">Prometheus&lt;/a> and its ecosystem before you continue.&lt;/p>
&lt;p>:bangbang: &lt;strong>The purpose of the monitoring stack is to observe the behaviour of the control plane and the system components deployed by Gardener onto the worker nodes. Monitoring of custom workloads running in the cluster is out of scope.&lt;/strong>&lt;/p>
&lt;h2 id="overview">Overview&lt;/h2>
&lt;p>&lt;img src="https://gardener.cloud/__resources/monitoring-architecture_cd945d.png" alt="Monitoring Architecture">&lt;/p>
&lt;p>Each Shoot cluster comes with its own monitoring stack. The following components are deployed into the seed and shoot:&lt;/p>
&lt;ul>
&lt;li>Seed
&lt;ul>
&lt;li>&lt;a href="https://github.com/prometheus/prometheus">Prometheus&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/grafana/grafana">Grafana&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/prometheus/blackbox_exporter">blackbox-exporter&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kube-state-metrics">kube-state-metrics&lt;/a> (Seed metrics)&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kube-state-metrics">kube-state-metrics&lt;/a> (Shoot metrics)&lt;/li>
&lt;li>&lt;a href="https://github.com/prometheus/alertmanager">Alertmanager&lt;/a> (Optional)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Shoot
&lt;ul>
&lt;li>&lt;a href="https://github.com/prometheus/node_exporter">node-exporter(s)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/kubernetes/kube-state-metrics">kube-state-metrics&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/prometheus/blackbox_exporter">blackbox-exporter&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>In each Seed cluster there is a Prometheus in the &lt;code>garden&lt;/code> namespace responsible for collecting metrics from the Seed kubelets and cAdvisors. These metrics are provided to each Shoot Prometheus via federation.&lt;/p>
&lt;p>The alerts for all Shoot clusters hosted on a Seed are routed to a central Alertmanger running in the &lt;code>garden&lt;/code> namespace of the Seed. The purpose of this central alertmanager is to forward all important alerts to the operators of the Gardener setup.&lt;/p>
&lt;p>The Alertmanager in the Shoot namespace on the Seed is only responsible for forwarding alerts from its Shoot cluster to a cluster owner/cluster alert receiver via email. The Alertmanager is optional and the conditions for a deployment are already described &lt;a href="https://gardener.cloud/docs/concepts/monitoring/alerting">here&lt;/a>.&lt;/p>
&lt;h2 id="adding-new-monitoring-targets">Adding New Monitoring Targets&lt;/h2>
&lt;p>After exploring the metrics which your component provides or adding new metrics, you should be aware which metrics are required to write the needed alerts and dashboards.&lt;/p>
&lt;p>Prometheus prefers a pull based metrics collection approach and therefore the targets to observe need to be defined upfront. The targets are defined in &lt;code>charts/seed-monitoring/charts/prometheus/templates/config.yaml&lt;/code>.
New scrape jobs can be added in the section &lt;code>scrape_configs&lt;/code>. Detailed information how to configure scrape jobs and how to use the kubernetes service discovery are available in the &lt;a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config">Prometheus documentation&lt;/a>.&lt;/p>
&lt;p>The &lt;code>job_name&lt;/code> of a scrape job should be the name of the component e.g. &lt;code>kube-apiserver&lt;/code> or &lt;code>vpn&lt;/code>. The collection interval should be the default of &lt;code>30s&lt;/code>. You do not need to specify this in the configuration.&lt;/p>
&lt;p>Please do not ingest all metrics which are provided by a component. Rather collect only those metrics which are needed to define the alerts and dashboards (i.e. whitelist). This can be achieved by adding the following &lt;code>metric_relabel_configs&lt;/code> statement to your scrape jobs (replace &lt;code>exampleComponent&lt;/code> with component name).&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="w"> &lt;/span>- &lt;span class="nt">job_name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">example-component&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">metric_relabel_configs&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>{{&lt;span class="w"> &lt;/span>&lt;span class="l">include &amp;#34;prometheus.keep-metrics.metric-relabel-config&amp;#34; .Values.allowedMetrics.exampleComponent | indent 6 }}&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The whitelist for the metrics of your job can be maintained in &lt;code>charts/seed-monitoring/charts/prometheus/values.yaml&lt;/code> in section &lt;code>allowedMetrics.exampleComponent&lt;/code> (replace &lt;code>exampleComponent&lt;/code> with component name). Check the following example:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="nt">allowedMetrics&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">exampleComponent&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>*&lt;span class="w"> &lt;/span>&lt;span class="l">metrics_name_1&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>*&lt;span class="w"> &lt;/span>&lt;span class="l">metrics_name_2&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="adding-alerts">Adding Alerts&lt;/h2>
&lt;p>The alert definitons are located in &lt;code>charts/seed-monitoring/charts/prometheus/rules&lt;/code>. There are two approaches for adding new alerts.&lt;/p>
&lt;ol>
&lt;li>Adding additional alerts for a component which already has a set of alerts. In this case you have to extend the existing rule file for the component.&lt;/li>
&lt;li>Adding alerts for a new component. In this case a new rule file with name scheme &lt;code>example-component.rules.yaml&lt;/code> needs to be added.&lt;/li>
&lt;li>Add the new alert to &lt;code>alertInhibitionGraph.dot&lt;/code>, add any required inhibition flows and render the new graph. To render the graph run:&lt;/li>
&lt;/ol>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">dot -Tpng ./content/alertInhibitionGraph.dot -o ./content/alertInhibitionGraph.png
&lt;/code>&lt;/pre>&lt;/div>&lt;ol>
&lt;li>Create a test for the new alert. See &lt;code>Alert Tests&lt;/code>.&lt;/li>
&lt;/ol>
&lt;p>Example alert:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="nt">groups&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w">&lt;/span>&lt;span class="nt">* name&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">example.rules&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">rules&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">* alert&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">ExampleAlert&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">expr&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">absent(up{job=&amp;#34;exampleJob&amp;#34;} == 1)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">for&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">20m&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">labels&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">service&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">example&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">severity&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">critical&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># How severe is the alert? (blocker|critical|info|warning)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">type&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">shoot&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># For which topology is the alert relevant? (seed|shoot)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">visibility&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">all&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c"># Who should receive the alerts? (all|operator|owner)&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">annotations&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">description&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">A longer description of the example alert that should also explain the impact of the alert.&lt;/span>&lt;span class="w">
&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nt">summary&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Short summary of an example alert.&lt;/span>&lt;span class="w">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>If the deployment of component is optional then the alert definitions needs to be added to &lt;code>charts/seed-monitoring/charts/prometheus/optional-rules&lt;/code> instead. Furthermore the alerts for component need to be activatable in &lt;code>charts/seed-monitoring/charts/prometheus/values.yaml&lt;/code> via &lt;code>rules.optional.example-component.enabled&lt;/code>. The default should be &lt;code>true&lt;/code>.&lt;/p>
&lt;p>Basic instruction how to define alert rules can be found in the &lt;a href="https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules">Prometheus documentation&lt;/a>.&lt;/p>
&lt;h3 id="routing-tree">Routing tree&lt;/h3>
&lt;p>The Alertmanager is grouping incoming alerts based on labels into buckets. Each bucket has its own configuration like alert receivers, initial delaying duration or resending frequency etc. You can find more information about Alertmanager routing in the &lt;a href="https://prometheus.io/docs/alerting/configuration/#route">Prometheus/Alertmanager documentation&lt;/a>. The routing trees for the Alertmanagers deployed by Gardener are depicted below.&lt;/p>
&lt;p>Central Seed Alertmanager&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-text" data-lang="text">âˆŸ main route (all alerts for all shoots on the seed will enter)
âˆŸ group by project and shoot name
âˆŸ group by visibility &amp;#34;all&amp;#34; and &amp;#34;operator&amp;#34;
âˆŸ group by severity &amp;#34;blocker&amp;#34;, &amp;#34;critical&amp;#34;, and &amp;#34;info&amp;#34; â†’ route to Garden operators
âˆŸ group by severity &amp;#34;warning&amp;#34; (dropped)
âˆŸ group by visibility &amp;#34;owner&amp;#34; (dropped)
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Shoot Alertmanager&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-text" data-lang="text">âˆŸ main route (only alerts for one Shoot will enter)
âˆŸ group by visibility &amp;#34;all&amp;#34; and &amp;#34;owner&amp;#34;
âˆŸ group by severity &amp;#34;blocker&amp;#34;, &amp;#34;critical&amp;#34;, and &amp;#34;info&amp;#34; â†’ route to cluster alert receiver
âˆŸ group by severity &amp;#34;warning&amp;#34; (dropped, will change soon â†’ route to cluster alert receiver)
âˆŸ group by visibility &amp;#34;operator&amp;#34; (dropped)
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="alert-inhibition">Alert Inhibition&lt;/h3>
&lt;p>All alerts related to components running on the Shoot workers are inhibited in case of an issue with the vpn connection, because those components can&amp;rsquo;t be scraped anymore and Prometheus will fire alerts in consequence. The components running on the workers are probably healthy and the alerts are presumably false positives. The inhibition flow is shown in the figure below. If you add a new alert make sure to add it to the diagram.&lt;/p>
&lt;p>&lt;img src="https://gardener.cloud/__resources/alertInhibitionGraph_ceaef0.png" alt="alertDiagram">&lt;/p>
&lt;h3 id="alert-attributes">Alert Attributes&lt;/h3>
&lt;p>Each alert rule definition has to contain the following annotations:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>summary&lt;/strong>: A short description of the issue.&lt;/li>
&lt;li>&lt;strong>description&lt;/strong>: A detailed explanation of the issue with hints to the possible root causes and the impact assessment of the issue.&lt;/li>
&lt;/ul>
&lt;p>In addtion each alert must contain the following labels:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>type&lt;/strong>
&lt;ul>
&lt;li>&lt;code>shoot&lt;/code>: Components running on the Shoot worker nodes in the &lt;code>kube-system&lt;/code> namespace.&lt;/li>
&lt;li>&lt;code>seed&lt;/code>: Components running on the Seed in the Shoot namespace as part of/next to the control plane.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>service&lt;/strong>
&lt;ul>
&lt;li>Name of the component (in lowercase) e.g. &lt;code>kube-apiserver&lt;/code>, &lt;code>alertmanager&lt;/code> or &lt;code>vpn&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;strong>severity&lt;/strong>
&lt;ul>
&lt;li>&lt;code>blocker&lt;/code>: All issues which make the cluster entirely unusable e.g. &lt;code>KubeAPIServerDown&lt;/code> or &lt;code>KubeSchedulerDown&lt;/code>&lt;/li>
&lt;li>&lt;code>critical&lt;/code>: All issues which affect single functionalities/components but not affect the cluster in its core functionality e.g. &lt;code>VPNDown&lt;/code> or &lt;code>KubeletDown&lt;/code>.&lt;/li>
&lt;li>&lt;code>info&lt;/code>: All issues that do not affect the cluster or its core functionality, but if this component is down we cannot determine if a blocker alert is firing. (i.e. A component with an info level severity is a dependency for a component with a blocker severity)&lt;/li>
&lt;li>&lt;code>warning&lt;/code>: No current existing issue, rather a hint for situations which could lead to real issue in the close future e.g. &lt;code>HighLatencyApiServerToWorkers&lt;/code> or &lt;code>ApiServerResponseSlow&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="alert-tests">Alert Tests&lt;/h3>
&lt;p>Execute the tests in &lt;code>$GARDENERHOME/.ci/test&lt;/code> or if you want to only test the Prometheus alerts:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="c1"># Install promtool&lt;/span>
go get -u github.com/prometheus/prometheus/cmd/promtool
&lt;span class="c1"># Move to seed-monitoring/prometheus chart&lt;/span>
&lt;span class="nb">cd&lt;/span> &lt;span class="nv">$GARDENERHOME&lt;/span>/charts/seed-monitoring/charts/prometheus/
&lt;span class="c1"># Execute tests&lt;/span>
promtool &lt;span class="nb">test&lt;/span> rules rules-tests/*test.yaml
&lt;/code>&lt;/pre>&lt;/div>&lt;p>If you want to add alert tests:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Create a new file in &lt;code>rules-tests&lt;/code> in the form &lt;code>&amp;lt;alert-group-name&amp;gt;.rules.test.yaml&lt;/code> or if the alerts are for an existing component with existing tests, simply add the tests to the appropriate files.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Make sure that newly added tests succeed. See above.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="adding-grafana-dashboards">Adding Grafana Dashboards&lt;/h2>
&lt;p>The dashboard definition files are located in &lt;code>charts/seed-monitoring/charts/grafana/dashboards&lt;/code>. Every dashboard needs its own file.&lt;/p>
&lt;p>If you are adding a new component dashboard please also update the overview dashboard by adding a chart for its current up/down status and with a drill down option to the component dashboard.&lt;/p>
&lt;h3 id="dashboard-structure">Dashboard Structure&lt;/h3>
&lt;p>The dashboards should be structured in the following way. The assignment of the component dashboards to the categories should be handled via dashboard tags.&lt;/p>
&lt;ul>
&lt;li>Kubernetes control plane components (Tag: &lt;code>control-plane&lt;/code>)
&lt;ul>
&lt;li>All components which are part of the Kubernetes control plane e. g. Kube API Server, Kube Controller Manager, Kube Scheduler and Cloud Controller Manager&lt;/li>
&lt;li>ETCD + Backup/Restore&lt;/li>
&lt;li>Kubernetes Addon Manager&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Node/Machine components (Tag: &lt;code>node/machine&lt;/code>)
&lt;ul>
&lt;li>All metrics which are related to the behaviour/control of the Kubernetes nodes and kubelets&lt;/li>
&lt;li>Machine-Controller-Manager + Cluster Autoscaler&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Networking components (Tag: &lt;code>network&lt;/code>)
&lt;ul>
&lt;li>CoreDNS, KubeProxy, Calico, VPN, Nginx Ingress&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Addon components (Tag: &lt;code>addon&lt;/code>)
&lt;ul>
&lt;li>Cert Broker&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Monitoring components (Tag: &lt;code>monitoring&lt;/code>)&lt;/li>
&lt;li>Logging components (Tag: &lt;code>logging&lt;/code>)&lt;/li>
&lt;/ul>
&lt;h4 id="mandatory-charts-for-component-dashboards">Mandatory Charts for Component Dashboards&lt;/h4>
&lt;p>For each new component, its corresponding dashboard should contain the following charts in the first row, before adding custom charts for the component in the subsequent rows.&lt;/p>
&lt;ol>
&lt;li>Pod up/down status &lt;code>up{job=&amp;quot;example-component&amp;quot;}&lt;/code>&lt;/li>
&lt;li>Pod/containers cpu utilization&lt;/li>
&lt;li>Pod/containers memorty consumption&lt;/li>
&lt;li>Pod/containers network i/o&lt;/li>
&lt;/ol>
&lt;p>These information is provided by the cAdvisor metrics. These metrics are already integrated. Please check the other dashboards for detailed information on how to query.&lt;/p>
&lt;h5 id="chart-requirements">Chart Requirements&lt;/h5>
&lt;p>Each chart needs to contain:&lt;/p>
&lt;ul>
&lt;li>a meaningful name&lt;/li>
&lt;li>a detailed description (for non trivial charts)&lt;/li>
&lt;li>appropriate x/y axis descriptions&lt;/li>
&lt;li>appropriate scaling levels for the x/y axis&lt;/li>
&lt;li>proper units for the x/y axis&lt;/li>
&lt;/ul>
&lt;h5 id="dashboard-parameters">Dashboard Parameters&lt;/h5>
&lt;p>The following parameters should be added to all dashboards to ensure a homogeneous experience across all dashboards.&lt;/p>
&lt;p>Dashboards have to &amp;hellip;&lt;/p>
&lt;ul>
&lt;li>contain a title which refers to the component name(s)&lt;/li>
&lt;li>contain a timezone statement which should be the browser time&lt;/li>
&lt;li>contain tags which express where the component is running (&lt;code>seed&lt;/code> or &lt;code>shoot&lt;/code>) and to which category the component belong (see dashboard structure)&lt;/li>
&lt;li>contain a version statement with a value of 1&lt;/li>
&lt;li>be immutable&lt;/li>
&lt;/ul>
&lt;p>Example dashboard configuration&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="p">{&lt;/span>
&lt;span class="nt">&amp;#34;title&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;example-component&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;timezone&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;utc&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;tags&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="s2">&amp;#34;seed&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;control-plane&amp;#34;&lt;/span>
&lt;span class="p">],&lt;/span>
&lt;span class="nt">&amp;#34;version&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;editable&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;false&amp;#34;&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Furthermore all dashboards should contain the following time options:&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-json" data-lang="json">&lt;span class="p">{&lt;/span>
&lt;span class="nt">&amp;#34;time&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nt">&amp;#34;from&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;now-1h&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="nt">&amp;#34;to&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="s2">&amp;#34;now&amp;#34;&lt;/span>
&lt;span class="p">},&lt;/span>
&lt;span class="nt">&amp;#34;timepicker&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">{&lt;/span>
&lt;span class="nt">&amp;#34;refresh_intervals&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="s2">&amp;#34;30s&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;1m&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;5m&amp;#34;&lt;/span>
&lt;span class="p">],&lt;/span>
&lt;span class="nt">&amp;#34;time_options&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="p">[&lt;/span>
&lt;span class="s2">&amp;#34;5m&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;15m&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;1h&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;6h&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;12h&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;24h&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;2d&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;span class="s2">&amp;#34;10d&amp;#34;&lt;/span>
&lt;span class="p">]&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;span class="p">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>Docs: Operator Alerts</title><link>https://gardener.cloud/docs/concepts/monitoring/operator_alerts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/concepts/monitoring/operator_alerts/</guid><description>
&lt;h1 id="operator-alerts">Operator Alerts&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Alertname&lt;/th>
&lt;th>Severity&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ApiServerUnreachableViaKubernetesService&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The Api server has been unreachable for 3 minutes via the kubernetes service in the shoot.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>CoreDNSDown&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>CoreDNS could not be found. Cluster DNS resolution will not work.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ApiServerNotReachable&lt;/td>
&lt;td>blocker&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>API server not reachable via external endpoint: {{ $labels.instance }}.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeApiserverDown&lt;/td>
&lt;td>blocker&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>All API server replicas are down/unreachable, or all API server could not be found.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeApiServerTooManyAuditlogFailures&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>The API servers cumulative failure rate in logging audit events is greater than 2%.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeletTooManyOpenFileDescriptorsSeed&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Seed-kubelet ({{ $labels.kubernetes_io_hostname }}) is using {{ $value }}% of the available file/socket descriptors. Kubelet could be under heavy load.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePersistentVolumeUsageCritical&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} is only {{ printf &amp;quot;%0.2f&amp;quot; $value }}% free.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePersistentVolumeFullInFourDays&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} is expected to fill up within four days. Currently {{ printf &amp;quot;%0.2f&amp;quot; $value }}% is available.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePodPendingControlPlane&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Pod {{ $labels.pod }} is stuck in &amp;quot;Pending&amp;quot; state for more than 30 minutes.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePodNotReadyControlPlane&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;code>Pod {{ $labels.pod }} is not ready for more than 30 minutes.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeStateMetricsShootDown&lt;/td>
&lt;td>info&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>There are no running kube-state-metric pods for the shoot cluster. No kubernetes resource metrics can be scraped.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeStateMetricsSeedDown&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>There are no running kube-state-metric pods for the seed cluster. No kubernetes resource metrics can be scraped.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NoWorkerNodes&lt;/td>
&lt;td>blocker&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;code>There are no worker nodes in the cluster or all of the worker nodes in the cluster are not schedulable.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>PrometheusCantScrape&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Prometheus failed to scrape metrics. Instance {{ $labels.instance }}, job {{ $labels.job }}.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>PrometheusConfigurationFailure&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Latest Prometheus configuration is broken and Prometheus is using the previous one.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VPNShootNoPods&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>vpn-shoot deployment in Shoot cluster has 0 available pods. VPN won't work.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VPNProbeAPIServerProxyFailed&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The API Server proxy functionality is not working. Probably the vpn connection from an API Server pod to the vpn-shoot endpoint on the Shoot workers does not work.&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>Docs: User Alerts</title><link>https://gardener.cloud/docs/concepts/monitoring/user_alerts/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/concepts/monitoring/user_alerts/</guid><description>
&lt;h1 id="user-alerts">User Alerts&lt;/h1>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Alertname&lt;/th>
&lt;th>Severity&lt;/th>
&lt;th>Type&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>ApiServerUnreachableViaKubernetesService&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The Api server has been unreachable for 3 minutes via the kubernetes service in the shoot.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>CoreDNSDown&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>CoreDNS could not be found. Cluster DNS resolution will not work.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>ApiServerNotReachable&lt;/td>
&lt;td>blocker&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>API server not reachable via external endpoint: {{ $labels.instance }}.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeApiServerTooManyOpenFileDescriptors&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>The API server ({{ $labels.instance }}) is using {{ $value }}% of the available file/socket descriptors.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeApiServerTooManyOpenFileDescriptors&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>The API server ({{ $labels.instance }}) is using {{ $value }}% of the available file/socket descriptors.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeApiServerLatency&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>seed&lt;/td>
&lt;td>&lt;code>Kube API server latency for verb {{ $labels.verb }} is high. This could be because the shoot workers and the control plane are in different regions. 99th percentile of request latency is greater than 3 seconds.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeKubeletNodeDown&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The kubelet {{ $labels.instance }} has been unavailable/unreachable for more than 1 hour. Workloads on the affected node may not be schedulable.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeletTooManyOpenFileDescriptorsShoot&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Shoot-kubelet ({{ $labels.kubernetes_io_hostname }}) is using {{ $value }}% of the available file/socket descriptors. Kubelet could be under heavy load.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubeletTooManyOpenFileDescriptorsShoot&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Shoot-kubelet ({{ $labels.kubernetes_io_hostname }}) is using {{ $value }}% of the available file/socket descriptors. Kubelet could be under heavy load.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePodPendingShoot&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Pod {{ $labels.pod }} is stuck in &amp;quot;Pending&amp;quot; state for more than 1 hour.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>KubePodNotReadyShoot&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Pod {{ $labels.pod }} is not ready for more than 1 hour.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NoWorkerNodes&lt;/td>
&lt;td>blocker&lt;/td>
&lt;td>&lt;/td>
&lt;td>&lt;code>There are no worker nodes in the cluster or all of the worker nodes in the cluster are not schedulable.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>NodeExporterDown&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The NodeExporter has been down or unreachable from Prometheus for more than 1 hour.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>K8SNodeOutOfDisk&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Node {{ $labels.node }} has run out of disk space.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>K8SNodeMemoryPressure&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Node {{ $labels.node }} is under memory pressure.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>K8SNodeDiskPressure&lt;/td>
&lt;td>warning&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Node {{ $labels.node }} is under disk pressure&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VMRootfsFull&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>Root filesystem device on instance {{ $labels.instance }} is almost full.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VMConntrackTableFull&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The nf_conntrack table is {{ $value }}% full.&lt;/code>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>VPNProbeAPIServerProxyFailed&lt;/td>
&lt;td>critical&lt;/td>
&lt;td>shoot&lt;/td>
&lt;td>&lt;code>The API Server proxy functionality is not working. Probably the vpn connection from an API Server pod to the vpn-shoot endpoint on the Shoot workers does not work.&lt;/code>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item></channel></rss>