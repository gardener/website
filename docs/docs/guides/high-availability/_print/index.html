<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=canonical type=text/html href=https://gardener.cloud/docs/guides/high-availability/><link rel=alternate type=application/rss+xml href=https://gardener.cloud/docs/guides/high-availability/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>High Availability | Gardener</title><meta name=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:url" content="https://gardener.cloud/docs/guides/high-availability/"><meta property="og:site_name" content="Gardener"><meta property="og:title" content="High Availability"><meta property="og:description" content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta property="og:locale" content="en_US"><meta property="og:type" content="website"><meta property="og:image" content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta itemprop=name content="High Availability"><meta itemprop=description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><meta itemprop=datePublished content="2023-03-17T00:00:00+00:00"><meta itemprop=dateModified content="2023-03-17T00:00:00+00:00"><meta itemprop=image content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://gardener.cloud/images/lp/gardener-logo.svg"><meta name=twitter:title content="High Availability"><meta name=twitter:description content="Project Gardener Website - A Managed Kubernetes Service Done Right"><link rel=preload href=/scss/main.min.64d56283aba037cc3a217d684edadfb4e3c57ca54122947d2f030f74bcd28a27.css as=style integrity="sha256-ZNVig6ugN8w6IX1oTtrftOPFfKVBIpR9LwMPdLzSiic=" crossorigin=anonymous><link href=/scss/main.min.64d56283aba037cc3a217d684edadfb4e3c57ca54122947d2f030f74bcd28a27.css rel=stylesheet integrity="sha256-ZNVig6ugN8w6IX1oTtrftOPFfKVBIpR9LwMPdLzSiic=" crossorigin=anonymous><script src=https://code.jquery.com/jquery-3.7.1.min.js integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin=anonymous></script><script defer src=https://unpkg.com/lunr@2.3.9/lunr.min.js integrity=sha384-203J0SNzyqHby3iU6hzvzltrWi/M41wOP5Gu+BiJMz5nwKykbkUx8Kp7iti0Lpli crossorigin=anonymous></script></head><body class=td-section><header><nav class="td-navbar js-navbar-scroll" data-bs-theme=dark><div class="container-fluid flex-column flex-md-row"><a class=navbar-brand href=/><span class="navbar-brand__logo navbar-logo"><svg width="90" height="90" viewBox="0 0 90 90" xmlns:xlink="http://www.w3.org/1999/xlink"><title>logo</title><desc>Created with Sketch.</desc><defs><path d="M41.8864954.994901575c.996545099999999-.479910833 2.6164002-.477918931 3.6088091.0L76.8159138 16.0781121C77.8124589 16.5580229 78.8208647 17.8257185 79.0659694 18.8995926l7.7355517 33.8916663C87.0476474 53.8696088 86.6852538 55.4484075 85.9984855 56.3095876L64.3239514 83.4885938C63.6343208 84.3533632 62.1740175 85.0543973 61.0725268 85.0543973H26.3092731c-1.1060816.0-2.5646564-.704623400000003-3.2514246-1.5658035L1.38331434 56.3095876C.693683723 55.4448182.335174016 53.865133.580278769 52.7912589L8.31583044 18.8995926C8.56195675 17.8212428 9.57347722 16.556031 10.5658861 16.0781121L41.8864954.994901575z" id="path-1"/><linearGradient x1="12.7542673%" y1="-18.6617048%" x2="88.2666158%" y2="84.6075483%" id="linearGradient-3"><stop stop-color="#FFF" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="50%" y1="4.93673768%" x2="148.756007%" y2="175.514523%" id="linearGradient-4"><stop stop-color="#FFF" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="19.1574381%" y1="-9.04800713%" x2="82.2203149%" y2="77.9084293%" id="linearGradient-5"><stop stop-color="#FFF" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient><linearGradient x1="57.4403751%" y1="26.3148481%" x2="137.966711%" y2="158.080556%" id="linearGradient-6"><stop stop-color="#FFF" offset="0"/><stop stop-color="#439246" offset="100%"/></linearGradient></defs><g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><g id="logo"><g id="Rectangle-2" transform="translate(1.000000, 0.000000)"><mask id="mask-2" fill="#fff"><use xlink:href="#path-1"/></mask><use id="Mask" fill="#009F76" xlink:href="#path-1"/><polygon fill="#000" opacity=".289628623" mask="url(#mask-2)" points="-17.6484375 54.5224609 30.8242188 25.0791016 63.4726562 58.5 24.7324219 92.6689453"/></g><path d="M56.8508631 39.260019C56.4193519 40.443987 55.6088085 41.581593 54.6736295 42.1938694l-8.0738997 5.2861089c-1.3854671.907087099999998-3.6247515.9116711-5.0172201.0L33.50861 42.1938694C32.123143 41.2867823 31 39.206345 31 37.545932V26.4150304c0-.725313.2131118-1.5301454.569268099999999-2.2825772L56.8508631 39.260019z" id="Combined-Shape" fill="url(#linearGradient-3)" transform="translate(43.925432, 36.147233) scale(-1, 1) translate(-43.925432, -36.147233)"/><path d="M56.0774672 25.1412464C56.4306829 25.8903325 56.6425556 26.6907345 56.6425556 27.4119019V38.5428034c0 1.6598979-1.1161415 3.73626640000001-2.50861 4.6479374l-8.0738997 5.286109c-1.3854671.907087000000004-3.6247516.911671000000005-5.0172201.0L32.9689261 43.1907408C32.2918101 42.7474223 31.6773514 42.0238435 31.2260376 41.206007L56.0774672 25.1412464z" id="Combined-Shape" fill="url(#linearGradient-4)" transform="translate(43.821278, 37.246598) scale(-1, 1) translate(-43.821278, -37.246598)"/><path d="M65.0702134 57.1846889C64.5985426 58.2007851 63.8367404 59.1236871 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.1597438 58.7930183 24 56.7816693 24 55.1323495V37.1145303C24 36.3487436 24.249712 35.5060005 24.6599102 34.7400631L65.0702134 57.1846889z" id="Combined-Shape" fill="url(#linearGradient-5)"/><path d="M65.0189476 34.954538C65.3636909 35.6617313 65.5692194 36.42021 65.5692194 37.1145303V55.1323495C65.5692194 56.7842831 64.4072119 58.7943252 62.9788591 59.6189851L47.37497 68.6278947c-1.4306165.825966800000003-3.75236779999999.8246599-5.1807206.0L26.5903603 59.6189851C25.9237304 59.2341061 25.3159155 58.5918431 24.8568495 57.8487596L65.0189476 34.954538z" id="Combined-Shape" fill="url(#linearGradient-6)"/></g></g></svg></span><span class=navbar-brand__name>Gardener</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class=navbar-nav><li class=nav-item><a class=nav-link href=https://demo.gardener.cloud target=_blank rel=noopener><span>Demo</span></a></li><li class=nav-item><a class=nav-link href=/adopter><span>Adopters</span></a></li><li class=nav-item><a class=nav-link href=/docs><span>Documentation</span></a></li><li class=nav-item><a class=nav-link href=/blog><span>Blogs</span></a></li><li class=nav-item><a class=nav-link href=/community><span>Community</span></a></li><li class=nav-item><a class=nav-link href=https://join.slack.com/t/gardener-cloud/shared_invite/zt-33c9daems-3oOorhnqOSnldZPWqGmIBw target=_blank rel=noopener><span>Join us on</span></a></li></ul></div><div class="d-none d-lg-block"><div class="td-search td-search--offline"><div class=td-search__icon></div><input type=search class="td-search__input form-control" placeholder="Search this site…" aria-label="Search this site…" autocomplete=off data-offline-search-index-json-src=/offline-search-index.98a41f9bfc4d7af900ca7ef46cbde11d.json data-offline-search-base-href=/ data-offline-search-max-results=10></div></div></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 ps-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/guides/high-availability/>Return to the regular view of this page</a>.</p></div><h1 class=title>High Availability</h1><div class=content></div></div><div class=td-content><h1 id=pg-6647773f8a1c094335ba88f765cd9f11>1 - Best Practices</h1><h1 id=implementing-high-availability-and-tolerating-zone-outages>Implementing High Availability and Tolerating Zone Outages<a class=td-heading-self-link href=#implementing-high-availability-and-tolerating-zone-outages aria-label="Heading self-link"></a></h1><p>Developing highly available workload that can tolerate a zone outage is no trivial task. You will find here various recommendations to get closer to that goal. While many recommendations are general enough, the examples are specific in how to achieve this in a Gardener-managed cluster and where/how to tweak the different control plane components. If you do not use Gardener, it may be still a worthwhile read.</p><p>First however, what is a zone outage? It sounds like a clear-cut &ldquo;thing&rdquo;, but it isn&rsquo;t. There are many things that can go haywire. Here are some examples:</p><ul><li>Elevated cloud provider API error rates for individual or multiple services</li><li>Network bandwidth reduced or latency increased, usually also effecting storage sub systems as they are network attached</li><li>No networking at all, no DNS, machines shutting down or restarting, &mldr;</li><li>Functional issues, of either the entire service (e.g. all block device operations) or only parts of it (e.g. LB listener registration)</li><li>All services down, temporarily or permanently (the proverbial burning down data center &#x1f525;)</li></ul><p>This and everything in between make it hard to prepare for such events, but you can still do a lot. The most important recommendation is to not target specific issues exclusively - tomorrow another service will fail in an unanticipated way. Also, focus more on <a href=https://research.google/pubs/pub50828>meaningful availability</a> than on internal signals (useful, but not as relevant as the former). Always prefer automation over manual intervention (e.g. leader election is a pretty robust mechanism, auto-scaling may be required as well, etc.).</p><p>Also remember that HA is costly - you need to balance it against the cost of an outage as silly as this may sound, e.g. running all this excess capacity &ldquo;just in case&rdquo; vs. &ldquo;going down&rdquo; vs. a risk-based approach in between where you have means that will kick in, but they are not guaranteed to work (e.g. if the cloud provider is out of resource capacity). Maybe some of your components must run at the highest possible availability level, but others not - that&rsquo;s a decision only you can make.</p><h2 id=control-plane>Control Plane<a class=td-heading-self-link href=#control-plane aria-label="Heading self-link"></a></h2><p>The Kubernetes cluster control plane is managed by Gardener (as pods in separate infrastructure clusters to which you have no direct access) and can be set up with no failure tolerance (control plane pods will be recreated best-effort when resources are available) or one of the <a href=/docs/guides/high-availability/control-plane/>failure tolerance types <code>node</code> or <code>zone</code></a>.</p><p>Strictly speaking, static workload does not depend on the (high) availability of the control plane, but static workload doesn&rsquo;t rhyme with Cloud and Kubernetes and also means, that when you possibly need it the most, e.g. during a zone outage, critical self-healing or auto-scaling functionality won&rsquo;t be available to you and your workload, if your control plane is down as well. That&rsquo;s why, even though the resource consumption is significantly higher, we generally recommend to use the failure tolerance type <code>zone</code> for the control planes of productive clusters, at least in all regions that have 3+ zones. Regions that have only 1 or 2 zones don&rsquo;t support the failure tolerance type <code>zone</code> and then your second best option is the failure tolerance type <code>node</code>, which means a zone outage can still take down your control plane, but individual node outages won&rsquo;t.</p><p>In the <code>shoot</code> resource it&rsquo;s merely only this what you need to add:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  controlPlane:
</span></span><span style=display:flex><span>    highAvailability:
</span></span><span style=display:flex><span>      failureTolerance:
</span></span><span style=display:flex><span>        type: zone <span style=color:green># valid values are `node` and `zone` (only available if your control plane resides in a region with 3+ zones)</span>
</span></span></code></pre></div><p>This setting will scale out all control plane components for a Gardener cluster as necessary, so that no single zone outage can take down the control plane for longer than just a few seconds for the fail-over to take place (e.g. lease expiration and new leader election or readiness probe failure and endpoint removal). Components run highly available in either active-active (servers) or active-passive (controllers) mode at all times, the persistence (ETCD), which is consensus-based, will tolerate the loss of one zone and still maintain quorum and therefore remain operational. These are all patterns that we will revisit down below also for your own workload.</p><h2 id=worker-pools>Worker Pools<a class=td-heading-self-link href=#worker-pools aria-label="Heading self-link"></a></h2><p>Now that you have configured your Kubernetes cluster control plane in HA, i.e. spread it across multiple zones, you need to do the same for your own workload, but in order to do so, you need to spread your nodes across multiple zones first.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  provider:
</span></span><span style=display:flex><span>    workers:
</span></span><span style=display:flex><span>    - name: ...
</span></span><span style=display:flex><span>      minimum: 6
</span></span><span style=display:flex><span>      maximum: 60
</span></span><span style=display:flex><span>      zones:
</span></span><span style=display:flex><span>      - ...
</span></span></code></pre></div><p>Prefer regions with at least 2, better 3+ zones and list the zones in the <code>zones</code> section for each of your worker pools. Whether you need 2 or 3 zones at a minimum depends on your fail-over concept:</p><ul><li>Consensus-based software components (like ETCD) depend on maintaining a quorum of <code>(n/2)+1</code>, so you need at least 3 zones to tolerate the outage of 1 zone.</li><li>Primary/Secondary-based software components need just 2 zones to tolerate the outage of 1 zone.</li><li>Then there are software components that can scale out horizontally. They are probably fine with 2 zones, but you also need to think about the load-shift and that the remaining zone must then pick up the work of the unhealthy zone. With 2 zones, the remaining zone must cope with an increase of 100% load. With 3 zones, the remaining zones must only cope with an increase of 50% load (per zone).</li></ul><p>In general, the question is also whether you have the fail-over capacity already up and running or not. If not, i.e. you depend on re-scheduling to a healthy zone or auto-scaling, be aware that during a zone outage, you will see a resource crunch in the healthy zones. If you have no automation, i.e. only human operators (a.k.a. &ldquo;red button approach&rdquo;), you probably will not get the machines you need and even with automation, it may be tricky. But holding the capacity available at all times is costly. In the end, that&rsquo;s a decision only you can make. If you made that decision, please adapt the <code>minimum</code>, <code>maximum</code>, <code>maxSurge</code> and <code>maxUnavailable</code> settings for your worker pools accordingly (visit <a href=/docs/guides/high-availability/best-practices/#on-specproviderworkersminimum-maximum-maxsurge-maxunavailable-zones-and-machinecontrollermanager>this section</a> for more information).</p><p>Also, consider fall-back worker pools (with different/alternative machine types) and <a href=https://github.com/gardener/autoscaler/blob/machine-controller-manager-provider/cluster-autoscaler/FAQ.md#what-are-expanders>cluster autoscaler expanders</a> using a <a href=https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/expander/priority/readme.md>priority-based strategy</a>.</p><p>Gardener-managed clusters deploy the <a href=https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler>cluster autoscaler</a> or CA for short and you can <a href=https://gardener.cloud/docs/gardener/api-reference/core/#clusterautoscaler>tweak the general CA knobs</a> for Gardener-managed clusters like this:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  kubernetes:
</span></span><span style=display:flex><span>    clusterAutoscaler:
</span></span><span style=display:flex><span>      expander: <span style=color:#a31515>&#34;least-waste&#34;</span>
</span></span><span style=display:flex><span>      scanInterval: 10s
</span></span><span style=display:flex><span>      scaleDownDelayAfterAdd: 60m
</span></span><span style=display:flex><span>      scaleDownDelayAfterDelete: 0s
</span></span><span style=display:flex><span>      scaleDownDelayAfterFailure: 3m
</span></span><span style=display:flex><span>      scaleDownUnneededTime: 30m
</span></span><span style=display:flex><span>      scaleDownUtilizationThreshold: 0.5
</span></span></code></pre></div><p>In addition to that, it is also possible to configure the <a href=https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/expander/priority/readme.md><code>cluster-autoscaler</code> priority expander</a> by adding priorities to the worker groups like this:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  provider:
</span></span><span style=display:flex><span>    workers:
</span></span><span style=display:flex><span>    - name: worker1
</span></span><span style=display:flex><span>      priority: 40 <span style=color:green># priority of this worker group</span>
</span></span><span style=display:flex><span>      machine:
</span></span><span style=display:flex><span>        type: local
</span></span><span style=display:flex><span>    - name: worker2
</span></span><span style=display:flex><span>      machine:
</span></span><span style=display:flex><span>        type: local
</span></span></code></pre></div><p>When at least one worker group has a priority defined, the respective <code>ConfigMap</code> will be generated and deployed, which the <code>cluster-autoscaler</code> uses.
When only a part of the worker groups have priorities configured, those who do not have these configured, will be defaulted to <code>0</code>.</p><p>If you want to be ready for a sudden spike or have some buffer in general, <a href=https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#how-can-i-configure-overprovisioning-with-cluster-autoscaler>over-provision nodes by means of &ldquo;placeholder&rdquo; pods</a> with <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption>low priority</a> and appropriate resource requests. This way, they will demand nodes to be provisioned for them, but if any pod comes up with a regular/higher priority, the low priority pods will be evicted to make space for the more important ones. Strictly speaking, this is not related to HA, but it may be important to keep this in mind as you generally want critical components to be rescheduled as fast as possible and if there is no node available, it may take 3 minutes or longer to do so (depending on the cloud provider). Besides, not only zones can fail, but also individual nodes.</p><h2 id=replicas-horizontal-scaling>Replicas (Horizontal Scaling)<a class=td-heading-self-link href=#replicas-horizontal-scaling aria-label="Heading self-link"></a></h2><p>Now let&rsquo;s talk about your workload. In most cases, this will mean to run multiple replicas. If you cannot do that (a.k.a. you have a singleton), that&rsquo;s a bad situation to be in. Maybe you can run a spare (secondary) as backup? If you cannot, you depend on quick detection and rescheduling of your singleton (more on that below).</p><p>Obviously, things get messier with persistence. If you have persistence, you should ideally replicate your data, i.e. let your spare (secondary) &ldquo;follow&rdquo; your main (primary). If your software doesn&rsquo;t support that, you have to deploy other means, e.g. <a href=https://kubernetes.io/docs/concepts/storage/volume-snapshots>volume snapshotting</a> or side-backups (specific to the software you deploy; keep the backups regional, so that you can switch to another zone at all times). If you have to do those, your HA scenario becomes more a DR scenario and terms like RPO and RTO become relevant to you:</p><ul><li><strong>Recovery Point Objective (RPO)</strong>: Potential data loss, i.e. how much data will you lose at most (time between backups)</li><li><strong>Recovery Time Objective (RTO)</strong>: Time until recovery, i.e. how long does it take you to be operational again (time to restore)</li></ul><p>Also, keep in mind that your persistent volumes are usually zonal, i.e. once you have a volume in one zone, it&rsquo;s bound to that zone and you cannot get up your pod in another zone w/o first recreating the volume yourself (Kubernetes won&rsquo;t help you here directly).</p><p>Anyway, best avoid that, if you can (from technical and cost perspective). The best solution (and also the most costly one) is to run multiple replicas in multiple zones and keep your data replicated at all times, so that your RPO is always 0 (best). That&rsquo;s what we do for Gardener-managed cluster HA control planes (ETCD) as any data loss may be disastrous and lead to orphaned resources (in addition, we deploy side cars that do side-backups for disaster recovery, with full and incremental snapshots with an RPO of 5m).</p><p>So, how to run with multiple replicas? That&rsquo;s the easiest part in Kubernetes and the two most important resources, <code>Deployments</code> and <code>StatefulSet</code>, support that out of the box:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: apps/v1
</span></span><span style=display:flex><span>kind: Deployment | StatefulSet
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  replicas: ...
</span></span></code></pre></div><p>The problem comes with the number of replicas. It&rsquo;s easy only if the number is static, e.g. 2 for active-active/passive or 3 for consensus-based software components, but what with software components that can scale out horizontally? Here you usually do not set the number of replicas statically, but make use of the <a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale>horizontal pod autoscaler</a> or HPA for short (built-in; part of the kube-controller-manager). There are also other options like the <a href=https://github.com/kubernetes-sigs/cluster-proportional-autoscaler>cluster proportional autoscaler</a>, but while the former works based on metrics, the latter is more a guesstimate approach that derives the number of replicas from the number of nodes/cores in a cluster. Sometimes useful, but often blind to the actual demand.</p><p>So, HPA it is then for most of the cases. However, what is the resource (e.g. CPU or memory) that drives the number of desired replicas? Again, this is up to you, but not always are CPU or memory the best choices. In some cases, <a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#scaling-on-custom-metrics>custom metrics</a> may be more appropriate, e.g. requests per second (it was also for us).</p><p>You will have to create specific <code>HorizontalPodAutoscaler</code> resources for your scale target and can <a href=https://gardener.cloud/docs/gardener/api-reference/core/#horizontalpodautoscalerconfig>tweak the general HPA knobs</a> for Gardener-managed clusters like this:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  kubernetes:
</span></span><span style=display:flex><span>    kubeControllerManager:
</span></span><span style=display:flex><span>      horizontalPodAutoscaler:
</span></span><span style=display:flex><span>        syncPeriod: 15s
</span></span><span style=display:flex><span>        tolerance: 0.1
</span></span><span style=display:flex><span>        downscaleStabilization: 5m0s
</span></span><span style=display:flex><span>        initialReadinessDelay: 30s
</span></span><span style=display:flex><span>        cpuInitializationPeriod: 5m0s
</span></span></code></pre></div><h2 id=resources-vertical-scaling>Resources (Vertical Scaling)<a class=td-heading-self-link href=#resources-vertical-scaling aria-label="Heading self-link"></a></h2><p>While it is important to set a sufficient number of replicas, it is also important to give the pods sufficient resources (CPU and memory). This is especially true when you think about HA. When a zone goes down, you might need to get up replacement pods, if you don&rsquo;t have them running already to take over the load from the impacted zone. Likewise, e.g. with active-active software components, you can expect the remaining pods to receive more load. If you cannot scale them out horizontally to serve the load, you will probably need to scale them out (or rather up) vertically. This is done by the <a href=https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler>vertical pod autoscaler</a> or VPA for short (not built-in; part of the <a href=https://github.com/kubernetes/autoscaler>kubernetes/autoscaler</a> repository).</p><p>A few caveats though:</p><ul><li>You cannot use HPA and VPA on the same metrics as they would influence each other, which would lead to pod trashing (more replicas require fewer resources; fewer resources require more replicas)</li><li>Scaling horizontally doesn&rsquo;t cause downtimes (at least not when out-scaling and only one replica is affected when in-scaling), but scaling vertically does (if the pod runs OOM anyway, but also when new recommendations are applied, resource requests for existing pods may be changed, which causes the pods to be rescheduled). Although the discussion is going on for a very long time now, that is still not supported in-place yet (see <a href=https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/1287-in-place-update-pod-resources/README.md>KEP 1287</a>, <a href=https://github.com/kubernetes/kubernetes/pull/102884>implementation in Kubernetes</a>, <a href=https://github.com/kubernetes/autoscaler/issues/4016>implementation in VPA</a>).</li></ul><p>VPA is a useful tool and Gardener-managed clusters deploy a VPA by default for you (HPA is supported anyway as it&rsquo;s built into the kube-controller-manager). You will have to create specific <code>VerticalPodAutoscaler</code> resources for your scale target and can <a href=https://gardener.cloud/docs/gardener/api-reference/core/#verticalpodautoscaler>tweak the general VPA knobs</a> for Gardener-managed clusters like this:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  kubernetes:
</span></span><span style=display:flex><span>    verticalPodAutoscaler:
</span></span><span style=display:flex><span>      enabled: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>      evictAfterOOMThreshold: 10m0s
</span></span><span style=display:flex><span>      evictionRateBurst: 1
</span></span><span style=display:flex><span>      evictionRateLimit: -1
</span></span><span style=display:flex><span>      evictionTolerance: 0.5
</span></span><span style=display:flex><span>      recommendationMarginFraction: 0.15
</span></span><span style=display:flex><span>      updaterInterval: 1m0s
</span></span><span style=display:flex><span>      recommenderInterval: 1m0s
</span></span></code></pre></div><p>While horizontal pod autoscaling is relatively straight-forward, it takes a long time to master vertical pod autoscaling. We saw <a href=https://github.com/kubernetes/autoscaler/issues/4498>performance issues</a>, hard-coded behavior (on OOM, memory is bumped by +20% and it may take a few iterations to reach a good level), unintended pod disruptions by applying new resource requests (after 12h all targeted pods will receive new requests even though individually they would be fine without, which also drives active-passive resource consumption up), difficulties to deal with spiky workload in general (due to the algorithmic approach it takes), recommended requests may exceed node capacity, limit scaling is proportional and therefore often questionable, and more. VPA is a double-edged sword: useful and necessary, but not easy to handle.</p><p>For the Gardener-managed components, we mostly removed limits. Why?</p><ul><li>CPU limits have almost always only downsides. They cause needless CPU throttling, which is not even easily visible. CPU requests turn into <code>cpu shares</code>, so if the node has capacity, the pod may consume the freely available CPU, but not if you have set limits, which curtail the pod by means of <code>cpu quota</code>. There are only certain scenarios in which they may make sense, e.g. if you set requests=limits and thereby define a pod with <code>guaranteed</code> <a href=https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod>QoS</a>, which influences your <code>cgroup</code> placement. However, that is difficult to do for the components you implement yourself and practically impossible for the components you just consume, because what&rsquo;s the correct value for requests/limits and will it hold true also if the load increases and what happens if a zone goes down or with the next update/version of this component? If anything, CPU limits caused outages, not helped prevent them.</li><li>As for memory limits, they are slightly more useful, because CPU is compressible and memory is not, so if one pod runs berserk, it may take others down (with CPU, <code>cpu shares</code> make it as fair as possible), depending on which OOM killer strikes (a complicated topic by itself). You don&rsquo;t want the operating system OOM killer to strike as the result is unpredictable. Better, it&rsquo;s the cgroup OOM killer or even the <code>kubelet</code>&rsquo;s eviction, if the consumption is slow enough as <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#interactions-of-pod-priority-and-qos>it takes priorities into consideration</a> even. If your component is critical and a singleton (e.g. node daemon set pods), you are better off also without memory limits, because letting the pod go OOM because of artificial/wrong memory limits can mean that the node becomes unusable. Hence, such components also better run only with no or a very high memory limit, so that you can catch the occasional memory leak (bug) eventually, but under normal operation, if you cannot decide about a true upper limit, rather not have limits and cause endless outages through them or when you need the pods the most (during a zone outage) where all your assumptions went out of the window.</li></ul><p>The downside of having poor or no limits and poor and no requests is that nodes may &ldquo;die&rdquo; more often. Contrary to the expectation, even for managed services, the managed service is not responsible or cannot guarantee the health of a node under all circumstances, since the end user defines what is run on the nodes (shared responsibility). If the workload exhausts any resource, it will be the end of the node, e.g. by compressing the CPU too much (so that the <code>kubelet</code> fails to do its work), exhausting the main memory too fast, disk space, file handles, or any other resource.</p><p>The <code>kubelet</code> allows for <a href=https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources>explicit reservation of resources</a> for operating system daemons (<code>system-reserved</code>) and Kubernetes daemons (<code>kube-reserved</code>) that are subtracted from the actual node resources and become the allocatable node resources for your workload/pods. All managed services configure these settings &ldquo;by rule of thumb&rdquo; (a balancing act), but cannot guarantee that the values won&rsquo;t waste resources or always will be sufficient. You will have to fine-tune them eventually and adapt them to your needs. In addition, you can configure <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/node-pressure-eviction>soft and hard eviction thresholds</a> to give the <code>kubelet</code> some headroom to evict &ldquo;greedy&rdquo; pods in a controlled way. These settings can be configured for Gardener-managed clusters like this:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  kubernetes:
</span></span><span style=display:flex><span>    kubelet:
</span></span><span style=display:flex><span>      kubeReserved:                            <span style=color:green># explicit resource reservation for Kubernetes daemons</span>
</span></span><span style=display:flex><span>        cpu: 100m
</span></span><span style=display:flex><span>        memory: 1Gi
</span></span><span style=display:flex><span>        ephemeralStorage: 1Gi
</span></span><span style=display:flex><span>        pid: 1000
</span></span><span style=display:flex><span>      evictionSoft:                            <span style=color:green># soft, i.e. graceful eviction (used if the node is about to run out of resources, avoiding hard evictions)</span>
</span></span><span style=display:flex><span>        memoryAvailable: 200Mi
</span></span><span style=display:flex><span>        imageFSAvailable: 10%
</span></span><span style=display:flex><span>        imageFSInodesFree: 10%
</span></span><span style=display:flex><span>        nodeFSAvailable: 10%
</span></span><span style=display:flex><span>        nodeFSInodesFree: 10%
</span></span><span style=display:flex><span>      evictionSoftGracePeriod:                 <span style=color:green># caps pod&#39;s `terminationGracePeriodSeconds` value during soft evictions (specific grace periods)</span>
</span></span><span style=display:flex><span>        memoryAvailable: 1m30s
</span></span><span style=display:flex><span>        imageFSAvailable: 1m30s
</span></span><span style=display:flex><span>        imageFSInodesFree: 1m30s
</span></span><span style=display:flex><span>        nodeFSAvailable: 1m30s
</span></span><span style=display:flex><span>        nodeFSInodesFree: 1m30s
</span></span><span style=display:flex><span>      evictionHard:                            <span style=color:green># hard, i.e. immediate eviction (used if the node is out of resources, avoiding the OS generally run out of resources fail processes indiscriminately)</span>
</span></span><span style=display:flex><span>        memoryAvailable: 100Mi
</span></span><span style=display:flex><span>        imageFSAvailable: 5%
</span></span><span style=display:flex><span>        imageFSInodesFree: 5%
</span></span><span style=display:flex><span>        nodeFSAvailable: 5%
</span></span><span style=display:flex><span>        nodeFSInodesFree: 5%
</span></span><span style=display:flex><span>      evictionMinimumReclaim:                  <span style=color:green># additional resources to reclaim after hitting the hard eviction thresholds to not hit the same thresholds soon after again</span>
</span></span><span style=display:flex><span>        memoryAvailable: 0Mi
</span></span><span style=display:flex><span>        imageFSAvailable: 0Mi
</span></span><span style=display:flex><span>        imageFSInodesFree: 0Mi
</span></span><span style=display:flex><span>        nodeFSAvailable: 0Mi
</span></span><span style=display:flex><span>        nodeFSInodesFree: 0Mi
</span></span><span style=display:flex><span>      evictionMaxPodGracePeriod: 90            <span style=color:green># caps pod&#39;s `terminationGracePeriodSeconds` value during soft evictions (general grace periods)</span>
</span></span><span style=display:flex><span>      evictionPressureTransitionPeriod: 5m0s   <span style=color:green># stabilization time window to avoid flapping of node eviction state</span>
</span></span></code></pre></div><p>You can tweak these settings also individually per worker pool (<code>spec.provider.workers.kubernetes.kubelet...</code>), which makes sense especially with different machine types (and also workload that you may want to schedule there).</p><p>Physical memory is not compressible, but you can overcome this issue to some degree (alpha since Kubernetes <code>v1.22</code> in combination with the feature gate <code>NodeSwap</code> on the <code>kubelet</code>) with swap memory. You can read more in this <a href=https://kubernetes.io/blog/2021/08/09/run-nodes-with-swap-alpha>introductory blog</a> and the <a href=https://kubernetes.io/docs/concepts/architecture/nodes/#swap-memory>docs</a>. If you chose to use it (still only alpha at the time of this writing) you may want to consider also the risks associated with swap memory:</p><ul><li>Reduced performance predictability</li><li>Reduced performance up to page trashing</li><li>Reduced security as secrets, normally held only in memory, could be swapped out to disk</li></ul><p>That said, the various options mentioned above are only remotely related to HA and will not be further explored throughout this document, but just to remind you: if a zone goes down, load patterns will shift, existing pods will probably receive more load and will require more resources (especially because it is often practically impossible to set &ldquo;proper&rdquo; resource requests, which drive node allocation - limits are always ignored by the scheduler) or more pods will/must be placed on the existing and/or new nodes and then these settings, which are generally critical (especially if you switch on <a href=/docs/gardener/shoot/shoot_scheduling_profiles/>bin-packing for Gardener-managed clusters</a> as a cost saving measure), will become even more critical during a zone outage.</p><h2 id=probes>Probes<a class=td-heading-self-link href=#probes aria-label="Heading self-link"></a></h2><p>Before we go down the rabbit hole even further and talk about how to spread your replicas, we need to talk about probes first, as they will become relevant later. Kubernetes supports three kinds of probes: <a href=https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes>startup, liveness, and readiness probes</a>. If you are a <a href=https://twitter.com/thockin/status/1615468485987143682>visual thinker</a>, also check out this <a href=https://speakerdeck.com/thockin/kubernetes-pod-probes>slide deck</a> by <a href=https://www.linkedin.com/in/tim-hockin-6501072>Tim Hockin</a> (Kubernetes networking SIG chair).</p><p>Basically, the <code>startupProbe</code> and the <code>livenessProbe</code> help you restart the container, if it&rsquo;s unhealthy for whatever reason, by letting the <code>kubelet</code> that orchestrates your containers on a node know, that it&rsquo;s unhealthy. The former is a special case of the latter and only applied at the startup of your container, if you need to handle the startup phase differently (e.g. with very slow starting containers) from the rest of the lifetime of the container.</p><p>Now, the <code>readinessProbe</code> helps you manage the ready status of your container and thereby pod (any container that is not ready turns the pod not ready). This again has impact on endpoints and pod disruption budgets:</p><ul><li>If the pod is not ready, the endpoint will be removed and the pod will not receive traffic anymore</li><li>If the pod is not ready, the pod counts into the pod disruption budget and if the budget is exceeded, no further voluntary pod disruptions will be permitted for the remaining ready pods (e.g. no eviction, no voluntary horizontal or vertical scaling, if the pod runs on a node that is about to be drained or in draining, draining will be paused until the max drain timeout passes)</li></ul><p>As you can see, all of these probes are (also) related to HA (mostly the <code>readinessProbe</code>, but depending on your workload, you can also leverage <code>livenessProbe</code> and <code>startupProbe</code> into your HA strategy). If Kubernetes doesn&rsquo;t know about the individual status of your container/pod, it won&rsquo;t do anything for you (right away). That said, later/indirectly something might/will happen via the node status that can also be ready or not ready, which influences the pods and load balancer listener registration (a not ready node will not receive cluster traffic anymore), but this process is worker pool global and reacts delayed and also doesn&rsquo;t discriminate between the containers/pods on a node.</p><p>In addition, Kubernetes also offers <a href=https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-readiness-gate>pod readiness gates</a> to amend your pod readiness with additional custom conditions (normally, only the sum of the container readiness matters, but pod readiness gates additionally count into the overall pod readiness). This may be useful if you want to block (by means of pod disruption budgets that we will talk about next) the roll-out of your workload/nodes in case some (possibly external) condition fails.</p><h2 id=pod-disruption-budgets>Pod Disruption Budgets<a class=td-heading-self-link href=#pod-disruption-budgets aria-label="Heading self-link"></a></h2><p>One of the most important resources that help you on your way to HA are <a href=https://kubernetes.io/docs/tasks/run-application/configure-pdb>pod disruption budgets</a> or PDB for short. They tell Kubernetes how to deal with voluntary pod disruptions, e.g. during the deployment of your workload, when the nodes are rolled, or just in general when a pod shall be evicted/terminated. Basically, if the budget is reached, they block all voluntary pod disruptions (at least for a while until possibly other timeouts act or things happen that leave Kubernetes no choice anymore, e.g. the node is forcefully terminated). You should always define them for your workload.</p><p>Very important to note is that they are based on the <code>readinessProbe</code>, i.e. even if all of your replicas are <code>lively</code>, but not enough of them are <code>ready</code>, this blocks voluntary pod disruptions, so they are very critical and useful. Here an example (you can specify either <code>minAvailable</code> or <code>maxUnavailable</code> in absolute numbers or as percentage):</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: policy/v1
</span></span><span style=display:flex><span>kind: PodDisruptionBudget
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  maxUnavailable: 1
</span></span><span style=display:flex><span>  selector:
</span></span><span style=display:flex><span>    matchLabels:
</span></span><span style=display:flex><span>      ...
</span></span></code></pre></div><p>And please do not specify a PDB of <code>maxUnavailable</code> being 0 or similar. That&rsquo;s pointless, even detrimental, as it blocks then even useful operations, forces always the hard timeouts that are less graceful and it doesn&rsquo;t make sense in the context of HA. You cannot &ldquo;force&rdquo; HA by preventing voluntary pod disruptions, you must work with the pod disruptions in a resilient way. Besides, PDBs are really only about voluntary pod disruptions - something bad can happen to a node/pod at any time and PDBs won&rsquo;t make this reality go away for you.</p><p>PDBs will not always work as expected and can also get in your way, e.g. if the PDB is violated or would be violated, it may possibly block whatever you are trying to do to salvage the situation, e.g. drain a node or deploy a patch version (if the PDB is or would be violated, not even unhealthy pods would be evicted as they could theoretically become healthy again, which Kubernetes doesn&rsquo;t know). In order to overcome this issue, it is now possible (alpha since Kubernetes <code>v1.26</code> in combination with the feature gate <code>PDBUnhealthyPodEvictionPolicy</code> on the API server, beta and enabled by default since Kubernetes <code>v1.27</code>) to configure the so-called <a href=https://kubernetes.io/docs/tasks/run-application/configure-pdb/#unhealthy-pod-eviction-policy>unhealthy pod eviction policy</a>. The default is still <code>IfHealthyBudget</code> as a change in default would have changed the behavior (as described above), but you can now also set <code>AlwaysAllow</code> at the PDB (<code>spec.unhealthyPodEvictionPolicy</code>). For more information, please check out <a href=https://github.com/kubernetes/kubernetes/issues/72320>this discussion</a>, <a href=https://github.com/kubernetes/kubernetes/pull/105296>the PR</a> and <a href="https://groups.google.com/g/kubernetes-sig-apps/c/_joO4swogKY?pli=1">this document</a> and balance the pros and cons for yourself. In short, the new <code>AlwaysAllow</code> option is probably the better choice in most of the cases while <code>IfHealthyBudget</code> is useful only if you have frequent temporary transitions or for special cases where you have already implemented controllers that depend on the old behavior.</p><h2 id=pod-topology-spread-constraints>Pod Topology Spread Constraints<a class=td-heading-self-link href=#pod-topology-spread-constraints aria-label="Heading self-link"></a></h2><p><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints>Pod topology spread constraints</a> or PTSC for short (no official abbreviation exists, but we will use this in the following) are enormously helpful to distribute your replicas across multiple zones, nodes, or any other user-defined topology domain. They complement and improve on <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity>pod (anti-)affinities</a> that still exist and can be used in combination.</p><p>PTSCs are an improvement, because they allow for <code>maxSkew</code> and <code>minDomains</code>. You can steer the &ldquo;level of tolerated imbalance&rdquo; with <code>maxSkew</code>, e.g. you probably want that to be at least 1, so that you can perform a rolling update, but this all depends on your <a href=https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#rolling-update-deployment>deployment</a> (<code>maxUnavailable</code> and <code>maxSurge</code>), etc. <a href=https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#rolling-updates>Stateful sets</a> are a bit different (<code>maxUnavailable</code>) as they are bound to volumes and depend on them, so there usually cannot be 2 pods requiring the same volume. <code>minDomains</code> is a hint to tell the scheduler how far to spread, e.g. if all nodes in one zone disappeared because of a zone outage, it may &ldquo;appear&rdquo; as if there are only 2 zones in a 3 zones cluster and the scheduling decisions may end up wrong, so a <code>minDomains</code> of 3 will tell the scheduler to spread to 3 zones before adding another replica in one zone. Be careful with this setting as it also means, if one zone is down the &ldquo;spread&rdquo; is already at least 1, if pods run in the other zones. This is useful where you have exactly as many replicas as you have zones and you do not want any imbalance. Imbalance is critical as if you end up with one, nobody is going to do the (active) re-balancing for you (unless you deploy and configure additional non-standard components such as the <a href=https://github.com/kubernetes-sigs/descheduler>descheduler</a>). So, for instance, if you have something like a DBMS that you want to spread across 2 zones (active-passive) or 3 zones (consensus-based), you better specify <code>minDomains</code> of 2 respectively 3 to force your replicas into at least that many zones before adding more replicas to another zone (if supported).</p><p>Anyway, PTSCs are critical to have, but not perfect, so we saw (unsurprisingly, because that&rsquo;s how the scheduler works), that the scheduler may block the deployment of new pods because it takes the decision pod-by-pod (see for instance <a href=https://github.com/kubernetes/kubernetes/issues/109364>#109364</a>).</p><h2 id=pod-affinities-and-anti-affinities>Pod Affinities and Anti-Affinities<a class=td-heading-self-link href=#pod-affinities-and-anti-affinities aria-label="Heading self-link"></a></h2><p>As said, you can combine PTSCs with <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity>pod affinities and/or anti-affinities</a>. Especially <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity>inter-pod (anti-)affinities</a> may be helpful to place pods <em>apart</em>, e.g. because they are fall-backs for each other or you do not want multiple potentially resource-hungry <a href=https://kubernetes.io/docs/concepts/workloads/pods/pod-qos/#besteffort>&ldquo;best-effort&rdquo;</a> or <a href=https://kubernetes.io/docs/concepts/workloads/pods/pod-qos/#burstable>&ldquo;burstable&rdquo;</a> pods side-by-side (noisy neighbor problem), or <em>together</em>, e.g. because they form a unit and you want to reduce the failure domain, reduce the network latency, and reduce the costs.</p><h2 id=topology-aware-hints>Topology Aware Hints<a class=td-heading-self-link href=#topology-aware-hints aria-label="Heading self-link"></a></h2><p>While <a href=https://kubernetes.io/docs/concepts/services-networking/topology-aware-hints>topology aware hints</a> are not directly related to HA, they are very relevant in the HA context. Spreading your workload across multiple zones may increase network latency and cost significantly, if the traffic is not shaped. Topology aware hints (beta since Kubernetes <code>v1.23</code>, replacing the now deprecated topology aware traffic routing with topology keys) help to route the traffic within the originating zone, if possible. Basically, they tell <code>kube-proxy</code> how to setup your routing information, so that clients can talk to endpoints that are located within the same zone.</p><p>Be aware however, that there are some limitations. Those are called <a href=https://kubernetes.io/docs/concepts/services-networking/topology-aware-hints/#safeguards>safeguards</a> and if they strike, the hints are off and traffic is routed again randomly. Especially controversial is the balancing limitation as there is the assumption, that the load that hits an endpoint is determined by the allocatable CPUs in that topology zone, but that&rsquo;s not always, if even often, the case (see for instance <a href=https://github.com/kubernetes/kubernetes/issues/113731>#113731</a> and <a href=https://github.com/kubernetes/kubernetes/issues/110714>#110714</a>). So, this limitation hits far too often and your hints are off, but then again, it&rsquo;s about network latency and cost optimization first, so it&rsquo;s better than nothing.</p><h2 id=networking>Networking<a class=td-heading-self-link href=#networking aria-label="Heading self-link"></a></h2><p>We have talked about networking only to some small degree so far (<code>readiness</code> probes, pod disruption budgets, topology aware hints). The most important component is probably your ingress load balancer - everything else is managed by Kubernetes. AWS, Azure, GCP, and also OpenStack offer multi-zonal load balancers, so make use of them. In Azure and GCP, LBs are regional whereas in AWS and OpenStack, they need to be bound to a zone, which the cloud-controller-manager does by observing the zone labels at the nodes (please note that this behavior is not always working as expected, see <a href=https://github.com/kubernetes/cloud-provider-aws/issues/569>#570</a> where the AWS cloud-controller-manager is not readjusting to newly observed zones).</p><p>Please be reminded that even if you use a service mesh like <a href=https://istio.io>Istio</a>, the off-the-shelf installation/configuration usually never comes with productive settings (to simplify first-time installation and improve first-time user experience) and you will have to fine-tune your installation/configuration, much like the rest of your workload.</p><h2 id=relevant-cluster-settings>Relevant Cluster Settings<a class=td-heading-self-link href=#relevant-cluster-settings aria-label="Heading self-link"></a></h2><p>Following now a summary/list of the more relevant settings you may like to tune for Gardener-managed clusters:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  controlPlane:
</span></span><span style=display:flex><span>    highAvailability:
</span></span><span style=display:flex><span>      failureTolerance:
</span></span><span style=display:flex><span>        type: zone <span style=color:green># valid values are `node` and `zone` (only available if your control plane resides in a region with 3+ zones)</span>
</span></span><span style=display:flex><span>  kubernetes:
</span></span><span style=display:flex><span>    kubeAPIServer:
</span></span><span style=display:flex><span>      defaultNotReadyTolerationSeconds: 300
</span></span><span style=display:flex><span>      defaultUnreachableTolerationSeconds: 300
</span></span><span style=display:flex><span>    kubelet:
</span></span><span style=display:flex><span>      ...
</span></span><span style=display:flex><span>    kubeScheduler:
</span></span><span style=display:flex><span>      featureGates:
</span></span><span style=display:flex><span>        MinDomainsInPodTopologySpread: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>    kubeControllerManager:
</span></span><span style=display:flex><span>      nodeMonitorGracePeriod: 40s
</span></span><span style=display:flex><span>      horizontalPodAutoscaler:
</span></span><span style=display:flex><span>        syncPeriod: 15s
</span></span><span style=display:flex><span>        tolerance: 0.1
</span></span><span style=display:flex><span>        downscaleStabilization: 5m0s
</span></span><span style=display:flex><span>        initialReadinessDelay: 30s
</span></span><span style=display:flex><span>        cpuInitializationPeriod: 5m0s
</span></span><span style=display:flex><span>    verticalPodAutoscaler:
</span></span><span style=display:flex><span>      enabled: <span style=color:#00f>true</span>
</span></span><span style=display:flex><span>      evictAfterOOMThreshold: 10m0s
</span></span><span style=display:flex><span>      evictionRateBurst: 1
</span></span><span style=display:flex><span>      evictionRateLimit: -1
</span></span><span style=display:flex><span>      evictionTolerance: 0.5
</span></span><span style=display:flex><span>      recommendationMarginFraction: 0.15
</span></span><span style=display:flex><span>      updaterInterval: 1m0s
</span></span><span style=display:flex><span>      recommenderInterval: 1m0s
</span></span><span style=display:flex><span>    clusterAutoscaler:
</span></span><span style=display:flex><span>      expander: <span style=color:#a31515>&#34;least-waste&#34;</span>
</span></span><span style=display:flex><span>      scanInterval: 10s
</span></span><span style=display:flex><span>      scaleDownDelayAfterAdd: 60m
</span></span><span style=display:flex><span>      scaleDownDelayAfterDelete: 0s
</span></span><span style=display:flex><span>      scaleDownDelayAfterFailure: 3m
</span></span><span style=display:flex><span>      scaleDownUnneededTime: 30m
</span></span><span style=display:flex><span>      scaleDownUtilizationThreshold: 0.5
</span></span><span style=display:flex><span>  provider:
</span></span><span style=display:flex><span>    workers:
</span></span><span style=display:flex><span>    - name: ...
</span></span><span style=display:flex><span>      minimum: 6
</span></span><span style=display:flex><span>      maximum: 60
</span></span><span style=display:flex><span>      maxSurge: 3
</span></span><span style=display:flex><span>      maxUnavailable: 0
</span></span><span style=display:flex><span>      zones:
</span></span><span style=display:flex><span>      - ... <span style=color:green># list of zones you want your worker pool nodes to be spread across, see above</span>
</span></span><span style=display:flex><span>      kubernetes:
</span></span><span style=display:flex><span>        kubelet:
</span></span><span style=display:flex><span>          ... <span style=color:green># similar to `kubelet` above (cluster-wide settings), but here per worker pool (pool-specific settings), see above</span>
</span></span><span style=display:flex><span>      machineControllerManager: <span style=color:green># optional, it allows to configure the machine-controller settings.</span>
</span></span><span style=display:flex><span>        machineCreationTimeout: 20m
</span></span><span style=display:flex><span>        machineHealthTimeout: 10m
</span></span><span style=display:flex><span>        machineDrainTimeout: 60h
</span></span><span style=display:flex><span>  systemComponents:
</span></span><span style=display:flex><span>    coreDNS:
</span></span><span style=display:flex><span>      autoscaling:
</span></span><span style=display:flex><span>        mode: horizontal <span style=color:green># valid values are `horizontal` (driven by CPU load) and `cluster-proportional` (driven by number of nodes/cores)</span>
</span></span></code></pre></div><h4 id=on-speccontrolplanehighavailabilityfailuretolerancetype>On <code>spec.controlPlane.highAvailability.failureTolerance.type</code><a class=td-heading-self-link href=#on-speccontrolplanehighavailabilityfailuretolerancetype aria-label="Heading self-link"></a></h4><p>If set, determines the degree of failure tolerance for your control plane. <code>zone</code> is preferred, but only available if your control plane resides in a region with 3+ zones. See <a href=/docs/guides/high-availability/best-practices/#control-plane>above</a> and the <a href=/docs/guides/high-availability/control-plane/>docs</a>.</p><h4 id=on-speckuberneteskubeapiserverdefaultunreachabletolerationseconds-and-defaultnotreadytolerationseconds>On <code>spec.kubernetes.kubeAPIServer.defaultUnreachableTolerationSeconds</code> and <code>defaultNotReadyTolerationSeconds</code><a class=td-heading-self-link href=#on-speckuberneteskubeapiserverdefaultunreachabletolerationseconds-and-defaultnotreadytolerationseconds aria-label="Heading self-link"></a></h4><p>This is a very interesting <a href=https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver>API server setting</a> that lets Kubernetes decide how fast to evict pods from nodes whose status condition of type <code>Ready</code> is either <code>Unknown</code> (node status unknown, a.k.a unreachable) or <code>False</code> (<code>kubelet</code> not ready) (see <a href=https://kubernetes.io/docs/concepts/architecture/nodes/#condition>node status conditions</a>; please note that <code>kubectl</code> shows both values as <code>NotReady</code> which is a somewhat &ldquo;simplified&rdquo; visualization).</p><p>You can also override the cluster-wide API server settings <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/#taint-based-evictions>individually per pod</a>:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  tolerations:
</span></span><span style=display:flex><span>  - key: <span style=color:#a31515>&#34;node.kubernetes.io/unreachable&#34;</span>
</span></span><span style=display:flex><span>    operator: <span style=color:#a31515>&#34;Exists&#34;</span>
</span></span><span style=display:flex><span>    effect: <span style=color:#a31515>&#34;NoExecute&#34;</span>
</span></span><span style=display:flex><span>    tolerationSeconds: 0
</span></span><span style=display:flex><span>  - key: <span style=color:#a31515>&#34;node.kubernetes.io/not-ready&#34;</span>
</span></span><span style=display:flex><span>    operator: <span style=color:#a31515>&#34;Exists&#34;</span>
</span></span><span style=display:flex><span>    effect: <span style=color:#a31515>&#34;NoExecute&#34;</span>
</span></span><span style=display:flex><span>    tolerationSeconds: 0
</span></span></code></pre></div><p>This will evict pods on unreachable or not-ready nodes immediately, but be cautious: <code>0</code> is very aggressive and may lead to unnecessary disruptions. Again, you must decide for your own workload and balance out the pros and cons (e.g. long startup time).</p><p>Please note, these settings replace <code>spec.kubernetes.kubeControllerManager.podEvictionTimeout</code> that was deprecated with Kubernetes <code>v1.26</code> (and acted as an upper bound).</p><h4 id=on-speckuberneteskubeschedulerfeaturegatesmindomainsinpodtopologyspread>On <code>spec.kubernetes.kubeScheduler.featureGates.MinDomainsInPodTopologySpread</code><a class=td-heading-self-link href=#on-speckuberneteskubeschedulerfeaturegatesmindomainsinpodtopologyspread aria-label="Heading self-link"></a></h4><p>Required to be enabled for <code>minDomains</code> to work with PTSCs (beta since Kubernetes <code>v1.25</code>, but off by default). See <a href=/docs/guides/high-availability/best-practices/#pod-topology-spread-constraints>above</a> and the <a href=https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/#topologyspreadconstraints-field>docs</a>. This tells the scheduler, how many topology domains to expect (=zones in the context of this document).</p><h4 id=on-speckuberneteskubecontrollermanagernodemonitorgraceperiod>On <code>spec.kubernetes.kubeControllerManager.nodeMonitorGracePeriod</code><a class=td-heading-self-link href=#on-speckuberneteskubecontrollermanagernodemonitorgraceperiod aria-label="Heading self-link"></a></h4><p>This is another very interesting <a href=https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager>kube-controller-manager setting</a> that can help you speed up or slow down how fast a node shall be considered <code>Unknown</code> (node status unknown, a.k.a unreachable) when the <code>kubelet</code> is not updating its status anymore (see <a href=https://kubernetes.io/docs/concepts/architecture/nodes/#condition>node status conditions</a>), which effects eviction (see <code>spec.kubernetes.kubeAPIServer.defaultUnreachableTolerationSeconds</code> and <code>defaultNotReadyTolerationSeconds</code> above). The shorter the time window, the faster Kubernetes will act, but the higher the chance of flapping behavior and pod trashing, so you may want to balance that out according to your needs, otherwise stick to the default which is a reasonable compromise.</p><h4 id=on-speckuberneteskubecontrollermanagerhorizontalpodautoscaler>On <code>spec.kubernetes.kubeControllerManager.horizontalPodAutoscaler...</code><a class=td-heading-self-link href=#on-speckuberneteskubecontrollermanagerhorizontalpodautoscaler aria-label="Heading self-link"></a></h4><p>This configures horizontal pod autoscaling in Gardener-managed clusters. See <a href=/docs/guides/high-availability/best-practices/#replicas-horizontal-scaling>above</a> and the <a href=https://kubernetes.io/de/docs/tasks/run-application/horizontal-pod-autoscale>docs</a> for the detailed fields.</p><h4 id=on-speckubernetesverticalpodautoscaler>On <code>spec.kubernetes.verticalPodAutoscaler...</code><a class=td-heading-self-link href=#on-speckubernetesverticalpodautoscaler aria-label="Heading self-link"></a></h4><p>This configures vertical pod autoscaling in Gardener-managed clusters. See <a href=/docs/guides/high-availability/best-practices/#resources-vertical-scaling>above</a> and the <a href=https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/README.md>docs</a> for the detailed fields.</p><h4 id=on-speckubernetesclusterautoscaler>On <code>spec.kubernetes.clusterAutoscaler...</code><a class=td-heading-self-link href=#on-speckubernetesclusterautoscaler aria-label="Heading self-link"></a></h4><p>This configures node auto-scaling in Gardener-managed clusters. See <a href=/docs/guides/high-availability/best-practices/#worker-pools>above</a> and the <a href=https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md>docs</a> for the detailed fields, especially about <a href=https://github.com/gardener/autoscaler/blob/machine-controller-manager-provider/cluster-autoscaler/FAQ.md#what-are-expanders>expanders</a>, which may become life-saving in case of a zone outage when a resource crunch is setting in and everybody rushes to get machines in the healthy zones.</p><p>In case of a zone outage, it is critical to understand how the cluster autoscaler will put a worker pool in one zone into &ldquo;back-off&rdquo; and what the consequences for your workload will be. Unfortunately, the official cluster autoscaler documentation does not explain these details, but you can find hints in the <a href=https://github.com/kubernetes/autoscaler/blob/b94f340af58eb063df9ebfcd65835f9a499a69a2/cluster-autoscaler/config/autoscaling_options.go#L214-L219>source code</a>:</p><p>If a node fails to come up, the node group (worker pool in that zone) will go into &ldquo;back-off&rdquo;, at first 5m, then <a href=https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/utils/backoff/exponential_backoff.go#L77-L82>exponentially longer</a> until the maximum of 30m is reached. The &ldquo;back-off&rdquo; is reset after 3 hours. This in turn means, that nodes must be first considered <code>Unknown</code>, which happens when <code>spec.kubernetes.kubeControllerManager.nodeMonitorGracePeriod</code> lapses (e.g. at the beginning of a zone outage). Then they must either remain in this state until <code>spec.provider.workers.machineControllerManager.machineHealthTimeout</code> lapses for them to be recreated, which will fail in the unhealthy zone, or <code>spec.kubernetes.kubeAPIServer.defaultUnreachableTolerationSeconds</code> lapses for the pods to be evicted (usually faster than node replacements, depending on your configuration), which will trigger the cluster autoscaler to create more capacity, but very likely in the same zone as it tries to balance its node groups at first, which will fail in the unhealthy zone. It will be considered failed only when <code>maxNodeProvisionTime</code> lapses (usually close to <code>spec.provider.workers.machineControllerManager.machineCreationTimeout</code>) and only then put the node group into &ldquo;back-off&rdquo; and not retry for 5m (at first and then exponentially longer). Only then you can expect new node capacity to be brought up somewhere else.</p><p>During the time of ongoing node provisioning (before a node group goes into &ldquo;back-off&rdquo;), the cluster autoscaler may have &ldquo;virtually scheduled&rdquo; pending pods onto those new upcoming nodes and will not reevaluate these pods anymore unless the node provisioning fails (which will fail during a zone outage, but the cluster autoscaler cannot know that and will therefore reevaluate its decision only after it has given up on the new nodes).</p><p>It&rsquo;s critical to keep that in mind and accommodate for it. If you have already capacity up and running, the reaction time is usually much faster with leases (whatever you set) or endpoints (<code>spec.kubernetes.kubeControllerManager.nodeMonitorGracePeriod</code>), but if you depend on new/fresh capacity, the above should inform you how long you will have to wait for it and for how long pods might be pending (because capacity is generally missing and pending pods may have been &ldquo;virtually scheduled&rdquo; to new nodes that won&rsquo;t come up until the node group goes eventually into &ldquo;back-off&rdquo; and nodes in the healthy zones come up).</p><h4 id=on-specproviderworkersminimum-maximum-maxsurge-maxunavailable-zones-and-machinecontrollermanager>On <code>spec.provider.workers.minimum</code>, <code>maximum</code>, <code>maxSurge</code>, <code>maxUnavailable</code>, <code>zones</code>, and <code>machineControllerManager</code><a class=td-heading-self-link href=#on-specproviderworkersminimum-maximum-maxsurge-maxunavailable-zones-and-machinecontrollermanager aria-label="Heading self-link"></a></h4><p>Each worker pool in Gardener may be configured differently. Among many other settings like machine type, root disk, Kubernetes version, <code>kubelet</code> settings, and many more you can also specify the lower and upper bound for the number of machines (<code>minimum</code> and <code>maximum</code>), how many machines may be added additionally during a rolling update (<code>maxSurge</code>) and how many machines may be in termination/recreation during a rolling update (<code>maxUnavailable</code>), and of course across how many zones the nodes shall be spread (<code>zones</code>).</p><p>Gardener divides <code>minimum</code>, <code>maximum</code>, <code>maxSurge</code>, <code>maxUnavailable</code> values by the number of zones specified for this worker pool. This fact must be considered when you plan the sizing of your worker pools.</p><p><em>Example:</em></p><pre tabindex=0><code>  provider:
    workers:
    - name: ...
      minimum: 6
      maximum: 60
      maxSurge: 3
      maxUnavailable: 0
      zones: [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;]
</code></pre><ul><li>The resulting <code>MachineDeployment</code>s <strong>per zone</strong> will get <code>minimum: 2</code>, <code>maximum: 20</code>, <code>maxSurge: 1</code>, <code>maxUnavailable: 0</code>.</li><li>If another zone is added all values will be divided by <code>4</code>, resulting in:<ul><li>Less workers per zone.</li><li>&#9888;&#xfe0f; One <code>MachineDeployment</code> with <code>maxSurge: 0</code>, i.e. there will be a replacement of nodes without rolling updates.</li></ul></li></ul><p>Interesting is also the configuration for Gardener&rsquo;s machine-controller-manager or MCM for short that provisions, monitors, terminates, replaces, or updates machines that back your nodes:</p><ul><li>The shorter <code>machineCreationTimeout</code> is, the faster MCM will retry to create a machine/node, if the process is stuck on cloud provider side. It is set to useful/practical timeouts for the different cloud providers and you probably don&rsquo;t want to change those (in the context of HA at least). Please align with the cluster autoscaler&rsquo;s <code>maxNodeProvisionTime</code>.</li><li>The shorter <code>machineHealthTimeout</code> is, the faster MCM will replace machines/nodes in case the kubelet isn&rsquo;t reporting back, which translates to <code>Unknown</code>, or reports back with <code>NotReady</code>, or the <a href=https://github.com/kubernetes/node-problem-detector>node-problem-detector</a> that Gardener deploys for you reports a non-recoverable issue/condition (e.g. read-only file system). If it is too short however, you risk node and pod trashing, so be careful.</li><li>The shorter <code>machineDrainTimeout</code> is, the faster you can get rid of machines/nodes that MCM decided to remove, but this puts a cap on the grace periods and PDBs. They are respected up until the drain timeout lapses - then the machine/node will be forcefully terminated, whether or not the pods are still in termination or not even terminated because of PDBs. Those PDBs will then be violated, so be careful here as well. Please align with the cluster autoscaler&rsquo;s <code>maxGracefulTerminationSeconds</code>.</li></ul><p>Especially the last two settings may help you recover faster from cloud provider issues.</p><h4 id=on-specsystemcomponentscorednsautoscaling>On <code>spec.systemComponents.coreDNS.autoscaling</code><a class=td-heading-self-link href=#on-specsystemcomponentscorednsautoscaling aria-label="Heading self-link"></a></h4><p>DNS is critical, in general and also within a Kubernetes cluster. Gardener-managed clusters deploy <a href=https://coredns.io>CoreDNS</a>, a graduated CNCF project. Gardener supports 2 auto-scaling modes for it, <code>horizontal</code> (using HPA based on CPU) and <code>cluster-proportional</code> (using <a href=https://github.com/kubernetes-sigs/cluster-proportional-autoscaler>cluster proportional autoscaler</a> that scales the number of pods based on the number of nodes/cores, not to be confused with the cluster autoscaler that scales nodes based on their utilization). Check out the <a href=/docs/gardener/autoscaling/dns-autoscaling/>docs</a>, especially the <a href=/docs/gardener/autoscaling/dns-autoscaling/#trade-offs-of-horizontal-and-cluster-proportional-dns-autoscaling>trade-offs</a> why you would chose one over the other (<code>cluster-proportional</code> gives you more configuration options, if CPU-based horizontal scaling is insufficient to your needs). Consider also Gardener&rsquo;s feature <a href=/docs/gardener/networking/node-local-dns/>node-local DNS</a> to decouple you further from the DNS pods and stabilize DNS. Again, that&rsquo;s not strictly related to HA, but may become important during a zone outage, when load patterns shift and pods start to initialize/resolve DNS records more frequently in bulk.</p><h2 id=more-caveats>More Caveats<a class=td-heading-self-link href=#more-caveats aria-label="Heading self-link"></a></h2><p>Unfortunately, there are a few more things of note when it comes to HA in a Kubernetes cluster that may be &ldquo;surprising&rdquo; and hard to mitigate:</p><ul><li>If the <code>kubelet</code> restarts, it will report all pods as <code>NotReady</code> on startup until it reruns its probes (<a href=https://github.com/kubernetes/kubernetes/issues/100277>#100277</a>), which leads to temporary endpoint and load balancer target removal (<a href=https://github.com/kubernetes/kubernetes/issues/102367>#102367</a>). This topic is somewhat controversial. Gardener uses rolling updates and a jitter to spread necessary <code>kubelet</code> restarts as good as possible.</li><li>If a <code>kube-proxy</code> pod on a node turns <code>NotReady</code>, all load balancer traffic to all pods (on this node) under services with <code>externalTrafficPolicy</code> <code>local</code> will cease as the load balancer will then take this node out of serving. This topic is somewhat controversial as well. So, please remember that <code>externalTrafficPolicy</code> <code>local</code> not only has the disadvantage of imbalanced traffic spreading, but also a dependency to the kube-proxy pod that may and will be unavailable during updates. Gardener uses rolling updates to spread necessary <code>kube-proxy</code> updates as good as possible.</li></ul><p>These are just a few additional considerations. They may or may not affect you, but other intricacies may. It&rsquo;s a reminder to be watchful as Kubernetes may have one or two relevant quirks that you need to consider (and will probably only find out over time and with extensive testing).</p><h2 id=meaningful-availability>Meaningful Availability<a class=td-heading-self-link href=#meaningful-availability aria-label="Heading self-link"></a></h2><p>Finally, let&rsquo;s go back to where we started. We recommended to measure <a href=https://research.google/pubs/pub50828>meaningful availability</a>. For instance, in Gardener, we do not trust only internal signals, but track also whether Gardener or the control planes that it manages are externally available through the external DNS records and load balancers, SNI-routing Istio gateways, etc. (the same path all users must take). It&rsquo;s a huge difference whether the API server&rsquo;s internal readiness probe passes or the user can actually reach the API server and it does what it&rsquo;s supposed to do. Most likely, you will be in a similar spot and can do the same.</p><p>What you do with these signals is another matter. Maybe there are some actionable metrics and you can trigger some active fail-over, maybe you can only use it to improve your HA setup altogether. In our case, we also use it to deploy mitigations, e.g. via our <a href=https://github.com/gardener/dependency-watchdog>dependency-watchdog</a> that watches, for instance, Gardener-managed API servers and shuts down components like the controller managers to avert cascading knock-off effects (e.g. melt-down if the <code>kubelets</code> cannot reach the API server, but the controller managers can and start taking down nodes and pods).</p><p>Either way, understanding how users perceive your service is key to the improvement process as a whole. Even if you are not struck by a zone outage, the measures above and tracking the meaningful availability will help you improve your service.</p><p>Thank you for your interest.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-b5a6d1d059abdd75c072cd004ca974fb>2 - Chaos Engineering</h1><h2 id=overview>Overview<a class=td-heading-self-link href=#overview aria-label="Heading self-link"></a></h2><p>Gardener provides <a href=https://chaostoolkit.org><code>chaostoolkit</code></a> modules to simulate <em>compute</em> and <em>network</em> outages for various cloud providers such as <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/aws>AWS</a>, <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/azure>Azure</a>, <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/gcp>GCP</a>, <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/openstack>OpenStack/Converged Cloud</a>, and <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/vsphere>VMware vSphere</a>, as well as <em>pod disruptions</em> for <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/k8s>any Kubernetes cluster</a>.</p><p>The API, parameterization, and implementation is as homogeneous as possible across the different cloud providers, so that you have only minimal effort. As a Gardener user, you benefit from an <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/garden>additional <code>garden</code> module</a> that leverages the generic modules, but exposes their functionality in the most simple, homogeneous, and secure way (no need to specify cloud provider credentials, cluster credentials, or filters explicitly; retrieves credentials and stores them in memory only).</p><h2 id=installation>Installation<a class=td-heading-self-link href=#installation aria-label="Heading self-link"></a></h2><p>The name of the package is <code>chaosgarden</code> and it was developed and tested with Python 3.9+. It&rsquo;s being published to <a href=https://pypi.org/project/chaosgarden>PyPI</a>, so that you can comfortably install it via Python&rsquo;s package installer <a href=https://pip.pypa.io/en/stable>pip</a> (you may want to <a href=https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/#creating-a-virtual-environment>create a virtual environment</a> before installing it):</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>pip install chaosgarden
</span></span></code></pre></div><p>ℹ️ If you want to use the <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/vsphere>VMware vSphere module</a>, please note the remarks in <a href=https://github.com/gardener/chaos-engineering/blob/main/requirements.txt><code>requirements.txt</code></a> for <code>vSphere</code>. Those are not contained in the published PyPI package.</p><p>The package can be used directly from Python scripts and supports this usage scenario with additional convenience that helps launch actions and probes in background (more on actions and probes later), so that you can compose also complex scenarios with ease.</p><p>If this technology is new to you, you will probably prefer the <a href=https://chaostoolkit.org><code>chaostoolkit</code></a> <a href=https://chaostoolkit.org/reference/usage/cli>CLI</a> in combination with <a href=https://chaostoolkit.org/reference/api/experiment>experiment files</a>, so we need to <a href=https://chaostoolkit.org/reference/usage/install/#install-the-cli>install the CLI</a> next:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>pip install chaostoolkit
</span></span></code></pre></div><p>Please verify that it was installed properly by running:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>chaos --help
</span></span></code></pre></div><h2 id=usage>Usage<a class=td-heading-self-link href=#usage aria-label="Heading self-link"></a></h2><p>ℹ️ We assume you are using Gardener and run Gardener-managed shoot clusters. You can also use the generic cloud provider and Kubernetes <code>chaosgarden</code> modules, but configuration and secrets will then differ. Please see the <a href=https://github.com/gardener/chaos-engineering/tree/main/docs>module docs</a> for details.</p><h3 id=a-simple-experiment>A Simple Experiment<a class=td-heading-self-link href=#a-simple-experiment aria-label="Heading self-link"></a></h3><p>The most important command is the <a href=https://chaostoolkit.org/reference/usage/run><code>run</code></a> command, but before we can use it, we need to compile an experiment file first. Let&rsquo;s start with a simple one, invoking only a read-only 📖 action from <code>chaosgarden</code> that lists cloud provider machines and networks (depends on cloud provider) for the &ldquo;first&rdquo; zone of one of your shoot clusters.</p><p>Let&rsquo;s assume, your project is called <code>my-project</code> and your shoot is called <code>my-shoot</code>, then we need to create the following experiment:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    &#34;title&#34;: <span style=color:#a31515>&#34;assess-filters-impact&#34;</span>,
</span></span><span style=display:flex><span>    &#34;description&#34;: <span style=color:#a31515>&#34;assess-filters-impact&#34;</span>,
</span></span><span style=display:flex><span>    &#34;method&#34;: [
</span></span><span style=display:flex><span>        {
</span></span><span style=display:flex><span>            &#34;type&#34;: <span style=color:#a31515>&#34;action&#34;</span>,
</span></span><span style=display:flex><span>            &#34;name&#34;: <span style=color:#a31515>&#34;assess-filters-impact&#34;</span>,
</span></span><span style=display:flex><span>            &#34;provider&#34;: {
</span></span><span style=display:flex><span>                &#34;type&#34;: <span style=color:#a31515>&#34;python&#34;</span>,
</span></span><span style=display:flex><span>                &#34;module&#34;: <span style=color:#a31515>&#34;chaosgarden.garden.actions&#34;</span>,
</span></span><span style=display:flex><span>                &#34;func&#34;: <span style=color:#a31515>&#34;assess_cloud_provider_filters_impact&#34;</span>,
</span></span><span style=display:flex><span>                &#34;arguments&#34;: {
</span></span><span style=display:flex><span>                    &#34;zone&#34;: 0
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    ],
</span></span><span style=display:flex><span>    &#34;configuration&#34;: {
</span></span><span style=display:flex><span>        &#34;garden_project&#34;: <span style=color:#a31515>&#34;my-project&#34;</span>,
</span></span><span style=display:flex><span>        &#34;garden_shoot&#34;: <span style=color:#a31515>&#34;my-shoot&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>We are not yet there and need one more thing to do before we can run it: We need to &ldquo;target&rdquo; the Gardener landscape resp. Gardener API server where you have created your shoot cluster (not to be confused with your shoot cluster API server). If you do not know what this is or how to download the Gardener API server <code>kubeconfig</code>, please follow <a href=/docs/dashboard/project-operations/#prerequisites>these instructions</a>. You can either download your <em>personal</em> credentials or <em>project</em> credentials (see <a href=/docs/dashboard/automated-resource-management/#prerequisites>creation of a <code>serviceaccount</code></a>) to interact with Gardener. For now (fastest and most convenient way, but generally not recommended), let&rsquo;s use your <em>personal</em> credentials, but if you later plan to automate your experiments, please use proper <em>project</em> credentials (a <code>serviceaccount</code> is not bound to your person, but to the project, and can be restricted using <a href=https://kubernetes.io/docs/reference/access-authn-authz/rbac>RBAC roles and role bindings</a>, which is why we recommend this for production).</p><p>To download your <em>personal</em> credentials, open the Gardener Dashboard and click on your avatar in the upper right corner of the page. Click &ldquo;My Account&rdquo;, then look for the &ldquo;Access&rdquo; pane, then &ldquo;Kubeconfig&rdquo;, then press the &ldquo;Download&rdquo; button and save the <code>kubeconfig</code> to disk. Run the following command next:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>export KUBECONFIG=path/to/kubeconfig
</span></span></code></pre></div><p>We are now set and you can run your first experiment:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>chaos run path/to/experiment
</span></span></code></pre></div><p>You should see output like this (depends on cloud provider):</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>[INFO] Validating the experiment&#39;s syntax
</span></span><span style=display:flex><span>[INFO] Installing signal handlers to terminate all active background threads on involuntary signals (note that SIGKILL cannot be handled).
</span></span><span style=display:flex><span>[INFO] Experiment looks valid
</span></span><span style=display:flex><span>[INFO] Running experiment: assess-filters-impact
</span></span><span style=display:flex><span>[INFO] Steady-state strategy: default
</span></span><span style=display:flex><span>[INFO] Rollbacks strategy: default
</span></span><span style=display:flex><span>[INFO] No steady state hypothesis defined. That&#39;s ok, just exploring.
</span></span><span style=display:flex><span>[INFO] Playing your experiment&#39;s method now...
</span></span><span style=display:flex><span>[INFO] Action: assess-filters-impact
</span></span><span style=display:flex><span>[INFO] Validating client credentials and listing probably impacted instances and/or networks with the given arguments zone=&#39;world-1a&#39; and filters={&#39;instances&#39;: [{&#39;Name&#39;: &#39;tag-key&#39;, &#39;Values&#39;: [&#39;kubernetes.io/cluster/shoot--my-project--my-shoot&#39;]}], &#39;vpcs&#39;: [{&#39;Name&#39;: &#39;tag-key&#39;, &#39;Values&#39;: [&#39;kubernetes.io/cluster/shoot--my-project--my-shoot&#39;]}]}:
</span></span><span style=display:flex><span>[INFO] 1 instance(s) would be impacted:
</span></span><span style=display:flex><span>[INFO] - i-aabbccddeeff0000
</span></span><span style=display:flex><span>[INFO] 1 VPC(s) would be impacted:
</span></span><span style=display:flex><span>[INFO] - vpc-aabbccddeeff0000
</span></span><span style=display:flex><span>[INFO] Let&#39;s rollback...
</span></span><span style=display:flex><span>[INFO] No declared rollbacks, let&#39;s move on.
</span></span><span style=display:flex><span>[INFO] Experiment ended with status: completed
</span></span></code></pre></div><p>🎉 Congratulations! You successfully ran your first <code>chaosgarden</code> experiment.</p><h3 id=a-destructive-experiment>A Destructive Experiment<a class=td-heading-self-link href=#a-destructive-experiment aria-label="Heading self-link"></a></h3><p>Now let&rsquo;s break 🪓 your cluster. Be advised that this experiment will be destructive in the sense that we will temporarily network-partition all nodes in one availability zone (machine termination or restart is available with <code>chaosgarden</code> as well). That means, these nodes and their pods won&rsquo;t be able to &ldquo;talk&rdquo; to other nodes, pods, and services. Also, the API server will become unreachable for them and the API server will report them as unreachable (confusingly shown as <code>NotReady</code> when you run <code>kubectl get nodes</code> and <code>Unknown</code> in the status <code>Ready</code> condition when you run <code>kubectl get nodes --output yaml</code>).</p><p>Being unreachable will trigger service endpoint and load balancer de-registration (when the node&rsquo;s grace period lapses) as well as eventually pod eviction and machine replacement (which will continue to fail under test). We won&rsquo;t run the experiment long enough for all of these effects to materialize, but the longer you run it, the more will happen, up to temporarily giving up/going into &ldquo;back-off&rdquo; for the affected worker pool in that zone. You will also see that the Kubernetes cluster autoscaler will try to create a new machine almost immediately, if pods are pending for the affected zone (which will initially fail under test, but may succeed later, which again depends on the runtime of the experiment and whether or not the cluster autoscaler goes into &ldquo;back-off&rdquo; or not).</p><p>But for now, all of this doesn&rsquo;t matter as we want to start &ldquo;small&rdquo;. You can later read up more on the various settings and effects in our <a href=/docs/guides/high-availability/best-practices/>best practices guide on high availability</a>.</p><p>Please create a new experiment file, this time with this content:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    &#34;title&#34;: <span style=color:#a31515>&#34;run-network-failure-simulation&#34;</span>,
</span></span><span style=display:flex><span>    &#34;description&#34;: <span style=color:#a31515>&#34;run-network-failure-simulation&#34;</span>,
</span></span><span style=display:flex><span>    &#34;method&#34;: [
</span></span><span style=display:flex><span>        {
</span></span><span style=display:flex><span>            &#34;type&#34;: <span style=color:#a31515>&#34;action&#34;</span>,
</span></span><span style=display:flex><span>            &#34;name&#34;: <span style=color:#a31515>&#34;run-network-failure-simulation&#34;</span>,
</span></span><span style=display:flex><span>            &#34;provider&#34;: {
</span></span><span style=display:flex><span>                &#34;type&#34;: <span style=color:#a31515>&#34;python&#34;</span>,
</span></span><span style=display:flex><span>                &#34;module&#34;: <span style=color:#a31515>&#34;chaosgarden.garden.actions&#34;</span>,
</span></span><span style=display:flex><span>                &#34;func&#34;: <span style=color:#a31515>&#34;run_cloud_provider_network_failure_simulation&#34;</span>,
</span></span><span style=display:flex><span>                &#34;arguments&#34;: {
</span></span><span style=display:flex><span>                    &#34;mode&#34;: <span style=color:#a31515>&#34;total&#34;</span>,
</span></span><span style=display:flex><span>                    &#34;zone&#34;: 0,
</span></span><span style=display:flex><span>                    &#34;duration&#34;: 60
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    ],
</span></span><span style=display:flex><span>    &#34;rollbacks&#34;: [
</span></span><span style=display:flex><span>        {
</span></span><span style=display:flex><span>            &#34;type&#34;: <span style=color:#a31515>&#34;action&#34;</span>,
</span></span><span style=display:flex><span>            &#34;name&#34;: <span style=color:#a31515>&#34;rollback-network-failure-simulation&#34;</span>,
</span></span><span style=display:flex><span>            &#34;provider&#34;: {
</span></span><span style=display:flex><span>                &#34;type&#34;: <span style=color:#a31515>&#34;python&#34;</span>,
</span></span><span style=display:flex><span>                &#34;module&#34;: <span style=color:#a31515>&#34;chaosgarden.garden.actions&#34;</span>,
</span></span><span style=display:flex><span>                &#34;func&#34;: <span style=color:#a31515>&#34;rollback_cloud_provider_network_failure_simulation&#34;</span>,
</span></span><span style=display:flex><span>                &#34;arguments&#34;: {
</span></span><span style=display:flex><span>                    &#34;mode&#34;: <span style=color:#a31515>&#34;total&#34;</span>,
</span></span><span style=display:flex><span>                    &#34;zone&#34;: 0
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    ],
</span></span><span style=display:flex><span>    &#34;configuration&#34;: {
</span></span><span style=display:flex><span>        &#34;garden_project&#34;: {
</span></span><span style=display:flex><span>            &#34;type&#34;: <span style=color:#a31515>&#34;env&#34;</span>,
</span></span><span style=display:flex><span>            &#34;key&#34;: <span style=color:#a31515>&#34;GARDEN_PROJECT&#34;</span>
</span></span><span style=display:flex><span>        },
</span></span><span style=display:flex><span>        &#34;garden_shoot&#34;: {
</span></span><span style=display:flex><span>            &#34;type&#34;: <span style=color:#a31515>&#34;env&#34;</span>,
</span></span><span style=display:flex><span>            &#34;key&#34;: <span style=color:#a31515>&#34;GARDEN_SHOOT&#34;</span>
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>ℹ️ There is an even more destructive action that terminates or alternatively restarts machines in a given zone 🔥 (immediately or delayed with some randomness/chaos for maximum inconvenience for the nodes and pods). You can find links to all these examples at the end of this tutorial.</p><p>This experiment is very similar, but this time we will break 🪓 your cluster - for <code>60s</code>. If that&rsquo;s too short to even see a node or pod transition from <code>Ready</code> to <code>NotReady</code> (actually <code>Unknown</code>), then increase the <code>duration</code>. Depending on the workload that your cluster runs, you may already see effects of the network partitioning, because it is effective immediately. It&rsquo;s just that Kubernetes cannot know immediately and rather assumes that something is failing only <strong>after</strong> the node&rsquo;s grace period lapses, but the actual workload is impacted immediately.</p><p>Most notably, this experiment also has a <a href=https://chaostoolkit.org/reference/concepts/#rollbacks><code>rollbacks</code></a> section, which is invoked even if you abort the experiment or it fails unexpectedly, but only if you run the CLI with the option <code>--rollback-strategy always</code> which we will do soon. Any <code>chaosgarden</code> action that can undo its activity, will do that implicitly when the <code>duration</code> lapses, but it is a best practice to always configure a <code>rollbacks</code> section in case something unexpected happens. Should you be in panic and just want to run the <code>rollbacks</code> section, you can remove all other actions and the CLI will execute the <code>rollbacks</code> section immediately.</p><p>One other thing is different in the second experiment as well. We now read the name of the project and the shoot from the environment, i.e. a <a href=https://chaostoolkit.org/reference/api/experiment/#configuration><code>configuration</code></a> section can automatically expand <a href=https://chaostoolkit.org/reference/api/experiment/#environment-configurations>environment variables</a>. Also useful to know (not shown here), <code>chaostoolkit</code> supports <a href=https://chaostoolkit.org/reference/api/experiment/#variable-substitution>variable substitution</a> too, so that you have to define variables only once. Please note that you can also add a <a href=https://chaostoolkit.org/reference/api/experiment/#secrets><code>secrets</code></a> section that can also automatically expand <a href=https://chaostoolkit.org/reference/api/experiment/#environment-secrets>environment variables</a>. For instance, instead of targeting the Gardener API server via <code>$KUBECONFIG</code>, which is supported by our <code>chaosgarden</code> package natively, you can also explicitly refer to it in a <code>secrets</code> section (for brevity reasons not shown here either).</p><p>Let&rsquo;s now run your second experiment (please watch your nodes and pods in parallel, e.g. by running <code>watch kubectl get nodes,pods --output wide</code> in another terminal):</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>export GARDEN_PROJECT=my-project
</span></span><span style=display:flex><span>export GARDEN_SHOOT=my-shoot
</span></span><span style=display:flex><span>chaos run --rollback-strategy always path/to/experiment
</span></span></code></pre></div><p>The output of the <code>run</code> command will be similar to the one above, but longer. It will mention either machines or networks that were network-partitioned (depends on cloud provider), but should revert everything back to normal.</p><p>Normally, you would not only run <a href=https://chaostoolkit.org/reference/concepts/#actions>actions</a> in the <code>method</code> section, but also <a href=https://chaostoolkit.org/reference/concepts/#probes>probes</a> as part of a <a href=https://chaostoolkit.org/reference/concepts/#steady-state-hypothesis>steady state hypothesis</a>. Such steady state hypothesis probes are run before and after the actions to validate that the &ldquo;system&rdquo; was in a healthy state before and gets back to a healthy state after the actions ran, hence show that the &ldquo;system&rdquo; is in a steady state when not under test. Eventually, you will write your own probes that don&rsquo;t even have to be part of a steady state hypothesis. We at Gardener run multi-zone (multiple zones at once) and rolling-zone (strike each zone once) outages with continuous custom probes all within the <code>method</code> section to validate our KPIs continuously under test (e.g. how long do the individual fail-overs take/how long is the actual outage). The most complex scenarios are even run via Python scripts as all actions and probes can also be invoked directly (which is what the CLI does).</p><h2 id=high-availability>High Availability<a class=td-heading-self-link href=#high-availability aria-label="Heading self-link"></a></h2><p>Developing highly available workload that can tolerate a zone outage is no trivial task. You can find more information on how to achieve this goal in our <a href=/docs/guides/high-availability/best-practices/>best practices guide on high availability</a>.</p><p>Thank you for your interest in Gardener chaos engineering and making your workload more resilient.</p><h2 id=further-reading>Further Reading<a class=td-heading-self-link href=#further-reading aria-label="Heading self-link"></a></h2><p>Here some links for further reading:</p><ul><li><strong>Examples</strong>: <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/tutorials/experiments>Experiments</a>, <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/tutorials/scripts>Scripts</a></li><li><strong>Gardener Chaos Engineering</strong>: <a href=https://github.com/gardener/chaos-engineering>GitHub</a>, <a href=https://pypi.org/project/chaosgarden>PyPI</a>, <a href=https://github.com/gardener/chaos-engineering/tree/main/docs/garden>Module Docs for Gardener Users</a></li><li><strong>Chaos Toolkit Core</strong>: <a href=https://chaostoolkit.org>Home Page</a>, <a href=https://chaostoolkit.org/reference/usage/install>Installation</a>, <a href=https://chaostoolkit.org/reference/concepts>Concepts</a>, <a href=https://github.com/chaostoolkit/chaostoolkit>GitHub</a></li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-747cf5936d365b93b5b0facc71cbec83>3 - Control Plane</h1><div class=lead>Failure tolerance types <code>node</code> and <code>zone</code>. Possible mitigations for zone or node outages</div><h1 id=highly-available-shoot-control-plane>Highly Available Shoot Control Plane<a class=td-heading-self-link href=#highly-available-shoot-control-plane aria-label="Heading self-link"></a></h1><p>Shoot resource offers a way to request for a highly available control plane.</p><h2 id=failure-tolerance-types>Failure Tolerance Types<a class=td-heading-self-link href=#failure-tolerance-types aria-label="Heading self-link"></a></h2><p>A highly available shoot control plane can be setup with either a failure tolerance of <code>zone</code> or <code>node</code>.</p><h3 id=node-failure-tolerance><code>Node</code> Failure Tolerance<a class=td-heading-self-link href=#node-failure-tolerance aria-label="Heading self-link"></a></h3><p>The failure tolerance of a <code>node</code> will have the following characteristics:</p><ul><li>Control plane components will be spread across different nodes within a single availability zone. There will not be
more than one replica per node for each control plane component which has more than one replica.</li><li><code>Worker pool</code> should have a minimum of 3 nodes.</li><li>A multi-node etcd (quorum size of 3) will be provisioned, offering zero-downtime capabilities with each member in a
different node within a single availability zone.</li></ul><h3 id=zone-failure-tolerance><code>Zone</code> Failure Tolerance<a class=td-heading-self-link href=#zone-failure-tolerance aria-label="Heading self-link"></a></h3><p>The failure tolerance of a <code>zone</code> will have the following characteristics:</p><ul><li>Control plane components will be spread across different availability zones. There will be at least
one replica per zone for each control plane component which has more than one replica.</li><li>Gardener scheduler will automatically select a <code>seed</code> which has a minimum of 3 zones to host the shoot control plane.</li><li>A multi-node etcd (quorum size of 3) will be provisioned, offering zero-downtime capabilities with each member in a
different zone.</li></ul><h2 id=shoot-spec>Shoot Spec<a class=td-heading-self-link href=#shoot-spec aria-label="Heading self-link"></a></h2><p>To request for a highly available shoot control plane Gardener provides the following configuration in the shoot spec:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>apiVersion: core.gardener.cloud/v1beta1
</span></span><span style=display:flex><span>kind: Shoot
</span></span><span style=display:flex><span>spec:
</span></span><span style=display:flex><span>  controlPlane:
</span></span><span style=display:flex><span>    highAvailability:
</span></span><span style=display:flex><span>      failureTolerance:
</span></span><span style=display:flex><span>        type: &lt;node | zone&gt;
</span></span></code></pre></div><p><strong>Allowed Transitions</strong></p><p>If you already have a shoot cluster with non-HA control plane, then the following upgrades are possible:</p><ul><li>Upgrade of non-HA shoot control plane to HA shoot control plane with <code>node</code> failure tolerance.</li><li>Upgrade of non-HA shoot control plane to HA shoot control plane with <code>zone</code> failure tolerance. However, it is essential that the <code>seed</code> which is currently hosting the shoot control plane should be <code>multi-zonal</code>. If it is not, then the request to upgrade will be rejected.</li></ul><blockquote><p><strong>Note:</strong> There will be a small downtime during the upgrade, especially for etcd, which will transition from a single node etcd cluster to a multi-node etcd cluster.</p></blockquote><p><strong>Disallowed Transitions</strong></p><p>If you already have a shoot cluster with HA control plane, then the following transitions are not possible:</p><ul><li>Upgrade of HA shoot control plane from <code>node</code> failure tolerance to <code>zone</code> failure tolerance is currently not supported, mainly because already existing volumes are bound to the zone they were created in originally.</li><li>Downgrade of HA shoot control plane with <code>zone</code> failure tolerance to <code>node</code> failure tolerance is currently not supported, mainly because of the same reason as above, that already existing volumes are bound to the respective zones they were created in originally.</li><li>Downgrade of HA shoot control plane with either <code>node</code> or <code>zone</code> failure tolerance, to a non-HA shoot control plane is currently not supported, mainly because <a href=https://github.com/gardener/etcd-druid>etcd-druid</a> does not currently support scaling down of a multi-node etcd cluster to a single-node etcd cluster.</li></ul><h2 id=zone-outage-situation>Zone Outage Situation<a class=td-heading-self-link href=#zone-outage-situation aria-label="Heading self-link"></a></h2><p>Implementing highly available software that can tolerate even a zone outage unscathed is no trivial task. You may find our <a href=/docs/guides/high-availability/best-practices/>HA Best Practices</a> helpful to get closer to that goal. In this document, we collected many options and settings for you that also Gardener internally uses to provide a highly available service.</p><p>During a zone outage, you may be forced to change your cluster setup on short notice in order to compensate for failures and shortages resulting from the outage.
For instance, if the shoot cluster has worker nodes across three zones where one zone goes down, the computing power from these nodes is also gone during that time.
Changing the worker pool (<code>shoot.spec.provider.workers[]</code>) and infrastructure (<code>shoot.spec.provider.infrastructureConfig</code>) configuration can eliminate this disbalance, having enough machines in healthy availability zones that can cope with the requests of your applications.</p><p>Gardener relies on a sophisticated reconciliation flow with several dependencies for which various flow steps wait for the <em>readiness</em> of prior ones.
During a zone outage, this can block the entire flow, e.g., because all three <code>etcd</code> replicas can never be ready when a zone is down, and required changes mentioned above can never be accomplished.
For this, a special one-off annotation <code>shoot.gardener.cloud/skip-readiness</code> helps to skip any readiness checks in the flow.</p><blockquote><p>The <code>shoot.gardener.cloud/skip-readiness</code> annotation serves as a last resort if reconciliation is stuck because of important changes during an AZ outage. Use it with caution, only in exceptional cases and after a case-by-case evaluation with your Gardener landscape administrator. If used together with other operations like Kubernetes version upgrades or credential rotation, the annotation may lead to a severe outage of your shoot control plane.</p></blockquote></div></main></div></div><footer class="footer row d-print-none"><div class="container-fluid footer-wrapper"><ul class=nav><li><a href=https://demo.gardener.cloud>Demo</a></li><li><a href=https://gardener.cloud/adopter/>Adopters</a></li><li><a href=/docs/>Documentation</a></li><li><a href=https://gardener.cloud/blog/>Blogs</a></li><li><a href=https://gardener.cloud/community/>Community</a></li></ul><img src=/images/lp/gardener-logo.svg alt="Logo Gardener" class=logo><ul class=media-wr><li><a target=_blank href=https://gardener-cloud.slack.com/><img src=/images/branding/slack-logo-white.svg class=media-icon><div class=media-text>Slack</div></a></li><li><a target=_blank href=https://github.com/gardener><img src=/images/branding/github-mark-logo.png class=media-icon><div class=media-text>GitHub</div></a></li><li><a target=_blank href=https://www.youtube.com/channel/UCwUhwKFREV8Su0gwAJQX7tw><img src=/images/branding/youtube-logo-dark.svg class=media-icon><div class=media-text>YouTube</div></a></li><li><a target=_blank href=https://x.com/GardenerProject><img src=/images/branding/x-logo-white.svg class=media-icon><div class=media-text>X</div></a></li></ul><span class=copyright>Copyright 2019-2025 Gardener project authors.
<a href=https://www.sap.com/about/legal/terms-of-use.html>Terms of Use
<i class="fa fa-external-link" aria-hidden=true></i>
</a>|
<a href=https://www.sap.com/about/legal/terms-of-use.html>Privacy Statement
<i class="fa fa-external-link" aria-hidden=true></i>
</a>|
<a href=https://www.sap.com/about/legal/terms-of-use.html>Legal Disclosure
<i class="fa fa-external-link" aria-hidden=true></i></a></span></div></footer></div><script src=/js/main.min.403ff095218c662472dab60ed98ecbb19431682de5ac7c6159891241cd366af5.js integrity="sha256-QD/wlSGMZiRy2rYO2Y7LsZQxaC3lrHxhWYkSQc02avU=" crossorigin=anonymous></script><script defer src=/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=/js/tabpane-persist.js></script><script src=/js/navbar.js></script><script src=/js/filtering.js></script><script src=/js/page-content.js></script><script src=/js/community-index.js></script></body></html>