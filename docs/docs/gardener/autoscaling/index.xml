<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Autoscaling on Gardener</title><link>https://gardener.cloud/docs/gardener/autoscaling/</link><description>Recent content in Autoscaling on Gardener</description><generator>Hugo</generator><language>en-US</language><atom:link href="https://gardener.cloud/docs/gardener/autoscaling/index.xml" rel="self" type="application/rss+xml"/><item><title>DNS Autoscaling</title><link>https://gardener.cloud/docs/gardener/autoscaling/dns-autoscaling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/autoscaling/dns-autoscaling/</guid><description>&lt;h1 id="dns-autoscaling">DNS Autoscaling&lt;/h1>
&lt;p>This is a short guide describing different options how to automatically scale CoreDNS in the shoot cluster.&lt;/p>
&lt;h2 id="background">Background&lt;/h2>
&lt;p>Currently, Gardener uses CoreDNS as DNS server. Per default, it is installed as a deployment into the shoot cluster that is auto-scaled horizontally to cover for QPS-intensive applications. However, doing so does not seem to be enough to completely circumvent DNS bottlenecks such as:&lt;/p>
&lt;ul>
&lt;li>Cloud provider limits for DNS lookups.&lt;/li>
&lt;li>Unreliable UDP connections that forces a period of timeout in case packets are dropped.&lt;/li>
&lt;li>Unnecessary node hopping since CoreDNS is not deployed on all nodes, and as a result DNS queries end-up traversing multiple nodes before reaching the destination server.&lt;/li>
&lt;li>Inefficient load-balancing of services (e.g., round-robin might not be enough when using IPTables mode).&lt;/li>
&lt;li>Overload of the CoreDNS replicas as the maximum amount of replicas is fixed.&lt;/li>
&lt;li>and more &amp;hellip;&lt;/li>
&lt;/ul>
&lt;p>As an alternative with extended configuration options, Gardener provides cluster-proportional autoscaling of CoreDNS. This guide focuses on the configuration of cluster-proportional autoscaling of CoreDNS and its advantages/disadvantages compared to the horizontal
autoscaling.
Please note that there is also the option to use a &lt;a href="https://gardener.cloud/docs/gardener/networking/node-local-dns/">node-local DNS cache&lt;/a>, which helps mitigate potential DNS bottlenecks (see &lt;a href="https://gardener.cloud/docs/gardener/autoscaling/dns-autoscaling/#trade-offs-in-conjunction-with-nodelocaldns">Trade-offs in conjunction with NodeLocalDNS&lt;/a> for considerations regarding using NodeLocalDNS together with one of the CoreDNS autoscaling approaches).&lt;/p></description></item><item><title>Shoot Autoscaling</title><link>https://gardener.cloud/docs/gardener/autoscaling/shoot_autoscaling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/autoscaling/shoot_autoscaling/</guid><description>&lt;h1 id="auto-scaling-in-shoot-clusters">Auto-Scaling in Shoot Clusters&lt;/h1>
&lt;p>There are three auto-scaling scenarios of relevance in Kubernetes clusters in general and Gardener shoot clusters in particular:&lt;/p>
&lt;ul>
&lt;li>Horizontal node auto-scaling, i.e., dynamically adding and removing worker nodes.&lt;/li>
&lt;li>Horizontal pod auto-scaling, i.e., dynamically adding and removing pod replicas.&lt;/li>
&lt;li>Vertical pod auto-scaling, i.e., dynamically raising or shrinking the resource requests/limits of pods.&lt;/li>
&lt;/ul>
&lt;p>This document provides an overview of these scenarios and how the respective auto-scaling components can be enabled and configured. For more details, please see our &lt;a href="https://gardener.cloud/docs/gardener/autoscaling/shoot_pod_autoscaling_best_practices/">pod auto-scaling best practices&lt;/a>.&lt;/p></description></item><item><title>Shoot Pod Autoscaling Best Practices</title><link>https://gardener.cloud/docs/gardener/autoscaling/shoot_pod_autoscaling_best_practices/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/gardener/autoscaling/shoot_pod_autoscaling_best_practices/</guid><description>&lt;h1 id="introduction">Introduction&lt;/h1>
&lt;p>There are two types of pod autoscaling in Kubernetes: Horizontal Pod Autoscaling (HPA) and Vertical Pod Autoscaling (VPA). HPA (implemented as part of the kube-controller-manager) scales the number of pod replicas, while VPA (implemented as independent community project) adjusts the CPU and memory requests for the pods. Both types of autoscaling aim to optimize resource usage/costs and maintain the performance and (high) availability of applications running on Kubernetes.&lt;/p>
&lt;h2 id="horizontal-pod-autoscaling-hpahttpskubernetesiodocstasksrun-applicationhorizontal-pod-autoscale">&lt;a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale">Horizontal Pod Autoscaling (HPA)&lt;/a>&lt;/h2>
&lt;p>Horizontal Pod Autoscaling involves increasing or decreasing the number of pod replicas in a deployment, replica set, stateful set, or &lt;a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-autoscaling/853-configurable-hpa-scale-velocity/README.md#summary">anything really with a scale subresource that manages pods&lt;/a>. HPA adjusts the number of replicas based on specified metrics, such as CPU or memory average utilization (usage divided by requests; most common) or average value (usage; less common). When the demand on your application increases, HPA automatically scales out the number of pods to meet the demand. Conversely, when the demand decreases, it scales in the number of pods to reduce resource usage.&lt;/p></description></item></channel></rss>