<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Gardener – Etcd Druid</title><link>https://gardener.cloud/docs/other-components/etcd-druid/</link><description>Recent content in Etcd Druid on Gardener</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><atom:link href="https://gardener.cloud/docs/other-components/etcd-druid/index.xml" rel="self" type="application/rss+xml"/><item><title>Docs: API Reference</title><link>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/api-reference/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/api-reference/</guid><description>
&lt;p>Packages:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="#druid.gardener.cloud%2fv1alpha1">druid.gardener.cloud/v1alpha1&lt;/a>
&lt;/li>
&lt;/ul>
&lt;h2 id="druid.gardener.cloud/v1alpha1">druid.gardener.cloud/v1alpha1&lt;/h2>
&lt;p>
&lt;p>Package v1alpha1 is the v1alpha1 version of the etcd-druid API.&lt;/p>
&lt;/p>
Resource Types:
&lt;ul>&lt;/ul>
&lt;h3 id="druid.gardener.cloud/v1alpha1.BackupSpec">BackupSpec
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdSpec">EtcdSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>BackupSpec defines parameters associated with the full and delta snapshots of etcd.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>port&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Port define the port on which etcd-backup-restore server will be exposed.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>tls&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.TLSConfig">
TLSConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>image&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Image defines the etcd container image and tag&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>store&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.StoreSpec">
StoreSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Store defines the specification of object store provider for storing backups.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>resources&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#resourcerequirements-v1-core">
Kubernetes core/v1.ResourceRequirements
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Resources defines compute Resources required by backup-restore container.
More info: &lt;a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/">https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>compactionResources&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#resourcerequirements-v1-core">
Kubernetes core/v1.ResourceRequirements
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>CompactionResources defines compute Resources required by compaction job.
More info: &lt;a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/">https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>fullSnapshotSchedule&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>FullSnapshotSchedule defines the cron standard schedule for full snapshots.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>garbageCollectionPolicy&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.GarbageCollectionPolicy">
GarbageCollectionPolicy
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>GarbageCollectionPolicy defines the policy for garbage collecting old backups&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>garbageCollectionPeriod&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>GarbageCollectionPeriod defines the period for garbage collecting old backups&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>deltaSnapshotPeriod&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>DeltaSnapshotPeriod defines the period after which delta snapshots will be taken&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>deltaSnapshotMemoryLimit&lt;/code>&lt;/br>
&lt;em>
k8s.io/apimachinery/pkg/api/resource.Quantity
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>DeltaSnapshotMemoryLimit defines the memory limit after which delta snapshots will be taken&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>compression&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.CompressionSpec">
CompressionSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>SnapshotCompression defines the specification for compression of Snapshots.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>enableProfiling&lt;/code>&lt;/br>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>EnableProfiling defines if profiling should be enabled for the etcd-backup-restore-sidecar&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>etcdSnapshotTimeout&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>EtcdSnapshotTimeout defines the timeout duration for etcd FullSnapshot operation&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>leaderElection&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.LeaderElectionSpec">
LeaderElectionSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>LeaderElection defines parameters related to the LeaderElection configuration.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.ClientService">ClientService
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdConfig">EtcdConfig&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>ClientService defines the parameters of the client service that a user can specify&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>annotations&lt;/code>&lt;/br>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Annotations specify the annotations that should be added to the client service&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>labels&lt;/code>&lt;/br>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Labels specify the labels that should be added to the client service&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.CompactionMode">CompactionMode
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.SharedConfig">SharedConfig&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>CompactionMode defines the auto-compaction-mode: &amp;lsquo;periodic&amp;rsquo; or &amp;lsquo;revision&amp;rsquo;.
&amp;lsquo;periodic&amp;rsquo; for duration based retention and &amp;lsquo;revision&amp;rsquo; for revision number based retention.&lt;/p>
&lt;/p>
&lt;h3 id="druid.gardener.cloud/v1alpha1.CompressionPolicy">CompressionPolicy
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.CompressionSpec">CompressionSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>CompressionPolicy defines the type of policy for compression of snapshots.&lt;/p>
&lt;/p>
&lt;h3 id="druid.gardener.cloud/v1alpha1.CompressionSpec">CompressionSpec
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.BackupSpec">BackupSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>CompressionSpec defines parameters related to compression of Snapshots(full as well as delta).&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>enabled&lt;/code>&lt;/br>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>policy&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.CompressionPolicy">
CompressionPolicy
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.Condition">Condition
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskStatus">EtcdCopyBackupsTaskStatus&lt;/a>,
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdStatus">EtcdStatus&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>Condition holds the information about the state of a resource.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>type&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.ConditionType">
ConditionType
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Type of the Etcd condition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.ConditionStatus">
ConditionStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Status of the condition, one of True, False, Unknown.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastTransitionTime&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#time-v1-meta">
Kubernetes meta/v1.Time
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Last time the condition transitioned from one status to another.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastUpdateTime&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#time-v1-meta">
Kubernetes meta/v1.Time
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Last time the condition was updated.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>reason&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The reason for the condition&amp;rsquo;s last transition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>message&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>A human-readable message indicating details about the transition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.ConditionStatus">ConditionStatus
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.Condition">Condition&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>ConditionStatus is the status of a condition.&lt;/p>
&lt;/p>
&lt;h3 id="druid.gardener.cloud/v1alpha1.ConditionType">ConditionType
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.Condition">Condition&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>ConditionType is the type of condition.&lt;/p>
&lt;/p>
&lt;h3 id="druid.gardener.cloud/v1alpha1.CrossVersionObjectReference">CrossVersionObjectReference
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdStatus">EtcdStatus&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>CrossVersionObjectReference contains enough information to let you identify the referred resource.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>kind&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Kind of the referent&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>name&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Name of the referent&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>apiVersion&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>API version of the referent&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.Etcd">Etcd
&lt;/h3>
&lt;p>
&lt;p>Etcd is the Schema for the etcds API&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdSpec">
EtcdSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>selector&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#labelselector-v1-meta">
Kubernetes meta/v1.LabelSelector
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>selector is a label query over pods that should match the replica count.
It must match the pod template&amp;rsquo;s labels.
More info: &lt;a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors">https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>labels&lt;/code>&lt;/br>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>annotations&lt;/code>&lt;/br>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>etcd&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdConfig">
EtcdConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>backup&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.BackupSpec">
BackupSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>sharedConfig&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.SharedConfig">
SharedConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>schedulingConstraints&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.SchedulingConstraints">
SchedulingConstraints
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>replicas&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>priorityClassName&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>PriorityClassName is the name of a priority class that shall be used for the etcd pods.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>storageClass&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>StorageClass defines the name of the StorageClass required by the claim.
More info: &lt;a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1">https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>storageCapacity&lt;/code>&lt;/br>
&lt;em>
k8s.io/apimachinery/pkg/api/resource.Quantity
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>StorageCapacity defines the size of persistent volume.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>volumeClaimTemplate&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>VolumeClaimTemplate defines the volume claim template to be created&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdStatus">
EtcdStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.EtcdConfig">EtcdConfig
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdSpec">EtcdSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>EtcdConfig defines parameters associated etcd deployed&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>quota&lt;/code>&lt;/br>
&lt;em>
k8s.io/apimachinery/pkg/api/resource.Quantity
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Quota defines the etcd DB quota.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>defragmentationSchedule&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>DefragmentationSchedule defines the cron standard schedule for defragmentation of etcd.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>serverPort&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>clientPort&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>image&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Image defines the etcd container image and tag&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>authSecretRef&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>metrics&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.MetricsLevel">
MetricsLevel
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Metrics defines the level of detail for exported metrics of etcd, specify &amp;lsquo;extensive&amp;rsquo; to include histogram metrics.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>resources&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#resourcerequirements-v1-core">
Kubernetes core/v1.ResourceRequirements
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Resources defines the compute Resources required by etcd container.
More info: &lt;a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/">https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>clientUrlTls&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.TLSConfig">
TLSConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ClientUrlTLS contains the ca, server TLS and client TLS secrets for client communication to ETCD cluster&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>peerUrlTls&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.TLSConfig">
TLSConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>PeerUrlTLS contains the ca and server TLS secrets for peer communication within ETCD cluster
Currently, PeerUrlTLS does not require client TLS secrets for gardener implementation of ETCD cluster.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>etcdDefragTimeout&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>EtcdDefragTimeout defines the timeout duration for etcd defrag call&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>heartbeatDuration&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>HeartbeatDuration defines the duration for members to send heartbeats. The default value is 10s.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>clientService&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.ClientService">
ClientService
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ClientService defines the parameters of the client service that a user can specify&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTask">EtcdCopyBackupsTask
&lt;/h3>
&lt;p>
&lt;p>EtcdCopyBackupsTask is a task for copying etcd backups from a source to a target store.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>metadata&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#objectmeta-v1-meta">
Kubernetes meta/v1.ObjectMeta
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
Refer to the Kubernetes API documentation for the fields of the
&lt;code>metadata&lt;/code> field.
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>spec&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskSpec">
EtcdCopyBackupsTaskSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;br/>
&lt;br/>
&lt;table>
&lt;tr>
&lt;td>
&lt;code>sourceStore&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.StoreSpec">
StoreSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>SourceStore defines the specification of the source object store provider for storing backups.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>targetStore&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.StoreSpec">
StoreSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>TargetStore defines the specification of the target object store provider for storing backups.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>maxBackupAge&lt;/code>&lt;/br>
&lt;em>
uint32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>MaxBackupAge is the maximum age in days that a backup must have in order to be copied.
By default all backups will be copied.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>maxBackups&lt;/code>&lt;/br>
&lt;em>
uint32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>MaxBackups is the maximum number of backups that will be copied starting with the most recent ones.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>waitForFinalSnapshot&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.WaitForFinalSnapshotSpec">
WaitForFinalSnapshotSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>WaitForFinalSnapshot defines the parameters for waiting for a final full snapshot before copying backups.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/table>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskStatus">
EtcdCopyBackupsTaskStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskSpec">EtcdCopyBackupsTaskSpec
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTask">EtcdCopyBackupsTask&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>EtcdCopyBackupsTaskSpec defines the parameters for the copy backups task.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>sourceStore&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.StoreSpec">
StoreSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>SourceStore defines the specification of the source object store provider for storing backups.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>targetStore&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.StoreSpec">
StoreSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>TargetStore defines the specification of the target object store provider for storing backups.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>maxBackupAge&lt;/code>&lt;/br>
&lt;em>
uint32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>MaxBackupAge is the maximum age in days that a backup must have in order to be copied.
By default all backups will be copied.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>maxBackups&lt;/code>&lt;/br>
&lt;em>
uint32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>MaxBackups is the maximum number of backups that will be copied starting with the most recent ones.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>waitForFinalSnapshot&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.WaitForFinalSnapshotSpec">
WaitForFinalSnapshotSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>WaitForFinalSnapshot defines the parameters for waiting for a final full snapshot before copying backups.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskStatus">EtcdCopyBackupsTaskStatus
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTask">EtcdCopyBackupsTask&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>EtcdCopyBackupsTaskStatus defines the observed state of the copy backups task.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>conditions&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.Condition">
[]Condition
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Conditions represents the latest available observations of an object&amp;rsquo;s current state.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>observedGeneration&lt;/code>&lt;/br>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ObservedGeneration is the most recent generation observed for this resource.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastError&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>LastError represents the last occurred error.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.EtcdMemberConditionStatus">EtcdMemberConditionStatus
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdMemberStatus">EtcdMemberStatus&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>EtcdMemberConditionStatus is the status of an etcd cluster member.&lt;/p>
&lt;/p>
&lt;h3 id="druid.gardener.cloud/v1alpha1.EtcdMemberStatus">EtcdMemberStatus
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdStatus">EtcdStatus&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>EtcdMemberStatus holds information about a etcd cluster membership.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>name&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Name is the name of the etcd member. It is the name of the backing &lt;code>Pod&lt;/code>.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>id&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ID is the ID of the etcd member.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>role&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdRole">
EtcdRole
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Role is the role in the etcd cluster, either &lt;code>Leader&lt;/code> or &lt;code>Member&lt;/code>.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>status&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdMemberConditionStatus">
EtcdMemberConditionStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Status of the condition, one of True, False, Unknown.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>reason&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>The reason for the condition&amp;rsquo;s last transition.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastTransitionTime&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#time-v1-meta">
Kubernetes meta/v1.Time
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>LastTransitionTime is the last time the condition&amp;rsquo;s status changed.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.EtcdRole">EtcdRole
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdMemberStatus">EtcdMemberStatus&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>EtcdRole is the role of an etcd cluster member.&lt;/p>
&lt;/p>
&lt;h3 id="druid.gardener.cloud/v1alpha1.EtcdSpec">EtcdSpec
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.Etcd">Etcd&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>EtcdSpec defines the desired state of Etcd&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>selector&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#labelselector-v1-meta">
Kubernetes meta/v1.LabelSelector
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>selector is a label query over pods that should match the replica count.
It must match the pod template&amp;rsquo;s labels.
More info: &lt;a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors">https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>labels&lt;/code>&lt;/br>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>annotations&lt;/code>&lt;/br>
&lt;em>
map[string]string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>etcd&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdConfig">
EtcdConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>backup&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.BackupSpec">
BackupSpec
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>sharedConfig&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.SharedConfig">
SharedConfig
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>schedulingConstraints&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.SchedulingConstraints">
SchedulingConstraints
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>replicas&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>priorityClassName&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>PriorityClassName is the name of a priority class that shall be used for the etcd pods.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>storageClass&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>StorageClass defines the name of the StorageClass required by the claim.
More info: &lt;a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1">https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1&lt;/a>&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>storageCapacity&lt;/code>&lt;/br>
&lt;em>
k8s.io/apimachinery/pkg/api/resource.Quantity
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>StorageCapacity defines the size of persistent volume.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>volumeClaimTemplate&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>VolumeClaimTemplate defines the volume claim template to be created&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.EtcdStatus">EtcdStatus
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.Etcd">Etcd&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>EtcdStatus defines the observed state of Etcd.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>observedGeneration&lt;/code>&lt;/br>
&lt;em>
int64
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ObservedGeneration is the most recent generation observed for this resource.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>etcd&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.CrossVersionObjectReference">
CrossVersionObjectReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>conditions&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.Condition">
[]Condition
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Conditions represents the latest available observations of an etcd&amp;rsquo;s current state.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>serviceName&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ServiceName is the name of the etcd service.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>lastError&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>LastError represents the last occurred error.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>clusterSize&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Cluster size is the size of the etcd cluster.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>currentReplicas&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>CurrentReplicas is the current replica count for the etcd cluster.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>replicas&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Replicas is the replica count of the etcd resource.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>readyReplicas&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ReadyReplicas is the count of replicas being ready in the etcd cluster.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>ready&lt;/code>&lt;/br>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Ready is &lt;code>true&lt;/code> if all etcd replicas are ready.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>updatedReplicas&lt;/code>&lt;/br>
&lt;em>
int32
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>UpdatedReplicas is the count of updated replicas in the etcd cluster.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>labelSelector&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#labelselector-v1-meta">
Kubernetes meta/v1.LabelSelector
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>LabelSelector is a label query over pods that should match the replica count.
It must match the pod template&amp;rsquo;s labels.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>members&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdMemberStatus">
[]EtcdMemberStatus
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Members represents the members of the etcd cluster&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>peerUrlTLSEnabled&lt;/code>&lt;/br>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>PeerUrlTLSEnabled captures the state of peer url TLS being enabled for the etcd member(s)&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.GarbageCollectionPolicy">GarbageCollectionPolicy
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.BackupSpec">BackupSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>GarbageCollectionPolicy defines the type of policy for snapshot garbage collection.&lt;/p>
&lt;/p>
&lt;h3 id="druid.gardener.cloud/v1alpha1.LeaderElectionSpec">LeaderElectionSpec
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.BackupSpec">BackupSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>LeaderElectionSpec defines parameters related to the LeaderElection configuration.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>reelectionPeriod&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>ReelectionPeriod defines the Period after which leadership status of corresponding etcd is checked.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>etcdConnectionTimeout&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>EtcdConnectionTimeout defines the timeout duration for etcd client connection during leader election.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.MetricsLevel">MetricsLevel
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdConfig">EtcdConfig&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>MetricsLevel defines the level &amp;lsquo;basic&amp;rsquo; or &amp;lsquo;extensive&amp;rsquo;.&lt;/p>
&lt;/p>
&lt;h3 id="druid.gardener.cloud/v1alpha1.SchedulingConstraints">SchedulingConstraints
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdSpec">EtcdSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>SchedulingConstraints defines the different scheduling constraints that must be applied to the
pod spec in the etcd statefulset.
Currently supported constraints are Affinity and TopologySpreadConstraints.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>affinity&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#affinity-v1-core">
Kubernetes core/v1.Affinity
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Affinity defines the various affinity and anti-affinity rules for a pod
that are honoured by the kube-scheduler.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>topologySpreadConstraints&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#topologyspreadconstraint-v1-core">
[]Kubernetes core/v1.TopologySpreadConstraint
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>TopologySpreadConstraints describes how a group of pods ought to spread across topology domains,
that are honoured by the kube-scheduler.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.SecretReference">SecretReference
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.TLSConfig">TLSConfig&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>SecretReference defines a reference to a secret.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>SecretReference&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>
(Members of &lt;code>SecretReference&lt;/code> are embedded into this type.)
&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>dataKey&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>DataKey is the name of the key in the data map containing the credentials.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.SharedConfig">SharedConfig
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdSpec">EtcdSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>SharedConfig defines parameters shared and used by Etcd as well as backup-restore sidecar.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>autoCompactionMode&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.CompactionMode">
CompactionMode
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>AutoCompactionMode defines the auto-compaction-mode:&amp;lsquo;periodic&amp;rsquo; mode or &amp;lsquo;revision&amp;rsquo; mode for etcd and embedded-Etcd of backup-restore sidecar.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>autoCompactionRetention&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>AutoCompactionRetention defines the auto-compaction-retention length for etcd as well as for embedded-Etcd of backup-restore sidecar.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.StorageProvider">StorageProvider
(&lt;code>string&lt;/code> alias)&lt;/p>&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.StoreSpec">StoreSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>StorageProvider defines the type of object store provider for storing backups.&lt;/p>
&lt;/p>
&lt;h3 id="druid.gardener.cloud/v1alpha1.StoreSpec">StoreSpec
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.BackupSpec">BackupSpec&lt;/a>,
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskSpec">EtcdCopyBackupsTaskSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>StoreSpec defines parameters related to ObjectStore persisting backups&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>container&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Container is the name of the container the backup is stored at.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>prefix&lt;/code>&lt;/br>
&lt;em>
string
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Prefix is the prefix used for the store.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>provider&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.StorageProvider">
StorageProvider
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Provider is the name of the backup provider.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>secretRef&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>SecretRef is the reference to the secret which used to connect to the backup store.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.TLSConfig">TLSConfig
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.BackupSpec">BackupSpec&lt;/a>,
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdConfig">EtcdConfig&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>TLSConfig hold the TLS configuration details.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>tlsCASecretRef&lt;/code>&lt;/br>
&lt;em>
&lt;a href="#druid.gardener.cloud/v1alpha1.SecretReference">
SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>serverTLSSecretRef&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>clientTLSSecretRef&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#secretreference-v1-core">
Kubernetes core/v1.SecretReference
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="druid.gardener.cloud/v1alpha1.WaitForFinalSnapshotSpec">WaitForFinalSnapshotSpec
&lt;/h3>
&lt;p>
(&lt;em>Appears on:&lt;/em>
&lt;a href="#druid.gardener.cloud/v1alpha1.EtcdCopyBackupsTaskSpec">EtcdCopyBackupsTaskSpec&lt;/a>)
&lt;/p>
&lt;p>
&lt;p>WaitForFinalSnapshotSpec defines the parameters for waiting for a final full snapshot before copying backups.&lt;/p>
&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Field&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>
&lt;code>enabled&lt;/code>&lt;/br>
&lt;em>
bool
&lt;/em>
&lt;/td>
&lt;td>
&lt;p>Enabled specifies whether to wait for a final full snapshot before copying backups.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>
&lt;code>timeout&lt;/code>&lt;/br>
&lt;em>
&lt;a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#duration-v1-meta">
Kubernetes meta/v1.Duration
&lt;/a>
&lt;/em>
&lt;/td>
&lt;td>
&lt;em>(Optional)&lt;/em>
&lt;p>Timeout is the timeout for waiting for a final full snapshot. When this timeout expires, the copying of backups
will be performed anyway. No timeout or 0 means wait forever.&lt;/p>
&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;hr/>
&lt;p>&lt;em>
Generated with &lt;a href="https://github.com/ahmetb/gen-crd-api-reference-docs">gen-crd-api-reference-docs&lt;/a>
&lt;/em>&lt;/p></description></item><item><title>Docs: Compactor</title><link>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/compactor/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/compactor/</guid><description>
&lt;h1 id="backup-compaction-for-etcd">Backup Compaction for ETCD&lt;/h1>
&lt;h2 id="current-problem">Current Problem&lt;/h2>
&lt;p>To ensure recoverability of ETCD, backups of the database are taken at regular interval.
Backups are of two types: Full Snapshots and Incremental Snapshots.&lt;/p>
&lt;h3 id="full-snapshots">Full Snapshots&lt;/h3>
&lt;p>Full snapshot is a snapshot of the complete database at given point in time.The size of the database keeps changing with time and typically the size is relatively large (measured in 100s of megabytes or even in gigabytes. For this reason, full snapshots are taken after some large intervals.&lt;/p>
&lt;h3 id="incremental-snapshots">Incremental Snapshots&lt;/h3>
&lt;p>Incremental Snapshots are collection of events on ETCD database, obtained through running WATCH API Call on ETCD. After some short intervals, all the events that are accumulated through WATCH API Call are saved in a file and named as Incremental Snapshots at relatively short time intervals.&lt;/p>
&lt;h3 id="recovery-from-the-snapshots">Recovery from the Snapshots&lt;/h3>
&lt;h4 id="recovery-from-full-snapshots">Recovery from Full Snapshots&lt;/h4>
&lt;p>As the full snapshots are snapshots of the complete database, the whole database can be recovered from a full snapshot in one go. ETCD provides API Call to restore the database from a full snapshot file.&lt;/p>
&lt;h4 id="recovery-from-incremental-snapshots">Recovery from Incremental Snapshots&lt;/h4>
&lt;p>Delta snapshots are collection of retrospective ETCD events. So, to restore from Incremental snapshot file, the events from the file are needed to be applied sequentially on ETCD database through ETCD Put/Delete API calls. As it is heavily dependent on ETCD calls sequentially, restoring from Incremental Snapshot files can take long if there are numerous commands captured in Incremental Snapshot files.&lt;/p>
&lt;p>Delta snapshots are applied on top of running ETCD database. So, if there is inconsistency between the state of database at the point of applying and the state of the database when the delta snapshot commands were captured, restoration will fail.&lt;/p>
&lt;p>Currently, in Gardener setup, ETCD is restored from the last full snapshot and then the delta snapshots, which were captured after the last full snapshot.&lt;/p>
&lt;p>The main problem with this is that the complete restoration time can be unacceptably large if the rate of change coming into the etcd database is quite high because there are large number of events in the delta snapshots to be applied sequentially.
A secondary problem is that, though auto-compaction is enabled for etcd, it is not quick enough to compact all the changes from the incremental snapshots being re-applied during the relatively short period of time of restoration (as compared to the actual period of time when the incremental snapshots were accumulated). This may lead to the etcd pod (the backup-restore sidecar container, to be precise) to run out of memory and/or storage space even if it is sufficient for normal operations.&lt;/p>
&lt;h2 id="solution">Solution&lt;/h2>
&lt;h3 id="compaction-command">Compaction command&lt;/h3>
&lt;p>To help with the problem mentioned earlier, our proposal is to introduce &lt;code>compact&lt;/code> subcommand with &lt;code>etcdbrctl&lt;/code>. On execution of &lt;code>compact&lt;/code> command, A separate embedded ETCD process will be started where the ETCD data will be restored from the snapstore (exactly as in the restoration scenario today). Then the new ETCD database will be compacted and defragmented using ETCD API calls. The compaction will strip off the ETCD database of old revisions as per the ETCD auto-compaction configuration. The defragmentation will free up the unused fragment memory space released after compaction. Then a full snapshot of the compacted database will be saved in snapstore which then can be used as the base snapshot during any subsequent restoration (or backup compaction).&lt;/p>
&lt;h3 id="how-the-solution-works">How the solution works&lt;/h3>
&lt;p>The newly introduced compact command does not disturb the running ETCD while compacting the backup snapshots. The command is designed to run potentially separately (from the main ETCD process/container/pod). ETCD Druid can be configured to run the newly introduced compact command as a separate job (scheduled periodically) based on total number of ETCD events accumulated after the most recent full snapshot.&lt;/p>
&lt;h3 id="druid-flags">Druid flags:&lt;/h3>
&lt;p>ETCD druid introduced following flags to configure the compaction job:&lt;/p>
&lt;ul>
&lt;li>&lt;code>--enable-backup-compaction&lt;/code> (default &lt;code>false&lt;/code>): Set this flag to &lt;code>true&lt;/code> to enable the automatic compaction of etcd backups when &lt;code>etcd-events-threshold&lt;/code> is exceeded.&lt;/li>
&lt;li>&lt;code>--compaction-workers&lt;/code> (default &lt;code>3&lt;/code>): If this flag is set to zero, no compaction job will be running. If it&amp;rsquo;s set to any value greater than zero, druid controller will have that many threads to kickstart the compaction job.&lt;/li>
&lt;li>&lt;code>--etcd-events-threshold&lt;/code> (default &lt;code>1000000&lt;/code>): Set this flag with the value which will signify the number of ETCD events allowed after the most recent full snapshot. Once the number of ETCD events crosses the value mentioned in this flag, compaction job will be kickstarted.&lt;/li>
&lt;li>&lt;code>--active-deadline-duration&lt;/code> (default &lt;code>3h&lt;/code>): This flag signifies the maximum duration till which a compaction job won&amp;rsquo;t be garbage-collected.&lt;/li>
&lt;/ul>
&lt;h3 id="points-to-take-care-while-saving-the-compacted-snapshot">&lt;strong>Points to take care while saving the compacted snapshot:&lt;/strong>&lt;/h3>
&lt;p>As compacted snapshot and the existing periodic full snapshots are taken by different processes running in different pods but accessing same store to save the snapshots, some problems may arise:&lt;/p>
&lt;ol>
&lt;li>When uploading the compacted snapshot to the snapstore, there is the problem of how does the restorer know when to start using the newly compacted snapshot. This communication needs to be atomic.&lt;/li>
&lt;li>With a regular schedule for compaction that happens potentially separately from the main etcd pod, is there a need for regular scheduled full snapshots anymore?&lt;/li>
&lt;li>We are planning to introduce new directory structure, under v2 prefix, for saving the snapshots (compacted and full), as mentioned in details below. But for backward compatibility, we also need to consider the older directory, which is currently under v1 prefix, during accessing snapshots.&lt;/li>
&lt;/ol>
&lt;h4 id="how-to-swap-full-snapshot-with-compacted-snapshot-atomically">&lt;strong>How to swap full snapshot with compacted snapshot atomically&lt;/strong>&lt;/h4>
&lt;p>Currently, full snapshots and the subsequent delta snapshots are grouped under same prefix path in the snapstore. When a full snapshot is created, it is placed under a prefix/directory with the name comprising of timestamp. Then subsequent delta snapshots are also pushed into the same directory. Thus each prefix/directory contains a single full snapshot and the subsequent delta snapshots. So far, it is the job of ETCDBR to start main ETCD process and snapshotter process which takes full snapshot and delta snapshot periodically. But as per our proposal, compaction will be running as parallel process to main ETCD process and snapshotter process. So we can&amp;rsquo;t reliably co-ordinate between the processes to achieve switching to the compacted snapshot as the base snapshot atomically.&lt;/p>
&lt;h5 id="current-directory-structure">&lt;strong>Current Directory Structure&lt;/strong>&lt;/h5>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>- Backup-192345
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-0-1-192345
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-1-100-192355
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-100-200-192365
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-200-300-192375
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>- Backup-192789
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-0-300-192789
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-300-400-192799
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-400-500-192809
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-500-600-192819
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>To solve the problem, proposal is:&lt;/p>
&lt;ol>
&lt;li>ETCDBR will take the first full snapshot after it starts main ETCD Process and snapshotter process. After taking the first full snapshot, snapshotter will continue taking full snapshots. On the other hand, ETCDBR compactor command will be run as periodic job in a separate pod and use the existing full or compacted snapshots to produce further compacted snapshots. Full snapshots and compacted snapshots will be named after same fashion. So, there is no need of any mechanism to choose which snapshots(among full and compacted snapshot) to consider as base snapshots.&lt;/li>
&lt;li>Flatten the directory structure of backup folder. Save all the full snapshots, delta snapshots and compacted snapshots under same directory/prefix. Restorer will restore from full/compacted snapshots and delta snapshots sorted based on the revision numbers in name (or timestamp if the revision numbers are equal).&lt;/li>
&lt;/ol>
&lt;h5 id="proposed-directory-structure">&lt;strong>Proposed Directory Structure&lt;/strong>&lt;/h5>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>Backup :
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-0-1-192355 (Taken by snapshotter)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-1-100-192365
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-100-200-192375
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-revision-0-200-192379 (Taken by snapshotter)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-200-300-192385
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-revision-0-300-192386 (Taken by compaction job)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-300-400-192396
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-400-500-192406
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-500-600-192416
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-revision-0-600-192419 (Taken by snapshotter)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-revision-0-600-192420 (Taken by compaction job)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h5 id="what-happens-to-the-delta-snapshots-that-were-compacted">What happens to the delta snapshots that were compacted?&lt;/h5>
&lt;p>The proposed &lt;code>compaction&lt;/code> sub-command in &lt;code>etcdbrctl&lt;/code> (and hence, the &lt;code>CronJob&lt;/code> provisioned by &lt;code>etcd-druid&lt;/code> that will schedule it at a regular interval) would only upload the compacted full snapshot.
It will not delete the snapshots (delta or full snapshots) that were compacted.
These snapshots which were superseded by a freshly uploaded compacted snapshot would follow the same life-cycle as other older snapshots.
I.e. they will be garbage collected according to the configured backup snapshot retention policy.
For example, if an &lt;code>exponential&lt;/code> retention policy is configured and if compaction is done every &lt;code>30m&lt;/code> then there might be at most &lt;code>48&lt;/code> additional (compacted) full snapshots (&lt;code>24h * 2&lt;/code>) in the backup for the latest day. As time rolls forward to the next day, these additional compacted snapshots (along with the delta snapshots that were compacted into them) will get garbage collected retaining only one full snapshot for the day before according to the retention policy.&lt;/p>
&lt;h5 id="future-work">&lt;strong>Future work&lt;/strong>&lt;/h5>
&lt;p>In future, we have plan to stop the snapshotter just after taking the first full snapshot. Then, the compaction job will be solely responsible for taking subsequent full snapshots. The directory structure would be looking like following:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="display:flex;">&lt;span>Backup :
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-0-1-192355 (Taken by snapshotter)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-1-100-192365
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-100-200-192375
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-200-300-192385
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-revision-0-300-192386 (Taken by compaction job)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-300-400-192396
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-400-500-192406
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Incremental-Snapshot-revision-500-600-192416
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> - Full-Snapshot-revision-0-600-192420 (Taken by compaction job)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="backward-compatibility">Backward Compatibility&lt;/h4>
&lt;ol>
&lt;li>&lt;strong>Restoration&lt;/strong> : The changes to handle the newly proposed backup directory structure must be backward compatible with older structures at least for restoration because we need have to restore from backups in the older structure. This includes the support for restoring from a backup without a metadata file if that is used in the actual implementation.&lt;/li>
&lt;li>&lt;strong>Backup&lt;/strong> : For new snapshots (even on a backup containing the older structure), the new structure may be used. The new structure must be setup automatically including creating the base full snapshot.&lt;/li>
&lt;li>&lt;strong>Garbage collection&lt;/strong> : The existing functionality of garbage collection of snapshots (full and incremental) according to the backup retention policy must be compatible with both old and new backup folder structure. I.e. the snapshots in the older backup structure must be retained in their own structure and the snapshots in the proposed backup structure should be retained in the proposed structure. Once all the snapshots in the older backup structure go out of the retention policy and are garbage collected, we can think of removing the support for older backup folder structure.&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Note:&lt;/strong> Compactor will run parallel to current snapshotter process and work only if there is any full snapshot already present in the store. By current design, a full snapshot will be taken if there is already no full snapshot or the existing full snapshot is older than 24 hours. It is not limitation but a design choice. As per proposed design, the backup storage will contain both periodic full snapshots as well as periodic compacted snapshot. Restorer will pickup the base snapshot whichever is latest one.&lt;/p></description></item><item><title>Docs: etcd Network Latency</title><link>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/etcd-network-latency/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/etcd-network-latency/</guid><description>
&lt;h1 id="network-latency-analysis-sn-etcd-sz-vs--mn-etcd-sz-vs-mn-etcd-mz">Network Latency analysis: &lt;code>sn-etcd-sz&lt;/code> vs &lt;code>mn-etcd-sz&lt;/code> vs &lt;code>mn-etcd-mz&lt;/code>&lt;/h1>
&lt;p>This page captures the ETCD cluster latency analysis for below scenarios using the benchmark tool (build from &lt;a href="https://github.com/seshachalam-yv/etcd">ETCD benchmark tool&lt;/a>).&lt;/p>
&lt;p>&lt;code>sn-etcd-sz&lt;/code> -&amp;gt; single-node ETCD single zone (Only single replica of etcd will be running)&lt;/p>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> -&amp;gt; multi-node ETCD single zone (Multiple replicas of etcd pods will be running across nodes in a single zone)&lt;/p>
&lt;p>&lt;code>mn-etcd-mz&lt;/code> -&amp;gt; multi-node ETCD multi zone (Multiple replicas of etcd pods will be running across nodes in multiple zones)&lt;/p>
&lt;h2 id="put-analysis">PUT Analysis&lt;/h2>
&lt;h3 id="summary">Summary&lt;/h3>
&lt;ul>
&lt;li>&lt;code>sn-etcd-sz&lt;/code> latency is &lt;strong>~20% less than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code> when benchmark tool with single client.&lt;/li>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency is less than &lt;code>mn-etcd-mz&lt;/code> but the difference is &lt;code>~+/-5%&lt;/code>.&lt;/li>
&lt;li>Compared to &lt;code>mn-etcd-sz&lt;/code>, &lt;code>sn-etcd-sz&lt;/code> latency is higher and gradually grows with more clients and larger value size.&lt;/li>
&lt;li>Compared to &lt;code>mn-etcd-mz&lt;/code>, &lt;code>mn-etcd-sz&lt;/code> latency is higher and gradually grows with more clients and larger value size.&lt;/li>
&lt;li>&lt;em>Compared to &lt;code>follower&lt;/code>, &lt;code>leader&lt;/code> latency is less&lt;/em>, when benchmark tool with single client for all cases.&lt;/li>
&lt;li>&lt;em>Compared to &lt;code>follower&lt;/code>, &lt;code>leader&lt;/code> latency is high&lt;/em>, when benchmark tool with multiple clients for all cases.&lt;/li>
&lt;/ul>
&lt;p>Sample commands:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># write to leader&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark put --target-leader --conns=1 --clients=1 --precise &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --sequential-keys --key-starts 0 --val-size=256 --total=10000 &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --endpoints=$ETCD_HOST
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># write to follower&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark put --conns=1 --clients=1 --precise &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --sequential-keys --key-starts 0 --val-size=256 --total=10000 &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --endpoints=$ETCD_FOLLOWER_HOST
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="latency-analysis-during-put-requests-to-etcd">Latency analysis during PUT requests to ETCD&lt;/h3>
&lt;ul>
&lt;li>
&lt;details>
&lt;summary>In this case benchmark tool tries to put key with random 256 bytes value.&lt;/summary>
&lt;ul>
&lt;li>
&lt;p>Benchmark tool loads key/value to &lt;code>leader&lt;/code> with single client .&lt;/p>
&lt;ul>
&lt;li>&lt;code>sn-etcd-sz&lt;/code> latency (~0.815ms) is &lt;strong>~50% lesser than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code> (~1.74ms ).&lt;/li>
&lt;li>
&lt;ul>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency (~1.74ms ) is slightly lesser than &lt;code>mn-etcd-mz&lt;/code> (~1.8ms) but the difference is negligible (within same ms).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">1220.0520&lt;/td>
&lt;td style="text-align:center">0.815ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">586.545&lt;/td>
&lt;td style="text-align:center">1.74ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">554.0155654442634&lt;/td>
&lt;td style="text-align:center">1.8ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool loads key/value to &lt;code>follower&lt;/code> with single client.&lt;/p>
&lt;ul>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~2.2ms&lt;/code>) is &lt;strong>20% to 30% lesser than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~2.7ms&lt;/code>).&lt;/li>
&lt;li>&lt;em>Compare to &lt;code>follower&lt;/code>, &lt;code>leader&lt;/code> has lower latency.&lt;/em>&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">445.743&lt;/td>
&lt;td style="text-align:center">2.23ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">378.9366747610789&lt;/td>
&lt;td style="text-align:center">2.63ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">457.967&lt;/td>
&lt;td style="text-align:center">2.17ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">345.6586129825796&lt;/td>
&lt;td style="text-align:center">2.89ms&lt;/td>
&lt;td style="text-align:center">eu-west-1b&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool loads key/value to &lt;code>leader&lt;/code> with multiple clients.&lt;/p>
&lt;ul>
&lt;li>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~78.3ms&lt;/code>) is &lt;strong>~10% greater than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~71.81ms&lt;/code>).&lt;/li>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~71.81ms&lt;/code>) is less than &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~72.5ms&lt;/code>) but the difference is negligible.&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">12638.905&lt;/td>
&lt;td style="text-align:center">78.32ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">13789.248&lt;/td>
&lt;td style="text-align:center">71.81ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">13728.446436395223&lt;/td>
&lt;td style="text-align:center">72.5ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool loads key/value to &lt;code>follower&lt;/code> with multiple clients.&lt;/p>
&lt;ul>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~69.8ms&lt;/code>) is &lt;strong>~5% greater than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~72.6ms&lt;/code>).&lt;/li>
&lt;li>&lt;em>Compare to &lt;code>leader&lt;/code>, &lt;code>follower&lt;/code> has lower latency&lt;/em>.&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">14271.983&lt;/td>
&lt;td style="text-align:center">69.80ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">13695.98&lt;/td>
&lt;td style="text-align:center">72.62ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">14325.436&lt;/td>
&lt;td style="text-align:center">69.47ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">15750.409490407475&lt;/td>
&lt;td style="text-align:center">63.3ms&lt;/td>
&lt;td style="text-align:center">eu-west-1b&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/details>
&lt;/li>
&lt;li>
&lt;details>
&lt;summary>In this case benchmark tool tries to put key with random 1 MB value.&lt;/summary>
&lt;ul>
&lt;li>
&lt;p>Benchmark tool loads key/value to &lt;code>leader&lt;/code> with single client.&lt;/p>
&lt;ul>
&lt;li>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~16.35ms&lt;/code>) is &lt;strong>~20% lesser than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~20.64ms&lt;/code>).&lt;/li>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~20.64ms&lt;/code>) is less than &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~21.08ms&lt;/code>) but the difference is negligible..&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">61.117&lt;/td>
&lt;td style="text-align:center">16.35ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">48.416&lt;/td>
&lt;td style="text-align:center">20.64ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">45.7517341664802&lt;/td>
&lt;td style="text-align:center">21.08ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool loads key/value withto &lt;code>follower&lt;/code> single client.&lt;/p>
&lt;ul>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~23.10ms&lt;/code>) is &lt;strong>~10% greater than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~21.8ms&lt;/code>).&lt;/li>
&lt;li>&lt;em>Compare to &lt;code>follower&lt;/code>, &lt;code>leader&lt;/code> has lower latency&lt;/em>.&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">43.261&lt;/td>
&lt;td style="text-align:center">23.10ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">45.7517341664802&lt;/td>
&lt;td style="text-align:center">21.8ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">45.33&lt;/td>
&lt;td style="text-align:center">22.05ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">40.0518&lt;/td>
&lt;td style="text-align:center">24.95ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">43.28573155709838&lt;/td>
&lt;td style="text-align:center">23.09ms&lt;/td>
&lt;td style="text-align:center">eu-west-1b&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">45.92&lt;/td>
&lt;td style="text-align:center">21.76ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">35.5705&lt;/td>
&lt;td style="text-align:center">28.1ms&lt;/td>
&lt;td style="text-align:center">eu-west-1b&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool loads key/value to &lt;code>leader&lt;/code> with multiple clients.&lt;/p>
&lt;ul>
&lt;li>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~6.0375secs&lt;/code>) is &lt;strong>~30% greater than&lt;/strong> &lt;code>mn-etcd-sz``~4.000secs&lt;/code>).&lt;/li>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~4.000secs&lt;/code>) is less than &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~ 4.09secs&lt;/code>) but the difference is negligible.&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">300&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">55.373&lt;/td>
&lt;td style="text-align:center">6.0375secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">300&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">67.319&lt;/td>
&lt;td style="text-align:center">4.000secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">300&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">65.91914167957594&lt;/td>
&lt;td style="text-align:center">4.09secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool loads key/value to &lt;code>follower&lt;/code> with multiple clients.&lt;/p>
&lt;ul>
&lt;li>&lt;em>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~4.04secs&lt;/code>) is &lt;strong>~5% greater than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~ 3.90secs&lt;/code>).&lt;/em>&lt;/li>
&lt;li>&lt;em>Compare to &lt;code>leader&lt;/code>, &lt;code>follower&lt;/code> has lower latency&lt;/em>.&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">300&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">66.528&lt;/td>
&lt;td style="text-align:center">4.0417secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">300&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">70.6493461856332&lt;/td>
&lt;td style="text-align:center">3.90secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">300&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">71.95&lt;/td>
&lt;td style="text-align:center">3.84secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of keys&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">300&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">66.447&lt;/td>
&lt;td style="text-align:center">4.0164secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">300&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">67.53038086369484&lt;/td>
&lt;td style="text-align:center">3.87secs&lt;/td>
&lt;td style="text-align:center">eu-west-1b&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">300&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">68.46&lt;/td>
&lt;td style="text-align:center">3.92secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/details>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;br>
&lt;h2 id="range-analysis">Range Analysis&lt;/h2>
&lt;p>Sample commands are:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Single connection read request with sequential keys&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark range 0 --target-leader --conns=1 --clients=1 --precise &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --sequential-keys --key-starts 0 --total=10000 &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --consistency=l &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --endpoints=$ETCD_HOST
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># --consistency=s [Serializable]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark range 0 --target-leader --conns=1 --clients=1 --precise &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --sequential-keys --key-starts 0 --total=10000 &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --consistency=s &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --endpoints=$ETCD_HOST
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Each read request with range query matches key 0 9999 and repeats for total number of requests. &lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark range 0 9999 --target-leader --conns=1 --clients=1 --precise &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --total=10 &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --consistency=s &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --endpoints=https://etcd-main-client:2379
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#008000"># Read requests with multiple connections&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark range 0 --target-leader --conns=100 --clients=1000 --precise &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --sequential-keys --key-starts 0 --total=100000 &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --consistency=l &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --endpoints=$ETCD_HOST
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>benchmark range 0 --target-leader --conns=100 --clients=1000 --precise &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --sequential-keys --key-starts 0 --total=100000 &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --consistency=s &lt;span style="color:#a31515">\
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#a31515">&lt;/span> --endpoints=$ETCD_HOST
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="latency-analysis-during-range-requests-to-etcd">Latency analysis during Range requests to ETCD&lt;/h3>
&lt;ul>
&lt;li>
&lt;details>
&lt;summary>In this case benchmark tool tries to get specific key with random 256 bytes value.&lt;/summary>
&lt;ul>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>leader&lt;/code> with single client.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~1.24ms&lt;/code>) is &lt;strong>~40% greater than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~0.67ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~0.67ms&lt;/code>) is &lt;strong>~20% lesser than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~0.85ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">800.272&lt;/td>
&lt;td style="text-align:center">1.24ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">1173.9081&lt;/td>
&lt;td style="text-align:center">0.67ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">999.3020189178693&lt;/td>
&lt;td style="text-align:center">0.85ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>Compare to consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>~40% less&lt;/strong> for all cases&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">1411.229&lt;/td>
&lt;td style="text-align:center">0.70ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">2033.131&lt;/td>
&lt;td style="text-align:center">0.35ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">2100.2426362012025&lt;/td>
&lt;td style="text-align:center">0.47ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>follower&lt;/code> with single client .&lt;/p>
&lt;ul>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~1.3ms&lt;/code>) is &lt;strong>~20% lesser than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~1.6ms&lt;/code>).&lt;/li>
&lt;li>&lt;em>Compare to &lt;code>follower&lt;/code>, &lt;code>leader&lt;/code> read request latency is &lt;strong>~50% less&lt;/strong> for both &lt;code>mn-etcd-sz&lt;/code>, &lt;code>mn-etcd-mz&lt;/code>&lt;/em>&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">765.325&lt;/td>
&lt;td style="text-align:center">1.3ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">596.1&lt;/td>
&lt;td style="text-align:center">1.6ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>Compare to consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>~50% less&lt;/strong> for all cases&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">1823.631&lt;/td>
&lt;td style="text-align:center">0.54ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">1442.6&lt;/td>
&lt;td style="text-align:center">0.69ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">1416.39&lt;/td>
&lt;td style="text-align:center">0.70ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">10000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">2077.449&lt;/td>
&lt;td style="text-align:center">0.47ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>leader&lt;/code> with multiple client.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~84.66ms&lt;/code>) is &lt;strong>~20% greater than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~73.95ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~73.95ms&lt;/code>) is &lt;strong>more or less equal to&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~ 73.8ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">11775.721&lt;/td>
&lt;td style="text-align:center">84.66ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">13446.9598&lt;/td>
&lt;td style="text-align:center">73.95ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">13527.19810605353&lt;/td>
&lt;td style="text-align:center">73.8ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>Compare to consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>~20% lesser&lt;/strong> for all cases&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~69.37ms&lt;/code>) is &lt;strong>more or less equal to&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~69.89ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~69.89ms&lt;/code>) is &lt;strong>slightly higher than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~67.63ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">14334.9027&lt;/td>
&lt;td style="text-align:center">69.37ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">14270.008&lt;/td>
&lt;td style="text-align:center">69.89ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">14715.287354023869&lt;/td>
&lt;td style="text-align:center">67.63ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>follower&lt;/code> with multiple client.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~60.69ms&lt;/code>) is &lt;strong>~20% lesser than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~70.76ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compare to &lt;code>leader&lt;/code>, &lt;code>follower&lt;/code> has lower read request latency.&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">11586.032&lt;/td>
&lt;td style="text-align:center">60.69ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">14050.5&lt;/td>
&lt;td style="text-align:center">70.76ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~86.09ms&lt;/code>) is &lt;strong>~20 higher than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~64.6ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;ul>
&lt;li>Compare to &lt;code>mn-etcd-sz&lt;/code> consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>~20% higher&lt;/strong>.*&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Compare to &lt;code>mn-etcd-mz&lt;/code> consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>~slightly less&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">11582.438&lt;/td>
&lt;td style="text-align:center">86.09ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">100000&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">15422.2&lt;/td>
&lt;td style="text-align:center">64.6ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>leader&lt;/code> all keys.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~678.77ms&lt;/code>) is &lt;strong>~5% slightly lesser than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~697.29ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~697.29ms&lt;/code>) is less than &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~701ms&lt;/code>) but the difference is negligible.&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">6.8875&lt;/td>
&lt;td style="text-align:center">678.77ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">6.720&lt;/td>
&lt;td style="text-align:center">697.29ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">6.7&lt;/td>
&lt;td style="text-align:center">701ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;ul>
&lt;li>Compare to consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>~5% slightly higher&lt;/strong> for all cases&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~687.36ms&lt;/code>) is less than &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~692.68ms&lt;/code>) but the difference is negligible.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~692.68ms&lt;/code>) is &lt;strong>~5% slightly lesser than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~735.7ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">6.76&lt;/td>
&lt;td style="text-align:center">687.36ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">6.635&lt;/td>
&lt;td style="text-align:center">692.68ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">6.3&lt;/td>
&lt;td style="text-align:center">735.7ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>follower&lt;/code> all keys&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code>(&lt;code>~737.68ms&lt;/code>) latency is &lt;strong>~5% slightly higher than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~713.7ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compare to &lt;code>leader&lt;/code> consistency &lt;code>Linearizable&lt;/code>read request, &lt;code>follower&lt;/code> is &lt;em>~5% slightly higher&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">6.163&lt;/td>
&lt;td style="text-align:center">737.68ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">6.52&lt;/td>
&lt;td style="text-align:center">713.7ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~757.73ms&lt;/code>) is &lt;strong>~10% higher than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~690.4ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compare to &lt;code>follower&lt;/code> consistency &lt;code>Linearizable&lt;/code>read request, &lt;code>follower&lt;/code> consistency &lt;code>Serializable&lt;/code> is &lt;em>~3% slightly higher&lt;/em> for &lt;code>mn-etcd-sz&lt;/code>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Compare to &lt;code>follower&lt;/code> consistency &lt;code>Linearizable&lt;/code>read request, &lt;code>follower&lt;/code> consistency &lt;code>Serializable&lt;/code> is &lt;em>~5% less&lt;/em> for &lt;code>mn-etcd-mz&lt;/code>.&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>*Compare to &lt;code>leader&lt;/code> consistency &lt;code>Serializable&lt;/code>read request, &lt;code>follower&lt;/code> consistency &lt;code>Serializable&lt;/code> is &lt;em>~5% less&lt;/em> for &lt;code>mn-etcd-mz&lt;/code>. *&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">6.0295&lt;/td>
&lt;td style="text-align:center">757.73ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">256&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">6.87&lt;/td>
&lt;td style="text-align:center">690.4ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;br>
&lt;/details>
&lt;/li>
&lt;li>
&lt;details>
&lt;summary>In this case benchmark tool tries to get specific key with random `1MB` value.&lt;/summary>
&lt;ul>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>leader&lt;/code> with single client.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~5.96ms&lt;/code>) is &lt;strong>~5% lesser than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~6.28ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~6.28ms&lt;/code>) is &lt;strong>~10% higher than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~5.3ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">167.381&lt;/td>
&lt;td style="text-align:center">5.96ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">158.822&lt;/td>
&lt;td style="text-align:center">6.28ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">187.94&lt;/td>
&lt;td style="text-align:center">5.3ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>Compare to consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>~15% less&lt;/strong> for &lt;code>sn-etcd-sz&lt;/code>, &lt;code>mn-etcd-sz&lt;/code>, &lt;code>mn-etcd-mz&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">184.95&lt;/td>
&lt;td style="text-align:center">5.398ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">176.901&lt;/td>
&lt;td style="text-align:center">5.64ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">209.99&lt;/td>
&lt;td style="text-align:center">4.7ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>follower&lt;/code> with single client.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~6.66ms&lt;/code>) is &lt;strong>~10% higher than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~6.16ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Compare to &lt;code>leader&lt;/code>, &lt;code>follower&lt;/code> read request latency is &lt;strong>~10% high&lt;/strong> for &lt;code>mn-etcd-sz&lt;/code>&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Compare to &lt;code>leader&lt;/code>, &lt;code>follower&lt;/code> read request latency is &lt;strong>~20% high&lt;/strong> for &lt;code>mn-etcd-mz&lt;/code>&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">150.680&lt;/td>
&lt;td style="text-align:center">6.66ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">162.072&lt;/td>
&lt;td style="text-align:center">6.16ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>Compare to consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>~15% less&lt;/strong> for &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~5.84ms&lt;/code>), &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~5.01ms&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Compare to &lt;code>leader&lt;/code>, &lt;code>follower&lt;/code> read request latency is &lt;strong>~5% slightly high&lt;/strong> for &lt;code>mn-etcd-sz&lt;/code>, &lt;code>mn-etcd-mz&lt;/code>&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">170.918&lt;/td>
&lt;td style="text-align:center">5.84ms&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">1&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">199.01&lt;/td>
&lt;td style="text-align:center">5.01ms&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>leader&lt;/code> with multiple clients.&lt;/p>
&lt;ul>
&lt;li>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~1.593secs&lt;/code>) is &lt;strong>~20% lesser than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~1.974secs&lt;/code>).&lt;/li>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~1.974secs&lt;/code>) is &lt;strong>~5% greater than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~1.81secs&lt;/code>).&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">252.149&lt;/td>
&lt;td style="text-align:center">1.593secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">205.589&lt;/td>
&lt;td style="text-align:center">1.974secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">230.42&lt;/td>
&lt;td style="text-align:center">1.81secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Compare to consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>more or less same&lt;/strong> for &lt;code>sn-etcd-sz&lt;/code>(&lt;code>~1.57961secs&lt;/code>), &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~1.8secs&lt;/code>) not a big difference&lt;/em>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compare to consistency &lt;code>Linearizable&lt;/code>, &lt;code>Serializable&lt;/code> is &lt;strong>~10% high&lt;/strong> for &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~ 2.277secs&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">252.406&lt;/td>
&lt;td style="text-align:center">1.57961secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">181.905&lt;/td>
&lt;td style="text-align:center">2.277secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">227.64&lt;/td>
&lt;td style="text-align:center">1.8secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>follower&lt;/code> with multiple client.&lt;/p>
&lt;ul>
&lt;li>&lt;code>mn-etcd-sz&lt;/code> latency is &lt;strong>~20% less than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>.&lt;/li>
&lt;li>Compare to &lt;code>leader&lt;/code> consistency &lt;code>Linearizable&lt;/code>, &lt;code>follower&lt;/code> read request latency is ~15 less for &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~1.694secs&lt;/code>).&lt;/li>
&lt;li>Compare to &lt;code>leader&lt;/code> consistency &lt;code>Linearizable&lt;/code>, &lt;code>follower&lt;/code> read request latency is ~10% higher for &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~1.977secs&lt;/code>).&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">248.489&lt;/td>
&lt;td style="text-align:center">1.694secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">210.22&lt;/td>
&lt;td style="text-align:center">1.977secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">205.765&lt;/td>
&lt;td style="text-align:center">1.967secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">195.2&lt;/td>
&lt;td style="text-align:center">2.159secs&lt;/td>
&lt;td style="text-align:center">eu-west-1b&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;ul>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">231.458&lt;/td>
&lt;td style="text-align:center">1.7413secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">214.80&lt;/td>
&lt;td style="text-align:center">1.907secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">183.320&lt;/td>
&lt;td style="text-align:center">2.2810secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">1000&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">100&lt;/td>
&lt;td style="text-align:center">500&lt;/td>
&lt;td style="text-align:center">true&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-2&lt;/td>
&lt;td style="text-align:center">195.40&lt;/td>
&lt;td style="text-align:center">2.164secs&lt;/td>
&lt;td style="text-align:center">eu-west-1b&lt;/td>
&lt;td style="text-align:center">etcd-main-2&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>leader&lt;/code> all keys.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~8.993secs&lt;/code>) is &lt;strong>~3% slightly lower than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~9.236secs&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~9.236secs&lt;/code>) is &lt;strong>~2% slightly lower than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~9.100secs&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">0.5139&lt;/td>
&lt;td style="text-align:center">8.993secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">0.506&lt;/td>
&lt;td style="text-align:center">9.236secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">0.508&lt;/td>
&lt;td style="text-align:center">9.100secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>Compare to consistency &lt;code>Linearizable&lt;/code>read request, &lt;code>follower&lt;/code> for &lt;code>sn-etcd-sz&lt;/code>(&lt;code>~9.secs&lt;/code>) is &lt;strong>a slight difference &lt;code>10ms&lt;/code>&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compare to consistency &lt;code>Linearizable&lt;/code>read request, &lt;code>follower&lt;/code> for &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~9.113secs&lt;/code>) is &lt;strong>~1% less&lt;/strong>, not a big difference.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compare to consistency &lt;code>Linearizable&lt;/code>read request, &lt;code>follower&lt;/code> for &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~8.799secs&lt;/code>) is &lt;strong>~3% less&lt;/strong>, not a big difference.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>sn-etcd-sz&lt;/code> latency(&lt;code>~9.secs&lt;/code>) is &lt;strong>~1% slightly less than&lt;/strong> &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~9.113secs&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~9.113secs&lt;/code>) is &lt;strong>~3% slightly higher than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~8.799secs&lt;/code>)&lt;/em>.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">0.51125&lt;/td>
&lt;td style="text-align:center">9.0003secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">sn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">0.4993&lt;/td>
&lt;td style="text-align:center">9.113secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">leader&lt;/td>
&lt;td style="text-align:center">0.522&lt;/td>
&lt;td style="text-align:center">8.799secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-1&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Benchmark tool range requests to &lt;code>follower&lt;/code> all keys&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;code>mn-etcd-sz&lt;/code> latency(&lt;code>~9.065secs&lt;/code>) is &lt;strong>~1% slightly higher than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~9.007secs&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compare to &lt;code>leader&lt;/code> consistency &lt;code>Linearizable&lt;/code>read request, &lt;code>follower&lt;/code> is &lt;em>~1% slightly higher&lt;/em> for both cases &lt;code>mn-etcd-sz&lt;/code>, &lt;code>mn-etcd-mz&lt;/code> .&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">0.512&lt;/td>
&lt;td style="text-align:center">9.065secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">l&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">0.533&lt;/td>
&lt;td style="text-align:center">9.007secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;li>
&lt;p>Compare to consistency &lt;code>Linearizable&lt;/code>read request, &lt;code>follower&lt;/code> for &lt;code>mn-etcd-sz&lt;/code>(&lt;code>~9.553secs&lt;/code>) is &lt;strong>~5% high&lt;/strong>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>Compare to consistency &lt;code>Linearizable&lt;/code>read request, &lt;code>follower&lt;/code> for &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~7.7433secs&lt;/code>) is &lt;strong>~15% less&lt;/strong>&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;em>&lt;code>mn-etcd-sz&lt;/code>(&lt;code>~9.553secs&lt;/code>) latency is &lt;strong>~20% higher than&lt;/strong> &lt;code>mn-etcd-mz&lt;/code>(&lt;code>~7.7433secs&lt;/code>)&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:center">Number of requests&lt;/th>
&lt;th style="text-align:center">Value size&lt;/th>
&lt;th style="text-align:center">Number of connections&lt;/th>
&lt;th style="text-align:center">Number of clients&lt;/th>
&lt;th style="text-align:center">sequential-keys&lt;/th>
&lt;th style="text-align:center">Consistency&lt;/th>
&lt;th style="text-align:center">Target etcd server&lt;/th>
&lt;th style="text-align:center">Average write QPS&lt;/th>
&lt;th style="text-align:center">Average latency per request&lt;/th>
&lt;th style="text-align:center">zone&lt;/th>
&lt;th style="text-align:center">server name&lt;/th>
&lt;th style="text-align:center">Test name&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">0.4743&lt;/td>
&lt;td style="text-align:center">9.553secs&lt;/td>
&lt;td style="text-align:center">eu-west-1a&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-sz&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:center">20&lt;/td>
&lt;td style="text-align:center">1000000&lt;/td>
&lt;td style="text-align:center">2&lt;/td>
&lt;td style="text-align:center">5&lt;/td>
&lt;td style="text-align:center">false&lt;/td>
&lt;td style="text-align:center">s&lt;/td>
&lt;td style="text-align:center">follower-1&lt;/td>
&lt;td style="text-align:center">0.5500&lt;/td>
&lt;td style="text-align:center">7.7433secs&lt;/td>
&lt;td style="text-align:center">eu-west-1c&lt;/td>
&lt;td style="text-align:center">etcd-main-0&lt;/td>
&lt;td style="text-align:center">mn-etcd-mz&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;br>
&lt;/details>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;br>
&lt;br>
&lt;blockquote>
&lt;p>NOTE: This Network latency analysis is inspired by &lt;a href="https://etcd.io/docs/v3.5/op-guide/performance/">ETCD performance&lt;/a>.&lt;/p>
&lt;/blockquote></description></item><item><title>Docs: Local e2e Tests</title><link>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/development/local-e2e-tests/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/development/local-e2e-tests/</guid><description>
&lt;h1 id="e2e-test-suite">e2e Test Suite&lt;/h1>
&lt;p>Developers can run extended e2e tests, in addition to unit tests, for Etcd-Druid in or from
their local environments. This is recommended to verify the desired behavior of several features
and to avoid regressions in future releases.&lt;/p>
&lt;p>The very same tests typically run as part of the component&amp;rsquo;s release job as well as on demand, e.g.,
when triggered by Etcd-Druid maintainers for open pull requests.&lt;/p>
&lt;p>Testing Etcd-Druid automatically involves a certain test coverage for &lt;a href="https://github.com/gardener/etcd-backup-restore/">gardener/etcd-backup-restore&lt;/a>
which is deployed as a side-car to the actual &lt;code>etcd&lt;/code> container.&lt;/p>
&lt;h2 id="prerequisites">Prerequisites&lt;/h2>
&lt;p>The e2e test lifecycle is managed with the help of &lt;a href="https://skaffold.dev/">skaffold&lt;/a>. Every involved step like &lt;code>setup&lt;/code>,
&lt;code>deploy&lt;/code>, &lt;code>undeploy&lt;/code> or &lt;code>cleanup&lt;/code> is executed against a &lt;strong>Kubernetes&lt;/strong> cluster which makes it a mandatory prerequisite at the same time.
Only &lt;a href="https://skaffold.dev/">skaffold&lt;/a> itself with involved &lt;code>docker&lt;/code>, &lt;code>helm&lt;/code> and &lt;code>kubectl&lt;/code> executions as well as
the e2e-tests are executed locally. Required binaries are automatically downloaded if you use the corresponding &lt;code>make&lt;/code> target,
as described in this document.&lt;/p>
&lt;p>It&amp;rsquo;s expected that especially the &lt;code>deploy&lt;/code> step is run against a Kubernetes cluster which doesn&amp;rsquo;t contain an Druid deployment or any left-overs like &lt;code>druid.gardener.cloud&lt;/code> CRDs.
The &lt;code>deploy&lt;/code> step will likely fail in such scenarios.&lt;/p>
&lt;blockquote>
&lt;p>Tip: Create a fresh &lt;a href="https://kind.sigs.k8s.io/">KinD&lt;/a> cluster or a similar one with a small footprint before executing the tests.&lt;/p>
&lt;/blockquote>
&lt;h2 id="providers">Providers&lt;/h2>
&lt;p>The following providers are supported for e2e tests:&lt;/p>
&lt;ul>
&lt;li>AWS&lt;/li>
&lt;li>Azure&lt;/li>
&lt;li>GCP&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>Valid credentials need to be provided when tests happen with mentioned cloud providers.&lt;/p>
&lt;/blockquote>
&lt;h2 id="flow">Flow&lt;/h2>
&lt;p>An e2e test execution involves the following steps:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Step&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;code>setup&lt;/code>&lt;/td>
&lt;td>Create a storage bucket which is used for etcd backups (only with cloud providers).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>deploy&lt;/code>&lt;/td>
&lt;td>Build Docker image, upload it to registry (if remote cluster - see &lt;a href="https://skaffold.dev/docs/pipeline-stages/builders/docker/">Docker build&lt;/a>), deploy Helm chart (&lt;code>charts/druid&lt;/code>) to Kubernetes cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>test&lt;/code>&lt;/td>
&lt;td>Execute e2e tests as defined in &lt;code>test/e2e&lt;/code>.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>undeploy&lt;/code>&lt;/td>
&lt;td>Remove the deployed artifacts from Kubernetes cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;code>cleanup&lt;/code>&lt;/td>
&lt;td>Delete storage bucket and Druid deployment from test cluster.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="make-target">Make target&lt;/h3>
&lt;p>Executing e2e-tests is as easy as executing the following command &lt;strong>with defined Env-Vars as desribed in the following
section and as needed for your test scenario&lt;/strong>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>make test-e2e
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="common-env-variables">Common Env Variables&lt;/h3>
&lt;p>The following environment variables influence how the flow described above is executed:&lt;/p>
&lt;ul>
&lt;li>&lt;code>PROVIDERS&lt;/code>: Providers used for testing (&lt;code>all&lt;/code>, &lt;code>aws&lt;/code>, &lt;code>azure&lt;/code>, &lt;code>gcp&lt;/code>). Multiple entries must be comma separated.
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: Some tests will use very first entry from env &lt;code>PROVIDERS&lt;/code> for e2e testing (ex: multi-node tests). So for multi-node tests to use specific provider, specify that provider as first entry in env &lt;code>PROVIDERS&lt;/code>.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>&lt;code>KUBECONFIG&lt;/code>: Kubeconfig pointing to cluster where Etcd-Druid will be deployed (preferably &lt;a href="https://kind.sigs.k8s.io">KinD&lt;/a>).&lt;/li>
&lt;li>&lt;code>TEST_ID&lt;/code>: Some ID which is used to create assets for and during testing.&lt;/li>
&lt;li>&lt;code>STEPS&lt;/code>: Steps executed by &lt;code>make&lt;/code> target (&lt;code>setup&lt;/code>, &lt;code>deploy&lt;/code>, &lt;code>test&lt;/code>, &lt;code>undeploy&lt;/code>, &lt;code>cleanup&lt;/code> - default: all steps).&lt;/li>
&lt;/ul>
&lt;h3 id="aws-env-variables">AWS Env Variables&lt;/h3>
&lt;ul>
&lt;li>&lt;code>AWS_ACCESS_KEY_ID&lt;/code>: Key ID of the user.&lt;/li>
&lt;li>&lt;code>AWS_SECRET_ACCESS_KEY&lt;/code>: Access key of the user.&lt;/li>
&lt;li>&lt;code>AWS_REGION&lt;/code>: Region in which the test bucket is created.&lt;/li>
&lt;/ul>
&lt;p>Example:&lt;/p>
&lt;pre tabindex="0">&lt;code>make \
AWS_ACCESS_KEY_ID=&amp;#34;abc&amp;#34; \
AWS_SECRET_ACCESS_KEY=&amp;#34;xyz&amp;#34; \
AWS_REGION=&amp;#34;eu-central-1&amp;#34; \
KUBECONFIG=&amp;#34;$HOME/.kube/config&amp;#34; \
PROVIDERS=&amp;#34;aws&amp;#34; \
TEST_ID=&amp;#34;some-test-id&amp;#34; \
STEPS=&amp;#34;setup,deploy,test,undeploy,cleanup&amp;#34; \
test-e2e
&lt;/code>&lt;/pre>&lt;h3 id="azure-env-variables">Azure Env Variables&lt;/h3>
&lt;ul>
&lt;li>&lt;code>STORAGE_ACCOUNT&lt;/code>: Storage account used for managing the storage container.&lt;/li>
&lt;li>&lt;code>STORAGE_KEY&lt;/code>: Key of storage account.&lt;/li>
&lt;/ul>
&lt;p>Example:&lt;/p>
&lt;pre tabindex="0">&lt;code>make \
STORAGE_ACCOUNT=&amp;#34;abc&amp;#34; \
STORAGE_KEY=&amp;#34;eHl6Cg==&amp;#34; \
KUBECONFIG=&amp;#34;$HOME/.kube/config&amp;#34; \
PROVIDERS=&amp;#34;azure&amp;#34; \
TEST_ID=&amp;#34;some-test-id&amp;#34; \
STEPS=&amp;#34;setup,deploy,test,undeploy,cleanup&amp;#34; \
test-e2e
&lt;/code>&lt;/pre>&lt;h3 id="gcp-env-variables">GCP Env Variables&lt;/h3>
&lt;ul>
&lt;li>&lt;code>GCP_SERVICEACCOUNT_JSON_PATH&lt;/code>: Path to the service account json file used for this test.&lt;/li>
&lt;li>&lt;code>GCP_PROJECT_ID&lt;/code>: ID of the GCP project.&lt;/li>
&lt;/ul>
&lt;p>Example:&lt;/p>
&lt;pre tabindex="0">&lt;code>make \
GCP_SERVICEACCOUNT_JSON_PATH=&amp;#34;/var/lib/secrets/serviceaccount.json&amp;#34; \
GCP_PROJECT_ID=&amp;#34;xyz-project&amp;#34; \
KUBECONFIG=&amp;#34;$HOME/.kube/config&amp;#34; \
PROVIDERS=&amp;#34;gcp&amp;#34; \
TEST_ID=&amp;#34;some-test-id&amp;#34; \
STEPS=&amp;#34;setup,deploy,test,undeploy,cleanup&amp;#34; \
test-e2e
&lt;/code>&lt;/pre>&lt;h2 id="e2e-test-with-localstack">e2e test with localstack&lt;/h2>
&lt;p>Above mentioned e2e tests need actual storage from cloud provider to be setup. But there is a tool named &lt;a href="https://docs.localstack.cloud/user-guide/aws/s3/">localstack&lt;/a> that enables to run e2e test with mock AWS storage. We can also provision KIND cluster for e2e tests. So, together with localstack and KIND cluster, we don&amp;rsquo;t need to depend on any actual cloud provider infrastructure to be setup to run e2e tests.&lt;/p>
&lt;h3 id="how-are-the-kind-cluster-and-localstack-set-up">How are the KIND cluster and localstack set up&lt;/h3>
&lt;p>KIND or Kubernetes-In-Docker is a kubernetes cluster that is set up inside a docker container. This cluster is with limited capability as it does not have much compute power. But this cluster can easily be setup inside a container and can be tear down easily just by removing a container. That&amp;rsquo;s why KIND cluster is very easy to use for e2e tests. &lt;code>Makefile&lt;/code> command helps to spin up a KIND cluster and use the cluster to run e2e tests.&lt;/p>
&lt;p>There is a docker image for localstack. The image is deployed as pod inside the KIND cluster through &lt;code>hack/e2e-test/infrastructure/localstack/localstack.yaml&lt;/code>. &lt;code>Makefile&lt;/code> takes care of deploying the yaml file in a KIND cluster.&lt;/p>
&lt;p>The developer needs to run &lt;code>make ci-e2e-kind&lt;/code> command. This command in turn runs &lt;code>hack/ci-e2e-kind.sh&lt;/code> which spin up the KIND cluster and deploy localstack in it and then run the e2e tests using localstack as mock AWS storage provider. e2e tests are actually run on host machine but deploy the druid controller inside KIND cluster. Druid controller spawns multinode ETCD clusters inside KIND cluster. e2e tests verify whether the druid controller performs its jobs correctly or not. Mock localstack storage is cleaned up after every e2e tests. That&amp;rsquo;s why the e2e tests need to access the localstack pod running inside KIND cluster. The network traffic between host machine and localstack pod is resolved via mapping localstack pod port to host port while setting up the KIND cluster via &lt;code>hack/e2e-test/infrastructure/kind/cluster.yaml&lt;/code>&lt;/p>
&lt;h3 id="how-to-execute-e2e-tests-with-localstack-and-kind-cluster">How to execute e2e tests with localstack and KIND cluster&lt;/h3>
&lt;p>The developer just needs to install KIND following &lt;a href="https://kind.sigs.k8s.io/docs/user/quick-start/">https://kind.sigs.k8s.io/docs/user/quick-start/&lt;/a> and start docker daemon. Additionaly, KIND cluster can be enabled via docker desktop.&lt;/p>
&lt;p>Check if KIND is working on your machine by running the following command:
&lt;code>kind create cluster --name kind-2&lt;/code>&lt;/p>
&lt;p>If successful, delete the cluster by:
&lt;code>kind delete cluster --name kind-2&lt;/code>&lt;/p>
&lt;p>Run the following &lt;code>make&lt;/code> command to perform e2e tests that will automatically take care of spinning up KIND clsuter and deploying localstack pod:
&lt;code>make ci-e2e-kind&lt;/code>&lt;/p></description></item><item><title>Docs: Metrics</title><link>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/development/metrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/development/metrics/</guid><description>
&lt;h1 id="monitoring">Monitoring&lt;/h1>
&lt;p>etcd-druid uses &lt;a href="http://prometheus.io/">Prometheus&lt;/a> for metrics reporting. The metrics can be used for real-time monitoring and debugging of compaction jobs.&lt;/p>
&lt;p>The simplest way to see the available metrics is to cURL the metrics endpoint &lt;code>/metrics&lt;/code>. The format is described &lt;a href="http://prometheus.io/docs/instrumenting/exposition_formats/">here&lt;/a>.&lt;/p>
&lt;p>Follow the &lt;a href="http://prometheus.io/docs/introduction/getting_started/">Prometheus getting started doc&lt;/a> to spin up a Prometheus server to collect etcd metrics.&lt;/p>
&lt;p>The naming of metrics follows the suggested &lt;a href="http://prometheus.io/docs/practices/naming/">Prometheus best practices&lt;/a>. All compaction related metrics are put under namespace &lt;code>etcddruid&lt;/code> and subsystem &lt;code>compaction&lt;/code>.&lt;/p>
&lt;h3 id="compaction">Compaction&lt;/h3>
&lt;p>These metrics give an idea about the compaction jobs that run after some interval in shoot control planes. Studying the metrices, we can deduce how many compaction job ran successfully, how many failed, how many delta events compacted etc.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>Type&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>etcddruid_compaction_jobs_total&lt;/td>
&lt;td>Total number of compaction jobs initiated by compaction controller.&lt;/td>
&lt;td>Counter&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>etcddruid_compaction_jobs_current&lt;/td>
&lt;td>Number of currently running compaction job.&lt;/td>
&lt;td>Gauge&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>etcddruid_compaction_job_duration_seconds&lt;/td>
&lt;td>Total time taken in seconds to finish a running compaction job.&lt;/td>
&lt;td>Histogram&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>etcddruid_compaction_num_delta_events&lt;/td>
&lt;td>Total number of etcd events to be compacted by a compaction job.&lt;/td>
&lt;td>Gauge&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>There are two labels for &lt;code>etcddruid_compaction_jobs_total&lt;/code> metrics. The label &lt;code>succeeded&lt;/code> shows how many of the compaction jobs are succeeded and label &lt;code>failed&lt;/code> shows how many of compaction jobs are failed.&lt;/p>
&lt;p>There are two labels for &lt;code>etcddruid_compaction_job_duration_seconds&lt;/code> metrics. The label &lt;code>succeeded&lt;/code> shows how much time taken by a successful job to complete and label &lt;code>failed&lt;/code> shows how much time taken by a failed compaction job.&lt;/p>
&lt;p>&lt;code>etcddruid_compaction_jobs_current&lt;/code> metric comes with label &lt;code>etcd_namespace&lt;/code> that indicates the namespace of the ETCD running in the control plane of a shoot cluster..&lt;/p>
&lt;h2 id="prometheus-supplied-metrics">Prometheus supplied metrics&lt;/h2>
&lt;p>The Prometheus client library provides a number of metrics under the &lt;code>go&lt;/code> and &lt;code>process&lt;/code> namespaces.&lt;/p></description></item><item><title>Docs: Multinode Metrics</title><link>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/multinode-metrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/multinode-metrics/</guid><description>
&lt;h2 id="metrics-multi-node-etcd">Metrics: Multi-node etcd&lt;/h2>
&lt;h4 id="etcd">Etcd&lt;/h4>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>No.&lt;/th>
&lt;th>Metrics Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;th>Comments&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1&lt;/td>
&lt;td>etcd_disk_wal_fsync_duration_seconds&lt;/td>
&lt;td>latency distributions of fsync called by WAL.&lt;/td>
&lt;td>High disk operation latencies indicate disk issues.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2&lt;/td>
&lt;td>etcd_disk_backend_commit_duration_seconds&lt;/td>
&lt;td>latency distributions of commit called by backend.&lt;/td>
&lt;td>High disk operation latencies indicate disk issues.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3&lt;/td>
&lt;td>etcd_server_has_leader&lt;/td>
&lt;td>whether or not a leader exists. 1: leader exists, 0: leader not exists.&lt;/td>
&lt;td>To capture quorum loss or to check the availability of etcd cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4&lt;/td>
&lt;td>etcd_server_is_leader&lt;/td>
&lt;td>whether or not this member is a leader. 1 if it is, 0 otherwise.&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5&lt;/td>
&lt;td>etcd_server_leader_changes_seen_total&lt;/td>
&lt;td>number of leader changes seen.&lt;/td>
&lt;td>Helpful in fine tuning the zonal cluster like etcd-heartbeat time etc, it can also indicates the etcd load and network issues.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>6&lt;/td>
&lt;td>etcd_server_is_learner&lt;/td>
&lt;td>whether or not this member is a learner. 1 if it is, 0 otherwise.&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>7&lt;/td>
&lt;td>etcd_server_learner_promote_successes&lt;/td>
&lt;td>total number of successful learner promotions while this member is leader.&lt;/td>
&lt;td>Might be helpful in checking the success of API calls called by backup-restore.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>8&lt;/td>
&lt;td>etcd_network_client_grpc_received_bytes_total&lt;/td>
&lt;td>total number of bytes received from grpc clients.&lt;/td>
&lt;td>Client Traffic In.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>9&lt;/td>
&lt;td>etcd_network_client_grpc_sent_bytes_total&lt;/td>
&lt;td>total number of bytes sent to grpc clients.&lt;/td>
&lt;td>Client Traffic Out.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>10&lt;/td>
&lt;td>etcd_network_peer_sent_bytes_total&lt;/td>
&lt;td>total number of bytes sent to peers.&lt;/td>
&lt;td>Useful for network usage.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>11&lt;/td>
&lt;td>etcd_network_peer_received_bytes_total&lt;/td>
&lt;td>total number of bytes received from peers.&lt;/td>
&lt;td>Useful for network usage.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>12&lt;/td>
&lt;td>etcd_network_active_peers&lt;/td>
&lt;td>current number of active peer connections.&lt;/td>
&lt;td>Might be useful in detecting issues like network partition.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>13&lt;/td>
&lt;td>etcd_server_proposals_committed_total&lt;/td>
&lt;td>total number of consensus proposals committed.&lt;/td>
&lt;td>A consistently large lag between a single member and its leader indicates that member is slow or unhealthy.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>14&lt;/td>
&lt;td>etcd_server_proposals_pending&lt;/td>
&lt;td>current number of pending proposals to commit.&lt;/td>
&lt;td>Pending proposals suggests there is a high client load or the member cannot commit proposals.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>15&lt;/td>
&lt;td>etcd_server_proposals_failed_total&lt;/td>
&lt;td>total number of failed proposals seen.&lt;/td>
&lt;td>Might indicates downtime caused by a loss of quorum.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>16&lt;/td>
&lt;td>etcd_server_proposals_applied_total&lt;/td>
&lt;td>total number of consensus proposals applied.&lt;/td>
&lt;td>Difference between etcd_server_proposals_committed_total and etcd_server_proposals_applied_total should usually be small.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>17&lt;/td>
&lt;td>etcd_mvcc_db_total_size_in_bytes&lt;/td>
&lt;td>total size of the underlying database physically allocated in bytes.&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>18&lt;/td>
&lt;td>etcd_server_heartbeat_send_failures_total&lt;/td>
&lt;td>total number of leader heartbeat send failures.&lt;/td>
&lt;td>Might be helpful in fine-tuning the cluster or detecting slow disk or any network issues.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>19&lt;/td>
&lt;td>etcd_network_peer_round_trip_time_seconds&lt;/td>
&lt;td>round-trip-time histogram between peers.&lt;/td>
&lt;td>Might be helpful in fine-tuning network usage specially for zonal etcd cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>20&lt;/td>
&lt;td>etcd_server_slow_apply_total&lt;/td>
&lt;td>total number of slow apply requests.&lt;/td>
&lt;td>Might indicate overloaded from slow disk.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>21&lt;/td>
&lt;td>etcd_server_slow_read_indexes_total&lt;/td>
&lt;td>total number of pending read indexes not in sync with leader&amp;rsquo;s or timed out read index requests.&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h4 id="backup-restore">Backup-restore&lt;/h4>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>No.&lt;/th>
&lt;th>Metrics Name&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>1.&lt;/td>
&lt;td>etcdbr_cluster_size&lt;/td>
&lt;td>to capture the scale-up/scale-down scenarios.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2.&lt;/td>
&lt;td>etcdbr_is_learner&lt;/td>
&lt;td>whether or not this member is a learner. 1 if it is, 0 otherwise.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>3.&lt;/td>
&lt;td>etcdbr_is_learner_count_total&lt;/td>
&lt;td>total number times member added as the learner.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>4.&lt;/td>
&lt;td>etcdbr_restoration_duration_seconds&lt;/td>
&lt;td>total latency distribution required to restore the etcd member.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>5.&lt;/td>
&lt;td>etcdbr_add_learner_duration_seconds&lt;/td>
&lt;td>total latency distribution of adding the etcd member as a learner to the cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>6.&lt;/td>
&lt;td>etcdbr_member_remove_duration_seconds&lt;/td>
&lt;td>total latency distribution removing the etcd member from the cluster.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>7.&lt;/td>
&lt;td>etcdbr_member_promote_duration_seconds&lt;/td>
&lt;td>total latency distribution of promoting the learner to the voting member.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>8.&lt;/td>
&lt;td>etcdbr_defragmentation_duration_seconds&lt;/td>
&lt;td>total latency distribution of defragmentation of each etcd cluster member.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table></description></item><item><title>Docs: Recover from etcd Permanent Quorum Loss</title><link>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/operation/recover_from_etcd_permanent_quorum_loss/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/operation/recover_from_etcd_permanent_quorum_loss/</guid><description>
&lt;h2 id="quorum-loss-in-etcd-cluster">Quorum loss in ETCD Cluster&lt;/h2>
&lt;p>&lt;a href="https://etcd.io/docs/v3.4/op-guide/recovery/">Quorum loss&lt;/a> means when majority of ETCD pods(greater than or equal to n/2 + 1) are down simultaneously for some reason.&lt;/p>
&lt;p>There are two types of quorum loss that can happen to &lt;a href="https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/proposals/multi-node/">ETCD multinode cluster&lt;/a> :&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;strong>Transient quorum loss&lt;/strong> - A quorum loss is called transient when majority of ETCD pods are down simultaneously for some time. The pods may be down due to network unavailability, high resource usages etc. When the pods come back after some time, they can re-join to the cluster and the quorum is recovered automatically without any manual intervention. There should not be a permanent failure for majority of etcd pods due to hardware failure or disk corruption.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Permanent quorum loss&lt;/strong> - A quorum loss is called permanent when majority of ETCD cluster members experience permanent failure, whether due to hardware failure or disk corruption etc. then the etcd cluster is not going to recover automatically from the quorum loss. A human operator will now need to intervene and execute the following steps to recover the multi-node ETCD cluster.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>If permanent quorum loss occurs to a multinode ETCD cluster, the operator needs to note down the PVCs, configmaps, statefulsets, CRs etc related to that ETCD cluster and work on those resources only. Following steps guide a human operator to recover from permanent quorum loss of a ETCD cluster. We assume the name of the ETCD CR for the ETCD cluster is &lt;code>etcd-main&lt;/code>.&lt;/p>
&lt;p>&lt;strong>ETCD cluster in shoot control plane of gardener deployment:&lt;/strong>
There are two &lt;a href="https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/proposals/multi-node/">ETCD clusters&lt;/a> running in shoot control plane. One is named as &lt;code>etcd-events&lt;/code> and another is named &lt;code>etcd-main&lt;/code>. The operator needs to take care of permanent quorum loss to a specific cluster. If permanent quorum loss occurs to &lt;code>etcd-events&lt;/code> cluster, the operator needs to note down the PVCs, configmaps, statefulsets, CRs etc related to &lt;code>etcd-events&lt;/code> cluster and work on those resources only.&lt;/p>
&lt;p>⚠️ &lt;strong>Note:&lt;/strong> Please note that manually restoring etcd can result in data loss. This guide is the last resort to bring an ETCD cluster up and running again.&lt;/p>
&lt;p>If etcd-druid and etcd-backup-restore is being used with gardener, then&lt;/p>
&lt;p>Target the control plane of affected shoot cluster via &lt;code>kubectl&lt;/code>. Alternatively, you can use &lt;a href="https://github.com/gardener/gardenctl-v2">gardenctl&lt;/a> to target the control plane of the affected shoot cluster. You can get the details to target the control plane from the Access tile in the shoot cluster details page on the Gardener dashboard. Ensure that you are targeting the correct namespace.&lt;/p>
&lt;ol>
&lt;li>Add the following annotation to the &lt;code>Etcd&lt;/code> resource &lt;code>kubectl annotate etcd etcd-main druid.gardener.cloud/ignore-reconciliation=&amp;quot;true&amp;quot;&lt;/code>&lt;/li>
&lt;li>Note down the configmap name that is attached to the &lt;code>etcd-main&lt;/code> statefulset. If you describe the statefulset with &lt;code>kubectl describe sts etcd-main&lt;/code>, look for the lines similar to following lines to identify attached configmap name. It will be needed at later stages:&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code> Volumes:
etcd-config-file:
Type: ConfigMap (a volume populated by a ConfigMap)
Name: etcd-bootstrap-4785b0
Optional: false
&lt;/code>&lt;/pre>&lt;pre tabindex="0">&lt;code> Alternatively, the related configmap name can be obtained by executing following command as well:
&lt;/code>&lt;/pre>&lt;p>&lt;code>kubectl get sts etcd-main -o jsonpath='{.spec.template.spec.volumes[?(@.name==&amp;quot;etcd-config-file&amp;quot;)].configMap.name}'&lt;/code>&lt;/p>
&lt;ol start="3">
&lt;li>
&lt;p>Scale down the &lt;code>etcd-main&lt;/code> statefulset replicas to &lt;code>0&lt;/code>&lt;/p>
&lt;p>&lt;code>kubectl scale sts etcd-main --replicas=0&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The PVCs will look like the following on listing them with the command &lt;code>kubectl get pvc&lt;/code> :&lt;/p>
&lt;pre tabindex="0">&lt;code>main-etcd-etcd-main-0 Bound pv-shoot--garden--aws-ha-dcb51848-49fa-4501-b2f2-f8d8f1fad111 80Gi RWO gardener.cloud-fast 13d
main-etcd-etcd-main-1 Bound pv-shoot--garden--aws-ha-b4751b28-c06e-41b7-b08c-6486e03090dd 80Gi RWO gardener.cloud-fast 13d
main-etcd-etcd-main-2 Bound pv-shoot--garden--aws-ha-ff17323b-d62e-4d5e-a742-9de823621490 80Gi RWO gardener.cloud-fast 13d
&lt;/code>&lt;/pre>&lt;p>Delete all PVCs that are attached to &lt;code>etcd-main&lt;/code> cluster.&lt;/p>
&lt;p>&lt;code>kubectl delete pvc -l instance=etcd-main&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Edit the &lt;code>etcd-main&lt;/code> cluster&amp;rsquo;s configmap (ex: &lt;code>etcd-bootstrap-4785b0&lt;/code>) as follows:&lt;/p>
&lt;p>Find the &lt;code>initial-cluster&lt;/code> field in the configmap. It will look like the following:&lt;/p>
&lt;pre tabindex="0">&lt;code># Initial cluster
initial-cluster: etcd-main-0=https://etcd-main-0.etcd-main-peer.default.svc:2380,etcd-main-1=https://etcd-main-1.etcd-main-peer.default.svc:2380,etcd-main-2=https://etcd-main-2.etcd-main-peer.default.svc:2380
&lt;/code>&lt;/pre>&lt;p>Change the &lt;code>initial-cluster&lt;/code> field to have only one member (&lt;code>etcd-main-0&lt;/code>) in the string. It should now look like this:&lt;/p>
&lt;pre tabindex="0">&lt;code># Initial cluster
initial-cluster: etcd-main-0=https://etcd-main-0.etcd-main-peer.default.svc:2380
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Scale up the &lt;code>etcd-main&lt;/code> statefulset replicas to &lt;code>1&lt;/code>&lt;/p>
&lt;p>&lt;code>kubectl scale sts etcd-main --replicas=1&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Wait for the single-member etcd cluster to be completely ready.&lt;/p>
&lt;p>&lt;code>kubectl get pods etcd-main-0&lt;/code> will give the following output when ready:&lt;/p>
&lt;pre tabindex="0">&lt;code>NAME READY STATUS RESTARTS AGE
etcd-main-0 2/2 Running 0 1m
&lt;/code>&lt;/pre>&lt;/li>
&lt;li>
&lt;p>Remove the following annotation from the &lt;code>Etcd&lt;/code> resource &lt;code>etcd-main&lt;/code>: &lt;code>kubectl annotate etcd etcd-main druid.gardener.cloud/ignore-reconciliation-&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Finally add the following annotation to the &lt;code>Etcd&lt;/code> resource &lt;code>etcd-main&lt;/code>: &lt;code>kubectl annotate etcd etcd-main gardener.cloud/operation=&amp;quot;reconcile&amp;quot;&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Verify that the etcd cluster is formed correctly.&lt;/p>
&lt;p>All the &lt;code>etcd-main&lt;/code> pods will have outputs similar to following:&lt;/p>
&lt;pre tabindex="0">&lt;code>NAME READY STATUS RESTARTS AGE
etcd-main-0 2/2 Running 0 5m
etcd-main-1 2/2 Running 0 1m
etcd-main-2 2/2 Running 0 1m
&lt;/code>&lt;/pre>&lt;p>Additionally, check if the ETCD CR is ready with &lt;code>kubectl get etcd etcd-main&lt;/code> :&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-✹" data-lang="✹">NAME READY AGE
etcd-main true 13d
&lt;/code>&lt;/pre>&lt;p>Additionally, check the leases for 30 seconds at least. There should be leases starting with &lt;code>etcd-main&lt;/code> as many as &lt;code>etcd-main&lt;/code> replicas. One of those leases will have holder identity as &lt;code>&amp;lt;etcd-member-id&amp;gt;:Leader&lt;/code> and rest of those leases have holder identities as &lt;code>&amp;lt;etcd-member-id&amp;gt;:Member&lt;/code>. The &lt;code>AGE&lt;/code> of those leases can also be inspected to identify if those leases were updated in conjunction with the restart of the ETCD cluster: Example:&lt;/p>
&lt;pre tabindex="0">&lt;code>NAME HOLDER AGE
etcd-main-0 4c37667312a3912b:Member 1m
etcd-main-1 75a9b74cfd3077cc:Member 1m
etcd-main-2 c62ee6af755e890d:Leader 1m
&lt;/code>&lt;/pre>&lt;/li>
&lt;/ol></description></item><item><title>Docs: Single Member Restoration</title><link>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/single_member_restoration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://gardener.cloud/docs/other-components/etcd-druid/etcd-druid/single_member_restoration/</guid><description>
&lt;h1 id="restoration-of-a-single-member-in-multi-node-etcd-deployed-by-etcd-druid">Restoration of a single member in multi-node etcd deployed by etcd-druid.&lt;/h1>
&lt;p>&lt;strong>Note&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>For a cluster with n members, we are proposing the solution to only single member restoration within a etcd cluster not the quorum loss scenario (when majority of members within a cluster fail).&lt;/li>
&lt;li>In this proposal we are not targetting the recovery of single member which got separated from cluster due to &lt;a href="https://etcd.io/docs/v3.3/op-guide/failures/#network-partition">network partition&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h2 id="motivation">Motivation&lt;/h2>
&lt;p>If a single etcd member within a multi-node etcd cluster goes down due to DB corruption/PVC corruption/Invalid data-dir then it needs to be brought back. Unlike in the single-node case, a minority member of a multi-node cluster can&amp;rsquo;t be restored from the snapshots present in storage container as you can&amp;rsquo;t restore from the old snapshots as it contains the metadata information of cluster which leads to &lt;strong>memberID mismatch&lt;/strong> that prevents the new member from coming up as new member is getting its metadata information from db which got restore from old snapshots.&lt;/p>
&lt;h2 id="solution">Solution&lt;/h2>
&lt;ul>
&lt;li>If a corresponding backup-restore sidecar detects that its corresponding etcd is down due to &lt;a href="https://github.com/gardener/etcd-backup-restore/blob/7d27a47f5793b0949492d225ada5fd8344b6b6a2/pkg/initializer/validator/datavalidator.go#L177">data-dir corruption&lt;/a> or &lt;a href="https://github.com/gardener/etcd-backup-restore/blob/7d27a47f5793b0949492d225ada5fd8344b6b6a2/pkg/initializer/validator/datavalidator.go#L204">Invalid data-dir&lt;/a>&lt;/li>
&lt;li>Then backup-restore will first remove the failing etcd member from the cluster using the &lt;a href="https://github.com/etcd-io/etcd/blob/ae9734ed278b7a1a7dfc82e800471ebbf9fce56f/clientv3/cluster.go#L45-L46">MemberRemove API&lt;/a> call and clean the data-dir of failed etcd member.&lt;/li>
&lt;li>It won&amp;rsquo;t affect the etcd cluster as quorum is still maintained.&lt;/li>
&lt;li>After successfully removing failed etcd member from the cluster, backup-restore sidecar will try to add a new etcd member to a cluster to get the same cluster size as before.&lt;/li>
&lt;li>Backup-restore firstly adds new member as a &lt;a href="https://etcd.io/docs/v3.3/learning/learner/">Learner&lt;/a> using the &lt;a href="https://github.com/etcd-io/etcd/blob/ae9734ed278b7a1a7dfc82e800471ebbf9fce56f/clientv3/cluster.go#L42-L43">MemberAddAsLearner API&lt;/a> call, once learner is added to the cluster and it&amp;rsquo;s get in sync with leader and becomes up-to-date then promote the learner(non-voting member) to a voting member using &lt;a href="https://github.com/etcd-io/etcd/blob/ae9734ed278b7a1a7dfc82e800471ebbf9fce56f/clientv3/cluster.go#L51-L52">MemberPromote API&lt;/a> call.&lt;/li>
&lt;li>So, the failed member first needs to be removed from the cluster and then added as a new member.&lt;/li>
&lt;/ul>
&lt;h3 id="example">Example:&lt;/h3>
&lt;ol>
&lt;li>If a &lt;code>3&lt;/code> member etcd cluster has 1 downed member(due to invalid data-dir), the cluster can still make forward progress because the quorum is &lt;code>2&lt;/code>.&lt;/li>
&lt;li>Etcd downed member get restarted and it&amp;rsquo;s corresponding backup-restore sidecar receives an &lt;a href="https://github.com/gardener/etcd-backup-restore/blob/master/doc/proposals/design.md#workflow">initialization&lt;/a> request.&lt;/li>
&lt;li>Then, backup-restore sidecar checks for data corruption/invalid data-dir.&lt;/li>
&lt;li>Backup-restore sidecar detects that data-dir is invalid and its a multi-node etcd cluster.&lt;/li>
&lt;li>Then, backup-restore sidecar removed the downed etcd member from cluster.&lt;/li>
&lt;li>The number of members in a cluster becomes &lt;code>2&lt;/code> and the quorum remains at &lt;code>2&lt;/code>, so it won&amp;rsquo;t affect the etcd cluster.&lt;/li>
&lt;li>Clean the data-dir and add a member as a learner(non-voting member).&lt;/li>
&lt;li>As soon as learner gets in sync with leader, promote the learner to a voting member, hence increasing number of members in a cluster back to &lt;code>3&lt;/code>.&lt;/li>
&lt;/ol></description></item></channel></rss>